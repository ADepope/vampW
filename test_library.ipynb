{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cbcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy\n",
    "emc = float( sympy.S.EulerGamma.n(10) )\n",
    "from tteVAMP.problem import Problem\n",
    "from tteVAMP.simulations import sim_model\n",
    "from tteVAMP.vamp import infere\n",
    "from tteVAMP.utils import plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945c1ed",
   "metadata": {},
   "source": [
    "EM updates are stable in low-dimensional setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "920c1e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weibull\n",
      "gam1 =  0.01\n",
      "tau1 =  0.1\n",
      "alpha =  60.136325138281805\n",
      "s.shape =  (100,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.]\n",
      "B / (A+B) =  [0.04976421]\n",
      "gam1 / (gam1 + 1/sigma) =  0.009900990099009901\n",
      "alpha1 part I =  [0.00049271]\n",
      "alpha2 part II =  [0.]\n",
      "alpha1 =  0.0004927149309449357\n",
      "true gam2 =  14.64717879889327\n",
      "gam2 =  20.285711316930986\n",
      "corr(z1_hat, X*beta_true) =  0.9721098217179749\n",
      "l2 error for z1_hat =  0.23553300589599196\n",
      "v1 =  0.0002997420433173985\n",
      "true tau2 =  2459.958114762066\n",
      "tau2 = 333.5201985322075\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99268236]]\n",
      "l2 error for x2_hat =  0.2011863513427952\n",
      "alpha2 =  0.12358975436085137\n",
      "true gam1 =  882.4999400154396\n",
      "gam1 =  143.8517725856727\n",
      "corr(z2_hat, beta_true) =  [[0.99587051]]\n",
      "l2 error for z2_hat =  0.15302365021546466\n",
      "true tau1 =  5639.136898854849\n",
      "tau1 =  2710.900609569851\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-8.89940966e-05]\n",
      "corr(x1_hat, beta_true) =  0.9985528444221963\n",
      "l2 error for x1_hat =  0.08315670267723096\n",
      "B / (A+B) =  [0.00452114]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930963910061332\n",
      "alpha1 part I =  [0.00448993]\n",
      "alpha2 part II =  [0.00033822]\n",
      "alpha1 =  0.03612195563426908\n",
      "true gam2 =  2060.2591047935907\n",
      "gam2 =  3838.539824429629\n",
      "corr(z1_hat, X*beta_true) =  0.9964580962716556\n",
      "l2 error for z1_hat =  0.1623344952655096\n",
      "v1 =  0.92664745699442\n",
      "true tau2 =  2916.449409666282\n",
      "tau2 = 214.5923479812917\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99806082]]\n",
      "l2 error for x2_hat =  0.08860457501617194\n",
      "alpha2 =  0.9664876687719954\n",
      "true gam1 =  1945.3047573427766\n",
      "gam1 =  133.09887149581354\n",
      "corr(z2_hat, beta_true) =  [[0.97214363]]\n",
      "l2 error for z2_hat =  0.3006608846627038\n",
      "true tau1 =  30657.43952370691\n",
      "tau1 =  51012.48499767772\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04547829]\n",
      "corr(x1_hat, beta_true) =  0.9534488946749589\n",
      "l2 error for x1_hat =  0.3015565442911743\n",
      "B / (A+B) =  [0.23354531]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9925428156937829\n",
      "alpha1 part I =  [0.23180372]\n",
      "alpha2 part II =  [1.49429647]\n",
      "alpha1 =  1.2016473572379938\n",
      "true gam2 =  16.31458775197574\n",
      "gam2 =  -22.33520136072209\n",
      "corr(z1_hat, X*beta_true) =  0.9731645715330449\n",
      "l2 error for z1_hat =  0.29563362546616284\n",
      "v1 =  0.9671382875436102\n",
      "true tau2 =  3353.2621885793933\n",
      "tau2 = 1733.3173913911392\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99356719]]\n",
      "l2 error for x2_hat =  0.11398919355547893\n",
      "alpha2 =  -0.03155708248578444\n",
      "true gam1 =  1352.9368329881645\n",
      "gam1 =  730.1066301923784\n",
      "corr(z2_hat, beta_true) =  [[0.9892646]]\n",
      "l2 error for z2_hat =  0.1683815657580356\n",
      "true tau1 =  18211.779840312993\n",
      "tau1 =  11709.020765712448\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00033982]\n",
      "corr(x1_hat, beta_true) =  0.998499158084158\n",
      "l2 error for x1_hat =  0.05477354487334312\n",
      "B / (A+B) =  [0.00700242]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9986322104619173\n",
      "alpha1 part I =  [0.00699284]\n",
      "alpha2 part II =  [0.01787694]\n",
      "alpha1 =  0.09426601104803053\n",
      "true gam2 =  4320.472164787252\n",
      "gam2 =  7015.067076376933\n",
      "corr(z1_hat, X*beta_true) =  0.9893798285106286\n",
      "l2 error for z1_hat =  0.1674523539321941\n",
      "v1 =  0.9220816938513764\n",
      "true tau2 =  3275.3880440213698\n",
      "tau2 = 989.4427693414639\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99839331]]\n",
      "l2 error for x2_hat =  0.0566642524186304\n",
      "alpha2 =  0.9289069161625484\n",
      "true gam1 =  1790.2768730153389\n",
      "gam1 =  536.8920643270794\n",
      "corr(z2_hat, beta_true) =  [[0.99446267]]\n",
      "l2 error for z2_hat =  0.12992892642681322\n",
      "true tau1 =  71863.33110114942\n",
      "tau1 =  110351.0945581704\n",
      "\n",
      "\n",
      "**** iteration =  4  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0005029]\n",
      "corr(x1_hat, beta_true) =  0.9974433981667079\n",
      "l2 error for x1_hat =  0.07271380302767932\n",
      "B / (A+B) =  [0.01493281]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9981408909587632\n",
      "alpha1 part I =  [0.01490505]\n",
      "alpha2 part II =  [0.05576751]\n",
      "alpha1 =  0.11485549151890591\n",
      "true gam2 =  2444.252594076883\n",
      "gam2 =  4137.608538360288\n",
      "corr(z1_hat, X*beta_true) =  0.9945356131043336\n",
      "l2 error for z1_hat =  0.12912277308018968\n",
      "v1 =  0.983709889617385\n",
      "true tau2 =  3514.765615460059\n",
      "tau2 = 1827.4000598836797\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99780459]]\n",
      "l2 error for x2_hat =  0.06732635845035773\n",
      "alpha2 =  0.8207629050577823\n",
      "true gam1 =  1653.7091186981695\n",
      "gam1 =  903.5653656540479\n",
      "corr(z2_hat, beta_true) =  [[0.99737328]]\n",
      "l2 error for z2_hat =  0.09262940631346887\n",
      "true tau1 =  50343.93021480729\n",
      "tau1 =  79736.0758700423\n",
      "\n",
      "\n",
      "**** iteration =  5  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.18591663e-05]\n",
      "corr(x1_hat, beta_true) =  0.998803671030211\n",
      "l2 error for x1_hat =  0.04923973769900623\n",
      "B / (A+B) =  [0.00354799]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9988944966964582\n",
      "alpha1 part I =  [0.00354406]\n",
      "alpha2 part II =  [0.00501715]\n",
      "alpha1 =  0.07942810674754636\n",
      "true gam2 =  5425.965351308204\n",
      "gam2 =  10472.324135601883\n",
      "corr(z1_hat, X*beta_true) =  0.9974099789597811\n",
      "l2 error for z1_hat =  0.09194616398898402\n",
      "v1 =  0.973110119365911\n",
      "true tau2 =  3601.956857453107\n",
      "tau2 = 2203.3411426994708\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9988521]]\n",
      "l2 error for x2_hat =  0.0482202555068313\n",
      "alpha2 =  0.9011255735309162\n",
      "true gam1 =  1820.7504482262204\n",
      "gam1 =  1149.0574378538108\n",
      "corr(z2_hat, beta_true) =  [[0.99869929]]\n",
      "l2 error for z2_hat =  0.06391629426960545\n",
      "true tau1 =  99776.36592557121\n",
      "tau1 =  176070.55405008135\n",
      "\n",
      "\n",
      "**** iteration =  6  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.62497429e-05]\n",
      "corr(x1_hat, beta_true) =  0.9990237145461389\n",
      "l2 error for x1_hat =  0.04429598628756875\n",
      "B / (A+B) =  [0.00254083]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999130478211709\n",
      "alpha1 part I =  [0.00253862]\n",
      "alpha2 part II =  [0.0025094]\n",
      "alpha1 =  0.07457358743187778\n",
      "true gam2 =  6701.823095796972\n",
      "gam2 =  14259.312702626063\n",
      "corr(z1_hat, X*beta_true) =  0.9987098748469828\n",
      "l2 error for z1_hat =  0.06363001735985177\n",
      "v1 =  0.9849600792413383\n",
      "true tau2 =  3665.4056324818393\n",
      "tau2 = 2688.5223438563717\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99905755]]\n",
      "l2 error for x2_hat =  0.04351127571479385\n",
      "alpha2 =  0.9096609020320637\n",
      "true gam1 =  1886.4044773876522\n",
      "gam1 =  1416.1029063911208\n",
      "corr(z2_hat, beta_true) =  [[0.99920572]]\n",
      "l2 error for z2_hat =  0.047162043903923145\n",
      "true tau1 =  124083.00990504844\n",
      "tau1 =  235394.20412397705\n",
      "\n",
      "\n",
      "**** iteration =  7  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.17118441e-06]\n",
      "corr(x1_hat, beta_true) =  0.9991839011268371\n",
      "l2 error for x1_hat =  0.040401222401615706\n",
      "B / (A+B) =  [0.00184219]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9992943349452675\n",
      "alpha1 part I =  [0.00184089]\n",
      "alpha2 part II =  [0.00102043]\n",
      "alpha1 =  0.08101003200506068\n",
      "true gam2 =  7849.397446496841\n",
      "gam2 =  16064.484020208998\n",
      "corr(z1_hat, X*beta_true) =  0.9992016413764522\n",
      "l2 error for z1_hat =  0.04732603282735208\n",
      "v1 =  0.989188695142089\n",
      "true tau2 =  3683.4319051004136\n",
      "tau2 = 2572.733104480232\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99917344]]\n",
      "l2 error for x2_hat =  0.04066221622744666\n",
      "alpha2 =  0.9210458418232677\n",
      "true gam1 =  1949.7459915696802\n",
      "gam1 =  1377.0843477761944\n",
      "corr(z2_hat, beta_true) =  [[0.99878062]]\n",
      "l2 error for z2_hat =  0.061107543202456906\n",
      "true tau1 =  143272.99211236314\n",
      "tau1 =  258108.4686350286\n",
      "\n",
      "\n",
      "**** iteration =  8  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-8.54776945e-06]\n",
      "corr(x1_hat, beta_true) =  0.999124375678992\n",
      "l2 error for x1_hat =  0.04191735738362136\n",
      "B / (A+B) =  [0.00214813]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9992743550120037\n",
      "alpha1 part I =  [0.00214657]\n",
      "alpha2 part II =  [0.00178921]\n",
      "alpha1 =  0.07500529555359088\n",
      "true gam2 =  7452.694467392262\n",
      "gam2 =  16982.743949844138\n",
      "corr(z1_hat, X*beta_true) =  0.9987910277086609\n",
      "l2 error for z1_hat =  0.0608466386493734\n",
      "v1 =  0.9855556358466864\n",
      "true tau2 =  3691.7584006536667\n",
      "tau2 = 3782.8536273506174\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99916603]]\n",
      "l2 error for x2_hat =  0.04090558869041396\n",
      "alpha2 =  0.8963838406848247\n",
      "true gam1 =  1829.9345749729662\n",
      "gam1 =  1963.0950747299325\n",
      "corr(z2_hat, beta_true) =  [[0.99921489]]\n",
      "l2 error for z2_hat =  0.0476445836260216\n",
      "true tau1 =  141624.87847712773\n",
      "tau1 =  288283.83962608996\n",
      "\n",
      "\n",
      "**** iteration =  9  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.55201401e-08]\n",
      "corr(x1_hat, beta_true) =  0.9995570565436278\n",
      "l2 error for x1_hat =  0.02978987011625335\n",
      "B / (A+B) =  [0.00167212]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994908596773823\n",
      "alpha1 part I =  [0.00167127]\n",
      "alpha2 part II =  [0.00114738]\n",
      "alpha1 =  0.0921930062903425\n",
      "true gam2 =  14241.686547940404\n",
      "gam2 =  19330.223732420985\n",
      "corr(z1_hat, X*beta_true) =  0.9992099608705725\n",
      "l2 error for z1_hat =  0.04781536185173951\n",
      "v1 =  0.9895900415687942\n",
      "true tau2 =  3703.967739803089\n",
      "tau2 = 3032.5919429610435\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99954206]]\n",
      "l2 error for x2_hat =  0.030295259527158513\n",
      "alpha2 =  0.9223781953478096\n",
      "true gam1 =  1979.3941519645934\n",
      "gam1 =  1626.7154384274324\n",
      "corr(z2_hat, beta_true) =  [[0.99897965]]\n",
      "l2 error for z2_hat =  0.057825824209274714\n",
      "true tau1 =  251450.72660536694\n",
      "tau1 =  309517.9298130897\n",
      "\n",
      "\n",
      "**** iteration =  10  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.57293864e-06]\n",
      "corr(x1_hat, beta_true) =  0.9992391231875751\n",
      "l2 error for x1_hat =  0.03911581370314421\n",
      "B / (A+B) =  [0.00194611]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9993856420008118\n",
      "alpha1 part I =  [0.00194491]\n",
      "alpha2 part II =  [0.00156039]\n",
      "alpha1 =  0.06785599654073769\n",
      "true gam2 =  8753.393805528836\n",
      "gam2 =  22346.338106675623\n",
      "corr(z1_hat, X*beta_true) =  0.9989865309579933\n",
      "l2 error for z1_hat =  0.057636826499277045\n",
      "v1 =  0.9873513277614479\n",
      "true tau2 =  3724.7510723924397\n",
      "tau2 = 3965.1446613609605\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99926429]]\n",
      "l2 error for x2_hat =  0.03846147590044928\n",
      "alpha2 =  0.9140725255563198\n",
      "true gam1 =  1901.1035201467776\n",
      "gam1 =  2100.6696327543186\n",
      "corr(z2_hat, beta_true) =  [[0.99921207]]\n",
      "l2 error for z2_hat =  0.04880910158082903\n",
      "true tau1 =  159202.46866998478\n",
      "tau1 =  365196.8433553916\n",
      "\n",
      "\n",
      "**** iteration =  11  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.27695635e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996780376358942\n",
      "l2 error for x1_hat =  0.02545993835654778\n",
      "B / (A+B) =  [0.00142253]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9995241878245681\n",
      "alpha1 part I =  [0.00142185]\n",
      "alpha2 part II =  [0.00061276]\n",
      "alpha1 =  0.09431979360867782\n",
      "true gam2 =  19473.618514690097\n",
      "gam2 =  20171.10972958992\n",
      "corr(z1_hat, X*beta_true) =  0.9992083239727881\n",
      "l2 error for z1_hat =  0.04893292511838275\n",
      "v1 =  0.991306758805448\n",
      "true tau2 =  3725.6307963296344\n",
      "tau2 = 3202.5850873881654\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99966485]]\n",
      "l2 error for x2_hat =  0.02598356387915073\n",
      "alpha2 =  0.9216078506203069\n",
      "true gam1 =  1974.5104377095788\n",
      "gam1 =  1715.7586559314752\n",
      "corr(z2_hat, beta_true) =  [[0.99908009]]\n",
      "l2 error for z2_hat =  0.05602797688566849\n",
      "true tau1 =  339516.07006218215\n",
      "tau1 =  323624.53857025417\n",
      "\n",
      "\n",
      "**** iteration =  12  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.55522528e-06]\n",
      "corr(x1_hat, beta_true) =  0.9993142861484006\n",
      "l2 error for x1_hat =  0.03720774096683429\n",
      "B / (A+B) =  [0.00187384]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994175069416165\n",
      "alpha1 part I =  [0.00187275]\n",
      "alpha2 part II =  [0.00146042]\n",
      "alpha1 =  0.07217281125861445\n",
      "true gam2 =  9597.830868434705\n",
      "gam2 =  22057.163944844793\n",
      "corr(z1_hat, X*beta_true) =  0.9990848805645143\n",
      "l2 error for z1_hat =  0.055886831488585295\n",
      "v1 =  0.9880168143132955\n",
      "true tau2 =  3744.5856327081265\n",
      "tau2 = 3925.087996763299\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99933099]]\n",
      "l2 error for x2_hat =  0.0367484000011059\n",
      "alpha2 =  0.9138686877955964\n",
      "true gam1 =  1911.9327184238434\n",
      "gam1 =  2078.8681125072862\n",
      "corr(z2_hat, beta_true) =  [[0.99921273]]\n",
      "l2 error for z2_hat =  0.04976386897036737\n",
      "true tau1 =  173969.5598071101\n",
      "tau1 =  360642.7232956899\n",
      "\n",
      "\n",
      "**** iteration =  13  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.67349363e-07]\n",
      "corr(x1_hat, beta_true) =  0.9996392790978953\n",
      "l2 error for x1_hat =  0.027002220938432613\n",
      "B / (A+B) =  [0.00145439]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9995192002829475\n",
      "alpha1 part I =  [0.00145369]\n",
      "alpha2 part II =  [0.00067571]\n",
      "alpha1 =  0.0924324520007659\n",
      "true gam2 =  17459.163959348167\n",
      "gam2 =  20411.805536289357\n",
      "corr(z1_hat, X*beta_true) =  0.9992096609306723\n",
      "l2 error for z1_hat =  0.04986440143500954\n",
      "v1 =  0.9909324318613504\n",
      "true tau2 =  3730.14401006889\n",
      "tau2 = 3300.07613238496\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99962838]]\n",
      "l2 error for x2_hat =  0.027411538252153818\n",
      "alpha2 =  0.9204257379590031\n",
      "true gam1 =  1962.2963595198923\n",
      "gam1 =  1764.6772525899396\n",
      "corr(z2_hat, beta_true) =  [[0.9990978]]\n",
      "l2 error for z2_hat =  0.05561433091708715\n",
      "true tau1 =  306206.1550359652\n",
      "tau1 =  328473.1427694503\n",
      "\n",
      "\n",
      "**** iteration =  14  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.38038925e-06]\n",
      "corr(x1_hat, beta_true) =  0.9993407862055277\n",
      "l2 error for x1_hat =  0.036499183179474405\n",
      "B / (A+B) =  [0.00183952]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994336450795109\n",
      "alpha1 part I =  [0.00183847]\n",
      "alpha2 part II =  [0.00141732]\n",
      "alpha1 =  0.07398978543346713\n",
      "true gam2 =  9946.441620910593\n",
      "gam2 =  22085.604813395606\n",
      "corr(z1_hat, X*beta_true) =  0.9991014039129138\n",
      "l2 error for z1_hat =  0.05550621378690441\n",
      "v1 =  0.9883828665741138\n",
      "true tau2 =  3743.0886263379393\n",
      "tau2 = 3860.7673761074257\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99935361]]\n",
      "l2 error for x2_hat =  0.03613888640154604\n",
      "alpha2 =  0.9151254316681574\n",
      "true gam1 =  1916.9124272936037\n",
      "gam1 =  2048.3598313595444\n",
      "corr(z2_hat, beta_true) =  [[0.99919184]]\n",
      "l2 error for z2_hat =  0.05078738397374449\n",
      "true tau1 =  179602.32311576442\n",
      "tau1 =  360042.5739416448\n",
      "\n",
      "\n",
      "**** iteration =  15  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.62932373e-08]\n",
      "corr(x1_hat, beta_true) =  0.9995987314016016\n",
      "l2 error for x1_hat =  0.028481765224642772\n",
      "B / (A+B) =  [0.00149796]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999512042743935\n",
      "alpha1 part I =  [0.00149723]\n",
      "alpha2 part II =  [0.00076224]\n",
      "alpha1 =  0.09065096150047007\n",
      "true gam2 =  15775.570248614637\n",
      "gam2 =  20547.758262202242\n",
      "corr(z1_hat, X*beta_true) =  0.9991893484627555\n",
      "l2 error for z1_hat =  0.050867617077543774\n",
      "v1 =  0.9907387192025098\n",
      "true tau2 =  3730.82012450382\n",
      "tau2 = 3365.6253780096154\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958977]]\n",
      "l2 error for x2_hat =  0.028800884880501375\n",
      "alpha2 =  0.9195649702973993\n",
      "true gam1 =  1952.7930259437867\n",
      "gam1 =  1797.3276489725063\n",
      "corr(z2_hat, beta_true) =  [[0.99910036]]\n",
      "l2 error for z2_hat =  0.055352130288943605\n",
      "true tau1 =  278274.27310577984\n",
      "tau1 =  331376.6271409366\n",
      "\n",
      "\n",
      "**** iteration =  16  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.99927841e-06]\n",
      "corr(x1_hat, beta_true) =  0.9993641304426004\n",
      "l2 error for x1_hat =  0.03584506796911906\n",
      "B / (A+B) =  [0.00180265]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994439278067201\n",
      "alpha1 part I =  [0.00180165]\n",
      "alpha2 part II =  [0.00134898]\n",
      "alpha1 =  0.07552478533190057\n",
      "true gam2 =  10282.647748336509\n",
      "gam2 =  22000.524156550484\n",
      "corr(z1_hat, X*beta_true) =  0.9991031143373125\n",
      "l2 error for z1_hat =  0.05526914330285425\n",
      "v1 =  0.9886558333643145\n",
      "true tau2 =  3739.688296895513\n",
      "tau2 = 3802.325896025905\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99937398]]\n",
      "l2 error for x2_hat =  0.035563762037350656\n",
      "alpha2 =  0.9159198170510146\n",
      "true gam1 =  1919.9533522658687\n",
      "gam1 =  2019.6179421165516\n",
      "corr(z2_hat, beta_true) =  [[0.99917398]]\n",
      "l2 error for z2_hat =  0.05155774704952109\n",
      "true tau1 =  185262.48994320908\n",
      "tau1 =  357978.60869902995\n",
      "\n",
      "\n",
      "**** iteration =  17  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.18868599e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995665134827162\n",
      "l2 error for x1_hat =  0.02959903582378974\n",
      "B / (A+B) =  [0.00153445]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9995051018902898\n",
      "alpha1 part I =  [0.00153369]\n",
      "alpha2 part II =  [0.00083295]\n",
      "alpha1 =  0.08895299176806466\n",
      "true gam2 =  14665.390745185521\n",
      "gam2 =  20684.71051242815\n",
      "corr(z1_hat, X*beta_true) =  0.9991719580778774\n",
      "l2 error for z1_hat =  0.0516219334930947\n",
      "v1 =  0.9905541746652959\n",
      "true tau2 =  3731.0185414802736\n",
      "tau2 = 3413.6481353722734\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955915]]\n",
      "l2 error for x2_hat =  0.029851755318682543\n",
      "alpha2 =  0.9190636560467604\n",
      "true gam1 =  1946.9771814172298\n",
      "gam1 =  1821.5765943876008\n",
      "corr(z2_hat, beta_true) =  [[0.99910091]]\n",
      "l2 error for z2_hat =  0.05515449066959769\n",
      "true tau1 =  259688.48075556252\n",
      "tau1 =  334001.952188209\n",
      "\n",
      "\n",
      "**** iteration =  18  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.79970978e-06]\n",
      "corr(x1_hat, beta_true) =  0.9993809470002427\n",
      "l2 error for x1_hat =  0.03536530667387831\n",
      "B / (A+B) =  [0.00177495]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994513262141743\n",
      "alpha1 part I =  [0.00177398]\n",
      "alpha2 part II =  [0.00129709]\n",
      "alpha1 =  0.07663238094164022\n",
      "true gam2 =  10541.172830517391\n",
      "gam2 =  21948.748325763736\n",
      "corr(z1_hat, X*beta_true) =  0.9991030312760074\n",
      "l2 error for z1_hat =  0.05509052001188899\n",
      "v1 =  0.9888803935705832\n",
      "true tau2 =  3737.2542900261446\n",
      "tau2 = 3755.732522494061\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99938859]]\n",
      "l2 error for x2_hat =  0.03514402512175516\n",
      "alpha2 =  0.9166091728868292\n",
      "true gam1 =  1923.0394766886259\n",
      "gam1 =  1996.842636016523\n",
      "corr(z2_hat, beta_true) =  [[0.9991585]]\n",
      "l2 error for z2_hat =  0.05218698012706154\n",
      "true tau1 =  189560.58497281422\n",
      "tau1 =  356546.0083293727\n",
      "\n",
      "\n",
      "**** iteration =  19  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.77157042e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995403262253304\n",
      "l2 error for x1_hat =  0.03047635191185962\n",
      "B / (A+B) =  [0.00156332]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994994600765985\n",
      "alpha1 part I =  [0.00156254]\n",
      "alpha2 part II =  [0.00088917]\n",
      "alpha1 =  0.08740495092688373\n",
      "true gam2 =  13882.304842060703\n",
      "gam2 =  20849.03296760836\n",
      "corr(z1_hat, X*beta_true) =  0.9991568687308765\n",
      "l2 error for z1_hat =  0.05223813170102559\n",
      "v1 =  0.9904136030332416\n",
      "true tau2 =  3731.072850086668\n",
      "tau2 = 3451.0749471640806\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99953434]]\n",
      "l2 error for x2_hat =  0.030675933027957313\n",
      "alpha2 =  0.9188634990078256\n",
      "true gam1 =  1943.5063362659505\n",
      "gam1 =  1840.9889889943552\n",
      "corr(z2_hat, beta_true) =  [[0.99910048]]\n",
      "l2 error for z2_hat =  0.05501688680509552\n",
      "true tau1 =  246404.57413556127\n",
      "tau1 =  336822.405418664\n",
      "\n",
      "\n",
      "**** iteration =  20  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.64289137e-06]\n",
      "corr(x1_hat, beta_true) =  0.9993941335389923\n",
      "l2 error for x1_hat =  0.034984413979991885\n",
      "B / (A+B) =  [0.00175344]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994571085896957\n",
      "alpha1 part I =  [0.00175248]\n",
      "alpha2 part II =  [0.00125719]\n",
      "alpha1 =  0.07750405219413807\n",
      "true gam2 =  10754.24928964016\n",
      "gam2 =  21912.46566113033\n",
      "corr(z1_hat, X*beta_true) =  0.9991021196232434\n",
      "l2 error for z1_hat =  0.054967516964173055\n",
      "v1 =  0.9890780087382661\n",
      "true tau2 =  3735.604788608481\n",
      "tau2 = 3719.394563662091\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99940009]]\n",
      "l2 error for x2_hat =  0.034810390614170614\n",
      "alpha2 =  0.9171627318120201\n",
      "true gam1 =  1925.7511040251882\n",
      "gam1 =  1979.1131188298068\n",
      "corr(z2_hat, beta_true) =  [[0.99914571]]\n",
      "l2 error for z2_hat =  0.05269393251902793\n",
      "true tau1 =  193082.64295318234\n",
      "tau1 =  355480.72345295735\n",
      "\n",
      "\n",
      "**** iteration =  21  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.13531977e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995195057231556\n",
      "l2 error for x1_hat =  0.03115624290760348\n",
      "B / (A+B) =  [0.00158658]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994949783472012\n",
      "alpha1 part I =  [0.00158578]\n",
      "alpha2 part II =  [0.00093509]\n",
      "alpha1 =  0.08608640848908389\n",
      "true gam2 =  13322.583575540037\n",
      "gam2 =  21010.731080336274\n",
      "corr(z1_hat, X*beta_true) =  0.9991444054840831\n",
      "l2 error for z1_hat =  0.052734587921560806\n",
      "v1 =  0.9903037881996025\n",
      "true tau2 =  3731.1165851161345\n",
      "tau2 = 3480.5646778599103\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99951468]]\n",
      "l2 error for x2_hat =  0.031313699657184266\n",
      "alpha2 =  0.9188110248285873\n",
      "true gam1 =  1941.4024801410465\n",
      "gam1 =  1856.5729817324407\n",
      "corr(z2_hat, beta_true) =  [[0.99909965]]\n",
      "l2 error for z2_hat =  0.05492268069557379\n",
      "true tau1 =  236819.59603887994\n",
      "tau1 =  339478.7763421703\n",
      "\n",
      "\n",
      "**** iteration =  22  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.52923562e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994044445825617\n",
      "l2 error for x1_hat =  0.034683952670604604\n",
      "B / (A+B) =  [0.00173682]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994616631433413\n",
      "alpha1 part I =  [0.00173588]\n",
      "alpha2 part II =  [0.00122683]\n",
      "alpha1 =  0.0781907347752859\n",
      "true gam2 =  10927.457622651025\n",
      "gam2 =  21887.582730169834\n",
      "corr(z1_hat, X*beta_true) =  0.9991009210176799\n",
      "l2 error for z1_hat =  0.05488451172343281\n",
      "v1 =  0.9892439991383222\n",
      "true tau2 =  3734.4755471835347\n",
      "tau2 = 3691.1358714718394\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99940909]]\n",
      "l2 error for x2_hat =  0.03454716850193837\n",
      "alpha2 =  0.9176054090666622\n",
      "true gam1 =  1928.04855247827\n",
      "gam1 =  1965.3528714551392\n",
      "corr(z2_hat, beta_true) =  [[0.99913516]]\n",
      "l2 error for z2_hat =  0.053105525751467896\n",
      "true tau1 =  195928.51341780619\n",
      "tau1 =  354695.09600709326\n",
      "\n",
      "\n",
      "**** iteration =  23  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.33914971e-07]\n",
      "corr(x1_hat, beta_true) =  0.999502957469543\n",
      "l2 error for x1_hat =  0.03168646489950354\n",
      "B / (A+B) =  [0.00160535]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994914442801612\n",
      "alpha1 part I =  [0.00160453]\n",
      "alpha2 part II =  [0.0009727]\n",
      "alpha1 =  0.08499360983141627\n",
      "true gam2 =  12911.98654678283\n",
      "gam2 =  21158.184008004286\n",
      "corr(z1_hat, X*beta_true) =  0.9991341185311635\n",
      "l2 error for z1_hat =  0.05313777111986562\n",
      "v1 =  0.990218103091222\n",
      "true tau2 =  3731.1544024155505\n",
      "tau2 = 3503.8653124592042\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99949909]]\n",
      "l2 error for x2_hat =  0.03181057990783542\n",
      "alpha2 =  0.9188325590541265\n",
      "true gam1 =  1940.1032597894982\n",
      "gam1 =  1869.0626861976998\n",
      "corr(z2_hat, beta_true) =  [[0.99909858]]\n",
      "l2 error for z2_hat =  0.054862371049164825\n",
      "true tau1 =  229735.49361314453\n",
      "tau1 =  341843.01482838526\n",
      "\n",
      "\n",
      "**** iteration =  24  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.44727296e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994124358342227\n",
      "l2 error for x1_hat =  0.03444953020803855\n",
      "B / (A+B) =  [0.00172406]\n",
      "gam1 / (gam1 + 1/sigma) =  0.99946525856733\n",
      "alpha1 part I =  [0.00172313]\n",
      "alpha2 part II =  [0.00120395]\n",
      "alpha1 =  0.07872596596752211\n",
      "true gam2 =  11065.934030579574\n",
      "gam2 =  21872.31238906996\n",
      "corr(z1_hat, X*beta_true) =  0.9990995637503303\n",
      "l2 error for z1_hat =  0.054832812811535625\n",
      "v1 =  0.9893805932063446\n",
      "true tau2 =  3733.676887182701\n",
      "tau2 = 3669.134061208616\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99941606]]\n",
      "l2 error for x2_hat =  0.03434206592853465\n",
      "alpha2 =  0.9179638397615476\n",
      "true gam1 =  1929.9670352607259\n",
      "gam1 =  1954.6745157209325\n",
      "corr(z2_hat, beta_true) =  [[0.9991264]]\n",
      "l2 error for z2_hat =  0.05344239705914095\n",
      "true tau1 =  198187.42928104597\n",
      "tau1 =  354137.3796072653\n",
      "\n",
      "\n",
      "**** iteration =  25  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.38380206e-07]\n",
      "corr(x1_hat, beta_true) =  0.9994897809553612\n",
      "l2 error for x1_hat =  0.03210260013876177\n",
      "B / (A+B) =  [0.00162052]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994886674689671\n",
      "alpha1 part I =  [0.00161969]\n",
      "alpha2 part II =  [0.00100355]\n",
      "alpha1 =  0.08409987096369669\n",
      "true gam2 =  12604.502018944724\n",
      "gam2 =  21287.62649285856\n",
      "corr(z1_hat, X*beta_true) =  0.9991255689725965\n",
      "l2 error for z1_hat =  0.053467930201514004\n",
      "v1 =  0.9901518909236526\n",
      "true tau2 =  3731.181908290594\n",
      "tau2 = 3522.2712538889637\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994867]]\n",
      "l2 error for x2_hat =  0.0322003731389588\n",
      "alpha2 =  0.9188901680911247\n",
      "true gam1 =  1939.2979108412937\n",
      "gam1 =  1879.0448157275873\n",
      "corr(z2_hat, beta_true) =  [[0.99909733]]\n",
      "l2 error for z2_hat =  0.054828273498118335\n",
      "true tau1 =  224397.6227345677\n",
      "tau1 =  343885.3039802591\n",
      "\n",
      "\n",
      "**** iteration =  26  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.38831382e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994185787910232\n",
      "l2 error for x1_hat =  0.034268393021699164\n",
      "B / (A+B) =  [0.00171429]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994680977859494\n",
      "alpha1 part I =  [0.00171338]\n",
      "alpha2 part II =  [0.00118679]\n",
      "alpha1 =  0.07913877718509914\n",
      "true gam2 =  11175.06424373582\n",
      "gam2 =  21864.622733401397\n",
      "corr(z1_hat, X*beta_true) =  0.999098094270451\n",
      "l2 error for z1_hat =  0.05480535373236732\n",
      "v1 =  0.9894918593177914\n",
      "true tau2 =  3733.092854267914\n",
      "tau2 = 3651.970573320376\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942141]]\n",
      "l2 error for x2_hat =  0.034184020944883035\n",
      "alpha2 =  0.9182570721580743\n",
      "true gam1 =  1931.5572334126255\n",
      "gam1 =  1946.381174268469\n",
      "corr(z2_hat, beta_true) =  [[0.99911907]]\n",
      "l2 error for z2_hat =  0.05372009930513935\n",
      "true tau1 =  199952.8825343472\n",
      "tau1 =  353758.3321633321\n",
      "\n",
      "\n",
      "**** iteration =  27  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-8.28162896e-07]\n",
      "corr(x1_hat, beta_true) =  0.9994792492352081\n",
      "l2 error for x1_hat =  0.032431525963750804\n",
      "B / (A+B) =  [0.00163282]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994864898494381\n",
      "alpha1 part I =  [0.00163198]\n",
      "alpha2 part II =  [0.00102889]\n",
      "alpha1 =  0.083372737309502\n",
      "true gam2 =  12370.144550864137\n",
      "gam2 =  21399.154033997263\n",
      "corr(z1_hat, X*beta_true) =  0.9991184100182258\n",
      "l2 error for z1_hat =  0.05374029262482712\n",
      "v1 =  0.9901011954267277\n",
      "true tau2 =  3731.196956114499\n",
      "tau2 = 3536.7946351608284\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994768]]\n",
      "l2 error for x2_hat =  0.03250851720587714\n",
      "alpha2 =  0.9189645098198063\n",
      "true gam1 =  1938.8083500174914\n",
      "gam1 =  1887.0053392230184\n",
      "corr(z2_hat, beta_true) =  [[0.99909595]]\n",
      "l2 error for z2_hat =  0.05481426531809291\n",
      "true tau1 =  220307.26304311366\n",
      "tau1 =  345623.2711381216\n",
      "\n",
      "\n",
      "**** iteration =  28  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34655898e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994232440120874\n",
      "l2 error for x1_hat =  0.034130283942800425\n",
      "B / (A+B) =  [0.00170686]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994703404809164\n",
      "alpha1 part I =  [0.00170595]\n",
      "alpha2 part II =  [0.00117402]\n",
      "alpha1 =  0.07945258455109805\n",
      "true gam2 =  11259.625898410179\n",
      "gam2 =  21863.075918478993\n",
      "corr(z1_hat, X*beta_true) =  0.9990965439673599\n",
      "l2 error for z1_hat =  0.05479647668541955\n",
      "v1 =  0.9895821380668661\n",
      "true tau2 =  3732.6523635788194\n",
      "tau2 = 3638.561551473506\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942546]]\n",
      "l2 error for x2_hat =  0.03406408923761274\n",
      "alpha2 =  0.918500196165551\n",
      "true gam1 =  1932.874900500883\n",
      "gam1 =  1939.941228115475\n",
      "corr(z2_hat, beta_true) =  [[0.99911289]]\n",
      "l2 error for z2_hat =  0.05395072217468965\n",
      "true tau1 =  201306.6803525726\n",
      "tau1 =  353521.71420718107\n",
      "\n",
      "\n",
      "**** iteration =  29  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.04745199e-07]\n",
      "corr(x1_hat, beta_true) =  0.9994707920243234\n",
      "l2 error for x1_hat =  0.03269337575819105\n",
      "B / (A+B) =  [0.0016428]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994847860483798\n",
      "alpha1 part I =  [0.00164195]\n",
      "alpha2 part II =  [0.00104975]\n",
      "alpha1 =  0.08278161000075505\n",
      "true gam2 =  12188.845109704174\n",
      "gam2 =  21494.505481700642\n",
      "corr(z1_hat, X*beta_true) =  0.9991123656326253\n",
      "l2 error for z1_hat =  0.05396667848879254\n",
      "v1 =  0.9900628966033724\n",
      "true tau2 =  3731.1993368498674\n",
      "tau2 = 3548.2410653725456\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99946885]]\n",
      "l2 error for x2_hat =  0.03275398793439789\n",
      "alpha2 =  0.9190457500353831\n",
      "true gam1 =  1938.5277249656858\n",
      "gam1 =  1893.3459727814732\n",
      "corr(z2_hat, beta_true) =  [[0.99909448]]\n",
      "l2 error for z2_hat =  0.054815384301507356\n",
      "true tau1 =  217127.12995833924\n",
      "tau1 =  347093.3686757734\n",
      "\n",
      "\n",
      "**** iteration =  30  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.31762051e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994267359219979\n",
      "l2 error for x1_hat =  0.03402660031959175\n",
      "B / (A+B) =  [0.00170124]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994721133233484\n",
      "alpha1 part I =  [0.00170034]\n",
      "alpha2 part II =  [0.00116464]\n",
      "alpha1 =  0.07968712712265238\n",
      "true gam2 =  11323.976829291172\n",
      "gam2 =  21866.400941764507\n",
      "corr(z1_hat, X*beta_true) =  0.9990949426760223\n",
      "l2 error for z1_hat =  0.054801570417933806\n",
      "v1 =  0.9896553960619384\n",
      "true tau2 =  3732.3112065809387\n",
      "tau2 = 3628.074421425929\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942847]]\n",
      "l2 error for x2_hat =  0.03397470523526137\n",
      "alpha2 =  0.9187043992800428\n",
      "true gam1 =  1933.9698962613284\n",
      "gam1 =  1934.9446911729838\n",
      "corr(z2_hat, beta_true) =  [[0.99910764]]\n",
      "l2 error for z2_hat =  0.05414360740439221\n",
      "true tau1 =  202323.05996034245\n",
      "tau1 =  353397.33795469784\n",
      "\n",
      "\n",
      "**** iteration =  31  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.69758032e-07]\n",
      "corr(x1_hat, beta_true) =  0.9994639665280394\n",
      "l2 error for x1_hat =  0.03290326121453587\n",
      "B / (A+B) =  [0.00165091]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994834563174456\n",
      "alpha1 part I =  [0.00165006]\n",
      "alpha2 part II =  [0.00106694]\n",
      "alpha1 =  0.08230025578143789\n",
      "true gam2 =  12046.803641819102\n",
      "gam2 =  21575.853334917647\n",
      "corr(z1_hat, X*beta_true) =  0.9991072220099826\n",
      "l2 error for z1_hat =  0.05415620875971364\n",
      "v1 =  0.9900344393067422\n",
      "true tau2 =  3731.190319371731\n",
      "tau2 = 3557.2526372813672\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99946243]]\n",
      "l2 error for x2_hat =  0.03295097374569188\n",
      "alpha2 =  0.9191286548373817\n",
      "true gam1 =  1938.3885066808507\n",
      "gam1 =  1898.3939550169584\n",
      "corr(z2_hat, beta_true) =  [[0.99909296]]\n",
      "l2 error for z2_hat =  0.05482761924827969\n",
      "true tau1 =  214623.5712059515\n",
      "tau1 =  348335.2630742698\n",
      "\n",
      "\n",
      "**** iteration =  32  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.2982373e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994293033770509\n",
      "l2 error for x1_hat =  0.033950198294306226\n",
      "B / (A+B) =  [0.00169703]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994735162774638\n",
      "alpha1 part I =  [0.00169613]\n",
      "alpha2 part II =  [0.00115787]\n",
      "alpha1 =  0.07985886641482391\n",
      "true gam2 =  11371.966095710692\n",
      "gam2 =  21873.46808414375\n",
      "corr(z1_hat, X*beta_true) =  0.999093319731936\n",
      "l2 error for z1_hat =  0.05481688966561456\n",
      "v1 =  0.9897149779521319\n",
      "true tau2 =  3732.041013697211\n",
      "tau2 = 3619.8662651158415\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943066]]\n",
      "l2 error for x2_hat =  0.033909544759357216\n",
      "alpha2 =  0.9188779353234885\n",
      "true gam1 =  1934.8840062697693\n",
      "gam1 =  1931.0735674557684\n",
      "corr(z2_hat, beta_true) =  [[0.99910314]]\n",
      "l2 error for z2_hat =  0.05430602042547148\n",
      "true tau1 =  203067.36876735484\n",
      "tau1 =  353359.8313844146\n",
      "\n",
      "\n",
      "**** iteration =  33  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.02481953e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994584290347452\n",
      "l2 error for x1_hat =  0.033072613287056345\n",
      "B / (A+B) =  [0.00165752]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994824213648775\n",
      "alpha1 part I =  [0.00165667]\n",
      "alpha2 part II =  [0.00108114]\n",
      "alpha1 =  0.0819070714384071\n",
      "true gam2 =  11934.284834253736\n",
      "gam2 =  21645.322628175607\n",
      "corr(z1_hat, X*beta_true) =  0.9991028133183674\n",
      "l2 error for z1_hat =  0.05431596958345409\n",
      "v1 =  0.9900137317547553\n",
      "true tau2 =  3731.171861122751\n",
      "tau2 = 3564.340523888156\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99945721]]\n",
      "l2 error for x2_hat =  0.03311017173701659\n",
      "alpha2 =  0.9192103497402025\n",
      "true gam1 =  1938.3461043868263\n",
      "gam1 =  1902.4133544460517\n",
      "corr(z2_hat, beta_true) =  [[0.99909142]]\n",
      "l2 error for z2_hat =  0.054847765804373824\n",
      "true tau1 =  212630.83238661004\n",
      "tau1 =  349385.87153186015\n",
      "\n",
      "\n",
      "**** iteration =  34  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28595943e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994311484988249\n",
      "l2 error for x1_hat =  0.03389520542645863\n",
      "B / (A+B) =  [0.00169391]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994746280424774\n",
      "alpha1 part I =  [0.00169302]\n",
      "alpha2 part II =  [0.00115309]\n",
      "alpha1 =  0.07998135849695175\n",
      "true gam2 =  11406.905075809671\n",
      "gam2 =  21883.296093319288\n",
      "corr(z1_hat, X*beta_true) =  0.9990917020140094\n",
      "l2 error for z1_hat =  0.05483943266070433\n",
      "v1 =  0.9897636104728305\n",
      "true tau2 =  3731.8229731364345\n",
      "tau2 = 3613.43843969086\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943221]]\n",
      "l2 error for x2_hat =  0.03386338333007638\n",
      "alpha2 =  0.919026930234657\n",
      "true gam1 =  1935.651260147697\n",
      "gam1 =  1928.0802367864928\n",
      "corr(z2_hat, beta_true) =  [[0.99909927]]\n",
      "l2 error for z2_hat =  0.05444364891092845\n",
      "true tau1 =  203595.67769024966\n",
      "tau1 =  353388.063433707\n",
      "\n",
      "\n",
      "**** iteration =  35  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.07142475e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994539124493391\n",
      "l2 error for x1_hat =  0.03321013870758092\n",
      "B / (A+B) =  [0.00166293]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994816182443164\n",
      "alpha1 part I =  [0.00166207]\n",
      "alpha2 part II =  [0.00109291]\n",
      "alpha1 =  0.08158463035384507\n",
      "true gam2 =  11844.276114523474\n",
      "gam2 =  21704.805374438474\n",
      "corr(z1_hat, X*beta_true) =  0.9990990100744485\n",
      "l2 error for z1_hat =  0.0544515040461785\n",
      "v1 =  0.9899990726507147\n",
      "true tau2 =  3731.1461102340436\n",
      "tau2 = 3569.9107667265785\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99945295]]\n",
      "l2 error for x2_hat =  0.03323970726230424\n",
      "alpha2 =  0.919289209102397\n",
      "true gam1 =  1938.3699873064227\n",
      "gam1 =  1905.6157634657332\n",
      "corr(z2_hat, beta_true) =  [[0.9990899]]\n",
      "l2 error for z2_hat =  0.054873295906100156\n",
      "true tau1 =  211029.00677099894\n",
      "tau1 =  350277.27393061464\n",
      "\n",
      "\n",
      "**** iteration =  36  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.2789377e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994324341706229\n",
      "l2 error for x1_hat =  0.0338568463051946\n",
      "B / (A+B) =  [0.00169163]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994755104729742\n",
      "alpha1 part I =  [0.00169074]\n",
      "alpha2 part II =  [0.00114983]\n",
      "alpha1 =  0.08006563251064998\n",
      "true gam2 =  11431.5781192356\n",
      "gam2 =  21895.055057591682\n",
      "corr(z1_hat, X*beta_true) =  0.9990901125929443\n",
      "l2 error for z1_hat =  0.0548668264514094\n",
      "v1 =  0.9898034784461741\n",
      "true tau2 =  3731.644224764449\n",
      "tau2 = 3608.4029317170284\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943326]]\n",
      "l2 error for x2_hat =  0.033831957591846436\n",
      "alpha2 =  0.9191559789099345\n",
      "true gam1 =  1936.2990027253495\n",
      "gam1 =  1925.7713962142793\n",
      "corr(z2_hat, beta_true) =  [[0.99909592]]\n",
      "l2 error for z2_hat =  0.05456097620314146\n",
      "true tau1 =  203955.0217121289\n",
      "tau1 =  353464.6751327234\n",
      "\n",
      "\n",
      "**** iteration =  37  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.11090196e-06]\n",
      "corr(x1_hat, beta_true) =  0.999450208582277\n",
      "l2 error for x1_hat =  0.0333225178978041\n",
      "B / (A+B) =  [0.00166736]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994809970700391\n",
      "alpha1 part I =  [0.00166649]\n",
      "alpha2 part II =  [0.00110269]\n",
      "alpha1 =  0.08131901076106697\n",
      "true gam2 =  11771.634080337719\n",
      "gam2 =  21755.916049205054\n",
      "corr(z1_hat, X*beta_true) =  0.9990957102506792\n",
      "l2 error for z1_hat =  0.054567179538475695\n",
      "v1 =  0.989989089170834\n",
      "true tau2 =  3731.1151131550305\n",
      "tau2 = 3574.2851943727155\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99944945]]\n",
      "l2 error for x2_hat =  0.033345801125174775\n",
      "alpha2 =  0.9193643090289981\n",
      "true gam1 =  1938.438695109353\n",
      "gam1 =  1908.1699236155853\n",
      "corr(z2_hat, beta_true) =  [[0.9990884]]\n",
      "l2 error for z2_hat =  0.05490224296460862\n",
      "true tau1 =  209729.84707487084\n",
      "tau1 =  351036.44872077124\n",
      "\n",
      "\n",
      "**** iteration =  38  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.27577257e-06]\n",
      "corr(x1_hat, beta_true) =  0.999433290581384\n",
      "l2 error for x1_hat =  0.03383127843267962\n",
      "B / (A+B) =  [0.00169]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994762121550154\n",
      "alpha1 part I =  [0.00168912]\n",
      "alpha2 part II =  [0.00114772]\n",
      "alpha1 =  0.08012056238837822\n",
      "true gam2 =  11448.28115966409\n",
      "gam2 =  21908.062348517993\n",
      "corr(z1_hat, X*beta_true) =  0.99908857009831\n",
      "l2 error for z1_hat =  0.054897223736735175\n",
      "v1 =  0.989836318761721\n",
      "true tau2 =  3731.495725682123\n",
      "tau2 = 3604.457121030606\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943394]]\n",
      "l2 error for x2_hat =  0.03381182939168835\n",
      "alpha2 =  0.9192685781366982\n",
      "true gam1 =  1936.849094745262\n",
      "gam1 =  1923.9959525764611\n",
      "corr(z2_hat, beta_true) =  [[0.999093]]\n",
      "l2 error for z2_hat =  0.05466156107595704\n",
      "true tau1 =  204184.09060362642\n",
      "tau1 =  353575.6383450285\n",
      "\n",
      "\n",
      "**** iteration =  39  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.14440057e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994471545681436\n",
      "l2 error for x1_hat =  0.03341491181245006\n",
      "B / (A+B) =  [0.001671]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994805183882794\n",
      "alpha1 part I =  [0.00167013]\n",
      "alpha2 part II =  [0.00111085]\n",
      "alpha1 =  0.08109913680457201\n",
      "true gam2 =  11712.528105398362\n",
      "gam2 =  21800.004429977485\n",
      "corr(z1_hat, X*beta_true) =  0.9990928326253978\n",
      "l2 error for z1_hat =  0.05466646226897706\n",
      "v1 =  0.9899826829993024\n",
      "true tau2 =  3731.0806680587834\n",
      "tau2 = 3577.718392301079\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99944655]]\n",
      "l2 error for x2_hat =  0.033433251462212384\n",
      "alpha2 =  0.9194351455166919\n",
      "true gam1 =  1938.5368834357416\n",
      "gam1 =  1910.2099731565272\n",
      "corr(z2_hat, beta_true) =  [[0.99908696]]\n",
      "l2 error for z2_hat =  0.05493310007751127\n",
      "true tau1 =  208667.4387800075\n",
      "tau1 =  351685.7190205805\n",
      "\n",
      "\n",
      "**** iteration =  40  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.27540306e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994338209927227\n",
      "l2 error for x1_hat =  0.033815439217039854\n",
      "B / (A+B) =  [0.00168887]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994767712527429\n",
      "alpha1 part I =  [0.00168798]\n",
      "alpha2 part II =  [0.00114649]\n",
      "alpha1 =  0.08015321947981746\n",
      "true gam2 =  11458.877065726405\n",
      "gam2 =  21921.770645382658\n",
      "corr(z1_hat, X*beta_true) =  0.9990870887016252\n",
      "l2 error for z1_hat =  0.054929209688382635\n",
      "v1 =  0.9898635082037809\n",
      "true tau2 =  3731.3709542812157\n",
      "tau2 = 3601.36460850888\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943432]]\n",
      "l2 error for x2_hat =  0.033800255164845465\n",
      "alpha2 =  0.919367431111785\n",
      "true gam1 =  1937.3189955416713\n",
      "gam1 =  1922.6357405090034\n",
      "corr(z2_hat, beta_true) =  [[0.99909044]]\n",
      "l2 error for z2_hat =  0.05474824752507364\n",
      "true tau1 =  204314.19304420988\n",
      "tau1 =  353709.79718782497\n",
      "\n",
      "\n",
      "**** iteration =  41  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.17289798e-06]\n",
      "corr(x1_hat, beta_true) =  0.999444622512468\n",
      "l2 error for x1_hat =  0.033491332675923045\n",
      "B / (A+B) =  [0.00167401]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994801510603377\n",
      "alpha1 part I =  [0.00167314]\n",
      "alpha2 part II =  [0.00111768]\n",
      "alpha1 =  0.0809162063509712\n",
      "true gam2 =  11664.068008151457\n",
      "gam2 =  21838.18829231377\n",
      "corr(z1_hat, X*beta_true) =  0.9990903118740869\n",
      "l2 error for z1_hat =  0.054752122609426176\n",
      "v1 =  0.9899789825496618\n",
      "true tau2 =  3731.044270713807\n",
      "tau2 = 3580.411415246365\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99944415]]\n",
      "l2 error for x2_hat =  0.033505784409664945\n",
      "alpha2 =  0.9195014800742117\n",
      "true gam1 =  1938.653479060394\n",
      "gam1 =  1911.8423118253763\n",
      "corr(z2_hat, beta_true) =  [[0.99908558]]\n",
      "l2 error for z2_hat =  0.054964731653624324\n",
      "true tau1 =  207791.91950397618\n",
      "tau1 =  352243.4142697131\n",
      "\n",
      "\n",
      "**** iteration =  42  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.27702483e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994341067217426\n",
      "l2 error for x1_hat =  0.03380690858694352\n",
      "B / (A+B) =  [0.00168811]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994772177540104\n",
      "alpha1 part I =  [0.00168723]\n",
      "alpha2 part II =  [0.0011459]\n",
      "alpha1 =  0.08016919075485422\n",
      "true gam2 =  11464.856997836254\n",
      "gam2 =  21935.751680628822\n",
      "corr(z1_hat, X*beta_true) =  0.9990856784802457\n",
      "l2 error for z1_hat =  0.054961719993250446\n",
      "v1 =  0.9898861378631294\n",
      "true tau2 =  3731.2651002910084\n",
      "tau2 = 3598.940518790319\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994345]]\n",
      "l2 error for x2_hat =  0.03379506634098558\n",
      "alpha2 =  0.9194546611665412\n",
      "true gam1 =  1937.7226694189599\n",
      "gam1 =  1921.5983411745813\n",
      "corr(z2_hat, beta_true) =  [[0.9990882]]\n",
      "l2 error for z2_hat =  0.05482332315241666\n",
      "true tau1 =  204370.31544165395\n",
      "tau1 =  353858.4191163081\n",
      "\n",
      "\n",
      "**** iteration =  43  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.19721563e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994425115995826\n",
      "l2 error for x1_hat =  0.033554917605351786\n",
      "B / (A+B) =  [0.00167651]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994798705592406\n",
      "alpha1 part I =  [0.00167563]\n",
      "alpha2 part II =  [0.00112343]\n",
      "alpha1 =  0.08076321961624588\n",
      "true gam2 =  11624.04890207344\n",
      "gam2 =  21871.38998080216\n",
      "corr(z1_hat, X*beta_true) =  0.9990880949389287\n",
      "l2 error for z1_hat =  0.054826389776031485\n",
      "v1 =  0.9899773014292091\n",
      "true tau2 =  3731.007113625432\n",
      "tau2 = 3582.522817865782\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99944214]]\n",
      "l2 error for x2_hat =  0.03356631168989684\n",
      "alpha2 =  0.919563249106256\n",
      "true gam1 =  1938.7804705444414\n",
      "gam1 =  1913.1512153139872\n",
      "corr(z2_hat, beta_true) =  [[0.99908427]]\n",
      "l2 error for z2_hat =  0.054996298325049174\n",
      "true tau1 =  207065.15463954528\n",
      "tau1 =  352724.5411109844\n",
      "\n",
      "\n",
      "**** iteration =  44  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28002901e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994342113687902\n",
      "l2 error for x1_hat =  0.03380378927170971\n",
      "B / (A+B) =  [0.00168763]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994775752343913\n",
      "alpha1 part I =  [0.00168675]\n",
      "alpha2 part II =  [0.00114578]\n",
      "alpha1 =  0.08017285598332581\n",
      "true gam2 =  11467.400838052665\n",
      "gam2 =  21949.678564778675\n",
      "corr(z1_hat, X*beta_true) =  0.9990843459678859\n",
      "l2 error for z1_hat =  0.05499397059048202\n",
      "v1 =  0.9899050735411007\n",
      "true tau2 =  3731.1745443975387\n",
      "tau2 = 3597.0401586355274\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943452]]\n",
      "l2 error for x2_hat =  0.033794563758553664\n",
      "alpha2 =  0.919531962327763\n",
      "true gam1 =  1938.0713185726343\n",
      "gam1 =  1920.811493243703\n",
      "corr(z2_hat, beta_true) =  [[0.99908622]]\n",
      "l2 error for z2_hat =  0.05488863958743091\n",
      "true tau1 =  204372.15982826138\n",
      "tau1 =  354014.7781672462\n",
      "\n",
      "\n",
      "**** iteration =  45  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.21803854e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994407420617705\n",
      "l2 error for x1_hat =  0.03360813239262823\n",
      "B / (A+B) =  [0.00167858]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994796576024675\n",
      "alpha1 part I =  [0.00167771]\n",
      "alpha2 part II =  [0.00112829]\n",
      "alpha1 =  0.0806346007688366\n",
      "true gam2 =  11590.772625909745\n",
      "gam2 =  21900.370417860293\n",
      "corr(z1_hat, X*beta_true) =  0.9990861383265679\n",
      "l2 error for z1_hat =  0.05489106920591757\n",
      "v1 =  0.9899771030285103\n",
      "true tau2 =  3730.970112949554\n",
      "tau2 = 3584.177489661509\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99944045]]\n",
      "l2 error for x2_hat =  0.03361712163635045\n",
      "alpha2 =  0.9196205067001835\n",
      "true gam1 =  1938.912081355346\n",
      "gam1 =  1914.2033745880913\n",
      "corr(z2_hat, beta_true) =  [[0.99908303]]\n",
      "l2 error for z2_hat =  0.055027194332484694\n",
      "true tau1 =  206457.70014285098\n",
      "tau1 =  353141.38446853403\n",
      "\n",
      "\n",
      "**** iteration =  46  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28395622e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994341843456844\n",
      "l2 error for x1_hat =  0.033804605012539866\n",
      "B / (A+B) =  [0.00168737]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994778622399748\n",
      "alpha1 part I =  [0.00168649]\n",
      "alpha2 part II =  [0.001146]\n",
      "alpha1 =  0.08016762295216186\n",
      "true gam2 =  11467.432677049852\n",
      "gam2 =  21963.30856973321\n",
      "corr(z1_hat, X*beta_true) =  0.9990830947630698\n",
      "l2 error for z1_hat =  0.05502539871239991\n",
      "v1 =  0.9899210037603003\n",
      "true tau2 =  3731.0965150395286\n",
      "tau2 = 3595.5502233211905\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943442]]\n",
      "l2 error for x2_hat =  0.033797427094277736\n",
      "alpha2 =  0.9196007062368797\n",
      "true gam1 =  1938.3739655173545\n",
      "gam1 =  1920.2187272496249\n",
      "corr(z2_hat, beta_true) =  [[0.99908447]]\n",
      "l2 error for z2_hat =  0.054945704719023235\n",
      "true tau1 =  204335.09397899103\n",
      "tau1 =  354173.78381234617\n",
      "\n",
      "\n",
      "**** iteration =  47  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.23593511e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994392505526404\n",
      "l2 error for x1_hat =  0.03365292462931942\n",
      "B / (A+B) =  [0.00168032]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994794970578745\n",
      "alpha1 part I =  [0.00167944]\n",
      "alpha2 part II =  [0.00113241]\n",
      "alpha1 =  0.0805258979993056\n",
      "true gam2 =  11562.920402771377\n",
      "gam2 =  21925.758467145446\n",
      "corr(z1_hat, X*beta_true) =  0.9990844060781157\n",
      "l2 error for z1_hat =  0.05494763231076335\n",
      "v1 =  0.9899779708580562\n",
      "true tau2 =  3730.933947248382\n",
      "tau2 = 3585.4737046353775\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943902]]\n",
      "l2 error for x2_hat =  0.03366002219954506\n",
      "alpha2 =  0.9196733861969573\n",
      "true gam1 =  1939.0441852559861\n",
      "gam1 =  1915.0515380380955\n",
      "corr(z2_hat, beta_true) =  [[0.99908188]]\n",
      "l2 error for z2_hat =  0.055056996135321605\n",
      "true tau1 =  205946.6308052361\n",
      "tau1 =  353504.0173003558\n",
      "\n",
      "\n",
      "**** iteration =  48  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28846164e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994340637799828\n",
      "l2 error for x1_hat =  0.033808215674261656\n",
      "B / (A+B) =  [0.00168727]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994780933705865\n",
      "alpha1 part I =  [0.00168639]\n",
      "alpha2 part II =  [0.00114647]\n",
      "alpha1 =  0.08015612326869011\n",
      "true gam2 =  11465.669488754369\n",
      "gam2 =  21976.467412032387\n",
      "corr(z1_hat, X*beta_true) =  0.9990819261189958\n",
      "l2 error for z1_hat =  0.05505561428261348\n",
      "v1 =  0.9899344775469199\n",
      "true tau2 =  3731.0288564759435\n",
      "tau2 = 3594.3819556705025\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943425]]\n",
      "l2 error for x2_hat =  0.03380263886808384\n",
      "alpha2 =  0.91966201887307\n",
      "true gam1 =  1938.6379118388713\n",
      "gam1 =  1919.7759480682955\n",
      "corr(z2_hat, beta_true) =  [[0.99908292]]\n",
      "l2 error for z2_hat =  0.054995753832796646\n",
      "true tau1 =  204270.98301076406\n",
      "tau1 =  354331.66052145447\n",
      "\n",
      "\n",
      "**** iteration =  49  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.2513756e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994379865826878\n",
      "l2 error for x1_hat =  0.033690839705573745\n",
      "B / (A+B) =  [0.00168178]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994793770710187\n",
      "alpha1 part I =  [0.0016809]\n",
      "alpha2 part II =  [0.00113593]\n",
      "alpha1 =  0.08043354721229527\n",
      "true gam2 =  11539.46053152249\n",
      "gam2 =  21948.075397605462\n",
      "corr(z1_hat, X*beta_true) =  0.9990828682282558\n",
      "l2 error for z1_hat =  0.05499728561296278\n",
      "v1 =  0.9899795840585007\n",
      "true tau2 =  3730.8990988159453\n",
      "tau2 = 3586.488728496121\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994378]]\n",
      "l2 error for x2_hat =  0.03369644893628173\n",
      "alpha2 =  0.9197220731987837\n",
      "true gam1 =  1939.1738824589045\n",
      "gam1 =  1915.7374184448101\n",
      "corr(z2_hat, beta_true) =  [[0.9990808]]\n",
      "l2 error for z2_hat =  0.055085420786081654\n",
      "true tau1 =  205513.96269637006\n",
      "tau1 =  353820.72108916286\n",
      "\n",
      "\n",
      "**** iteration =  50  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.29328844e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994338788791932\n",
      "l2 error for x1_hat =  0.03381374750763921\n",
      "B / (A+B) =  [0.00168727]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994782801283175\n",
      "alpha1 part I =  [0.00168639]\n",
      "alpha2 part II =  [0.00114709]\n",
      "alpha1 =  0.08014037303136723\n",
      "true gam2 =  11462.662503627951\n",
      "gam2 =  21989.035494141754\n",
      "corr(z1_hat, X*beta_true) =  0.9990808394751598\n",
      "l2 error for z1_hat =  0.05508436042842361\n",
      "v1 =  0.9899459340364793\n",
      "true tau2 =  3730.96986849247\n",
      "tau2 = 3593.4658113963214\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943402]]\n",
      "l2 error for x2_hat =  0.03380942174672775\n",
      "alpha2 =  0.91971683624635\n",
      "true gam1 =  1938.869097875286\n",
      "gam1 =  1919.448756169282\n",
      "corr(z2_hat, beta_true) =  [[0.99908154]]\n",
      "l2 error for z2_hat =  0.05503980483226345\n",
      "true tau1 =  204188.8949440086\n",
      "tau1 =  354485.67739954364\n",
      "\n",
      "\n",
      "**** iteration =  51  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.2647486e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994369097617509\n",
      "l2 error for x1_hat =  0.03372310932275254\n",
      "B / (A+B) =  [0.00168301]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994792883711229\n",
      "alpha1 part I =  [0.00168214]\n",
      "alpha2 part II =  [0.00113894]\n",
      "alpha1 =  0.08035468629465552\n",
      "true gam2 =  11519.580516203137\n",
      "gam2 =  21967.754899019983\n",
      "corr(z1_hat, X*beta_true) =  0.9990814996232388\n",
      "l2 error for z1_hat =  0.05504102436127656\n",
      "v1 =  0.9899816974170976\n",
      "true tau2 =  3730.8658926275634\n",
      "tau2 = 3587.2832667102307\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943676]]\n",
      "l2 error for x2_hat =  0.03372754719187344\n",
      "alpha2 =  0.9197667860973329\n",
      "true gam1 =  1939.2991867869328\n",
      "gam1 =  1916.2940045411858\n",
      "corr(z2_hat, beta_true) =  [[0.99907981]]\n",
      "l2 error for z2_hat =  0.0551122925854525\n",
      "true tau1 =  205145.49132556858\n",
      "tau1 =  354098.3276885784\n",
      "\n",
      "\n",
      "**** iteration =  52  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.29824726e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994336518380785\n",
      "l2 error for x1_hat =  0.033820536531157665\n",
      "B / (A+B) =  [0.00168736]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994784315824118\n",
      "alpha1 part I =  [0.00168648]\n",
      "alpha2 part II =  [0.00114782]\n",
      "alpha1 =  0.0801219032297704\n",
      "true gam2 =  11458.831586126487\n",
      "gam2 =  22000.93620709912\n",
      "corr(z1_hat, X*beta_true) =  0.9990798329144642\n",
      "l2 error for z1_hat =  0.055111481782613755\n",
      "v1 =  0.9899557256433765\n",
      "true tau2 =  3730.9181933131026\n",
      "tau2 = 3592.7472920207156\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943376]]\n",
      "l2 error for x2_hat =  0.033817187494030135\n",
      "alpha2 =  0.9197659453220542\n",
      "true gam1 =  1939.0723841970369\n",
      "gam1 =  1919.2103464847216\n",
      "corr(z2_hat, beta_true) =  [[0.99908031]]\n",
      "l2 error for z2_hat =  0.05507870135666027\n",
      "true tau1 =  204095.6860139505\n",
      "tau1 =  354633.9240576218\n",
      "\n",
      "\n",
      "**** iteration =  53  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.27637518e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994359876575243\n",
      "l2 error for x1_hat =  0.033750719459461814\n",
      "B / (A+B) =  [0.00168406]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999479223720552\n",
      "alpha1 part I =  [0.00168318]\n",
      "alpha2 part II =  [0.00114153]\n",
      "alpha1 =  0.08028700920719806\n",
      "true gam2 =  11502.636552439622\n",
      "gam2 =  21985.159307288064\n",
      "corr(z1_hat, X*beta_true) =  0.9990802790049118\n",
      "l2 error for z1_hat =  0.05507967436683167\n",
      "v1 =  0.9899841252141194\n",
      "true tau2 =  3730.834530644511\n",
      "tau2 = 3587.904985262664\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943587]]\n",
      "l2 error for x2_hat =  0.03375423506892234\n",
      "alpha2 =  0.9198077618612557\n",
      "true gam1 =  1939.4187919656003\n",
      "gam1 =  1916.7473941736678\n",
      "corr(z2_hat, beta_true) =  [[0.99907888]]\n",
      "l2 error for z2_hat =  0.05513751662374202\n",
      "true tau1 =  204829.9257314045\n",
      "tau1 =  354342.4951170577\n",
      "\n",
      "\n",
      "**** iteration =  54  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.30320055e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994333993660894\n",
      "l2 error for x1_hat =  0.03382808299288833\n",
      "B / (A+B) =  [0.00168751]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999478554890473\n",
      "alpha1 part I =  [0.00168663]\n",
      "alpha2 part II =  [0.0011486]\n",
      "alpha1 =  0.08010186466715821\n",
      "true gam2 =  11454.49332269289\n",
      "gam2 =  22012.12619869707\n",
      "corr(z1_hat, X*beta_true) =  0.9990789035433179\n",
      "l2 error for z1_hat =  0.05513689929780496\n",
      "v1 =  0.9899641361995513\n",
      "true tau2 =  3730.872734332925\n",
      "tau2 = 3592.1836859240925\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943349]]\n",
      "l2 error for x2_hat =  0.03382549583161014\n",
      "alpha2 =  0.9198100144740977\n",
      "true gam1 =  1939.2517718252552\n",
      "gam1 =  1919.0398598531026\n",
      "corr(z2_hat, beta_true) =  [[0.99907921]]\n",
      "l2 error for z2_hat =  0.055113146627110296\n",
      "true tau1 =  203996.47817432837\n",
      "tau1 =  354775.1273807452\n",
      "\n",
      "\n",
      "**** iteration =  55  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28652092e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994351941266995\n",
      "l2 error for x1_hat =  0.0337744628469698\n",
      "B / (A+B) =  [0.00168495]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791774791194\n",
      "alpha1 part I =  [0.00168407]\n",
      "alpha2 part II =  [0.00114377]\n",
      "alpha1 =  0.08022865129298154\n",
      "true gam2 =  11488.115538141592\n",
      "gam2 =  22000.59270189958\n",
      "corr(z1_hat, X*beta_true) =  0.9990791882941279\n",
      "l2 error for z1_hat =  0.05511392482995632\n",
      "v1 =  0.9899867282649882\n",
      "true tau2 =  3730.805120739111\n",
      "tau2 = 3588.3912923890557\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994351]]\n",
      "l2 error for x2_hat =  0.03377725196164817\n",
      "alpha2 =  0.9198452456653237\n",
      "true gam1 =  1939.531895668866\n",
      "gam1 =  1917.1182452136607\n",
      "corr(z2_hat, beta_true) =  [[0.99907803]]\n",
      "l2 error for z2_hat =  0.055161057964719463\n",
      "true tau1 =  204558.23647158217\n",
      "tau1 =  354557.9292521085\n",
      "\n",
      "\n",
      "**** iteration =  56  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.30805035e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994331339031498\n",
      "l2 error for x1_hat =  0.033836015020362695\n",
      "B / (A+B) =  [0.00168769]\n",
      "gam1 / (gam1 + 1/sigma) =  0.99947865570723\n",
      "alpha1 part I =  [0.00168681]\n",
      "alpha2 part II =  [0.00114941]\n",
      "alpha1 =  0.08008111179753895\n",
      "true gam2 =  11449.883679296412\n",
      "gam2 =  22022.587412975983\n",
      "corr(z1_hat, X*beta_true) =  0.9990780477995718\n",
      "l2 error for z1_hat =  0.05516059041696989\n",
      "v1 =  0.9899713951718752\n",
      "true tau2 =  3730.8325967331325\n",
      "tau2 = 3591.741517471129\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994332]]\n",
      "l2 error for x2_hat =  0.03383402156017402\n",
      "alpha2 =  0.9198496164384679\n",
      "true gam1 =  1939.4105746867765\n",
      "gam1 =  1918.9210895164517\n",
      "corr(z2_hat, beta_true) =  [[0.99907823]]\n",
      "l2 error for z2_hat =  0.055143730144117296\n",
      "true tau1 =  203895.04370697154\n",
      "tau1 =  354908.50343406724\n",
      "\n",
      "\n",
      "**** iteration =  57  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.29540586e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994345080104122\n",
      "l2 error for x1_hat =  0.03379497967528798\n",
      "B / (A+B) =  [0.00168572]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791452599482\n",
      "alpha1 part I =  [0.00168484]\n",
      "alpha2 part II =  [0.00114572]\n",
      "alpha1 =  0.08017809902315243\n",
      "true gam2 =  11475.606249093677\n",
      "gam2 =  22014.311462708807\n",
      "corr(z1_hat, X*beta_true) =  0.9990782120252101\n",
      "l2 error for z1_hat =  0.055144354229602434\n",
      "v1 =  0.9899894035918616\n",
      "true tau2 =  3730.7777003680435\n",
      "tau2 = 3588.7715331138656\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943443]]\n",
      "l2 error for x2_hat =  0.03379719615628727\n",
      "alpha2 =  0.9198794833922235\n",
      "true gam1 =  1939.6380664795797\n",
      "gam1 =  1917.4229222423778\n",
      "corr(z2_hat, beta_true) =  [[0.99907725]]\n",
      "l2 error for z2_hat =  0.055182925397405096\n",
      "true tau1 =  204323.16034792713\n",
      "tau1 =  354748.5617801402\n",
      "\n",
      "\n",
      "**** iteration =  58  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.31272886e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994328645823956\n",
      "l2 error for x1_hat =  0.03384405978513319\n",
      "B / (A+B) =  [0.00168789]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994787385052556\n",
      "alpha1 part I =  [0.00168701]\n",
      "alpha2 part II =  [0.00115023]\n",
      "alpha1 =  0.0800602693255193\n",
      "true gam2 =  11445.176097507738\n",
      "gam2 =  22032.32066962932\n",
      "corr(z1_hat, X*beta_true) =  0.9990772616966019\n",
      "l2 error for z1_hat =  0.05518257359170754\n",
      "v1 =  0.9899776888236599\n",
      "true tau2 =  3730.7970434330205\n",
      "tau2 = 3591.394549249269\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943292]]\n",
      "l2 error for x2_hat =  0.03384252846111104\n",
      "alpha2 =  0.9198852458393608\n",
      "true gam1 =  1939.5515548970625\n",
      "gam1 =  1918.8414663886927\n",
      "corr(z2_hat, beta_true) =  [[0.99907735]]\n",
      "l2 error for z2_hat =  0.05517094884167091\n",
      "true tau1 =  203794.11192839927\n",
      "tau1 =  355033.63894189673\n",
      "\n",
      "\n",
      "**** iteration =  59  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.30321281e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994339121116457\n",
      "l2 error for x1_hat =  0.03381278929882773\n",
      "B / (A+B) =  [0.00168638]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791236581211\n",
      "alpha1 part I =  [0.0016855]\n",
      "alpha2 part II =  [0.00114741]\n",
      "alpha1 =  0.08013411887353286\n",
      "true gam2 =  11464.777302369437\n",
      "gam2 =  22026.53278071566\n",
      "corr(z1_hat, X*beta_true) =  0.9990773368960038\n",
      "l2 error for z1_hat =  0.05517145083842331\n",
      "v1 =  0.9899920762357177\n",
      "true tau2 =  3730.7522555159826\n",
      "tau2 = 3589.068718404788\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943385]]\n",
      "l2 error for x2_hat =  0.03381455409103641\n",
      "alpha2 =  0.9199107163081292\n",
      "true gam1 =  1939.73714311045\n",
      "gam1 =  1917.6744018189456\n",
      "corr(z2_hat, beta_true) =  [[0.99907653]]\n",
      "l2 error for z2_hat =  0.05520315885092638\n",
      "true tau1 =  204118.82133751613\n",
      "tau1 =  354917.6930314529\n",
      "\n",
      "\n",
      "**** iteration =  60  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.31719115e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994325979891282\n",
      "l2 error for x1_hat =  0.033852020748761855\n",
      "B / (A+B) =  [0.00168811]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994788068267071\n",
      "alpha1 part I =  [0.00168723]\n",
      "alpha2 part II =  [0.00115103]\n",
      "alpha1 =  0.08003978484935066\n",
      "true gam2 =  11440.495833381197\n",
      "gam2 =  22041.34054841306\n",
      "corr(z1_hat, X*beta_true) =  0.9990765410129702\n",
      "l2 error for z1_hat =  0.05520289629354651\n",
      "v1 =  0.9899831689930028\n",
      "true tau2 =  3730.7654619864707\n",
      "tau2 = 3591.122216861157\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943264]]\n",
      "l2 error for x2_hat =  0.03385084869872397\n",
      "alpha2 =  0.9199173327454335\n",
      "true gam1 =  1939.6770291689058\n",
      "gam1 =  1918.7912632488758\n",
      "corr(z2_hat, beta_true) =  [[0.99907656]]\n",
      "l2 error for z2_hat =  0.05519522392074185\n",
      "true tau1 =  203695.6118171281\n",
      "tau1 =  355150.3972628247\n",
      "\n",
      "\n",
      "**** iteration =  61  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.31009412e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994333923916044\n",
      "l2 error for x1_hat =  0.033828315021059735\n",
      "B / (A+B) =  [0.00168695]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791100370424\n",
      "alpha1 part I =  [0.00168607]\n",
      "alpha2 part II =  [0.00114889]\n",
      "alpha1 =  0.0800957011864649\n",
      "true gam2 =  11455.36019909956\n",
      "gam2 =  22037.44152859446\n",
      "corr(z1_hat, X*beta_true) =  0.9990765514072483\n",
      "l2 error for z1_hat =  0.055195629051903936\n",
      "v1 =  0.989994692796026\n",
      "true tau2 =  3730.7287355846584\n",
      "tau2 = 3589.3008862423067\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943335]]\n",
      "l2 error for x2_hat =  0.0338297232158403\n",
      "alpha2 =  0.919939177388992\n",
      "true gam1 =  1939.8291580858725\n",
      "gam1 =  1917.8829866001247\n",
      "corr(z2_hat, beta_true) =  [[0.99907587]]\n",
      "l2 error for z2_hat =  0.055221819723731615\n",
      "true tau1 =  203940.4385576506\n",
      "tau1 =  355068.10673812486\n",
      "\n",
      "\n",
      "**** iteration =  62  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.32140954e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994323387567046\n",
      "l2 error for x1_hat =  0.03385975979037322\n",
      "B / (A+B) =  [0.00168833]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994788634810027\n",
      "alpha1 part I =  [0.00168745]\n",
      "alpha2 part II =  [0.0011518]\n",
      "alpha1 =  0.08001997028554592\n",
      "true gam2 =  11435.931245462674\n",
      "gam2 =  22049.671359599797\n",
      "corr(z1_hat, X*beta_true) =  0.9990758814368742\n",
      "l2 error for z1_hat =  0.055221625807900326\n",
      "v1 =  0.9899879600100749\n",
      "true tau2 =  3730.7373393955168\n",
      "tau2 = 3590.9084023334053\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943237]]\n",
      "l2 error for x2_hat =  0.033858866645215854\n",
      "alpha2 =  0.9199462532911998\n",
      "true gam1 =  1939.7889527433697\n",
      "gam1 =  1918.7629709003709\n",
      "corr(z2_hat, beta_true) =  [[0.99907586]]\n",
      "l2 error for z2_hat =  0.05521691430064302\n",
      "true tau1 =  203600.86267172016\n",
      "tau1 =  355258.84441641014\n",
      "\n",
      "\n",
      "**** iteration =  63  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.31617722e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994329373367158\n",
      "l2 error for x1_hat =  0.03384190353062083\n",
      "B / (A+B) =  [0.00168744]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791023604696\n",
      "alpha1 part I =  [0.00168656]\n",
      "alpha2 part II =  [0.0011502]\n",
      "alpha1 =  0.0800620157898437\n",
      "true gam2 =  11447.136202695405\n",
      "gam2 =  22047.195817059302\n",
      "corr(z1_hat, X*beta_true) =  0.9990758455715121\n",
      "l2 error for z1_hat =  0.055217242442250423\n",
      "v1 =  0.9899972163555196\n",
      "true tau2 =  3730.7070649226484\n",
      "tau2 = 3589.4821720481823\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994329]]\n",
      "l2 error for x2_hat =  0.033843029914303026\n",
      "alpha2 =  0.9199650888922274\n",
      "true gam1 =  1939.9142800519942\n",
      "gam1 =  1918.0568683522201\n",
      "corr(z2_hat, beta_true) =  [[0.99907527]]\n",
      "l2 error for z2_hat =  0.05523898351535174\n",
      "true tau1 =  203784.10000210695\n",
      "tau1 =  355202.16236064263\n",
      "\n",
      "\n",
      "**** iteration =  64  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.32536915e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994320900326739\n",
      "l2 error for x1_hat =  0.03386718322614135\n",
      "B / (A+B) =  [0.00168855]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999478910700099\n",
      "alpha1 part I =  [0.00168767]\n",
      "alpha2 part II =  [0.00115254]\n",
      "alpha1 =  0.08000103433284986\n",
      "true gam2 =  11431.542632625247\n",
      "gam2 =  22057.344004241644\n",
      "corr(z1_hat, X*beta_true) =  0.9990752786738492\n",
      "l2 error for z1_hat =  0.055238842228307834\n",
      "v1 =  0.9899921641582645\n",
      "true tau2 =  3730.71224274832\n",
      "tau2 = 3590.740472736204\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943211]]\n",
      "l2 error for x2_hat =  0.03386650623555601\n",
      "alpha2 =  0.9199723381022211\n",
      "true gam1 =  1939.8889858333494\n",
      "gam1 =  1918.750809373046\n",
      "corr(z2_hat, beta_true) =  [[0.99907522]]\n",
      "l2 error for z2_hat =  0.05523632741181768\n",
      "true tau1 =  203510.72308185828\n",
      "tau1 =  355359.1913468627\n",
      "\n",
      "\n",
      "**** iteration =  65  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.32156907e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994325374589159\n",
      "l2 error for x1_hat =  0.033853840188257905\n",
      "B / (A+B) =  [0.00168787]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790990606085\n",
      "alpha1 part I =  [0.00168699]\n",
      "alpha2 part II =  [0.00115134]\n",
      "alpha1 =  0.08003237684850052\n",
      "true gam2 =  11439.926134596912\n",
      "gam2 =  22055.931499577964\n",
      "corr(z1_hat, X*beta_true) =  0.999075210676764\n",
      "l2 error for z1_hat =  0.0552365942383222\n",
      "v1 =  0.9899996225089458\n",
      "true tau2 =  3730.6871516257447\n",
      "tau2 = 3589.6236499345505\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943251]]\n",
      "l2 error for x2_hat =  0.0338547436000384\n",
      "alpha2 =  0.9199886608639528\n",
      "true gam1 =  1939.9927703232772\n",
      "gam1 =  1918.2025716674832\n",
      "corr(z2_hat, beta_true) =  [[0.99907472]]\n",
      "l2 error for z2_hat =  0.05525473426655504\n",
      "true tau1 =  203646.58634402585\n",
      "tau1 =  355321.8695153967\n",
      "\n",
      "\n",
      "**** iteration =  66  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.32906458e-06]\n",
      "corr(x1_hat, beta_true) =  0.999431853842084\n",
      "l2 error for x1_hat =  0.03387423091638227\n",
      "B / (A+B) =  [0.00168876]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994789502605078\n",
      "alpha1 part I =  [0.00168788]\n",
      "alpha2 part II =  [0.00115324]\n",
      "alpha1 =  0.07998310781145995\n",
      "true gam2 =  11427.369119747707\n",
      "gam2 =  22064.393555869385\n",
      "corr(z1_hat, X*beta_true) =  0.9990747285250255\n",
      "l2 error for z1_hat =  0.05525463317951968\n",
      "v1 =  0.9899958659943838\n",
      "true tau2 =  3730.6898041829495\n",
      "tau2 = 3590.608526620108\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943187]]\n",
      "l2 error for x2_hat =  0.03387372112448408\n",
      "alpha2 =  0.9199958790606715\n",
      "true gam1 =  1939.9785464276933\n",
      "gam1 =  1918.7503451635587\n",
      "corr(z2_hat, beta_true) =  [[0.99907465]]\n",
      "l2 error for z2_hat =  0.055253727891627274\n",
      "true tau1 =  203425.706723814\n",
      "tau1 =  355451.74923823174\n",
      "\n",
      "\n",
      "**** iteration =  67  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.3263599e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994321849002844\n",
      "l2 error for x1_hat =  0.03386436108374484\n",
      "B / (A+B) =  [0.00168825]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790989346509\n",
      "alpha1 part I =  [0.00168737]\n",
      "alpha2 part II =  [0.00115236]\n",
      "alpha1 =  0.08000621497656123\n",
      "true gam2 =  11433.582403710516\n",
      "gam2 =  22063.76583468171\n",
      "corr(z1_hat, X*beta_true) =  0.9990746390931192\n",
      "l2 error for z1_hat =  0.05525394577539853\n",
      "v1 =  0.990001896267976\n",
      "true tau2 =  3730.668894169153\n",
      "tau2 = 3589.733993450123\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943216]]\n",
      "l2 error for x2_hat =  0.03386508783779308\n",
      "alpha2 =  0.9200100903406492\n",
      "true gam1 =  1940.0649503248314\n",
      "gam1 =  1918.3253035929044\n",
      "corr(z2_hat, beta_true) =  [[0.99907422]]\n",
      "l2 error for z2_hat =  0.05526916041169027\n",
      "true tau1 =  203525.23309818402\n",
      "tau1 =  355428.9481115854\n",
      "\n",
      "\n",
      "**** iteration =  68  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33249729e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994316313696235\n",
      "l2 error for x1_hat =  0.03388086781079864\n",
      "B / (A+B) =  [0.00168896]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999478983579215\n",
      "alpha1 part I =  [0.00168808]\n",
      "alpha2 part II =  [0.00115389]\n",
      "alpha1 =  0.07996626336264197\n",
      "true gam2 =  11423.433998499566\n",
      "gam2 =  22070.857420794502\n",
      "corr(z1_hat, X*beta_true) =  0.9990742269421672\n",
      "l2 error for z1_hat =  0.05526908989080449\n",
      "v1 =  0.989999135773337\n",
      "true tau2 =  3730.669709108939\n",
      "tau2 = 3590.5048033329354\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943164]]\n",
      "l2 error for x2_hat =  0.03388048705677759\n",
      "alpha2 =  0.9200171348012591\n",
      "true gam1 =  1940.0588524364891\n",
      "gam1 =  1918.7581917040839\n",
      "corr(z2_hat, beta_true) =  [[0.99907413]]\n",
      "l2 error for z2_hat =  0.0552693446202509\n",
      "true tau1 =  203346.07193342588\n",
      "tau1 =  355536.89523779077\n",
      "\n",
      "\n",
      "**** iteration =  69  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33062611e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994318731195628\n",
      "l2 error for x1_hat =  0.03387366257067249\n",
      "B / (A+B) =  [0.00168858]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791010637062\n",
      "alpha1 part I =  [0.0016877]\n",
      "alpha2 part II =  [0.00115325]\n",
      "alpha1 =  0.07998305506804748\n",
      "true gam2 =  11427.982755455127\n",
      "gam2 =  22070.800472586183\n",
      "corr(z1_hat, X*beta_true) =  0.9990741241139369\n",
      "l2 error for z1_hat =  0.055269523337755574\n",
      "v1 =  0.9900040296585345\n",
      "true tau2 =  3730.652186327818\n",
      "tau2 = 3589.819994287779\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943185]]\n",
      "l2 error for x2_hat =  0.03387424914297261\n",
      "alpha2 =  0.920029561058858\n",
      "true gam1 =  1940.1311773690582\n",
      "gam1 =  1918.429229104048\n",
      "corr(z2_hat, beta_true) =  [[0.99907377]]\n",
      "l2 error for z2_hat =  0.05528235172773023\n",
      "true tau1 =  203417.82233691588\n",
      "tau1 =  355524.87706819817\n",
      "\n",
      "\n",
      "**** iteration =  70  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33567361e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994314231778969\n",
      "l2 error for x1_hat =  0.033887077412055745\n",
      "B / (A+B) =  [0.00168916]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790117891105\n",
      "alpha1 part I =  [0.00168828]\n",
      "alpha2 part II =  [0.00115451]\n",
      "alpha1 =  0.07995053070020881\n",
      "true gam2 =  11419.74885178037\n",
      "gam2 =  22076.773958446993\n",
      "corr(z1_hat, X*beta_true) =  0.9990737700646117\n",
      "l2 error for z1_hat =  0.05528230431762878\n",
      "v1 =  0.9900020321686821\n",
      "true tau2 =  3730.65168689987\n",
      "tau2 = 3590.4232200156293\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943143]]\n",
      "l2 error for x2_hat =  0.03388679597881501\n",
      "alpha2 =  0.9200363352250547\n",
      "true gam1 =  1940.1309554825514\n",
      "gam1 =  1918.7717751317607\n",
      "corr(z2_hat, beta_true) =  [[0.99907366]]\n",
      "l2 error for z2_hat =  0.055283376438487464\n",
      "true tau1 =  203271.8906598993\n",
      "tau1 =  355615.04642630316\n",
      "\n",
      "\n",
      "**** iteration =  71  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33443274e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994315966430237\n",
      "l2 error for x1_hat =  0.03388190882689462\n",
      "B / (A+B) =  [0.00168888]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999479104749349\n",
      "alpha1 part I =  [0.001688]\n",
      "alpha2 part II =  [0.00115405]\n",
      "alpha1 =  0.07996249863638157\n",
      "true gam2 =  11423.025350798154\n",
      "gam2 =  22077.123899128128\n",
      "corr(z1_hat, X*beta_true) =  0.999073659824395\n",
      "l2 error for z1_hat =  0.05528352372464211\n",
      "v1 =  0.9900060198634307\n",
      "true tau2 =  3730.636920768978\n",
      "tau2 = 3589.88696931348\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943158]]\n",
      "l2 error for x2_hat =  0.03388238396455421\n",
      "alpha2 =  0.9200472435300235\n",
      "true gam1 =  1940.1918268052032\n",
      "gam1 =  1918.517688170094\n",
      "corr(z2_hat, beta_true) =  [[0.99907335]]\n",
      "l2 error for z2_hat =  0.055294397130238\n",
      "true tau1 =  203322.49728268705\n",
      "tau1 =  355610.93389659777\n",
      "\n",
      "\n",
      "**** iteration =  72  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33860321e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994312293756028\n",
      "l2 error for x1_hat =  0.03389285674370175\n",
      "B / (A+B) =  [0.00168934]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790357983346\n",
      "alpha1 part I =  [0.00168846]\n",
      "alpha2 part II =  [0.00115508]\n",
      "alpha1 =  0.07993590836534162\n",
      "true gam2 =  11416.316724660162\n",
      "gam2 =  22082.181464476547\n",
      "corr(z1_hat, X*beta_true) =  0.9990733542422987\n",
      "l2 error for z1_hat =  0.05529436707253777\n",
      "v1 =  0.9900046044387756\n",
      "true tau2 =  3730.6355034824373\n",
      "tau2 = 3590.3590086916015\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943124]]\n",
      "l2 error for x2_hat =  0.03389265151521017\n",
      "alpha2 =  0.9200536852450939\n",
      "true gam1 =  1940.195768129539\n",
      "gam1 =  1918.7891512697022\n",
      "corr(z2_hat, beta_true) =  [[0.99907324]]\n",
      "l2 error for z2_hat =  0.05529599681547244\n",
      "true tau1 =  203203.10127899508\n",
      "tau1 =  355686.64028251293\n",
      "\n",
      "\n",
      "**** iteration =  73  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33783535e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994313508660085\n",
      "l2 error for x1_hat =  0.03388923786586197\n",
      "B / (A+B) =  [0.00168914]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791094640062\n",
      "alpha1 part I =  [0.00168826]\n",
      "alpha2 part II =  [0.00115476]\n",
      "alpha1 =  0.07994420971383974\n",
      "true gam2 =  11418.624878142757\n",
      "gam2 =  22082.81344306461\n",
      "corr(z1_hat, X*beta_true) =  0.9990732409921652\n",
      "l2 error for z1_hat =  0.055296118798810086\n",
      "v1 =  0.9900078677930693\n",
      "true tau2 =  3730.622991619447\n",
      "tau2 = 3589.939079842499\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943134]]\n",
      "l2 error for x2_hat =  0.033889624242898\n",
      "alpha2 =  0.9200632953715135\n",
      "true gam1 =  1940.2472790312816\n",
      "gam1 =  1918.5933668307487\n",
      "corr(z2_hat, beta_true) =  [[0.99907298]]\n",
      "l2 error for z2_hat =  0.05530538311949129\n",
      "true tau1 =  203237.6946827474\n",
      "tau1 =  355688.2269668653\n",
      "\n",
      "\n",
      "**** iteration =  74  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34129795e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994310497465176\n",
      "l2 error for x1_hat =  0.033898212494333196\n",
      "B / (A+B) =  [0.00168952]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790563369934\n",
      "alpha1 part I =  [0.00168863]\n",
      "alpha2 part II =  [0.00115561]\n",
      "alpha1 =  0.07992237274105675\n",
      "true gam2 =  11413.134550593275\n",
      "gam2 =  22087.117437662822\n",
      "corr(z1_hat, X*beta_true) =  0.9990729760482436\n",
      "l2 error for z1_hat =  0.05530536597673323\n",
      "v1 =  0.9900068941556978\n",
      "true tau2 =  3730.6209553901535\n",
      "tau2 = 3590.3084318250017\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943105]]\n",
      "l2 error for x2_hat =  0.033898065512181774\n",
      "alpha2 =  0.9200693679244609\n",
      "true gam1 =  1940.2540859356038\n",
      "gam1 =  1918.8088627508741\n",
      "corr(z2_hat, beta_true) =  [[0.99907287]]\n",
      "l2 error for z2_hat =  0.055307357677127904\n",
      "true tau1 =  203139.54881960692\n",
      "tau1 =  355752.120231264\n",
      "\n",
      "\n",
      "**** iteration =  75  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34088167e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994311318944278\n",
      "l2 error for x1_hat =  0.033895766329679965\n",
      "B / (A+B) =  [0.00168937]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791148122073\n",
      "alpha1 part I =  [0.00168849]\n",
      "alpha2 part II =  [0.0011554]\n",
      "alpha1 =  0.07992790356580495\n",
      "true gam2 =  11414.70947033643\n",
      "gam2 =  22087.936931239725\n",
      "corr(z1_hat, X*beta_true) =  0.9990728629759673\n",
      "l2 error for z1_hat =  0.05530745922142961\n",
      "v1 =  0.9900095769912088\n",
      "true tau2 =  3730.6102962514233\n",
      "tau2 = 3589.9795820017803\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943112]]\n",
      "l2 error for x2_hat =  0.03389608184675066\n",
      "alpha2 =  0.9200778618109962\n",
      "true gam1 =  1940.297910205669\n",
      "gam1 =  1918.6584320742809\n",
      "corr(z2_hat, beta_true) =  [[0.99907263]]\n",
      "l2 error for z2_hat =  0.05531539272231802\n",
      "true tau1 =  203162.09105980935\n",
      "tau1 =  355757.7219033632\n",
      "\n",
      "\n",
      "**** iteration =  76  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34377102e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994308838478924\n",
      "l2 error for x1_hat =  0.03390315807880977\n",
      "B / (A+B) =  [0.00168968]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994790739939503\n",
      "alpha1 part I =  [0.0016888]\n",
      "alpha2 part II =  [0.00115609]\n",
      "alpha1 =  0.0799098849255065\n",
      "true gam2 =  11410.194997922636\n",
      "gam2 =  22091.618067045823\n",
      "corr(z1_hat, X*beta_true) =  0.9990726322831226\n",
      "l2 error for z1_hat =  0.05531538508434123\n",
      "v1 =  0.990008936588821\n",
      "true tau2 =  3730.6078649570522\n",
      "tau2 = 3590.2685593931255\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943089]]\n",
      "l2 error for x2_hat =  0.03390305541192218\n",
      "alpha2 =  0.9200835471286757\n",
      "true gam1 =  1940.30660541288\n",
      "gam1 =  1918.8298275911434\n",
      "corr(z2_hat, beta_true) =  [[0.99907252]]\n",
      "l2 error for z2_hat =  0.05531759256158382\n",
      "true tau1 =  203081.01541020052\n",
      "tau1 =  355811.92514646775\n",
      "\n",
      "\n",
      "**** iteration =  77  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34361288e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994309364178219\n",
      "l2 error for x1_hat =  0.0339015933223523\n",
      "B / (A+B) =  [0.00168957]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791205003546\n",
      "alpha1 part I =  [0.00168869]\n",
      "alpha2 part II =  [0.00115596]\n",
      "alpha1 =  0.07991333763327706\n",
      "true gam2 =  11411.21825119435\n",
      "gam2 =  22092.55405924723\n",
      "corr(z1_hat, X*beta_true) =  0.9990725216486379\n",
      "l2 error for z1_hat =  0.05531767753412264\n",
      "v1 =  0.9900111528021796\n",
      "true tau2 =  3730.5987364743505\n",
      "tau2 = 3590.0110229976085\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943093]]\n",
      "l2 error for x2_hat =  0.03390185212700347\n",
      "alpha2 =  0.9200910763024589\n",
      "true gam1 =  1940.3440857627788\n",
      "gam1 =  1918.7146382276796\n",
      "corr(z2_hat, beta_true) =  [[0.99907232]]\n",
      "l2 error for z2_hat =  0.05532450480908798\n",
      "true tau1 =  203094.5598250111\n",
      "tau1 =  355820.26326235884\n",
      "\n",
      "\n",
      "**** iteration =  78  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34603629e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994307310850582\n",
      "l2 error for x1_hat =  0.033907711412504135\n",
      "B / (A+B) =  [0.00168982]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999479089245825\n",
      "alpha1 part I =  [0.00168894]\n",
      "alpha2 part II =  [0.00115654]\n",
      "alpha1 =  0.07989839593729188\n",
      "true gam2 =  11407.48786648536\n",
      "gam2 =  22095.7178884726\n",
      "corr(z1_hat, X*beta_true) =  0.999072319974081\n",
      "l2 error for z1_hat =  0.055324504063841554\n",
      "v1 =  0.9900107618151972\n",
      "true tau2 =  3730.596076406329\n",
      "tau2 = 3590.237094180623\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943073]]\n",
      "l2 error for x2_hat =  0.03390764227240191\n",
      "alpha2 =  0.9200963697856948\n",
      "true gam1 =  1940.3539387367819\n",
      "gam1 =  1918.8512523871213\n",
      "corr(z2_hat, beta_true) =  [[0.99907222]]\n",
      "l2 error for z2_hat =  0.05532681923302237\n",
      "true tau1 =  203027.24315079773\n",
      "tau1 =  355866.48191109515\n",
      "\n",
      "\n",
      "**** iteration =  79  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34606462e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994307616073975\n",
      "l2 error for x1_hat =  0.03390680348502119\n",
      "B / (A+B) =  [0.00168975]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791263131679\n",
      "alpha1 part I =  [0.00168887]\n",
      "alpha2 part II =  [0.00115647]\n",
      "alpha1 =  0.07990030424252413\n",
      "true gam2 =  11408.099375900214\n",
      "gam2 =  22096.717531465896\n",
      "corr(z1_hat, X*beta_true) =  0.9990722133320731\n",
      "l2 error for z1_hat =  0.055326890715233806\n",
      "v1 =  0.9900126017415255\n",
      "true tau2 =  3730.5882192851027\n",
      "tau2 = 3590.035394939601\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943075]]\n",
      "l2 error for x2_hat =  0.03390701677258784\n",
      "alpha2 =  0.9201030612074489\n",
      "true gam1 =  1940.3861560451091\n",
      "gam1 =  1918.7634109281335\n",
      "corr(z2_hat, beta_true) =  [[0.99907204]]\n",
      "l2 error for z2_hat =  0.055332793691929776\n",
      "true tau1 =  203034.13692444167\n",
      "tau1 =  355876.59240775707\n",
      "\n",
      "\n",
      "**** iteration =  80  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34810782e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994305907675619\n",
      "l2 error for x1_hat =  0.03391189323823961\n",
      "B / (A+B) =  [0.00168996]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791024798642\n",
      "alpha1 part I =  [0.00168908]\n",
      "alpha2 part II =  [0.00115695]\n",
      "alpha1 =  0.07988785062549525\n",
      "true gam2 =  11405.001136198314\n",
      "gam2 =  22099.44957020549\n",
      "corr(z1_hat, X*beta_true) =  0.9990720363693935\n",
      "l2 error for z1_hat =  0.055332797846652806\n",
      "v1 =  0.9900123956134417\n",
      "true tau2 =  3730.5854526438115\n",
      "tau2 = 3590.2122348708144\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943059]]\n",
      "l2 error for x2_hat =  0.03391184928680239\n",
      "alpha2 =  0.9201079678256663\n",
      "true gam1 =  1940.3966258620926\n",
      "gam1 =  1918.872564781926\n",
      "corr(z2_hat, beta_true) =  [[0.99907194]]\n",
      "l2 error for z2_hat =  0.055335141858043654\n",
      "true tau1 =  202977.95113979196\n",
      "tau1 =  355916.2003231729\n",
      "\n",
      "\n",
      "**** iteration =  81  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34826794e-06]\n",
      "corr(x1_hat, beta_true) =  0.99943060503386\n",
      "l2 error for x1_hat =  0.033911469471683726\n",
      "B / (A+B) =  [0.00168992]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791320953568\n",
      "alpha1 part I =  [0.00168904]\n",
      "alpha2 part II =  [0.00115692]\n",
      "alpha1 =  0.07988862471779465\n",
      "true gam2 =  11405.308459798736\n",
      "gam2 =  22100.474013786854\n",
      "corr(z1_hat, X*beta_true) =  0.9990719347419001\n",
      "l2 error for z1_hat =  0.05533520231103273\n",
      "v1 =  0.9900139310244275\n",
      "true tau2 =  3730.5786572858933\n",
      "tau2 = 3590.0542553710766\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994306]]\n",
      "l2 error for x2_hat =  0.03391164611406316\n",
      "alpha2 =  0.9201139285081072\n",
      "true gam1 =  1940.4244535198848\n",
      "gam1 =  1918.805913451117\n",
      "corr(z2_hat, beta_true) =  [[0.99907178]]\n",
      "l2 error for z2_hat =  0.05534032893151119\n",
      "true tau1 =  202979.99320667773\n",
      "tau1 =  355927.3623180964\n",
      "\n",
      "\n",
      "**** iteration =  82  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34999956e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994304621510188\n",
      "l2 error for x1_hat =  0.033915725880537796\n",
      "B / (A+B) =  [0.00169009]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791140119981\n",
      "alpha1 part I =  [0.00168921]\n",
      "alpha2 part II =  [0.00115733]\n",
      "alpha1 =  0.07987819057691141\n",
      "true gam2 =  11402.721747144875\n",
      "gam2 =  22102.843795846922\n",
      "corr(z1_hat, X*beta_true) =  0.9990717789302559\n",
      "l2 error for z1_hat =  0.055340336473279336\n",
      "v1 =  0.9900138601857862\n",
      "true tau2 =  3730.575872612771\n",
      "tau2 = 3590.192568764481\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943046]]\n",
      "l2 error for x2_hat =  0.03391570068859885\n",
      "alpha2 =  0.9201184598569699\n",
      "true gam1 =  1940.4351445645566\n",
      "gam1 =  1918.8933609999829\n",
      "corr(z2_hat, beta_true) =  [[0.99907168]]\n",
      "l2 error for z2_hat =  0.05534265282737832\n",
      "true tau1 =  202932.8480037778\n",
      "tau1 =  355961.469788886\n",
      "\n",
      "\n",
      "**** iteration =  83  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35024993e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994304646009582\n",
      "l2 error for x1_hat =  0.033915653949342726\n",
      "B / (A+B) =  [0.00169006]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791377373797\n",
      "alpha1 part I =  [0.00168918]\n",
      "alpha2 part II =  [0.00115733]\n",
      "alpha1 =  0.07987814461071858\n",
      "true gam2 =  11402.807313714775\n",
      "gam2 =  22103.86493354474\n",
      "corr(z1_hat, X*beta_true) =  0.9990716829401922\n",
      "l2 error for z1_hat =  0.055342704221996795\n",
      "v1 =  0.9900151482161158\n",
      "true tau2 =  3730.5699688623267\n",
      "tau2 = 3590.068821694159\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943046]]\n",
      "l2 error for x2_hat =  0.03391580098870882\n",
      "alpha2 =  0.9201237805271697\n",
      "true gam1 =  1940.4592911747425\n",
      "gam1 =  1918.843099151357\n",
      "corr(z2_hat, beta_true) =  [[0.99907155]]\n",
      "l2 error for z2_hat =  0.055347175296161656\n",
      "true tau1 =  202931.41210409114\n",
      "tau1 =  355973.1499072856\n",
      "\n",
      "\n",
      "**** iteration =  84  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35172505e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994303444679484\n",
      "l2 error for x1_hat =  0.0339192323288532\n",
      "B / (A+B) =  [0.0016902]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791241011091\n",
      "alpha1 part I =  [0.00168932]\n",
      "alpha2 part II =  [0.00115767]\n",
      "alpha1 =  0.07986935625023031\n",
      "true gam2 =  11400.636173370109\n",
      "gam2 =  22105.929219529047\n",
      "corr(z1_hat, X*beta_true) =  0.9990715453206743\n",
      "l2 error for z1_hat =  0.05534718508319695\n",
      "v1 =  0.9900151747434339\n",
      "true tau2 =  3730.5672290961866\n",
      "tau2 = 3590.176987716138\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943034]]\n",
      "l2 error for x2_hat =  0.03391922095296159\n",
      "alpha2 =  0.9201279526227484\n",
      "true gam1 =  1940.4699188114996\n",
      "gam1 =  1918.9133651548875\n",
      "corr(z2_hat, beta_true) =  [[0.99907146]]\n",
      "l2 error for z2_hat =  0.055349434288778\n",
      "true tau1 =  202891.6409839014\n",
      "tau1 =  356002.6573623553\n",
      "\n",
      "\n",
      "**** iteration =  85  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35203434e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994303384915448\n",
      "l2 error for x1_hat =  0.0339194112204398\n",
      "B / (A+B) =  [0.00169019]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791431644003\n",
      "alpha1 part I =  [0.00168931]\n",
      "alpha2 part II =  [0.0011577]\n",
      "alpha1 =  0.07986872981958522\n",
      "true gam2 =  11400.562921649765\n",
      "gam2 =  22106.92715452665\n",
      "corr(z1_hat, X*beta_true) =  0.999071455294845\n",
      "l2 error for z1_hat =  0.05534947820790688\n",
      "v1 =  0.9900162609762023\n",
      "true tau2 =  3730.5620781870243\n",
      "tau2 = 3590.0800451293353\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943033]]\n",
      "l2 error for x2_hat =  0.03391953425698516\n",
      "alpha2 =  0.9201327106378722\n",
      "true gam1 =  1940.4909617803532\n",
      "gam1 =  1918.8757529705294\n",
      "corr(z2_hat, beta_true) =  [[0.99907133]]\n",
      "l2 error for z2_hat =  0.05535339283029309\n",
      "true tau1 =  202887.7715239436\n",
      "tau1 =  356014.46632693877\n",
      "\n",
      "\n",
      "**** iteration =  86  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.3532973e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994302369501493\n",
      "l2 error for x1_hat =  0.033922435573385534\n",
      "B / (A+B) =  [0.00169031]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791329603216\n",
      "alpha1 part I =  [0.00168943]\n",
      "alpha2 part II =  [0.00115799]\n",
      "alpha1 =  0.07986128851622126\n",
      "true gam2 =  11398.730838624137\n",
      "gam2 =  22108.73247402134\n",
      "corr(z1_hat, X*beta_true) =  0.9990713333961948\n",
      "l2 error for z1_hat =  0.05535340400730854\n",
      "v1 =  0.9900163559829842\n",
      "true tau2 =  3730.5594268798795\n",
      "tau2 = 3590.1646222672116\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943024]]\n",
      "l2 error for x2_hat =  0.03392243422510336\n",
      "alpha2 =  0.9201365422735884\n",
      "true gam1 =  1940.5013257837793\n",
      "gam1 =  1918.93239775119\n",
      "corr(z2_hat, beta_true) =  [[0.99907125]]\n",
      "l2 error for z2_hat =  0.05535555944377278\n",
      "true tau1 =  202854.04239434437\n",
      "tau1 =  356040.1067908285\n",
      "\n",
      "\n",
      "**** iteration =  87  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35364208e-06]\n",
      "corr(x1_hat, beta_true) =  0.999430225123605\n",
      "l2 error for x1_hat =  0.033922788544281365\n",
      "B / (A+B) =  [0.00169031]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791483277373\n",
      "alpha1 part I =  [0.00168943]\n",
      "alpha2 part II =  [0.00115803]\n",
      "alpha1 =  0.07986026341974366\n",
      "true gam2 =  11398.546610856454\n",
      "gam2 =  22109.693549365045\n",
      "corr(z1_hat, X*beta_true) =  0.9990712494445122\n",
      "l2 error for z1_hat =  0.055355597162795714\n",
      "v1 =  0.9900172768750721\n",
      "true tau2 =  3730.5549151008204\n",
      "tau2 = 3590.0886686355225\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943022]]\n",
      "l2 error for x2_hat =  0.033922892040814404\n",
      "alpha2 =  0.9201408039516684\n",
      "true gam1 =  1940.5197377823768\n",
      "gam1 =  1918.904524334103\n",
      "corr(z2_hat, beta_true) =  [[0.99907114]]\n",
      "l2 error for z2_hat =  0.055359036999160165\n",
      "true tau1 =  202848.52908826774\n",
      "tau1 =  356051.7656232875\n",
      "\n",
      "\n",
      "**** iteration =  88  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35472869e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994301388446076\n",
      "l2 error for x1_hat =  0.03392535813372848\n",
      "B / (A+B) =  [0.00169041]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791407659468\n",
      "alpha1 part I =  [0.00168953]\n",
      "alpha2 part II =  [0.00115828]\n",
      "alpha1 =  0.07985392974417554\n",
      "true gam2 =  11396.99241166468\n",
      "gam2 =  22111.278216598137\n",
      "corr(z1_hat, X*beta_true) =  0.9990711411920242\n",
      "l2 error for z1_hat =  0.0553590489314769\n",
      "v1 =  0.9900174184758234\n",
      "true tau2 =  3730.5523812065862\n",
      "tau2 = 3590.1547900374617\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943014]]\n",
      "l2 error for x2_hat =  0.03392536392137263\n",
      "alpha2 =  0.9201443154845365\n",
      "true gam1 =  1940.5297017993996\n",
      "gam1 =  1918.950351357114\n",
      "corr(z2_hat, beta_true) =  [[0.99907106]]\n",
      "l2 error for z2_hat =  0.055361093650400324\n",
      "true tau1 =  202819.77408802006\n",
      "tau1 =  356074.13829780166\n",
      "\n",
      "\n",
      "**** iteration =  89  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35509158e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994301231142613\n",
      "l2 error for x1_hat =  0.03392582721811236\n",
      "B / (A+B) =  [0.00169041]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791531982621\n",
      "alpha1 part I =  [0.00168953]\n",
      "alpha2 part II =  [0.00115833]\n",
      "alpha1 =  0.07985264306348522\n",
      "true gam2 =  11396.733374970328\n",
      "gam2 =  22112.19348731948\n",
      "corr(z1_hat, X*beta_true) =  0.9990710632681986\n",
      "l2 error for z1_hat =  0.055361126200562626\n",
      "v1 =  0.990018203265236\n",
      "true tau2 =  3730.548414910248\n",
      "tau2 = 3590.0952722610336\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943012]]\n",
      "l2 error for x2_hat =  0.03392591473941816\n",
      "alpha2 =  0.9201481379758459\n",
      "true gam1 =  1940.5458716401681\n",
      "gam1 =  1918.9299532627901\n",
      "corr(z2_hat, beta_true) =  [[0.99907097]]\n",
      "l2 error for z2_hat =  0.05536415888495232\n",
      "true tau1 =  202813.21004454195\n",
      "tau1 =  356085.45204810885\n",
      "\n",
      "\n",
      "**** iteration =  90  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35603086e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994300494244772\n",
      "l2 error for x1_hat =  0.03392802173416457\n",
      "B / (A+B) =  [0.0016905]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791476645799\n",
      "alpha1 part I =  [0.00168962]\n",
      "alpha2 part II =  [0.00115854]\n",
      "alpha1 =  0.07984722454325134\n",
      "true gam2 =  11395.40801013167\n",
      "gam2 =  22113.58920115505\n",
      "corr(z1_hat, X*beta_true) =  0.9990709669109543\n",
      "l2 error for z1_hat =  0.05536417110727506\n",
      "v1 =  0.9900183749878024\n",
      "true tau2 =  3730.546016468548\n",
      "tau2 = 3590.146955289464\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943005]]\n",
      "l2 error for x2_hat =  0.033928032461242846\n",
      "alpha2 =  0.9201513504397368\n",
      "true gam1 =  1940.5553473429966\n",
      "gam1 =  1918.9671718666812\n",
      "corr(z2_hat, beta_true) =  [[0.9990709]]\n",
      "l2 error for z2_hat =  0.05536609536580958\n",
      "true tau1 =  202788.5704183117\n",
      "tau1 =  356105.048899455\n",
      "\n",
      "\n",
      "**** iteration =  91  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35639916e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994300312501709\n",
      "l2 error for x1_hat =  0.033928563465687206\n",
      "B / (A+B) =  [0.00169051]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791577613134\n",
      "alpha1 part I =  [0.00168963]\n",
      "alpha2 part II =  [0.00115859]\n",
      "alpha1 =  0.07984577883722724\n",
      "true gam2 =  11395.101319322941\n",
      "gam2 =  22114.45325200654\n",
      "corr(z1_hat, X*beta_true) =  0.9990708948587799\n",
      "l2 error for z1_hat =  0.05536612358414194\n",
      "v1 =  0.9900190471944044\n",
      "true tau2 =  3730.542518129183\n",
      "tau2 = 3590.100308647753\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99943003]]\n",
      "l2 error for x2_hat =  0.0339286378666971\n",
      "alpha2 =  0.9201547832361564\n",
      "true gam1 =  1940.569596476155\n",
      "gam1 =  1918.9524911345\n",
      "corr(z2_hat, beta_true) =  [[0.99907081]]\n",
      "l2 error for z2_hat =  0.055368805415405065\n",
      "true tau1 =  202781.39731419322\n",
      "tau1 =  356115.8862644603\n",
      "\n",
      "\n",
      "**** iteration =  92  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.3572147e-06]\n",
      "corr(x1_hat, beta_true) =  0.999429967996347\n",
      "l2 error for x1_hat =  0.03393044708954767\n",
      "B / (A+B) =  [0.00169058]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791537787432\n",
      "alpha1 part I =  [0.0016897]\n",
      "alpha2 part II =  [0.00115878]\n",
      "alpha1 =  0.07984112024367489\n",
      "true gam2 =  11393.965335580733\n",
      "gam2 =  22115.68636761225\n",
      "corr(z1_hat, X*beta_true) =  0.9990708089113848\n",
      "l2 error for z1_hat =  0.05536881759203896\n",
      "v1 =  0.9900192367429304\n",
      "true tau2 =  3730.540265092741\n",
      "tau2 = 3590.140697245901\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942997]]\n",
      "l2 error for x2_hat =  0.033930461097552156\n",
      "alpha2 =  0.9201577177032593\n",
      "true gam1 =  1940.5785313570004\n",
      "gam1 =  1918.982844111207\n",
      "corr(z2_hat, beta_true) =  [[0.99907074]]\n",
      "l2 error for z2_hat =  0.05537061695596502\n",
      "true tau1 =  202760.18007679572\n",
      "tau1 =  356133.1130948071\n",
      "\n",
      "\n",
      "**** iteration =  93  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35757931e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994299484630613\n",
      "l2 error for x1_hat =  0.03393102917118465\n",
      "B / (A+B) =  [0.00169059]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791620127924\n",
      "alpha1 part I =  [0.00168971]\n",
      "alpha2 part II =  [0.00115884]\n",
      "alpha1 =  0.07983959148699914\n",
      "true gam2 =  11393.631204112377\n",
      "gam2 =  22116.4964008407\n",
      "corr(z1_hat, X*beta_true) =  0.9990707424998471\n",
      "l2 error for z1_hat =  0.05537064152465874\n",
      "v1 =  0.9900198153499494\n",
      "true tau2 =  3730.5371701887334\n",
      "tau2 = 3590.104130822031\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942995]]\n",
      "l2 error for x2_hat =  0.0339310927449768\n",
      "alpha2 =  0.9201608038617056\n",
      "true gam1 =  1940.5911269314227\n",
      "gam1 =  1918.972517225354\n",
      "corr(z2_hat, beta_true) =  [[0.99907067]]\n",
      "l2 error for z2_hat =  0.05537301961086868\n",
      "true tau1 =  202752.72325841282\n",
      "tau1 =  356143.39064068254\n",
      "\n",
      "\n",
      "**** iteration =  94  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35829039e-06]\n",
      "corr(x1_hat, beta_true) =  0.99942989390471\n",
      "l2 error for x1_hat =  0.03393265377421535\n",
      "B / (A+B) =  [0.00169065]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791592113802\n",
      "alpha1 part I =  [0.00168977]\n",
      "alpha2 part II =  [0.00115899]\n",
      "alpha1 =  0.0798355671828293\n",
      "true gam2 =  11392.652756903248\n",
      "gam2 =  22117.58894203962\n",
      "corr(z1_hat, X*beta_true) =  0.9990706656956558\n",
      "l2 error for z1_hat =  0.05537303150486178\n",
      "v1 =  0.9900200136419479\n",
      "true tau2 =  3730.535066588241\n",
      "tau2 = 3590.135685266946\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942989]]\n",
      "l2 error for x2_hat =  0.03393266982010008\n",
      "alpha2 =  0.9201634809920277\n",
      "true gam1 =  1940.5994949271437\n",
      "gam1 =  1918.9973808545033\n",
      "corr(z2_hat, beta_true) =  [[0.99907061]]\n",
      "l2 error for z2_hat =  0.055374705394597545\n",
      "true tau1 =  202734.36709573364\n",
      "tau1 =  356158.58381072653\n",
      "\n",
      "\n",
      "**** iteration =  95  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.3586449e-06]\n",
      "corr(x1_hat, beta_true) =  0.999429873809413\n",
      "l2 error for x1_hat =  0.03393325248841915\n",
      "B / (A+B) =  [0.00169067]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999479165956177\n",
      "alpha1 part I =  [0.00168979]\n",
      "alpha2 part II =  [0.00115905]\n",
      "alpha1 =  0.07983401094163314\n",
      "true gam2 =  11392.306066253164\n",
      "gam2 =  22118.3440757521\n",
      "corr(z1_hat, X*beta_true) =  0.9990706046453837\n",
      "l2 error for z1_hat =  0.05537472687209264\n",
      "v1 =  0.9900205140268485\n",
      "true tau2 =  3730.532321129064\n",
      "tau2 = 3590.107013944404\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942987]]\n",
      "l2 error for x2_hat =  0.033933307082690774\n",
      "alpha2 =  0.9201662581310024\n",
      "true gam1 =  1940.6106601502142\n",
      "gam1 =  1918.9903519173306\n",
      "corr(z2_hat, beta_true) =  [[0.99907054]]\n",
      "l2 error for z2_hat =  0.05537684083943141\n",
      "true tau1 =  202726.8628292733\n",
      "tau1 =  356168.2537889908\n",
      "\n",
      "\n",
      "**** iteration =  96  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35926733e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994298265343661\n",
      "l2 error for x1_hat =  0.03393466015231565\n",
      "B / (A+B) =  [0.00169072]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791640494436\n",
      "alpha1 part I =  [0.00168984]\n",
      "alpha2 part II =  [0.00115919]\n",
      "alpha1 =  0.079830518847257\n",
      "true gam2 =  11391.459355604915\n",
      "gam2 =  22119.314542342636\n",
      "corr(z1_hat, X*beta_true) =  0.9990705358988369\n",
      "l2 error for z1_hat =  0.0553768522886771\n",
      "v1 =  0.9900207144444333\n",
      "true tau2 =  3730.53036672483\n",
      "tau2 = 3590.1316593991173\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942983]]\n",
      "l2 error for x2_hat =  0.033934677313094866\n",
      "alpha2 =  0.9201686978634359\n",
      "true gam1 =  1940.6184544601645\n",
      "gam1 =  1919.0108144121186\n",
      "corr(z2_hat, beta_true) =  [[0.99907048]]\n",
      "l2 error for z2_hat =  0.05537840286924441\n",
      "true tau1 =  202710.9112408475\n",
      "tau1 =  356181.6935083907\n",
      "\n",
      "\n",
      "**** iteration =  97  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.35960742e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994298064534954\n",
      "l2 error for x1_hat =  0.03393525834924324\n",
      "B / (A+B) =  [0.00169074]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791696002472\n",
      "alpha1 part I =  [0.00168986]\n",
      "alpha2 part II =  [0.00115925]\n",
      "alpha1 =  0.07982897507729479\n",
      "true gam2 =  11391.11090465445\n",
      "gam2 =  22120.015272970653\n",
      "corr(z1_hat, X*beta_true) =  0.9990704799018654\n",
      "l2 error for z1_hat =  0.055378421714805386\n",
      "v1 =  0.9900211491129158\n",
      "true tau2 =  3730.5279252848827\n",
      "tau2 = 3590.1091723283635\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9994298]]\n",
      "l2 error for x2_hat =  0.03393530545803254\n",
      "alpha2 =  0.9201711989792005\n",
      "true gam1 =  1940.6283768353915\n",
      "gam1 =  1919.0062672706345\n",
      "corr(z2_hat, beta_true) =  [[0.99907042]]\n",
      "l2 error for z2_hat =  0.05538030507261245\n",
      "true tau1 =  202703.52784155513\n",
      "tau1 =  356190.7344751123\n",
      "\n",
      "\n",
      "**** iteration =  98  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.36015422e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994297653112985\n",
      "l2 error for x1_hat =  0.03393648335328131\n",
      "B / (A+B) =  [0.00169078]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791683667671\n",
      "alpha1 part I =  [0.0016899]\n",
      "alpha2 part II =  [0.00115937]\n",
      "alpha1 =  0.07982593190905854\n",
      "true gam2 =  11390.374943067915\n",
      "gam2 =  22120.87928592099\n",
      "corr(z1_hat, X*beta_true) =  0.999070418278067\n",
      "l2 error for z1_hat =  0.05538031597137554\n",
      "v1 =  0.9900213469213063\n",
      "true tau2 =  3730.526116823346\n",
      "tau2 = 3590.1284151348486\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942976]]\n",
      "l2 error for x2_hat =  0.033936500951814656\n",
      "alpha2 =  0.9201734203288028\n",
      "true gam1 =  1940.6356044410682\n",
      "gam1 =  1919.023190306375\n",
      "corr(z2_hat, beta_true) =  [[0.99907037]]\n",
      "l2 error for z2_hat =  0.055381747309054916\n",
      "true tau1 =  202689.60796294085\n",
      "tau1 =  356202.65538419184\n",
      "\n",
      "\n",
      "**** iteration =  99  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.36047712e-06]\n",
      "corr(x1_hat, beta_true) =  0.9994297456531325\n",
      "l2 error for x1_hat =  0.033937068889991095\n",
      "B / (A+B) =  [0.0016908]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9994791729573639\n",
      "alpha1 part I =  [0.00168992]\n",
      "alpha2 part II =  [0.00115943]\n",
      "alpha1 =  0.07982442867854027\n",
      "true gam2 =  11390.032416932063\n",
      "gam2 =  22121.527078264215\n",
      "corr(z1_hat, X*beta_true) =  0.9990703670124483\n",
      "l2 error for z1_hat =  0.055381763902226155\n",
      "v1 =  0.9900217260866496\n",
      "true tau2 =  3730.523940975635\n",
      "tau2 = 3590.110772756045\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99942974]]\n",
      "l2 error for x2_hat =  0.03393710972596604\n",
      "alpha2 =  0.920175674467398\n",
      "true gam1 =  1940.6444423332564\n",
      "gam1 =  1919.020495511041\n",
      "corr(z2_hat, beta_true) =  [[0.99907031]]\n",
      "l2 error for z2_hat =  0.05538344513620597\n",
      "true tau1 =  202682.4621568347\n",
      "tau1 =  356211.0650018908\n",
      "\n",
      "\n",
      "Saving results!!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB8UAAALFCAYAAABanDJaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxWZf7/8fcNyuKuqaBI4lZmo2CaZJNbQ+JSmWQu9U2jslFjymiyaBTLalAzBjPTxrLUNptEpykHM0YcTcLGpZrSMjcUAZdGSVTQm/v3x/07t/cNNwgK3Auv5+NxHvd9rnOdc66Dy+E6n/O5LpPFYrEIAAAAAAAAAAAAAAAv5OPqBgAAAAAAAAAAAAAAUFMIigMAAAAAAAAAAAAAvBZBcQAAAAAAAAAAAACA1yIoDgAAAAAAAAAAAADwWgTFAQAAAAAAAAAAAABei6A4AAAAAAAAAAAAAMBrERQHAAAAAAAAAAAAAHgtguIAAAAAAAAAAAAAAK9FUBwAAAAAAAAAAAAA4LUIigMAAADwenv37pXJZJKPj4+OHTvmtM67774rk8kkk8mkd99912mdY8eOycfHRyaTSXv37q3JJuudd96RyWTSAw88UKP7eLLnnntOJpNJzz33XJX3feCBB2QymfTOO+9Ue7vWrl2rO+64Q8HBwapfv74aN26sXr166cUXX9Svv/5a7n7FxcWaM2eOwsPD1bBhQzVv3lwDBw7Uxx9/fMlz/u1vf9PAgQPVvHlzNWzYUOHh4Zo7d67Onz9fbddVWFio999/X08++aQGDhyoJk2ayGQyqXPnzpXaPz8/X3FxcerQoYP8/f0VFBSke+65R9u3b69wvyv5udQVV/JvAQAAAADqAoLiAAAAALxep06dFBoaKovFoo0bNzqts2HDBtv3jIwMp3UyMjJksVgUGhqqTp061URTUQ0yMjJkMpk0cODAWj/3008/reHDh+vTTz9VaGio7r77bvXt21e7d+/WjBkz1KtXL+Xn55fZ78yZMxo0aJCeeeYZZWdna8iQIerTp4++/PJL3XPPPfrjH/9Y7jmnTp2q0aNH68svv1SfPn00ZMgQZWdn6+mnn9att96qs2fPVsu17dmzR/fdd5+Sk5O1cePGCgP8pf3000/q0aOHFi5cKB8fH911111q3769Pv74Y0VGRmr16tVO97uSn4snIJgNAAAAALWDoDgAAACAOmHQoEGSHIPf9jIyMtSqVSu1a9euwqC4/bHczciRI7Vr1y4lJSW5uim1Ii4uTrt27VJcXJyrmyJJ2rFjh+bOnav69evr888/19dff60PP/xQn3/+uQ4cOKDw8HDt2bNHM2fOLLPvs88+qy1btqh79+7as2ePVq1apXXr1umrr75So0aN9Morr+jTTz8ts9+aNWs0f/58NWrUSFlZWVq3bp1WrVqlPXv2qHv37tq8ebNmzJhRLdfXuHFjxcbGasGCBdq8ebPT9jhjsVg0duxYHT16VPfff79++uknrVy5Ulu3btUbb7yhCxcuaPz48crLyyuz7+X+XOoad/u3AAAAAADuhqA4AAAAgDqhoqD4oUOHtG/fPg0YMEADBgzQ3r17dejQoTL1jH3dNSjetGlTde3aVW3atHF1U2pFy5Yt1bVrV7Vs2dLVTZEk/etf/5Ik3XbbbbrtttsctrVq1UrTpk2TJGVmZjps+9///qdFixZJkhYtWuRwPb169dLTTz8tSXrppZfKnPPPf/6zJOmZZ57RDTfcYCtv2bKlXn/9dUnSa6+9plOnTl3RtUnWEReWLl2quLg4/fa3v1XDhg0rtd8///lP7dixQ82aNdPrr78uX19f27ZHHnlEv/vd73T69GnNnz/fYb8r+bnUNe72bwEAAAAA3A1BcQAAAAB1ghHI3rVrV5nhq40M8IEDB2rAgAEOZYb8/Hzt2rXL4ViGrVu3avTo0Wrbtq38/PzUunVr3XHHHVq/fr3TttjPZ/3f//5XY8aMUZs2beTr61upYZT37dunrl27ymQy6YknnlBJSYmk8ucUtx9O/Pz585ozZ46uv/56BQYG6qqrrlJMTIzt2pzZvHmzhgwZombNmqlRo0a68cYbtXz5ckmyzcNeWTfccINMJlOZeaSPHj1qm6/dCB7bu/XWW2UymWyBZ8n50NMDBw60/fls3LjR1j6TyaSwsDCnbdq/f7/uv/9+BQcHy9/fX506ddL06dNVVFRU6euSpICAgErVKx24XLt2rYqLi3X11Vfrt7/9bZn69957ryTpq6++0pEjR2zlOTk5+vrrrx3q2LvlllsUGhqqoqIirV271lb+8ccfy2QyqVWrVjp8+HCZ/datWydfX181bdpUe/bsqdQ1VcQYGv3OO+9Uo0aNymw32p6amupQfrk/l0sJCwuTyWTSgQMH9M9//lMDBw5U06ZN1bx5c91+++367rvvbHXff/999e3bV40bN1azZs0UExOjvXv3Oj1uamqqHn74Yf3mN79R8+bNFRAQoA4dOujBBx/Ujz/+WKa+yWTS888/L0l6/vnnHf6u2v8btm/v3//+d916661q0aKFTCaT7f8pZ/8WfvnlF7Vv314mk0mLFy8uc/7Tp0/b/h+ZM2dOpX9+AAAAAOCJCIoDAAAAqBPat2+vDh06SCob8DbWjUxxqWxGuVGnQ4cOat++va18yZIl6tu3r/72t78pODhYo0aNUpcuXfTpp59q8ODBtqCXM1u2bFHv3r21detW9e/fX8OHD1fjxo0rvI6vvvpKN910k/bs2aMFCxboL3/5i3x8Kte1O3/+vIYNG6ZZs2bp6quv1vDhw9WwYUOtXr1aN998sw4cOFBmnw8//FADBgzQunXrdPXVV+vOO+9UgwYNFBsbq2eeeaZS57UXFRUlSfriiy8cyr/44gtZLBan286ePastW7YoMDDQaXDU3pAhQxQdHS1JCgoK0oQJE2zLqFGjytTfuXOnIiIitGnTJg0YMED9+/dXbm6uXnrpJY0dO7bK11avXj2tX7++zDUcO3ZMc+fOlST9/ve/d9i2Y8cOSVLv3r2dHrdjx45q0aKFrb2l92vRooXt73ZpxjGNupI0atQo/eEPf9Dx48c1btw4XbhwwbYtJydH999/v0pKSrRkyRJ16dLlktd9KZe6PqN8z549KiwsrPR+5f1cKuuNN97Q8OHDdeHCBQ0ZMkStW7fWZ599pv79+2vv3r2aNm2aJkyYoAYNGmjIkCFq0qSJVq9erf79++t///tfmeONHj1aH3zwgQIDA3XrrbcqOjpaPj4+evvtt9WrVy9t2bLFof6ECRMUHh4uSQoPD3f4u3rLLbeUOf4rr7yiu+66S7/++quGDBmiAQMGOGTdl9aiRQt99NFHql+/vp544okyP6NHHnlEP/74o4YPH+70RRQAAAAA8CoWAAAAAKgjHnzwQYsky+9//3uH8o4dO1patWplKSkpsVgsFktwcLClQ4cODnUmTZpkkWR58MEHbWXffvutpV69ehaTyWRZvny5Q/21a9da/Pz8LJIsn3/+ucO2CRMmWCRZJFmeeeYZi9lsLtPWt99+2yLJMmHCBFvZxx9/bAkMDLQ0aNDA8ve//71S+1gsFsuGDRts5+vZs6clNzfXtu3s2bOW6OhoiyTLI4884rBfTk6OpVGjRhZJlvnz5zts27hxo6Vhw4a241bWunXrLJIst912m0N5bGysRZKlR48eFpPJZDl27Ngl95k5c6ZFkmXmzJlOr3fAgAHltsP+z+BPf/qT5cKFC7Zt3333ne3atmzZUulrs1gslkWLFlnq1atnkWS58cYbLWPGjLEMHjzY0qBBA0ubNm0sS5YsKbNPTEyMRZJl6tSp5R63R48eFkmW1157zVb26quvWiRZIiIiyt3vscces0iyjBo1yqG8qKjI0qdPH4sky9NPP22xWCyW8+fPW2655RaLJMujjz56yWs1fs6dOnWqsF6LFi0skixr1qxxuv2XX36x/Vn897//tZVf7s/lUtq3b2+RZPH397d88cUXtvILFy5Y7rnnHosky29+8xvLVVddZdm5c6dte2FhoeXmm2+2SLK8+OKLZY774YcfWk6fPu1QVlJSYlm4cKFFkuX666+3/R9jKO/vsLP2+vr6Ov13f6nj/OUvf7FIsnTp0sVSUFBgsVisf08lWa6++mrLiRMnyj03AAAAAHgLMsUBAAAA1BnO5hXPzs7Wvn371L9/f9sw4AMGDND+/ft18OBBWz1n84nPnz9fFy5c0MiRI3X//fc7nGvo0KF65JFHJEkvv/yy0/Zcc801evHFFyuV6T1v3jzdc889atKkiTZu3Kg777yzMpfswGQy6e2331ZwcLCtLCAgwJbNXjq7+a233tLp06fVt29fPfbYYw7b+vfvr8mTJ1e5Df369ZO/v782b97sMDx5enq62rdvr9///veyWCxKT0+3bTPaZWSZV6devXrphRdecMi4/c1vfmP78yz9M7mUSZMm6bPPPlPr1q319ddfa+XKlfr888915swZ9evXz2nW86+//ipJFc7RbQw7XlBQcMX7SZKfn59Wrlyp5s2ba+7cuVq7dq3+9Kc/afPmzerVq5deeeWVSl7xpV2qnfZDqlfX9VXGY489pt/97ne2dV9fXyUkJEiS/vvf/2rWrFm2TG5JatCggZ588klJcvj7aRgzZkyZtppMJk2ZMkV9+/bV999/X+E0BZcyYcKEy/p3P3XqVMXExGjPnj2aOHGiduzYoalTp6p+/fpauXKlLdseAAAAALwZQXEAAAAAdYYR0P7pp5+Um5sryXHodEPpecXz8vJscwLbB8WN7aXn8DY89NBDkqRNmzbJbDaX2X7XXXdVOPyxJJnNZk2ZMkVPPfWUunbtqq+++qrc4aQv5eqrr3YI8hmuu+46Sdahs+1t3LhRknTfffc5PV555RUJDAzUzTffrLNnz2rz5s2SrH8e2dnZuu2225wOr16TQfHbb7/d6Zzo5f1MLmX69OmKjo7WDTfcoK+//lqnT5/Wvn379MILL2jNmjW6+eab9fnnn1dL269UWFiY3nnnHUnSuHHj9PLLL6tp06b66KOP5O/v79rG1YJhw4aVKbMfLr6i7eXNYf7zzz/rtdde09SpU/XQQw/pgQce0AMPPKD8/HxJcjq3eGU5G/6/spYuXaqOHTtq5cqVGjRokIqKijR79mzddNNNl31MAAAAAPAk9VzdAAAAAACoLSEhIerSpYv27NmjDRs26N5777UFtgcOHGirZx8UnzBhgq1Oly5dFBISYqtnBEzLm8+5U6dOkqRz587pxIkTat26tcP2sLCwS7b5ww8/1IULF9S6dWt9+eWXat68eWUu1amrr77aaXmTJk0kySFzW5IOHz5cYTsr035noqKitGHDBn3xxRf63e9+Zwt633bbbbrmmmsUGhpqKztx4oR27typq666Sj179rys81XkUj+Tc+fOVfpY7733nl566SX16NFD//jHP1SvnrXL3aFDB02fPl316tVTQkKCJk2apD179theiDDmkbefT7u006dPO7TrSvazd+edd+rhhx/WkiVLJEl//etf1bFjx0pdb2U1btxYv/zyS7ntNNpYup3VcX0VcfZnb5+17my70abSfy/MZrPi4uL0xhtvyGKxlHvOy8loN1zuvzdJatq0qVasWKHf/va3OnXqlIYNG6b4+PjLPh4AAAAAeBoyxQEAAADUKaWHUM/IyNBVV12l3/zmN7Y63bp1U6tWrWx1nA2dXh0CAwMvWadfv37q0KGDjh49qqeeekolJSWXfb7KDNPujLNM6orKL8XI+F6/fr0kaya4j4+PbSjrqKgoHThwQD///LPS09NlsVh06623Xvb5KnK5PxNnjKzre+65xxYQt3fvvfdKkvbv3699+/bZyo1gZ3Z2drnHdvaCgvH90KFD5e5nbCsvoHrixAn985//tK1/9dVX5R7rcl3q+ow2mkwmtW/fvtL7SZd+caMil/qzr8rfjfnz52vx4sUKCgrS+++/rwMHDujs2bOyWCyyWCwaN26cJFUYML+Uyvx/UZEVK1bYvu/atUunTp26ouMBAAAAgCchKA4AAACgTrEPimdnZ2v//v0O84kb+vfvr4MHD+rAgQO2TPHSQXEja9w+wGnPKA8ICLjseXuvvvpqbd68Wdddd53eeust3Xvvvbpw4cJlHauqjOs7cOCA0+3llV9K79691axZM+3YsUPHjh3Thg0bFBERoauuukqSHIZQr8mh06ubEbwtL2u5adOmtu+//PKL7fsNN9wgSfrPf/7jdL99+/bZ6ttnyxvfT5w4of379zvd1zimcQ57FotF999/vw4fPqy77rpLLVq00F/+8hd98sknzi/wMl3q+ozyLl26OGRqX+7PxRU++ugjSdIbb7yhcePGqX379goICLBt37Nnj6uaJsk64oQRtB8+fLj279+vBx980KVtAgAAAIDaRFAcAAAAQJ1iDJO+d+9evfvuuw5l9owh1N977z399NNPTusZ60aGcGlLly6VZM32dpY5XFlt27bVv//9b/Xs2VMrV65UTExMmaHOa0L//v0lSR988IHT7e+///5lHdfHx0eDBg1SSUmJ5s6dq5MnT+q2226zbf/d734nk8mk9evXX1ZQ3M/PT5Jq7eUBg/ESQVZWltPt9lnY9pnNw4YNk5+fn7Kzs/Xll1+W2c/4Od90001q27atrbxdu3a68cYbHerY27x5sw4dOiR/f3+n82PPnj1b//znP3Xdddfp3Xff1bJly2QymfTAAw/o4MGDlbjiyhk5cqQk6ZNPPnE6FLrR9piYGIfyy/25uIIRnLfPdDd8//332rlzp9P9auPv6k8//aRHHnlEPj4+eu+99/T++++rU6dOSk1N1auvvlpj5wUAAAAAd0JQHAAAAECdEhwcrOuuu06S9Morr0iqOCienJwsSbruuusUHBzsUOfxxx9XvXr1tGbNGluA3fD555/rjTfekCT98Y9/vOJ2t2zZUhs2bNBvf/tb/eMf/9Dw4cMrnGu5Ojz00ENq0KCBNm/erIULFzps+/LLL/X6669f9rGNIPdrr70mSQ5B8aCgIP3mN7/R2rVrtX//fnXo0KFK81y3a9dOkjU79/z585fdxqoaNWqUJOtLBB9++KHDtn379unxxx+XZA36BwUF2bY1b95ckydPliRNmTJFJ06csG3bvn275syZI0n605/+VOaczz77rCRrgHv79u228hMnTmjKlCmSpLi4OIcsdUn697//rRkzZqhBgwb629/+poYNG+r222/Xk08+qf/9738aPXp0tf3shg4dqp49e+rkyZOaMmWKzGazbdtf//pXpaenq1GjRrafj+FKfi61zfg/ZeHChQ5THOTm5mr8+PHlBr2Nv6vff/99jbTr3Llzuueee/Trr79qxowZ+t3vfqcmTZroo48+kr+/v5566il9/fXXNXJuAAAAAHAnBMUBAAAA1DnGMOi//PKLWrRooe7du5ep0717d7Vo0cKWAepsPvHu3btr4cKFMplMuv/++9WrVy/dd999uuWWWzRkyBAVFRXpueee0+DBg6ul3U2bNtW6desUFRWl9PR03XbbbTp58mS1HNuZdu3a6Y033pCPj4/i4uIUHh6ue++9VwMHDlT//v01adIkSVL9+vWrfGwjKH7u3DkFBgbqlltuKbP93LlzDnUr6+qrr1bv3r119OhRde/eXf/3f/+nhx9+WM8880yV21kVjzzyiG6//XbbHNLdu3fX6NGjNWjQIF1//fX68ccf1a5dO/31r38ts++f//xn9e3bV99++626dOmiUaNGaejQobrpppt0+vRpxcfH6/bbby+z31133aXHHntMp0+f1k033aShQ4dq1KhR6ty5s7777jv99re/1QsvvOCwz7FjxzRu3DiZzWYtXLhQ119/vUM7brrpJm3dulXTpk0rc76RI0fqpptu0k033WQLuh8+fNhWdtNNN+nNN9902MdkMumDDz5Qq1attHz5cl1zzTUaO3asIiMj9fvf/1716tXT8uXLy7x0ciU/l9r27LPPys/PT0uWLNG1116rMWPGaOjQoerUqZOKiops2fKlRUdHq2HDhlqzZo1uueUWxcbG6uGHH9bbb79dLe36wx/+oG+//Va33nqrEhMTbeU33HCD5s2bp+LiYo0ZM6ZG/x8BAAAAAHdAUBwAAABAnWMf4HY2n7hkDeT169fP6T72HnnkEW3ZskWjRo3SkSNH9NFHH2n37t0aNmyYPv/8c82cObNa296wYUN9+umnGjFihDIzMzVo0CAdO3asWs9h7//+7//0r3/9S7fddpsOHDigv//97/r111+1ZMkSPfbYY5KsWexVdc011yg0NFSSdMstt8jf399hu30g/HLmE1+1apXuvfdeFRQUaOXKlXrrrbfKZG9Xt3r16umTTz7RsmXLFBUVpby8PK1evVr/+c9/1LVrV82YMUPffvut06z3Bg0aKCMjQ0lJSQoJCdHatWuVmZmpvn376qOPPrKNauDM/PnztXLlSvXt21dbtmzR2rVr1a5dO82ePVv/+te/FBgYaKtbUlKi//u//9ORI0c0YcIEPfDAAw7Hql+/vlauXKkWLVooJSVFa9ascdi+Y8cOZWVlKSsrS7t27ZIkFRUV2cqysrJ0+PDhMm289tpr9e233+rRRx+V2WzW6tWrtX//fsXExCgrK6vcoPGV/FxqU2RkpP7zn//ozjvvVGFhoT755BPt3btXf/jDH5SZmVnuPPNBQUH65z//qaioKP3www9avny53nrrLW3cuPGK2/Tee+/pzTffVFBQkN577z35+Dg+AoqLi9OoUaOYXxwAAABAnWCyWCwWVzcCAAAAAOB5li9frgkTJuiOO+7QJ5984urmAAAAAAAAOEWmOAAAAACgXNnZ2crLyytT/uWXX9rmSo+Nja3tZgEAAAAAAFRaPVc3AAAAAADgvv71r3/poYceUnh4uK6++mr5+vpq7969+uabbyRZA+LlDX0NAAAAAADgDhg+HQAAAABQrt27d2vevHnatGmT8vPzVVhYqGbNmikiIkIPPvigxo0b5+omAgAAAAAAVIigOAAAAAAAAAAAAADAazGnOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXougOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXougOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXougOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXougOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXougOAAAAAAAAAAAAADAaxEUBwAAAAAAAAAAAAB4LYLiAAAAAAAAAAAAAACvRVAcAAAAAAAAAAAAAOC1CIoDAAAAAAAAAAAAALwWQXEAAAAAAAAAAAAAgNciKA4AAAAAAAAAAAAA8FoExQEAAAAAAAAAAAAAXqueqxvgqUpKSnTkyBE1btxYJpPJ1c0BAHgYi8WiX3/9VW3btpWPD++ouQL3cgDAleBe7nrcywEAV4r7uetxPwcAXImq3MsJil+mI0eOKDQ01NXNAAB4uEOHDqldu3aubkadxL0cAFAduJe7DvdyAEB14X7uOtzPAQDVoTL3coLil6lx48aSrD/kJk2auLg1AABPU1BQoNDQUNv9BLWPezkA4EpwL3c97uUAgCvF/dz1uJ8DAK5EVe7lBMUvkzGUS5MmTbhZAwAuG0ODuQ73cgBAdfCGe/m///1vvfzyy9q2bZtyc3O1evVq3XXXXRXuk5GRofj4eH3//fcKDQ3V9OnT9cADDzjUWbhwoV5++WXl5eUpPDxcCxYsUJ8+fWzbz507pyeffFIffvihioqKFB0drddff11BQUGVajf3cgBAdfGG+7mn4n4OAKgOlbmXM1EKAAAAAAB1WGFhocLDw7Vw4cJK1d+/f7+GDx+uQYMGaefOnZo6daoefvhhrVu3zlZn5cqVio+P18yZM7V9+3aFh4crOjpaR48etdV54okn9I9//EN/+9vftHHjRh05ckQxMTHVfn0AAAAAABAUBwAAAACgDhs6dKhefPFFjRw5slL1Fy9erA4dOuiVV17Rddddp7i4OI0aNUp/+ctfbHWSk5M1ceJExcbGqlu3blq8eLEaNGigpUuXSpJOnTqlt956S8nJybr11lvVq1cvvf3229qyZYu++uorp+ctKipSQUGBwwIAACpv4cKFCgsLU0BAgCIjI7V169Zy66ampqp3795q1qyZGjZsqIiICK1YscKhjsViUWJiotq0aaPAwEBFRUVpz549NX0ZAABcFoLiAAAAAACg0jIzMxUVFeVQFh0drczMTElScXGxtm3b5lDHx8dHUVFRtjrbtm3T+fPnHep07dpVV199ta1OaUlJSWratKltCQ0Nre5LAwDAa1VmFBd7LVq00J/+9CdlZmbq22+/VWxsrGJjYx1Ghpk7d65effVVLV68WFlZWWrYsKGio6N17ty52rosAAAqjaA4AAAAAACotLy8vDLzfgcFBamgoEBnz57V8ePHZTabndbJy8uzHcPPz0/NmjUrt05pCQkJOnXqlG05dOhQ9V0UAABe7lKjuJQ2cOBAjRw5Utddd506deqkxx9/XD169NDmzZslWbPEU1JSNH36dI0YMUI9evTQ8uXLdeTIEa1Zs6YWrwwAgMpx+6D4v//9b91xxx1q27atTCZTpW6oGRkZuuGGG+Tv76/OnTvrnXfeKVOnKkPF1Clms5SRIX3wgfXTbK789ivZFwAAb8C9DgCAGuPv768mTZo4LJ7kcrvTNdVNr8nuPwDAvVRmFJeKWCwWpaen68cff1T//v0lSfv371deXp7DMZs2barIyMgKj1nb06FwzwIAGOq5ugGXUlhYqPDwcD344IOKiYm5ZP39+/dr+PDhmjRpkt577z2lp6fr4YcfVps2bRQdHS3p4lAxixcvVmRkpFJSUhQdHa0ff/xRrVu3rulLcj2zWdq0ScrNldq0kfr1k3x9pdRU6fHHpcOHL9Zt106aP1+Kial4u1R2W0iI9MgjUpcu0p490pIl5W83fu5Hj1rbdPPN0pYtF9tov16Vup64rye00duvzxPayPW5/jz2/38C0qXvowAAeIng4GDl5+c7lOXn56tJkyYKDAyUr6+vfH19ndYJDg62HaO4uFgnT550yBa3r+NNqtqdvpKudsuW0v/9n9S8efnd8P/9T3rvPenYscoft7L71tav8u7YvfD0Nnl6+92xTZ7efndsU+m6dMsrp6JRXHbv3l3ufqdOnVJISIiKiork6+ur119/Xbfddpsk2UZ2qWhkGGeSkpL0/PPPX+6lVAnddACAA4sHkWRZvXp1hXWmTZtmuf766x3KxowZY4mOjrat9+nTx/Loo4/a1s1ms6Vt27aWpKSkco977tw5y6lTp2zLoUOHLJIsp06duryLqUkXLlgsGzZYLO+/b/28cOHitlWrLJZ27SwW6eISEmKxjBnjWFZ6uf32irdX9+LrW/F6Vep64r6e0EZvvz5PaCPX5/rztGtn/X/1Mpw6dcritveROqJa/wxWrbJYTKayf4dMJutymX9PAADuy1vv5ZXtd//mN79xKBs3blyZfndcXJxt3Ww2W0JCQmz97pMnT1rq169v+fjjj211du/ebZFkyczMrFRbPeXPoKJfE8r7NdTTl9r6Vb62fu2vS23y9Pa7Y5s8vf3u2Cb75Qq65RaLxXPuJVcqJyfHIsmyZcsWh/KnnnrK0qdPn3L3M5vNlj179lh27NhhmTdvnqVp06aWDRs2WCwWi+XLL7+0SLIcOXLEYZ977rnHMnr06HKPWVvP2emmA0DdUJV7udsPn15VmZmZDkO2SFJ0dLRtyJbLHSomKSlJTZs2tS2hoaE1cwGXyxgH5oknrK9JDhok3Xuv9bN9e2nWLOu2u+92fDVOknJypJUrKz7+p5/WWNOdcjZu2+XW9cR9a+s8XJ/rz8P11cy+tXWenBxp1Cjrq8e4pKpMXZKamqrevXurWbNmatiwoSIiIrRixQqHOhaLRYmJiWrTpo0CAwMVFRWlPXv21PRllGU2W189t1jKbjPKpk5ljDYAgNs6ffq0du7cqZ07d0qyjsC2c+dOZWdnS7LO5T1+/Hhb/UmTJmnfvn2aNm2adu/erddff10fffSRnnjiCVud+Ph4LVmyRMuWLdOuXbs0efJkFRYWKjY2VpJ1eNWHHnpI8fHx2rBhg7Zt26bY2Fj17dtXN910U+1dfA2rzK8J3qi2fpWvSl3aVP11aVP116VNVa9Lt7xyWrZseclRXJzx8fFR586dFRERoSeffFKjRo1SUlKSJNn2q+oxa2M6FLrpAABnvC4onpeX53TIloKCAp09e7bCoWIqGtYlISFBp06dsi2HDh2qkfZXmv1kKLNmSWFh1gB4SorjGGaS9bfDmTOt2wAA1YeeVKUZU5fMnDlT27dvV3h4uKKjo3X06FGn9Vu0aKE//elPyszM1LfffqvY2FjFxsZq3bp1tjpz587Vq6++qsWLFysrK0sNGzZUdHS0zp07V1uXZbVpU9kXzuxZLNKhQ9Z6AAC4of/85z/q2bOnevbsKcka0O7Zs6cSExMlSbm5ubYAuSR16NBBn332mdavX6/w8HC98sorevPNN21TlknSmDFjNG/ePCUmJioiIkI7d+5UWlqaQ1/8L3/5i26//Xbdfffd6t+/v4KDg5XqRVENs1lasKDiXxMAAFeGbnnl+Pn5qVevXkpPT7eVlZSUKD09XX379q30cUpKSlRUVCTJ+vtAcHCwwzELCgqUlZVVpWPWBLrpAABn3H5OcXfh7+8vf39/VzfDytlkKAAA17DvSQ0c6OrWuK3k5GRNnDjRlh22ePFiffbZZ1q6dKmeeeaZMvUHlvpZPv7441q2bJk2b96s6OhoWSwWpaSkaPr06RoxYoQkafny5QoKCtKaNWs0duzYMscsKiqydd4la2e9WuTmVm89AABq2cCBA2WpIG35nXfecbrPjh07KjxuXFyc4uLiyt0eEBCghQsXauHChZVuq6eg2w4AtYdueeXEx8drwoQJ6t27t/r06aOUlBSHUVzGjx+vkJAQWyZ4UlKSevfurU6dOqmoqEhr167VihUrtGjRIkmSyWTS1KlT9eKLL6pLly7q0KGDZsyYobZt2+quu+5y1WVKopsOAHDO64LiwcHBTodsadKkiQIDA+Xr63tZQ8XUCLPZ+ttabq51yPN+/SRf34q3//3v1jGBvHmcNQDwRPSkymVMXZKQkGArq8zUJQaLxaJ//etf+vHHHzVnzhxJ1mFd8/LyHKZDadq0qSIjI5WZmek0KJ6UlKTnn3++Gq6olDZtqrceAADwaKmpdNsBwBXolldszJgxOnbsmBITE5WXl6eIiAiHUVyys7Pl43NxYNnCwkJNmTJFhw8fVmBgoLp27ap3331XY8aMsdWZNm2aCgsL9cgjj+jkyZO65ZZblJaWpoCAgFq/Pnt00wEAznhdULxv375au3atQ9n69ettQ7bYDxVjvLFmDBVT0Rvs1c7Za+Pt2knz50sxMc63h4RI587RswYAd0RPqlwVTV2ye/fucvc7deqUQkJCVFRUJF9fX73++uu67bbbJMk25UlVpkNJSEhQfHy8bb2goEChoaGXdU0O+vWz3sNzcpzfo00m6/Z+/a78XAAAwK1VNIcpAKBm0S2/tIpGccnIyHBYf/HFF/Xiiy9WeDyTyaRZs2Zp1qxZ1dXEakE3HQDgjNsHxU+fPq2ff/7Ztr5//37t3LlTLVq00NVXX62EhATl5ORo+fLlkqRJkybptdde07Rp0/Tggw/qX//6lz766CN99tlntmNcaqiYGlfea+M5OdbyP/5RmjfP+XYAgHuhJ1VjGjdurJ07d+r06dNKT09XfHy8OnbsWGZo9cqqsalQfH2tL7WNGmX9+2B//zaZrJ8pKY6jwQAAAK90qTlMAQDVj245SqObDgBwxufSVVzrP//5j3r27KmePXtKsga0e/bsqcTERElSbm6usrOzbfU7dOigzz77TOvXr1d4eLheeeUVvfnmm4qOjrbVGTNmjObNm6fExERFRERo586dDkPF1KiKXhu3WKxLcjKvlQOAJ6AnVSktW7a8rKlLfHx81LlzZ0VEROjJJ5/UqFGjbHObGfu5xXQoknWUl48/ltq2dSxv185aHhNT+20CAAC1jqF7AaB20S1HeYxuekiIYznddACou9w+KD5w4EBZLJYyyzvvvCNJeuedd8oM7TJw4EDt2LFDRUVF2rt3rx544IEyx42Li9PBgwdVVFSkrKwsRUZG1vzFSJV7bdxsrp22VIbxm2Vpt99e8fYxY6y/Ydhr1056/nnp/fetn6W32yv9W2xFv9Veqq4n7ltb5+H6XH8erq9m9q2t89CTqhT7qUsMxtQlxvQmlVFSUqKioiJJ1pfggoODHY5ZUFCgrKysKh2zWsXESDt3Xlx/9VVp/37+fgAAUIdU19C9l9PVnjpVatXK+bbyuuGtWln3c7btSvatrV/lq1KXNlV/XdpU/XVpU9Xr0i1HRWJipAMHLt4fx4yhmw4AdZnbD5/uddzptfGpU6XmzaUlSxwD9aGh1tcrpbLzmhvbypv33H672Wx9CSA31/pkoF8/x99i//Sni9tbt7aWHT1qrXvzzdKWLRf3tV+vSl1P3NcT2ujt1+cJbeT6XH8eZ/+voVyXmrpk/PjxCgkJsWWCJyUlqXfv3urUqZOKioq0du1arVixQosWLZJknbds6tSpevHFF9WlSxd16NBBM2bMUNu2bXXXXXe56jKlkpKL37t35+8HAAB1zKXmMK2IMfxvcrL0xBOX19WeN6/y3fDS2yvaVtV9a+NXeXfsXnh6mzy9/e7YJk9vvzu2qXRduuW4FPu/H61b8/cFAOoyk8XCON2Xo6CgQE2bNtWpU6fUpEmTyu+YkSENGlRj7bJp1Uq6776Kg97GK3EV9agvFdi+1HYAgFOXfR/xYK+99ppefvll5eXlKSIiQq+++qptpJaBAwcqLCzMNhLM9OnTtXLlSh0+fFiBgYHq2rWrHn/8cY0ZM8Z2PIvFopkzZ+qvf/2rTp48qVtuuUWvv/66rrnmmkq1p0b+DHJyLqZKff65dNtt1XNcAIDbqYv3cnfjrn8GqanS3XeXLbef07S8+U2NbEe62gBQO9z1XlKX1MafQdOmUkGB9Mgj0htv1MgpAAAuUpX7CEHxy3TZN2uzWQoLq/i1cV9fa6ZZVf5o2rWTJk6UunSpemAbAFDr6Hi7Xo38GRw4IHXoYP2+dq00dGj1HBcA4Ha4l7ueO/8Z3Hij9J//OJZVdlA2AEDtced7SV1RG38G/v5ScbE0fry0bFmNnAIA4CJVuY8wfHpt8/WV5s+XRo0q/9Xw+HjrmGeV0aKF9NFH0sCB5Qe6fX2t2wEAQM0qLr74/fx517UDAAC4TEGB9N131u9vvSUFBpZ9P33ECN5dBwCgNlgsF7vq5865ti0AANciKO4KMTHWMdFKvxrert3FV8Nvusk6/Pml7tS//GLtOdN7BgDA9ewD4RcuuK4dAACg1hmDtH38sVRUJF1zjRQbe/H9d3u8uw4AQO0oKrr4naA4ANRtPq5uQJ0VE2MdYrVVK+v6okXS/v0Xx0ozAuOVkZtbI00EAABVZB8UJ1McAIA6IzXVOlPaoEHSwoXWstxcafVqlzYLAIA6j6A4AMBAUNyVfH2lxo2t38PDy2Z7BwRU7jht2lRvuwAAwOUhUxwAgDonNdU6Q5r9QHCSdPq0tTw11TXtAgAAjoFwguIAULcRFHe1ev9/BHtnD85btKh4X5NJCg21Tj4GAABcj0xxAADqFLPZOjOaxVJ2m1E2daq1HgAAqH32meL23wEAdQ9BcVerKCheUnLxe+lJyIz1lBTmEwcAwF0QFAcAoE7ZtKlshrg9i0U6dMhaDwAA1D4yxQEABoLirlZRUNwoe/hhKSTEcVu7dtLHH1+cgxwAALhecfHF7wyfDgCA18vNrd56AACgejGnOADAUM/VDajzjKC4s2wy42F6797S4sXWV8tzc61ziPfrR4Y4AADuhkxxAADqlDZtqrceAACoXmSKAwAMBMVdrX5962dFmeL161sD4AMH1lqzAADAZbAPhJMpDgCA1+vXzzqQW06O83nFTSbr9n79ar9tAACAoDgA4CKGT3e1ioZPNx6s1+PdBQAAPAKZ4gAA1Cm+vtL8+c63mUzWz5QUBnoDAMBVGD4dAGAgKO5qlZlTnKA4AACegUxxAAA8mtksZWRIH3xg/TSbL71PTIz08cdS48aO5e3aWctjYmqipQAAoDLsA+H2AXIAQN1DUNzVCIoDAOA9yBQHAMBjpaZKYWHSoEHSvfdaP8PCrOWXEhNjrS9JEyZIGzZI+/cTEAcAwNVKZ4o7m+4EAFA3EBR3NSPg7ezBOUFxAAA8S3Hxxe8ExQEA8BipqdKoUdLhw47lOTnW8soExvfssX7ee680cCBDpgMA4A5KD5lu320HANQtBMVdrX5962dFmeJGHQAA4N4YPh0AAI9jNkuPP+48c8womzq14qHUzWbp55+t36+5ptqbCAAALlPpIdOZVxwA6i6C4q5W0fDpxoN1MsUBAPAMDJ8OAIDH2bSpbIa4PYtFOnTIWq88Bw9ab/3+/tLVV1d/GwEAwOUpHQQnKA4AdRdBcVdjTnEAALwHmeIAAHic3Nwrr/fTT9bPLl0kH560AADgNsgUBwAY6Kq5GkFxAAC8B5niAAB4nDZtrryeERRn6HQAANxL6SB46SA5AKDuICjuakbA29mDc4LiAAB4FjLFAQDwOP36Se3aSSaT8+0mkxQaaq1XHoLiAAC4JzLFAQAGguKuVplM8fr1a689AADg8hUXX/xOpjgAAB7B11eaP9/6vXRg3FhPSbHWKw9BcQAA3BNzigMADATFXc0IeDsLihsP08kUBwDAMzB8OgAAHikmRvr4YykkxLG8XTtreUxMxfv/+KP1k6A4AADuhUxxAICBoLirMac4AADeg+HTAQDwWDEx0oEDUufO1vXYWGn//ksHxM+elbKzrd8JigMA4F7IFAcAGAiKuxpBcQAAvAeZ4gAAeDRfXykgwPq9XbuKh0w3/Pyz9bN5c6lly5prGwAAqDqC4gAAA0FxVyMoDgCA9yBTHAAAj2fcwiv7fpv9fOKl5yQHAACuxfDpAAADQXFXMwLeznrbRk/cmHccAAC4NzLFAQDweMYt/HKC4gAAwL2UDoKXDpIDAOoOguKuZgS8nWWTGT1wMsUBAPAMxcUXv5MpDgDwIAsXLlRYWJgCAgIUGRmprVu3llv3/PnzmjVrljp16qSAgACFh4crLS3Noc6vv/6qqVOnqn379goMDNTNN9+sr7/+2qHOAw88IJPJ5LAMGTKkRq6vKoxbeGVv5QTFAQBwX2SKAwAMBMVdjeHTAQDwHmSKAwA80MqVKxUfH6+ZM2dq+/btCg8PV3R0tI4ePeq0/vTp0/XGG29owYIF+uGHHzRp0iSNHDlSO3bssNV5+OGHtX79eq1YsULfffedBg8erKioKOXk5Dgca8iQIcrNzbUtH3zwQY1ea2WQKQ4AgPdgTnEAgIGguKuVFxS3WAiKAwDgaQiKAwA8UHJysiZOnKjY2Fh169ZNixcvVoMGDbR06VKn9VesWKFnn31Ww4YNU8eOHTV58mQNGzZMr7zyiiTp7NmzWrVqlebOnav+/furc+fOeu6559S5c2ctWrTI4Vj+/v4KDg62Lc2bNy+3nUVFRSooKHBYakJl5xQ3m6WMDOnbb63rnTrVSHMAAMAVMDLFGzWyfhIUB4C6i6C4q5UXFC8pKVsHAAC4N/un5wyfDgDwAMXFxdq2bZuioqJsZT4+PoqKilJmZqbTfYqKihQQEOBQFhgYqM2bN0uSLly4ILPZXGEdQ0ZGhlq3bq1rr71WkydP1okTJ8pta1JSkpo2bWpbQkNDq3StlWXcziu6laemSmFh0qBB0unT1rIRI6zlAADAfRhB8KZNHdcBAHUPQXFXMwLepV9Bt+99ExQHAMAzkCkOAPAwx48fl9lsVlBQkEN5UFCQ8vLynO4THR2t5ORk7dmzRyUlJVq/fr1SU1OVm5srSWrcuLH69u2rF154QUeOHJHZbNa7776rzMxMWx3JOnT68uXLlZ6erjlz5mjjxo0aOnSozGaz0/MmJCTo1KlTtuXQoUPV9FNwdKlM8dRUadQo6fBhx/IjR6zlBMYBAHAfRqZ4s2bWT4LiAFB3ERR3tfr1rZ+lX0G3730bdQAAgHsjUxwAUAfMnz9fXbp0UdeuXeXn56e4uDjFxsbKx+fiI4YVK1bIYrEoJCRE/v7+evXVVzVu3DiHOmPHjtWdd96p7t2766677tKnn36qr7/+WhkZGU7P6+/vryZNmjgsNaGiOcXNZunxx60znpVmlE2daq0HAABcr3SmuBEkBwDUPQTFXa284dPJFAcAwPMUF1/8TqY4AMADtGzZUr6+vsrPz3coz8/PV3BwsNN9WrVqpTVr1qiwsFAHDx7U7t271ahRI3Xs2NFWp1OnTtq4caNOnz6tQ4cOaevWrTp//rxDndI6duyoli1b6ueff66ei7tMFWWKb9pUNkPcnsUiHTpkrQcAgLtZuHChwsLCFBAQoMjISG3durXcukuWLFG/fv3UvHlzNW/eXFFRUWXqP/DAAzKZTA7LkCFDavoyqoRMcQCAgaC4qxEUBwDUEXWi802mOADAw/j5+alXr15KT0+3lZWUlCg9PV19+/atcN+AgACFhITowoULWrVqlUaMGFGmTsOGDdWmTRv973//07p165zWMRw+fFgnTpxQmzZtLv+CrpDFcvEW7uxWbjf6e4UqWw8AgNqycuVKxcfHa+bMmdq+fbvCw8MVHR2to0ePOq2fkZGhcePGacOGDcrMzFRoaKgGDx6snJwch3pDhgxRbm6ubfnggw9q43IqzQiCExQHABAUd7VLBcVNJsmHPyYAgGerM51v5hQHAHig+Ph4LVmyRMuWLdOuXbs0efJkFRYWKjY2VpI0fvx4JSQk2OpnZWUpNTVV+/bt06ZNmzRkyBCVlJRo2rRptjrr1q1TWlqa9u/fr/Xr12vQoEHq2rWr7ZinT5/WU089pa+++koHDhxQenq6RowYoc6dOys6Orp2fwB27Ic9d3Yrr2y83oVxfQAAnEpOTtbEiRMVGxurbt26afHixWrQoIGWLl3qtP57772nKVOmKCIiQl27dtWbb75pe3HOnr+/v4KDg21L8+bNa+NyKs3IFDeGTycoDgB1F9FWV7tUUJwscQCAF6gznW+C4gAADzRmzBjNmzdPiYmJioiI0M6dO5WWlqagoCBJUnZ2tnLtUp/PnTun6dOnq1u3bho5cqRCQkK0efNmNTNSsCSdOnVKjz76qLp27arx48frlltu0bp161S/fn1Jkq+vr7799lvdeeeduuaaa/TQQw+pV69e2rRpk/z9/Wv1+u1d6lber5/Urp31/XVnTCYpNNRaDwAAd1FcXKxt27YpKirKVubj46OoqChlZmZW6hhnzpzR+fPn1aJFC4fyjIwMtW7dWtdee60mT56sEydOVHicoqIiFRQUOCw1qfSc4gTFAaDuIuLqakbQu3Rv21j//w8MAADwVEbn2z7DrLo7382bN9ett96qF198UVdddZXTYxQVFanIeEVcqpmON8OnAwA8VFxcnOLi4pxuy8jIcFgfMGCAfvjhhwqPN3r0aI0ePbrc7YGBgVq3bl2V21nT7G/fzm7lvr7S/PnSqFHWALjFcnGbEShPSbHWAwDAXRw/flxms9n2wpshKChIu3fvrtQxnn76abVt29YhsD5kyBDFxMSoQ4cO2rt3r5599lkNHTpUmZmZ8i3nZpiUlKTnn3/+8i+mCiwWqbjY+p2gOACATHFXM4LeZIoDALxURZ3vvLy8Sh2jvM738uXLlZ6erjlz5mjjxo0aOnSozPbjntpJSkpS06ZNbUtoaOjlX1R5yBQHAMCjVeZWHhMjffyxFBLiWN6unbU8Jqbm2gcAgCvMnj1bH374oVavXq2AgABb+dixY3XnnXeqe/fuuuuuu/Tpp5/q66+/LvNCnb2EhASdOnXKthw6dKjG2m33XrxtTnH7MgBA3eIRQfGFCxcqLCxMAQEBioyM1NatW8ute/78ec2aNUudOnVSQECAwsPDlZaW5lDn119/1dSpU9W+fXsFBgbq5ptv1tdff13Tl+Ecw6cDAFCh6up810rH23gFXSJTHAAAD2R/+67o/baYGOnbby+u//Of0v79BMQBAO6pZcuW8vX1VX5+vkN5fn6+goODK9x33rx5mj17tj7//HP16NGjwrodO3ZUy5Yt9fPPP5dbx9/fX02aNHFYaop9VjiZ4gAAtw+Kr1y5UvHx8Zo5c6a2b9+u8PBwRUdH6+jRo07rT58+XW+88YYWLFigH374QZMmTdLIkSO1Y8cOW52HH35Y69ev14oVK/Tdd99p8ODBioqKUk5OTm1d1kUExQEAXs5dOt+10vEmUxwAAI9WlZlQjClTGzaUhgxhyHQAgPvy8/NTr169lJ6ebisrKSlRenq6+vbtW+5+c+fO1QsvvKC0tDT17t37kuc5fPiwTpw4oTZt2lRLu6+UfVa48QiAoDgA1F1uHxRPTk7WxIkTFRsbq27dumnx4sVq0KCBli5d6rT+ihUr9Oyzz2rYsGHq2LGjJk+erGHDhumVV16RJJ09e1arVq3S3Llz1b9/f3Xu3FnPPfecOnfurEWLFtXmpVkRFAcAeLk61flmTnEAADxaZTPFJenYMetnq1Y11x4AAKpLfHy8lixZomXLlmnXrl2aPHmyCgsLFRsbK0kaP368EhISbPXnzJmjGTNmaOnSpQoLC1NeXp7y8vJ0+vRpSdLp06f11FNP6auvvtKBAweUnp6uESNGqHPnzoqOjnbJNZZmBMD9/SVj4DmC4gBQd7l1xLW4uFjbtm1zuBn7+PgoKipKmZmZTvcpKipyGFpVkgIDA7V582ZJ0oULF2Q2myusU95xi+xeLSsoKKjy9ThlBL1L97aNnrgx5zgAAB4sPj5eEyZMUO/evdWnTx+lpKSU6XyHhIQoKSlJkrXznZiYqPfff9/W+ZakRo0aqVGjRjp9+rSef/553X333QoODtbevXs1bdo013e+SwfFLRbJZHJdewAAQJVUZdAXguIAAE8yZswYHTt2TImJicrLy1NERITS0tIUFBQkScrOzpaPz8UcukWLFqm4uFijRo1yOM7MmTP13HPPydfXV99++62WLVumkydPqm3btho8eLBeeOEF+fv71+q1lcd4nB8QQFAcAODmQfHjx4/LbDbbbsyGoKAg7d692+k+0dHRSk5OVv/+/dWpUyelp6crNTVVZrNZktS4cWP17dtXL7zwgq677joFBQXpgw8+UGZmpjp37lxuW5KSkvT8889X38UZjKB36Wwyo/dNpjgAwAvUmc63s5fceMENAACPUZVMcWNWt9ata649AABUp7i4OMXFxTndlpGR4bB+4MCBCo8VGBiodevWVVPLagaZ4gAAe14XcZ0/f74mTpyorl27ymQyqVOnToqNjXUYbn3FihV68MEHFRISIl9fX91www0aN26ctm3bVu5xExISFB8fb1svKChQaGjolTeY4dMBAHVEneh8ExQHAMCjVWUmFDLFAQBwb84yxe3nGQcA1C1uPad4y5Yt5evrq/z8fIfy/Px8BQcHO92nVatWWrNmjQoLC3Xw4EHt3r1bjRo1UseOHW11OnXqpI0bN+r06dM6dOiQtm7dqvPnzzvUKc3f319NmjRxWKoFQXEAALyDxSIVFzuWXSrFDAAAuBXmFAcAwHuQKQ4AsOfWQXE/Pz/16tVL6enptrKSkhKlp6erb9++Fe4bEBCgkJAQXbhwQatWrdKIESPK1GnYsKHatGmj//3vf1q3bp3TOjWOoDgAAN7h/0/V4uBSKWYAAMCtMKc4AACex2yWMjKkDz6wfhrdc+YUBwDYc/uIa3x8vCZMmKDevXurT58+SklJUWFhoWJjYyVJ48ePV0hIiJKSkiRJWVlZysnJUUREhHJycvTcc8+ppKRE06ZNsx1z3bp1slgsuvbaa/Xzzz/rqaeeUteuXW3HrFVG0NvZcKsSQ64CAOApnD05J1McAACPYv8+26XebWNOcQAAXC81VXr8cenw4Ytl7dpJ8+dLfn7WdftM8fPnrUFzX9/abysAwLXcPig+ZswYHTt2TImJicrLy1NERITS0tIUFBQkScrOzpaPz8WE93Pnzmn69Onat2+fGjVqpGHDhmnFihVq1qyZrc6pU6eUkJCgw4cPq0WLFrr77rv10ksvqb4rAtDGOUv3to2H6GSKAwDgGZwFwMkUBwDAo5ApDgCA50hNlUaNss5mZi8nx1r+5JPW9YAAa2DcUFQkNWhQe+0EALgHj4i4xsXFKS4uzum2jIwMh/UBAwbohx9+qPB4o0eP1ujRo6ureVeG4dMBAPAO9k/O/f2tvWwyxQEA8CjMKQ4AgGcwm60Z4qUD4pK1zGSSli61rttnikvWIdQJigNA3ePWc4rXCQTFAQDwDsaTc5Pp4ivoBMUBAPAolc0Ut1gIigMA4EqbNjkOmV6axSL98ov1e0CA9TG7MWS6Mdc4AKBuISjuagTFAQDwDsXF1k8/v/Lv7wAAwK3Z37pLSqyLM7/+evGBOkFxAABqX25u5esaWeLG57lz1d8eAID7IyjuapcKirtinnMAAFB1RjpZ/foX799kigMA4FFK37rLe7/NyBJv0EBq2LBm2wQAAMpq06bydY3B3AiKA0DdRlDc1YygeOmet7FOpjgAAJ7BPihOpjgAAB6p9K27vPfbGDodAADX6tdPatfOOoOZMyaT1LSp9TuZ4gAAiaC46xmZZBaL47hsDJ8OAIBnIVMcAACPV9lM8aNHrZ+tW9dsewAAgHO+vtL8+dbvpQPjxvrgwdZPI1Pc+CQoDgB1E0FxV7MPetv3tgmKAwDgWcgUBwDA45EpDgCA54iJkT7+WAoJcSxv185a3rGjdZ1McQCARFDc9QiKAwDgHcgUBwDA45U3s1lpBMUBAHAPMTHSgQNS167W9Zdekvbvt5YbwW/mFAcASATFXY+gOAAA3qG42Prp50dQHAAAD1U6U7y8QV8IigMA4D58fa3Z4ZLUvr11XZKKiqyfpTPFjXIAQN1CUNzV7IPe9g/O7bPNAACA+2P4dAAAPF5lM8WZUxwAAPfSpIn189dfL5aRKQ4AsEdQ3NWM19YkMsUBAPBkDJ8OAIDHY05xAAA8U+PG1s+Cgotl5WWKExQHgLqJoLirmUzOs8kIigMA4FnIFAcAwOMxpzgAAJ7JyBS3D4qXzhQ3PgmKA0DdRFDcHRAUBwDA85EpDgCAx2NOcQAAPJOz4dPJFAcA2CMo7g4IigMA4PnIFAcAwONVJlPcYmFOcQAA3I2z4dOZUxwAYI+Iqztw9uDc/sE6AABwf8XF1k8/v4v3djLFAQDwKJWZU/z06YuZZ2SKAwDgHpwNn15eprhRDgCoWwiKuwNnQ6ySKQ4AgGdxlilOUBwAAI9S+tbtbNAXY+j0wECpYcOabxMAALi0yswpTqY4ANRtRFzdAcOnAwDg+eyD4r6+1u8Mnw4AgEepTKY4Q6cDAOB+nM0pbgS/mVMcACARFHcPBMUBAPB8zoLiZIoDAOBRKjOnuJEpztDpAAC4D2dzihvDpJMpDgCQCIq7B4LiAAB4PvuguI+P9TuZ4gAAeJTKZIoTFAcAwP1UNHy6EQw3guMExQGgbiLi6g6cBcXtH6wDAAD35ywoTqY4AAAepSpzihMUBwDAfTgbPt3IFGf4dACARFDcPRhBcfveN5niAAB4luJi66ef38UyMsUBAPAozCkOAIBnMoZP//VXqaTE+q66EfwuPXy6ESwHANQtPq5uAHQxG5zh0wEA8Fz2meLGvZ1McQCAh1i4cKHCwsIUEBCgyMhIbd26tdy658+f16xZs9SpUycFBAQoPDxcaWlpDnV+/fVXTZ06Ve3bt1dgYKBuvvlmff311w51LBaLEhMT1aZNGwUGBioqKkp79uypkeurLOYUBwDAMxmZ4haLVFho/U6mOADAHkFxd8Cc4gAAeD77oLizUWAAAHBTK1euVHx8vGbOnKnt27crPDxc0dHROmqkRJcyffp0vfHGG1qwYIF++OEHTZo0SSNHjtSOHTtsdR5++GGtX79eK1as0HfffafBgwcrKipKOTk5tjpz587Vq6++qsWLFysrK0sNGzZUdHS0zrnwSXXpTHGGTwcAwDMEBFzsihcUWLPFjQHdSmeKExQHgLqJoLg7ICgOAIDnc5YpzvDpAAAPkJycrIkTJyo2NlbdunXT4sWL1aBBAy1dutRp/RUrVujZZ5/VsGHD1LFjR02ePFnDhg3TK6+8Ikk6e/asVq1apblz56p///7q3LmznnvuOXXu3FmLFi2SZM0ST0lJ0fTp0zVixAj16NFDy5cv15EjR7RmzRqn5y0qKlJBQYHDUt0qkyluvCtAUBwAAPdhMjnOK24ExCUyxQEAVgTF3YGzoLj9g3UAAOD+GD4dAOCBiouLtW3bNkVFRdnKfHx8FBUVpczMTKf7FBUVKcB4qvz/BQYGavPmzZKkCxcuyGw2V1hn//79ysvLczhv06ZNFRkZWe55k5KS1LRpU9sSGhpa9Qu+hMrMKW5kijOnOAAA7sWYV7ygwDHwbWSKG58ExQGgbiIo7g6cDbFKpjgAAJ7F2fDpZIoDANzc8ePHZTabFRQU5FAeFBSkvLw8p/tER0crOTlZe/bsUUlJidavX6/U1FTl5uZKkho3bqy+ffvqhRde0JEjR2Q2m/Xuu+8qMzPTVsc4dlXOm5CQoFOnTtmWQ4cOXdG1O1M6CO5sOHWjeXv3SmZztTcBAABcJiNTvKDg4nzikuTnZ/0kUxwA6jaC4u7A2RCrBMUBAPAsxthsfn5kigMAvNr8+fPVpUsXde3aVX5+foqLi1NsbKx8fC4+YlixYoUsFotCQkLk7++vV199VePGjXOoU1X+/v5q0qSJw1LdKsoUT02VwsIult17r3U9NbXamwEAAC6D/fDpRuDb3986tLp0MShuHzAHANQdBMXdAXOKAwDqgIULFyosLEwBAQGKjIzU1q1by627ZMkS9evXT82bN1fz5s0VFRVVpr7FYlFiYqLatGmjwMBARUVFac+ePTV9GeUjUxwA4IFatmwpX19f5efnO5Tn5+crODjY6T6tWrXSmjVrVFhYqIMHD2r37t1q1KiROnbsaKvTqVMnbdy4UadPn9ahQ4e0detWnT9/3lbHOHZVzlsbjNu5MbyqsZ6aKo0aJeXkONbPybGWExgHAMD1nGWK28/mQqY4ANRtBMXdAUFxAICXW7lypeLj4zVz5kxt375d4eHhio6O1tGjR53Wz8jI0Lhx47RhwwZlZmYqNDRUgwcPVo7dk+i5c+fq1Vdf1eLFi5WVlaWGDRsqOjpa51zVu2VOcQCAB/Lz81OvXr2Unp5uKyspKVF6err69u1b4b4BAQEKCQnRhQsXtGrVKo0YMaJMnYYNG6pNmzb63//+p3Xr1tnqdOjQQcHBwQ7nLSgoUFZW1iXPW5OMrnhgoPXz/HnrEOmPPy5ZLGXrG2VTpzKUOgAAruZsTnHjRTeJoDgA1HUExd1BRUFx46E6AAAeLDk5WRMnTlRsbKy6deumxYsXq0GDBlq6dKnT+u+9956mTJmiiIgIde3aVW+++abtAb1kzRJPSUnR9OnTNWLECPXo0UPLly/XkSNHtGbNmlq8MjvOMsUJigMAPEB8fLyWLFmiZcuWadeuXZo8ebIKCwsVGxsrSRo/frwSEhJs9bOyspSamqp9+/Zp06ZNGjJkiEpKSjRt2jRbnXXr1iktLU379+/X+vXrNWjQIHXt2tV2TJPJpKlTp+rFF1/UJ598ou+++07jx49X27Ztddddd9Xq9dszbt0NGlg/L1yQNm2SDh8ufx+LRTp0yFoPAAC4DpniAICKkIbsDpwFxY2eOJniAAAPV1xcrG3btjk8TPfx8VFUVJQyMzMrdYwzZ87o/PnzatGihSRp//79ysvLU1RUlK1O06ZNFRkZqczMTI0dO7bMMYqKilRkN3FYQUHB5V6Sc/ZBcQPDpwMAPMCYMWN07NgxJSYmKi8vTxEREUpLS1NQUJAkKTs722Eu8HPnzmn69Onat2+fGjVqpGHDhmnFihVq1qyZrc6pU6eUkJCgw4cPq0WLFrr77rv10ksvqb7dfXLatGkqLCzUI488opMnT+qWW25RWlqaAuyfXtcyZ5niubmV27ey9QAAQM0ob05xg/H93DnrS23GXOMAgLqBTHF34GyIVYZPBwB4iePHj8tsNtserBuCgoKUl5dXqWM8/fTTatu2rS0IbuxXlWMmJSWpadOmtiU0NLSql1Ixhk8HAHiwuLg4HTx4UEVFRcrKylJkZKRtW0ZGht555x3b+oABA/TDDz/o3LlzOn78uJYvX662bds6HG/06NHau3evioqKlJubq9dee01NmzZ1qGMymTRr1izl5eXp3Llz+uKLL3TNNdfU6HVeinHrtg+Kt2lTuX0rWw8AAFdZuHChwsLCFBAQoMjISG3durXcukuWLFG/fv3UvHlzNW/eXFFRUWXqWywWJSYmqk2bNgoMDFRUVJT27NlT05dRLmfDpzvLFC8p4R12AKiLCIq7A+YUBwCgXLNnz9aHH36o1atXX1HmWEJCgk6dOmVbDh06VI2tlFRcbP3083N+bwcAAG6vdKb4hQtSv35Su3blZ5OZTFJoqLUeAADuauXKlYqPj9fMmTO1fft2hYeHKzo6WkePHnVaPyMjQ+PGjdOGDRuUmZmp0NBQDR48WDk5ObY6c+fO1auvvqrFixcrKytLDRs2VHR0tM65aHxyZ8OnO5tTXLq4HQBQdxAUdwcExQEAXqxly5by9fVVfn6+Q3l+fr6Cg4Mr3HfevHmaPXu2Pv/8c/Xo0cNWbuxXlWP6+/urSZMmDku1IlMcAACP5yxT3NdXmj/feX0jUJ6SYq0HAIC7Sk5O1sSJExUbG6tu3bpp8eLFatCggZYuXeq0/nvvvacpU6YoIiJCXbt21ZtvvqmSkhKlp6dLsmaJp6SkaPr06RoxYoR69Oih5cuX68iRI1qzZk0tXtlFzoZPtw+E2wfImVccAOoeguLuoKKguP28pAAAeCA/Pz/16tXL1nGWZOtI9+3bt9z95s6dqxdeeEFpaWnq3bu3w7YOHTooODjY4ZgFBQXKysqq8Jg1yj4oTqY4AAAeydmc4pIUEyN9/LFUagR4tWtnLY+Jqb02AgBQVcXFxdq2bZttSjJJ8vHxUVRUlDIzMyt1jDNnzuj8+fNq0aKFJGn//v3Ky8tzOGbTpk0VGRlZ4TGLiopUUFDgsFSXS2WK+/hYB3eTCIoDQF1EUNwdOHtwbvS8yRQHAHiB+Ph4LVmyRMuWLdOuXbs0efJkFRYWKjY2VpI0fvx4JSQk2OrPmTNHM2bM0NKlSxUWFqa8vDzl5eXp9OnTkqxzkE6dOlUvvviiPvnkE3333XcaP3682rZtq7vuussVl0imOAAAXsC4dTdo4LguWQPfTz9t/d6/v7Rhg7R/PwFxAID7O378uMxms4KCghzKg4KClJeXV6ljPP3002rbtq0tCG7sV9VjJiUlqWnTprYlNDS0KpdSoUvNKW6/TlAcAOoeIq7uwNmDc4ZPBwB4kTFjxujYsWNKTExUXl6eIiIilJaWZus8Z2dny8fn4rt6ixYtUnFxsUaNGuVwnJkzZ+q5556TJE2bNk2FhYV65JFHdPLkSd1yyy1KS0u7onnHr4h9UNy4jxMUBwDAozibU9yecWu/7jpp4MBaaxYAAC41e/Zsffjhh8rIyLjiPndCQoLi4+Nt6wUFBdUWGHeWKe4sKG4fNAcA1B1EXN0Bc4oDAOqAuLg4xcXFOd2WkZHhsH7gwIFLHs9kMmnWrFmaNWtWNbSuGjgLijN8OgAAHsXZnOL2jAfsxtCrAAB4gpYtW8rX11f5+fkO5fn5+QoODq5w33nz5mn27Nn64osv1KNHD1u5sV9+fr7atGnjcMyIiIhyj+fv7y9/+zHNq5GzOcVLn8pYJygOAHUPw6e7A4LiAAAPY7FYXN0E91NcbP3082P4dAAAPFR5c4obnM1PCgCAu/Pz81OvXr2Unp5uKyspKVF6err69u1b7n5z587VCy+8oLS0NPXu3dthW4cOHRQcHOxwzIKCAmVlZVV4zJpkP3x6RZniEkFxAKiLCIq7A4LiAAA39MADD6iwsLBM+YEDB9S/f38XtMjN2WeKO7u3AwAAt1d6TvHSt3LjHTiC4gCA2pKdna0iI8Jrp6SkRNnZ2ZU+Tnx8vJYsWaJly5Zp165dmjx5sgoLCxUbGytJGj9+vBISEmz158yZoxkzZmjp0qUKCwtTXl6e8vLydPr0aUnW0dumTp2qF198UZ988om+++47jR8/Xm3bttVdd911ZRd9mYxM8bNnpf/fzDL3bCMo7uRHCgDwcgTF3YGzB+f2D9YBAHCBb775Rj169FBmZqatbNmyZQoPD1fLli1d2DI3ZX/vJlMcAACPRKY4AMDdhIWF6YYbbtDevXsdyo8dO6YOHTpU+jhjxozRvHnzlJiYqIiICO3cuVNpaWkKCgqSZA2+5+bm2uovWrRIxcXFGjVqlNq0aWNb5s2bZ6szbdo0/eEPf9AjjzyiG2+8UadPn1ZaWtoVzzt+uYxMcUk6ftz6SaY4AMDgEUHxhQsXKiwsTAEBAYqMjNTWrVvLrXv+/HnNmjVLnTp1UkBAgMLDw5WWluZQx2w2a8aMGerQoYMCAwPVqVMnvfDCC64bCrZ0UNxiIVMcAOByW7duVUxMjAYOHKhnn31Wo0ePVlxcnObNm6fVq1e7unnuh0xxAAA8HnOKAwDc0XXXXac+ffo4DFUuVX1qs7i4OB08eFBFRUXKyspSZGSkbVtGRobeeecd2/qBAwdksVjKLM8995ytjslk0qxZs5SXl6dz587piy++0DXXXHNZ11gd6te/eA8/etT6WV6mOEFxAKh73D7iunLlSsXHx2vx4sWKjIxUSkqKoqOj9eOPP6p169Zl6k+fPl3vvvuulixZoq5du2rdunUaOXKktmzZop49e0qyDv2yaNEiLVu2TNdff73+85//KDY2Vk2bNtVjjz1W25dYNpuspOTiNoLiAAAXqV+/vl5++WU1aNBAL7zwgurVq6eNGze6bG4wt0emOAAAHs1ikcxm63fjgXrp99vIFAcA1DaTyaTXX39d7733noYPH665c+fanmGbTCYXt879NG5sHT792DHrOpniAABDrWeKV/XtteTkZE2cOFGxsbHq1q2bFi9erAYNGmjp0qVO669YsULPPvushg0bpo4dO2ry5MkaNmyYXnnlFVudLVu2aMSIERo+fLjCwsI0atQoDR48uMIM9KKiIhUUFDgs1aZ0Npl9r5ugOADARc6fP68nn3xSc+bMUUJCgvr27auYmBitXbvW1U1zT84yxQmKAwDgMey74uVlijOnOACgthnP05944gmtXr1aiYmJmjhxooqNmxIcGPOKl5cpbqwTFAeAuqdGguIPPPCACgsLy5QfOHBA/fv3r/RxiouLtW3bNkVFRdnKfHx8FBUV5TC/qb2ioqIyc5YEBgZq8+bNtvWbb75Z6enp+umnnyRZ50zdvHmzhg4dWm5bkpKS1LRpU9sSGhpa6eu4JILiAAA31Lt3b33yySfKyMjQSy+9pIyMDE2dOlUxMTGaMmWKq5vnfowHEn5+FzPFGT4dAFBDsrOzVWSkLdspKSlRdna2C1rk+SoTFCdTHADgSkOHDtWWLVu0YcMG3X777a5ujlsyguJkigMASquRoPg333yjHj16OASuly1bpvDwcLVs2bLSxzl+/LjMZrOCgoIcyoOCgpSXl+d0n+joaCUnJ2vPnj0qKSnR+vXrlZqaqtzcXFudZ555RmPHjlXXrl1Vv3599ezZU1OnTtV9991XblsSEhJ06tQp23Lo0KFKX8cllQ6K2/e6jYfqAADUst69e2vnzp266aabJFmHZXv66aeVmZmpf//73y5unRti+HQAQC0KCwvTDTfcoL179zqUHzt2TB06dHBRqzyb/W27QYOyZRJzigMAat+AAQPkZ3fj6datm7KystSsWbMqj8paFzRubP08edL6Wd6c4k7eLQQAeLkaCYpv3bpVMTExGjhwoJ599lmNHj1acXFxmjdvnlavXl0Tp7SZP3++unTpoq5du8rPz09xcXGKjY2Vj8/FS/3oo4/03nvv6f3339f27du1bNkyzZs3T8uWLSv3uP7+/mrSpInDUm3IFAcAuKG33npLDRs2LFPes2dPbdu2zbY+e/ZsnTR6m3WV/SSk9sOnkykOAKhB1113nfr06aP09HSHch6QXx5nmeLMKQ4AcLUNGzaoWbNmDmVXXXWVNm7cqJKSElsZfXOr0o/tyRQHABhqJChev359vfzyy3rmmWc0e/ZsrVmzRp9//rkmTpxYpeO0bNlSvr6+ys/PdyjPz89XcHCw031atWqlNWvWqLCwUAcPHtTu3bvVqFEjdezY0VbnqaeesmWLd+/eXffff7+eeOIJJSUlVf1iq0PpbDKj120yST61Pu07AACX5G/3JPjPf/6zfvnlFxe2xg2UHuWFTHEAQA0zmUx6/fXXNX36dA0fPlyvvvqqwzZUnf1t23hgzpziAABPQd/cqnRQvLxMcYLiAFD31EjE9fz583ryySc1Z84cJSQkqG/fvoqJidHatWurdBw/Pz/16tXL4a33kpISpaenq2/fvhXuGxAQoJCQEF24cEGrVq3SiBEjbNvOnDnjkDkuSb6+vg5v1tWq8jLFyRIHAHgAstFUNihu3MMJigMAaohx/33iiSe0evVqJSYmauLEiSo2oraoMvuueHnvt5EpDgBwV/TNrcgUBwCUp0airr1799aZM2eUkZGhm266SRaLRXPnzlVMTIwefPBBvf7665U+Vnx8vCZMmKDevXurT58+SklJUWFhoWJjYyVJ48ePV0hIiC3LOysrSzk5OYqIiFBOTo6ee+45lZSUaNq0abZj3nHHHXrppZd09dVX6/rrr9eOHTuUnJysBx98sHp/EJVFUBwAAM9WXqa42WwdWp2MPQBADRo6dKi2bNmiO++8U1u3bnV1czyWcTu3D4qXN3w6c4oDAOCejDnFDaVfZDPWCYoDQN1TY0HxV1991TYPqclk0tNPP63Bgwfr/vvvr9KxxowZo2PHjikxMVF5eXmKiIhQWlqagoKCJEnZ2dkOWd/nzp3T9OnTtW/fPjVq1EjDhg3TihUrHOZdWbBggWbMmKEpU6bo6NGjatu2rX7/+98rMTHxyi/+cpQOihs9caMXDgAA3Jt9Vp59prhkvb9zTwcAVLMBAwbIzy4y261bN2VlZSkmJoZMsctkdMkrmgmFTHEAANwbmeIAgPLUSFD8rbfeclres2dPbdu2zbY+e/ZsTZo0ySFg7UxcXJzi4uKcbsvIyHBYHzBggH744YcKj9e4cWOlpKQoJSWlwnq1hkxxAAA8m31qmcnkGAQnKA4AqAEbNmwoU3bVVVdp48aNDmWV7XfD8XZe3kwoBMUBAHBvlZ1T3LinAwDqjhqZU7wi/nZ3oT//+c/65ZdfarsJ7qf0K+gExQEA8CylR3mxD4IzrzgAwIXod1deZTLFjcFhCIoDAOCeSg+fTqY4AMBQ60Fxewzp9v+RKQ4AcDMXLlzQ8uXLlZ+ff8m6/fr1U2BgYC20yo2VDoqXHj4dAAAXod9decwpDgBwN/TNq47h0wEA5XFpUBz/H0FxAICbqVevniZNmqRzleglrl27Vm3atKmFVrmx0kFxX9+y2wAAgFuzzxRn+HQAgDugb151lR0+naA4ANQ9BMXdQemgeOkH6wAAuECfPn20c+dOVzfDM5S+d5tM5T9NBwAAbslZprj9bdxiISgOAKh99M2rhkxxAEB5SEV2B2SKAwDc0JQpUxQfH69Dhw6pV69eatiwocP2Hj16uKhlbsiYYNR+LNX69a33dIZPBwDAIzibU/zCBWsw3GRyvKUTFAcA1Bb65lVTek7x0vdsY52gOADUPURd3QFBcQCAGxo7dqwk6bHHHrOVmUwmWSwWmUwmmc1mVzXN/Tgb5YVMcQAAPIqzTHFJMputZUaWuERQHABQe+ibV01lM8Xt7+sAgLqh2qOuFy5c0Pvvv6/o6GgFBQVVWLdfv34KDAys7iZ4ntLjshEUBwC4gf3797u6CZ7DWVDcPsUMAIBqRL+7ZjibU1yy3uZLB8XtB4cBAKAm0TevGuYUBwCUp9qjrvXq1dOkSZO0a9euS9Zdu3ZtdZ/eM5EpDgBwM+fPn9ett96qTz/9VNddd52rm+P+KgqKkykOAKhm9LtrRnmZ4kYX3QiK+/jQXQcA1A765lXXsKF12hOLxbpe+kU2guIAUHf51MRB+/Tpo507d9bEob1T6aC4swfrAADUovr16+scPcTKq2j4dDLFAQA1gH539XM2p7h08TZfXGz9ZOh0AEBtoW9edT4+UqNG1u/+/tYAuT2C4gBQd9XIu81TpkxRfHy8Dh06pF69eqlhw4YO23v06FETp/VcZIoDANzQo48+qjlz5ujNN99UPe5JFSNTHABQy+h3Vz/727mPT9lyI1OcoDgAoDbRN6+6Jk2kX38tO5+4dLGrXlAgZWRI/fpJvr612jwAgIvUyF107NixkqTHHnvMVmYymWSxWGQymWQ2m2vitJ6LoDgAwA19/fXXSk9P1+eff67u3buXediemprqopa5ISN1zH5cNuM+TlAcAFAD6HdXP/uuuMlkfWh+/nzZoDjziQMAahN986pr0kTKySn7IltqqhQXZ/1+9qw0aJDUrp00f74UE1P77QQA1K4aibru37+/Jg7rvUpnkhEUBwC4gWbNmunuu+92dTM8Q0WZ4gyfDgCoAfS7q1/p27kRFC89pziZ4gCA2kTfvOoaN7Z+2meKp6ZKo0ZdnGvckJNjLf/4YwLjAODtqj3qev78ed1666369NNPdd1111X34b0TmeIAADf09ttvu7oJnqOiOcXJFAcAVLOa6HcvXLhQL7/8svLy8hQeHq4FCxaoT58+5Z4/KSlJy5YtU05Ojq699lrNmTNHQ4YMsdUxm8167rnn9O677yovL09t27bVAw88oOnTp8v0/yf3fOCBB7Rs2TKHY0dHRystLa1arqmqSnfFS7+/zpziAABXoG9edU2aWD+Ne7bZLD3+eNmAuGQtM5mkqVOlESMYSh0AvJnPpatUTf369XXu3LnqPqx3Kx0UN3rcBMUBAC524cIFffHFF3rjjTf066+/SpKOHDmi06dPu7hlboZMcQBALarufvfKlSsVHx+vmTNnavv27QoPD1d0dLSOHj3qtP706dP1xhtvaMGCBfrhhx80adIkjRw5Ujt27LDVmTNnjhYtWqTXXntNu3bt0pw5czR37lwtWLDA4VhDhgxRbm6ubfnggw+q7bqqqvTtvPT7bWSKAwBchb551RiZ4ufOWecNz8iQDh8uv77FIh06JG3aVButAwC4SrUHxSXp0Ucf1Zw5c3SBh8CVY/S0S0qsi/Fzs3+wDgBALTt48KC6d++uESNG6NFHH9WxY8ckWR9y//GPf3Rx69xMRUFxMsUBADWgOvvdycnJmjhxomJjY9WtWzctXrxYDRo00NKlS53WX7FihZ599lkNGzZMHTt21OTJkzVs2DC98sortjpbtmzRiBEjNHz4cIWFhWnUqFEaPHiwtm7d6nAsf39/BQcH25bmzZtf8fVcrvIyxUsPn86c4gCA2kTfvGpSU6V166zfDx2yzhs+enTl9s3Nrbl2AQBcr0ZSkb/++mulp6fr888/V/fu3dWwYUOH7ampqTVxWs9lnxFuNjN8OgDALTz++OPq3bu3vvnmG1111VW28pEjR2rixIkubJkbqmj4dF4SBADUgOrqdxcXF2vbtm1KSEiwlfn4+CgqKkqZmZlO9ykqKlKA/SSdkgIDA7V582bb+s0336y//vWv+umnn3TNNdfom2++0ebNm5WcnOywX0ZGhlq3bq3mzZvr1ltv1Ysvvujwe0fp8xYZkWlJBQUFlbrGynI2p7h9OZniAABXoG9eeeXNG/7LL5Xbv02b6m8TAMB91EjUtVmzZrr77rtr4tDeyf4B+vnzBMUBAG5h06ZN2rJli/xKpUOFhYUpJyfHRa1yU8Yko/Y/KzLFAQA1qLr63cePH5fZbFZQUJBDeVBQkHbv3u10n+joaCUnJ6t///7q1KmT0tPTlZqaKrPZbKvzzDPPqKCgQF27dpWvr6/MZrNeeukl3XfffbY6Q4YMUUxMjDp06KC9e/fq2Wef1dChQ5WZmSlfJxN6JiUl6fnnn7/iay5P6a546eHTmVMcAOAK9M0rp6J5wy/FZJLatZP69av+dgEA3EeNRF3ffvvtmjis97IPfl+4QFAcAOAWSkpKHB5uGw4fPqzGxgRdsKooU5ygOACgBriy3z1//nxNnDhRXbt2lclkUqdOnRQbG+sw3PpHH32k9957T++//76uv/567dy5U1OnTlXbtm01YcIESdLYsWNt9bt3764ePXqoU6dOysjI0O9+97sy501ISFB8fLxtvaCgQKGhodV2XWSKAwDcEX3zytm0qeJ5w8tjMlk/U1IkJ+/kAQC8SI3MKW44duyYNm/erM2bN9vmOoETBMUBAG5o8ODBSklJsa2bTCadPn1aM2fO1LBhw6p0rIULFyosLEwBAQGKjIwsM5+ove+//1533323wsLCZDKZHNpgeO6552QymRyWrl27VqlN1aqiOcUZPh0AUIOutN/dsmVL+fr6Kj8/36E8Pz9fwcHBTvdp1aqV1qxZo8LCQh08eFC7d+9Wo0aN1LFjR1udp556Ss8884zGjh2r7t276/7779cTTzyhpKSkctvSsWNHtWzZUj///LPT7f7+/mrSpInDUp2YUxwA4I6qs2/uzSo7H3iLFo7r7dpJH38sxcRUf5sAAO6lRoLihYWFevDBB9WmTRv1799f/fv3V9u2bfXQQw/pzJkzNXFKz2b/CtqFC84frAMAUMteeeUVffnll+rWrZvOnTune++91zY825w5cyp9nJUrVyo+Pl4zZ87U9u3bFR4erujoaB09etRp/TNnzqhjx46aPXt2uQ/jJen6669Xbm6ubbGfx7TWkSkOAKhl1dXv9vPzU69evZSenm4rKykpUXp6uvr27VvhvgEBAQoJCdGFCxe0atUqjRgxwrbtzJkz8vFxfOTg6+urkpKSco93+PBhnThxQm1cNKFn6dt56Vs5meIAAFeorr65t6vsrw8ffSQ99pj1e//+0v79BMQBoK6okaB4fHy8Nm7cqH/84x86efKkTp48qb///e/auHGjnnzyyZo4pWczmS4GxskUBwC4iXbt2umbb77Rn/70Jz3xxBPq2bOnZs+erR07dqh169aVPk5ycrImTpyo2NhYdevWTYsXL1aDBg0chli1d+ONN+rll1/W2LFj5V/BU+d69eopODjYtrRs2bLCdhQVFamgoMBhqTZkigMAall19rvj4+O1ZMkSLVu2TLt27dLkyZNVWFio2NhYSdL48eOVkJBgq5+VlaXU1FTt27dPmzZt0pAhQ1RSUqJp06bZ6txxxx166aWX9Nlnn+nAgQNavXq1kpOTNXLkSEnS6dOn9dRTT+mrr77SgQMHlJ6erhEjRqhz586Kjo6uhp9Q1ZWXKU5QHADgStXVN/d2/fpZs76N4dBLM5mk0FBp4EBpwABr2fnzDJkOAHVJjURdV61apY8//lgDBw60lQ0bNkyBgYEaPXq0Fi1aVBOn9Wz16klmM0FxAIBbqVevnu677z7dd9995dYZPny43nzzTadZXcXFxdq2bZvDg3QfHx9FRUUpMzPzitq2Z88etW3bVgEBAerbt6+SkpJ09dVXl1s/KSlJzz///BWds1wVBcXJFAcA1IDq7HePGTNGx44dU2JiovLy8hQREaG0tDQFBQVJkrKzsx2yvs+dO6fp06dr3759atSokYYNG6YVK1aoWbNmtjoLFizQjBkzNGXKFB09elRt27bV73//eyUmJkqyZo1/++23WrZsmU6ePKm2bdtq8ODBeuGFFyp8Ka4mlTenuNFFLy62fhIUBwDUtivtm9cFvr7S/PnSqFHWALjFcnFb6XnD27a1rh85UuvNBAC4UI1EXc+cOWPrPNtr3bo1w6eXp35962vn588TFAcAeJR///vfOnv2rNNtx48fl9lsLvN7QVBQkHbv3n3Z54yMjNQ777yja6+9Vrm5uXr++efVr18//fe//1Xjxo2d7pOQkKD4+HjbekFBgUJDQy+7DQ6Mp+T2k4wa93EyxQEANaC6+91xcXGKi4tzui0jI8NhfcCAAfrhhx8qPF7jxo2VkpLiMAeqvcDAQK1bt67K7axJZIoDADxZRX3zuiImxjo/+OOPS4cPXyxv184aEDeGSbcPilss5WeXAwC8S40Mn963b1/NnDlT586ds5WdPXtWzz///CXnJKuz7B+cExQHAKBCQ4cO1T333KMePXooOjpaa9eu1cmTJ/XRRx+Vu4+/v7+aNGnisFQbMsUBALWMfnf1q+yc4vbvwAEAAPcSEyMdOCBt2CC9/771s/S84UYy/fnz0okTLmkmAMAFaiTqmpKSoiFDhqhdu3YKDw+XJH3zzTfy9/fX559/XhOn9Hz2QXFnD9YBAPBALVu2lK+vr/Lz8x3K8/PzFRwcXG3nadasma655hr9/PPP1XbMKnF27y79JB0AgGpEv7v6lZcpbpSTKQ4AgGfw9bXOHV6e+vWl1q2lo0elnBypZctaaxoAwIVqJFO8e/fu2rNnj5KSkhQREaGIiAjNnj1bP//8s66//vqaOKXnI1McAOCF/Pz81KtXL6Wnp9vKSkpKlJ6eXq1ZbKdPn9bevXtdN3daRZniDJ8OAKgB9LurX3lzihvlzCkOAID3YF5xAKh7aiTqmpSUpKCgIE2cONGhfOnSpTp27JiefvrpmjitZyMoDgDwUvHx8ZowYYJ69+6tPn36KCUlRYWFhYqNjZUkjR8/XiEhIUpKSpIkFRcX2+YpLS4uVk5Ojnbu3KlGjRqpc+fOkqQ//vGPuuOOO9S+fXsdOXJEM2fOlK+vr8aNG+eaiyRTHABQy+h3V7/SXfHyhk8nKA4AgOdr21bauZOgOADUJTWSKf7GG2+oa9euZcqvv/56LV68uCZO6fnsX0EnKA4A8CJjxozRvHnzlJiYqIiICO3cuVNpaWkKCgqSJGVnZys3N9dW/8iRI+rZs6d69uyp3NxczZs3Tz179tTDDz9sq3P48GGNGzdO1157rUaPHq2rrrpKX331lVq1alXr1yeJTHEAQK2j3139LpUpzpziAABPt3DhQoWFhSkgIECRkZHaunVruXW///573X333QoLC5PJZFJKSkqZOs8995xMJpPD4uz3E3dEpjgA1D01EnXNy8tzOnxpq1atHB56ww6Z4gAAD/Xss8+qRYsWFdaJi4tTXFyc020ZGRkO62FhYbJYLBUe78MPP6xSG2ucMZ6q/VPy0k/SAQCoRvS7qx9zigMAPNml+uYrV65UfHy8Fi9erMjISKWkpCg6Olo//vijWrduXab+mTNn1LFjR91zzz164oknyj3u9ddfry+++MK2Xs9DnmmHhFg/CYoDQN1RI5nioaGh+vLLL8uUf/nll2prvIIFR/ZBcWfZZgAA1LLDhw/r9OnTZcrPnz+vf//737b1hIQENWvWrBZb5oYqGj6dTHEAQA2g3139St/OSw+fzpziAABXqK6+eXJysiZOnKjY2Fh169ZNixcvVoMGDbR06VKn9W+88Ua9/PLLGjt2rPwruPnVq1dPwcHBtqVly5YVXk9RUZEKCgocFlcwfl3KyXHJ6QEALlAjQfGJEydq6tSpevvtt3Xw4EEdPHhQS5cu1RNPPFFmvjP8f2SKAwDcRG5urvr06aP27durWbNmGj9+vEMH/JdfftGgQYNc2EI3VNHw6WSKAwBqAP3u6ldepjhzigMAXKE6++bFxcXatm2boqKibGU+Pj6KiopSZmbmFbVzz549atu2rTp27Kj77rtP2dnZFdZPSkpS06ZNbUtoaOgVnf9yMXw6ANQ9NRJ1feqpp3TixAlNmTJFxf//VeqAgAA9/fTTSkhIqIlTej6C4gAAN/HMM8/Ix8dHWVlZOnnypJ555hkNGjRIn3/+uZo3by5JlxzevM6pKFOcoDgAoAbQ765+5c0pXnr4dOYUBwDUhursmx8/flxms1lBQUEO5UFBQdq9e/dltzEyMlLvvPOOrr32WuXm5ur5559Xv3799N///leNGzd2uk9CQoLi4+Nt6wUFBS4JjBMUB4C6p0airiaTSXPmzNGMGTO0a9cuBQYGqkuXLhUOs1Ln2fe2CYoDAFzoiy++0OrVq9W7d29J1mFY77nnHt16661KT0+XZL3Xw05FmeIMnw4AqAH0u6sfmeIAAHfiCX3zoUOH2r736NFDkZGRat++vT766CM99NBDTvfx9/d3i99XjKB4fr71dwAexQOA96uR4dMNjRo10o033qjf/OY3bnGjc2v22WQExQEALnTq1CnbW+eStcOampqqsLAwDRo0SEePHnVh69wUmeIAABeh3119mFMcAOBOqrNv3rJlS/n6+io/P9+hPD8/X8HBwdXW5mbNmumaa67Rzz//XG3HrCmtW0u+vlJJicRjDgCoG2o0KI4qsB8+3dmDdQAAaknHjh317bffOpTVq1dPf/vb39SxY0fdfvvtLmqZGzOektuPp0qmOAAAHoVMcQCAO6nOvrmfn5969eplyzCXpJKSEqWnp6tv377V1ubTp09r7969atOmTbUds6b4+EhGM3NyXNsWAEDtICjuLphTHADgJoYOHaq//vWvZcqNzndERARzipdW0fDpZIoDAOARmFMcAOBOqrtvHh8fryVLlmjZsmXatWuXJk+erMLCQsXGxkqSxo8fr4SEBFv94uJi7dy5Uzt37lRxcbFycnK0c+dOhyzwP/7xj9q4caMOHDigLVu2aOTIkfL19dW4ceOu4MprD/OKA0DdQtTVXRAUBwC4iZdeeklnzpxxuq1evXpatWqVcniN2lFFw6eTKQ4AgEco3RUvPXw6meIAgNpU3X3zMWPG6NixY0pMTFReXp4iIiKUlpamoKAgSVJ2drZ8fC7m0B05ckQ9e/a0rc+bN0/z5s3TgAEDlJGRIUk6fPiwxo0bpxMnTqhVq1a65ZZb9NVXX6lVq1aXccW1j6A4ANQtRF3dhf0r6ATFAQAuEh8fX+m6ycnJNdgSD0OmOAAAHq+8THGC4gCA2lZTffO4uDjFxcU53WYEug1hYWGXzET/8MMPK31ud0RQHADqFqKu7sL+FXSC4gAAF9mxY0el6plMphpuiYepKFOcoDgAAB6hvDnFjfLiYusnQXEAQE2jb147QkKsnwTFAaBuIOrqLuyHWHX2YB0AgFqwYcMGVzfBM1WUKc7w6QAAeITKZoozpzgAoKbRN68dRqY4M8QBQN3gc+kqrrdw4UKFhYUpICBAkZGR2rp1a7l1z58/r1mzZqlTp04KCAhQeHi40tLSHOqEhYXJZDKVWR599NGavpTyMac4AACey0gds39KTqY4AAAehTnFAQCoWxg+HQDqFrcPiq9cuVLx8fGaOXOmtm/frvDwcEVHR+vo0aNO60+fPl1vvPGGFixYoB9++EGTJk3SyJEjHYac+frrr5Wbm2tb1q9fL0m65557auWanCIoDgCA5yJTHAAAj1depviFC5LFwvDpAAB4G4LiAFC3uH1QPDk5WRMnTlRsbKy6deumxYsXq0GDBlq6dKnT+itWrNCzzz6rYcOGqWPHjpo8ebKGDRumV155xVanVatWCg4Oti2ffvqpOnXqpAEDBpTbjqKiIhUUFDgs1YqgOAAAnquioDiZ4gAAeITy5hQ/f97xdk5QHAAA72AExU+cuDgiDADAe7l1ULy4uFjbtm1TVFSUrczHx0dRUVHKzMx0uk9RUZECAgIcygIDA7V58+Zyz/Huu+/qwQcflMlkKrctSUlJatq0qW0JDQ29jCuqgH1vm6A4AACexVlQ3P6FNwAA4PZK387th0+3f1BOUBwAAO/QvLlkhBJyc13bFgBAzXProPjx48dlNpsVFBTkUB4UFKS8vDyn+0RHRys5OVl79uxRSUmJ1q9fr9TUVOWWc1dbs2aNTp48qQceeKDCtiQkJOjUqVO25dChQ5d1TeWyf3Bu9MQJigMA4P7MZuuYqhKZ4gAAeLCKMsXtg+J+frXbLgAAUDNMpovZ4jk5rm0LAKDmuXVQ/HLMnz9fXbp0UdeuXeXn56e4uDjFxsbKx8f5pb711lsaOnSo2hp3v3L4+/urSZMmDku1cjZ8uv2DdQAA4J7sg97OMsUJigMA4BEqmlPcCIr7+loXAADgHdq0sX5+9JGUkWF97x0A4J3cOijesmVL+fr6Kj8/36E8Pz9fwcHBTvdp1aqV1qxZo8LCQh08eFC7d+9Wo0aN1LFjxzJ1Dx48qC+++EIPP/xwjbS/SphTHAAAz1RcfPG7feqY/ZN0AADg9kp3xe3fbzNu9wydDgCA90hNlbZvt35/9VVp0CApLMxaDgDwPm4dFPfz81OvXr2Unp5uKyspKVF6err69u1b4b4BAQEKCQnRhQsXtGrVKo0YMaJMnbffflutW7fW8OHDq73tVUZQHAAAz0SmOAAAHs9iuZgZVjpT3H74dILiAAB4h9RUadQo6exZx/KcHGs5gXEA8D5uHRSXpPj4eC1ZskTLli3Trl27NHnyZBUWFio2NlaSNH78eCUkJNjqZ2VlKTU1Vfv27dOmTZs0ZMgQlZSUaNq0aQ7HLSkp0dtvv60JEyaonjsEn+2zyQiKAwDgOYygt8nkOJ4qmeIAAHgM+9t16TnF7YdPZz5xAAA8n9ksPf649aW40oyyqVMZSh0AvI3bR13HjBmjY8eOKTExUXl5eYqIiFBaWpqCgoIkSdnZ2Q7zhZ87d07Tp0/Xvn371KhRIw0bNkwrVqxQs2bNHI77xRdfKDs7Ww8++GBtXk757LPJjIfrBMUBAHB/pScgNdinlwEAALfmbOAXMsUBAPBOmzZJhw+Xv91ikQ4dstYbOLDWmgUAqGEeEXWNi4tTXFyc020ZGRkO6wMGDNAPP/xwyWMOHjxYFmevgrmKfVDceEW99MN1AADgfsoLittPjQIAANyas0xx5hQHAMA75eZWbz0AgGdw++HT6wyjt230tO3LAACA+yJTHAAAj0emOAAAdUebNtVbDwDgGQiKuwsjAH7uXNkyAADgvowX2kpPMmqfXgYAANyafaa4MUMbc4oDAOCd+vWT2rWTTCbn200mKTTUWg8A4D0IirsLo7dNUBwAAM9yqUxxs9k6IRkAAHBb9rdz4wG5/fttZIoDAOA9fH2l+fOt30sHxo31lBRrPQCA9yAo7i6M3vbZs2XLAACA+7rUnOIS84oDAODmjFu1/e3bfvh05hQHAMC7xMRIH38shYQ4lrdrZy2PiXFNuwAANYeguLtwFhQv/XAdAAC4n0tliksExQEAbm/hwoUKCwtTQECAIiMjtXXr1nLrnj9/XrNmzVKnTp0UEBCg8PBwpaWlOdQxm82aMWOGOnTooMDAQHXq1EkvvPCCLHajp1gsFiUmJqpNmzYKDAxUVFSU9uzZU2PXWBFnt3Nnw6cTFAcAwHvExEgHDki9e1vXn35a2r+fgDgAeCuC4u6i9JziJtPFicwAAID7qkxQnHnFAQBubOXKlYqPj9fMmTO1fft2hYeHKzo6WkePHnVaf/r06XrjjTe0YMEC/fDDD5o0aZJGjhypHTt22OrMmTNHixYt0muvvaZdu3Zpzpw5mjt3rhYsWGCrM3fuXL366qtavHixsrKy1LBhQ0VHR+uc/bRitcRZpriz4dOZUxwAAO/i6yt172793rgxQ6YDgDcj6uouSgfFGTodAADPwPDpAAAPl5ycrIkTJyo2NlbdunXT4sWL1aBBAy1dutRp/RUrVujZZ5/VsGHD1LFjR02ePFnDhg3TK6+8YquzZcsWjRgxQsOHD1dYWJhGjRqlwYMH2zLQLRaLUlJSNH36dI0YMUI9evTQ8uXLdeTIEa1Zs6Y2LttBRZnizCkOAIB3M4ZQz8lxbTsAADWLoLi7ICgOAIBnMiYZLR0Ut3+9nExxAICbKi4u1rZt2xQVFWUr8/HxUVRUlDIzM53uU1RUpICAAIeywMBAbd682bZ+8803Kz09XT/99JMk6ZtvvtHmzZs1dOhQSdL+/fuVl5fncN6mTZsqMjKywvMWFBQ4LNWlojnFGT4dAADvRlAcAOoGIq/uwuhtExQHAMCzGAHv0uOpmkzW+/mFCwTFAQBu6/jx4zKbzQoKCnIoDwoK0u7du53uEx0dreTkZPXv31+dOnVSenq6UlNTZTabbXWeeeYZFRQUqGvXrvL19ZXZbNZLL72k++67T5KUl5dnO0/p8xrbSktKStLzzz9/2ddakYoyxUtKLnbVCYoDAOB9CIoDQN1Apri7MILgZ89aP0tnmwEA4MEWLlyosLAwBQQEKDIy0jZ0qjPff/+97r77boWFhclkMiklJeWKj1mjyhs+3b6M4dMBAF5k/vz56tKli7p27So/Pz/FxcUpNjZWPj4XHzF89NFHeu+99/T+++9r+/btWrZsmebNm6dly5Zd9nkTEhJ06tQp23Lo0KHquBxJFc8pLkmFhdZP5hQHAMD7EBQHgLqBoLi7KB0UJ1McAOAlVq5cqfj4eM2cOVPbt29XeHi4oqOjdfToUaf1z5w5o44dO2r27NkKDg6ulmPWqIqC4sb9nExxAICbatmypXx9fZWfn+9Qnp+fX+59uFWrVlqzZo0KCwt18OBB7d69W40aNVLHjh1tdZ566ik988wzGjt2rLp37677779fTzzxhJKSkiTJduyqnNff319NmjRxWKpLRZniknT6tNGGajslAABwE0ZQPD+f7jsAeDOC4u6COcUBAF4qOTlZEydOVGxsrLp166bFixerQYMGWrp0qdP6N954o15++WWNHTtW/uU8ea7qMWsUmeIAAA/m5+enXr16KT093VZWUlKi9PR09e3bt8J9AwICFBISogsXLmjVqlUaMWKEbduZM2ccMsclydfXVyUlJZKkDh06KDg42OG8BQUFysrKuuR5a0JFc4pLBMUBAPBmrVpZ7/sWi1TOLC4AAC9AUNxdGD1vZz1xAAA8VHFxsbZt26aoqChbmY+Pj6KiopSZmVmrxywqKlJBQYHDUi0qExTnVXMAgBuLj4/XkiVLtGzZMu3atUuTJ09WYWGhYmNjJUnjx49XQkKCrX5WVpZSU1O1b98+bdq0SUOGDFFJSYmmTZtmq3PHHXfopZde0meffaYDBw5o9erVSk5O1siRIyVJJpNJU6dO1YsvvqhPPvlE3333ncaPH6+2bdvqrrvuqtXrl5zfzp0Nn05QHAAA7+PjI7VpY/3OEOoA4L2IvLqL0g/SCYoDALzA8ePHZTabFRQU5FAeFBSk3bt31+oxk5KS9Pzzz1/WOStUXGz9rGj4dDLFAQBubMyYMTp27JgSExOVl5eniIgIpaWl2e612dnZDlnf586d0/Tp07Vv3z41atRIw4YN04oVK9SsWTNbnQULFmjGjBmaMmWKjh49qrZt2+r3v/+9EhMTbXWmTZumwsJCPfLIIzp58qRuueUWpaWlKSAgoNau3eDs/XSTSfL1lcxmguIAAHi7kBApO5ugOAB4MyKv7qJ0ENzZg3UAAHDZEhISFB8fb1svKChQaGjolR/YSC3z8yu7jUxxAICHiIuLU1xcnNNtGRkZDusDBgzQDz/8UOHxGjdurJSUFKWkpJRbx2QyadasWZo1a1ZVm1vtyhv4pX59a1DcGD7d2e0eAAB4PmNecYLiAOC9CIq7i9JBcTLFAQBeoGXLlvL19VV+fr5DeX5+voKDg2v1mP7+/uXOUX5FKho+3bifExQHAMCtlTeTmbFOpjgAAN6NoDgAeD/mFHcXBMUBAF7Iz89PvXr1Unp6uq2spKRE6enp6tu3r9sc84pUZk5xhk8HAMCtVZQpLl3MFCcoDgCAdyIoDgDej8iruyAoDgDwUvHx8ZowYYJ69+6tPn36KCUlRYWFhYqNjZUkjR8/XiEhIUpKSpIkFRcX24ZkLS4uVk5Ojnbu3KlGjRqpc+fOlTpmrSJTHAAAj1deprhxeydTHAAA70ZQHAC8H5FXd1H6QTpBcQCAlxgzZoyOHTumxMRE5eXlKSIiQmlpaQoKCpIkZWdny8fn4uA1R44cUc+ePW3r8+bN07x58zRgwADbnKaXOmatIlMcAACPV9lMceYUBwDAOxEUBwDvR+TVXZApDgDwYnFxcYqLi3O6zQh0G8LCwmSxWK7omLWquNj6WVFQnExxAADcGnOKAwBQt9kHxS0WyWRybXsAANWPOcXdRXljtAEAAPdmBLydpY4Z93cyxQEAcGuXyhQ33oEjKA4AgHcyguJnzkinTrm2LQCAmkFQ3F2QKQ4AgGeqzPDpZIoDAODWLjWnuIGgOAAA3ikwUGre3PqdIdQBwDsRFHcXBMUBAPA8ZrN08KD1++HD1nV7xv2coDgAAG6tvHfcSnfNmVMcAADvxbziAODdCIq7C4LiAAB4ltRUKSxM+vRT6/rbb1vXU1Mv1jGerDN8OgAAbo1McQBAXbBw4UKFhYUpICBAkZGR2rp1a7l1v//+e919990KCwuTyWRSSkrKFR/T3REUBwDvRlDcXVzqdXQAAOA+UlOlUaOs2eH2cnKs5UZgnExxAAA8wqXmFDcQFAcAeKqVK1cqPj5eM2fO1Pbt2xUeHq7o6GgdPXrUaf0zZ86oY8eOmj17toKDg6vlmO6OoDgAeDeC4u7iUq+jAwAA92A2S48/LlksZbcZZVOnWuuRKQ4AgEcgUxwA4O2Sk5M1ceJExcbGqlu3blq8eLEaNGigpUuXOq1/44036uWXX9bYsWPlX84NsKrHlKSioiIVFBQ4LO6CoDgAeDeC4u6C4dMBAPAMmzaVzRC3Z7FIhw5Z6xlP0skUBwDArTGnOADAmxUXF2vbtm2Kioqylfn4+CgqKkqZmZm1esykpCQ1bdrUtoSGhl7W+WsCQXEA8G4Exd0FQXEAADxDbm7l6xn3czLFAQBwa2SKAwC82fHjx2U2mxUUFORQHhQUpLy8vFo9ZkJCgk6dOmVbDh06dFnnrwkExQHAuxF5dRcExQEA8Axt2lS+HpniAAB4BOYUBwCgdvj7+5c7HLurERQHAO9Gpri7+H/s3XtcVHX+x/H3MAp4A++ggkLqppZpaRkaqeWGZaWhZVarWenWT3dFu1qmZRfbLgablpvbxS3vRNZmWWbqWpqWZWVeMsVEBNRSMUvQmfP74zQjAwMMMDDDzOv5ePCYOed8zpnvnEG/nPmc7+dLUhwAgNohMVGKiZEsFvfbLRYpNtaMc/TnJMUBAPBrpY0UL77sp9/hAwBQpubNm8tqtSovL89lfV5enqKjo/3mmL7maHZenvTxx5LN5tv2AAC8i6S4v7BYJKv1zHLx29EBAIB/sFqltDTzefHEuGM5NdWMc/TnlE8HAMCvMVIcABDIQkND1aNHD61atcq5zm63a9WqVUpISPCbY/pSRoZ00UVnlv/8ZykuzlwPAAgMJMX9SdFb0BkpDgCA/0pOltLTz9RWc4iJMdcnJ5vLxUeK22zSmjXSwoXmI7edAwDgFzydUzw0tGbaAwCAt02aNElz587VvHnztH37dt111106ceKERo8eLUkaOXKkJk+e7IwvLCzUli1btGXLFhUWFio7O1tbtmzRjz/+6PExa4uMDGnYMGn/ftf12dnmehLjABAYyLz6kzp1pIKCM88BAID/Sk6WBg+W1q2TcnLMOcQTE91Xfjl92ryKnjDB9So7JsYcde5IogMAAJ8obaR48XvXQxhaAACopYYPH65Dhw5p6tSpys3NVffu3bVixQpFRUVJkvbt26eQIh3dgQMHdP755zuXn332WT377LPq27ev1qxZ49ExawObzbxUN4yS2wzDLAiXkmJe/he93AcA1D5kXv0JI8UBAKhdrFapX7/Stzu+Wd+2TXrmmZJX2Y7bzouOLgcAADXOk5HilE4HANR248eP1/jx491ucyS6HeLi4mS4yxRX4Ji1wbp1JUeIF2UYUlaWGVfW5T8AwP9xj7M/KXq1TVIcAIDaz9Gfr1lT+m3nknnbOaXUAQDwGU/mFCcpDgBA4MnJ8W4cAMB/kRT3J0UT4cWvxAEAQO3j6M9//bX0mKK3nQMAAJ/wZKQ484kDABB4WrXybhwAwH+RFPcnlE8HACCwVKQ/57ZzAAB8xpM5xRkpDgBA4ElMlGJizLnD3bFYpNhYMw4AULuRFPcnJMUBAAgsFan8wm3nAAD4DHOKAwAQnKxWKS3NfF48Me5YTk014wAAtRtJcX9CUhwAgMDi6M/r1y89htvOAQDwOeYUBwAgeCUnS+npUps2ruujo831ycm+aRcAwLtqRVJ89uzZiouLU3h4uHr16qVNmzaVGnvq1ClNnz5d7du3V3h4uLp166YVK1aUiMvOztYtt9yiZs2aqV69euratau+/PLL6nwb5St6tU1SHACA2s/Rt3fv7n47t50DAOAXShspXnSZOcUBAAhcycnS3r3S6tVnCrm9/joJcQAIJH6fFF+8eLEmTZqkadOm6auvvlK3bt2UlJSkgwcPuo2fMmWK/vWvf+mFF17Qtm3bdOedd+q6667T119/7Yw5cuSI+vTpo7p16+qDDz7Qtm3b9Nxzz6lJkyY19bbcK3q1XZFyqwAAwD85+vOoKKlnz5LbY2K47RwAAD/ASHEAAGC1Sv36SRdcYC5nZvq0OQAAL/P7pPjMmTM1ZswYjR49Wl26dNGcOXNUv359vfrqq27j33jjDT344IO66qqrdNZZZ+muu+7SVVddpeeee84Z849//EOxsbF67bXXdNFFFyk+Pl5XXHGF2rdvX1Nvyz3KpwMAEFgc/XlhobR7t/n8iivMx4QE8wqbhDgAAD7HnOIAAMDBkSZwXMYDAAKDXyfFCwsLtXnzZg0YMMC5LiQkRAMGDNCGDRvc7lNQUKDw8HCXdfXq1dOnn37qXH733XfVs2dPXX/99WrZsqXOP/98zZ07t8y2FBQUKD8/3+XH60iKAwAQWBzfpH/9tXTkiNSwofTgg+a6rCxKpgMA4CdKGyle9NKcpDgAAMGhQwfz8ccffdsOAIB3+XVS/PDhw7LZbIqKinJZHxUVpdzcXLf7JCUlaebMmdq1a5fsdrtWrlypjIwM5eTkOGP27Nmjl156SR07dtSHH36ou+66S3//+981b968UtsyY8YMRUZGOn9iY2O98yaLIikOAEBgcfTnBw6Yj336nKnDtn+/dPiwb9oFAABceDJSnDnFAQAIDowUB4DA5NdJ8cpIS0tTx44d1alTJ4WGhmr8+PEaPXq0QkLOvFW73a4LLrhATz75pM4//3yNHTtWY8aM0Zw5c0o97uTJk3Xs2DHnT1ZWlvcbT1IcAIDAUny4Wd++UqNGZ247/+abmm8TAAAogTnFAQCAg+OSffduyTB82xYAgPf4dVK8efPmslqtysvLc1mfl5en6Ohot/u0aNFCy5Yt04kTJ/TTTz9px44datiwoc466yxnTKtWrdSlSxeX/Tp37qx9+/aV2pawsDBFRES4/Hhd0avt4lfiAACg9il+k9ull5qP3bubj1u21GRrAABAKZhTHAAAOMTFSSEh0okTUrHUBACgFvPrpHhoaKh69OihVatWOdfZ7XatWrVKCQkJZe4bHh6uNm3a6PTp03rrrbc0ePBg57Y+ffpo586dLvE//PCD2rVr5903UFGMFAcAILAUqVSj0NAzpdNJigMA4FeYUxwAADiEhkpt25rPmVccAAKHXyfFJWnSpEmaO3eu5s2bp+3bt+uuu+7SiRMnNHr0aEnSyJEjNXnyZGf8xo0blZGRoT179mjdunUaOHCg7Ha77rvvPmfMxIkT9fnnn+vJJ5/Ujz/+qAULFujll1/WuHHjavz9uSApDgBA4MjIkMaMObNcWCj96U/mepLiAAA/M3v2bMXFxSk8PFy9evXSpk2bSo09deqUpk+frvbt2ys8PFzdunXTihUrXGLi4uJksVhK/BS97u7Xr1+J7XfeeWe1vceyMKc4AAAoinnFASDw+H3mdfjw4Tp06JCmTp2q3Nxcde/eXStWrFBUVJQkad++fS7zhZ88eVJTpkzRnj171LBhQ1111VV644031LhxY2fMhRdeqLfffluTJ0/W9OnTFR8fr9TUVN188801/fZckRQHACAwZGRIw4aVnHwsO9tc/69/mcvbt0snT0rh4TXfRgAA/rB48WJNmjRJc+bMUa9evZSamqqkpCTt3LlTLVu2LBE/ZcoUvfnmm5o7d646deqkDz/8UNddd53Wr1+v888/X5L0xRdfyGazOffZunWr/vznP+v66693OdaYMWM0ffp053L9+vWr6V2WjTnFAQBAUR06SKtWMVIcAAJJrci8jh8/XuPHj3e7bc2aNS7Lffv21bZt28o95tVXX62rr77aG83zHpLiAADUfjabNGFCyYS4ZK6zWKTHHpOaNZN+/ln6/nupR4+abycAAH+YOXOmxowZ46zINmfOHC1fvlyvvvqqHnjggRLxb7zxhh566CFdddVVkqS77rpLH3/8sZ577jm9+eabkqQWLVq47PPUU0+pffv26tu3r8v6+vXrKzo6ujreVoWUNlKc8ukAAAQnRooDQODx+/LpQaXoLegkxQEAqJ3WrZP27y99u2FIWVlSu3bmMiXUAQA+VFhYqM2bN2vAgAHOdSEhIRowYIA2bNjgdp+CggKFF6tyUq9ePX366aelvsabb76p2267TRaLxWXb/Pnz1bx5c5177rmaPHmyfvvtt1LbWlBQoPz8fJcfb2GkOAAAKMqRFGekOAAEDpLi/qRoIrz4lTgAALVcReYqlaSlS5eqU6dOCg8PV9euXfX++++7bL/11ltLzEM6cODA6nwLnsnJ8SzOMSpuyRJpzRpzhDkAADXs8OHDstlszinKHKKiopSbm+t2n6SkJM2cOVO7du2S3W7XypUrlZGRoZxS+sBly5bp6NGjuvXWW13W33TTTXrzzTe1evVqTZ48WW+88YZuueWWUts6Y8YMRUZGOn9iY2Mr9mbL4Mmc4iTFAQAIHh06mI+MFAeAwEFS3J9QPh0AEKAcc5VOmzZNX331lbp166akpCQdPHjQbfz69es1YsQI3X777fr66681ZMgQDRkyRFu3bnWJGzhwoHJycpw/CxcurIm3U7ZWrTyLW7fOfPzoI6l/fykuzpyLHAAAP5eWlqaOHTuqU6dOCg0N1fjx4zV69GiFhLj/iuGVV17RlVdeqdatW7usHzt2rJKSktS1a1fdfPPN+s9//qO3335bu0v59nny5Mk6duyY8ycrK8tr78mTkeKhoV57OQAA4OfOOst8/OUX6cgR37YFAOAdJMX9CUlxAECAKjpXaZcuXTRnzhzVr19fr776qtv4tLQ0DRw4UPfee686d+6sxx57TBdccIFmzZrlEhcWFqbo6GjnT5MmTWri7ZQtMVGKiTHnDi/L8eOuy9nZ0rBhJMYBADWqefPmslqtysvLc1mfl5dX6lzfLVq00LJly3TixAn99NNP2rFjhxo2bKizHN8eF/HTTz/p448/1h133FFuW3r16iVJ+rGUOqVhYWGKiIhw+fEGu938kZhTHAAAmBo2PFPgjdHiABAYSIr7E5LiAIAAVJm5Sjds2OASL5mlWovHr1mzRi1bttTZZ5+tu+66Sz///HOp7ajOeUhdWK1SWpr5vLzEeFGGYT6mpFBKHQBQY0JDQ9WjRw+tWrXKuc5ut2vVqlVKSEgoc9/w8HC1adNGp0+f1ltvvaXBgweXiHnttdfUsmVLDRo0qNy2bNmyRZLUytOqK17iKJ0uMac4AAA4wzGvOElxAAgMJMX9SdGrbZLiAIAAUZm5SnNzc8uNHzhwoP7zn/9o1apV+sc//qG1a9fqyiuvlK2UhHJ1zkNaQnKylJ4utWnjur5Fi7L3MwwpK0t64QUS4wCAGjNp0iTNnTtX8+bN0/bt23XXXXfpxIkTGj16tCRp5MiRmjx5sjN+48aNysjI0J49e7Ru3ToNHDhQdrtd9913n8tx7Xa7XnvtNY0aNUp1il3j7t69W4899pg2b96svXv36t1339XIkSN16aWX6rzzzqv+N11E0aQ4c4oDAAAHRxGct96S1qzhMh0Aajsyr/6k6NV38dvTAQCAixtvvNH5vGvXrjrvvPPUvn17rVmzRpdffnmJ+MmTJ2vSpEnO5fz8/OpPjA8ebM4dnpNjzjWenS3dckv5+06cKD33nDniPDm5+toIAICk4cOH69ChQ5o6dapyc3PVvXt3rVixwnmD2r59+1zmCz958qSmTJmiPXv2qGHDhrrqqqv0xhtvqHHjxi7H/fjjj7Vv3z7ddtttJV4zNDRUH3/8sVJTU3XixAnFxsZq6NChmjJlSrW+V3cc84lLJS/Fi16mM6c4AADBIyNDeucd8/nSpeZPTAyX6QBQm5EU9yeUTwcABKDKzFUaHR1doXhJOuuss9S8eXP9+OOPbpPiYWFhCqvpIV5Wq9Sv35nlNWs839cxx3h6esnkemKieWwAALxk/PjxGj9+vNtta4r1X3379tW2bdvKPeYVV1whwzE9SDGxsbFau3ZthdtZHRgpDgAAisrIMC/Hi/8ZU/QyncQ4ANQ+lE/3JyTFAQABqDJzlSYkJLjES9LKlSvLnNt0//79+vnnn2t8HtIKSUw0by33ZK5xwzB/Ro2SoqOl/v2lm24yH+PizKt0AABQZY6R4hZLyXvOSIoDABBcbDZpwoSSCXHpzLqUFKmw0LzvfeFCSqsDQG1BUtyfkBQHAASois5VOmHCBK1YsULPPfecduzYoUceeURffvmlcwTbr7/+qnvvvVeff/659u7dq1WrVmnw4MHq0KGDkpKSfPIePWK1mrXWJM8S45L066/S4cOu6xy3pzsS4zYbV+MAAFSSY6S4u8vwoutIigMAEPjWrZP27y99u2FIWVnm/e7cuw4AtQuZV39CUhwAEKAqOldp7969tWDBAk2ZMkUPPvigOnbsqGXLluncc8+VJFmtVn377beaN2+ejh49qtatW+uKK67QY489VvMl0isqOdmstTZhQtlX2mUxDDOpnpIi2e3mHORFj8VEZwAAeMwxUrz4fOLF1zGnOAAAgS8nx7O4Q4dclymtDgD+j8yrPyl6te3uahwAgFqsInOVStL111+v66+/3m18vXr19OGHH3qzeTUrOdmcJ/yFF8yEdmU4bk93d44qMh+5zcZ85QCAoFbWSHHKpwMAEFwqOyNb0XvXBw8213GpDQD+hfLp/oSR4gAABA+rVfrb3zyfY7wiHBOdjR1r1nArraZbRkbZ28sry07ZdgBAAChrpHiRQjb67ju6OgAAAl1iYuUv0x33rj/xRNmX2gAA3yDz6k9IigMAEFwcc4wPG2ZecTuS2d5gGNLPP5dc7xhFfs890rPPlnzNotsXLiy9LHtGRskS8EW3lzcCvaztvtoXABCUShspnpFh3r/mMGaM9OijzFACAEAg88Zl+rRpJdd5q6BbVS6H4Vve+iqjZUtz3cGDZmzv3tL69Wf2Lbpckdiq7BtMbaL91fM6NfX/FZlXf0JSHACA4OONOcYrwnFFP3Om+6t7x7pnnim5rSYS6lLZyXZv79u8uXTLLea3Ev5yJVDb9q0NbeT9+f51/PX98U0h5H6keEaG2aWV1tUxXygAAIGrtMv0Jk2kI0cqd0xHefWxY6vnkresbY6/WXxxb3rxbbXhEqE62rRrlzR3ruvn06aN+ftw5Ig0f77rPPWObR07ut+3KKvVtZpR8eWKxFZl32BqE+33fmzx/6+qi8UwvDkkKXjk5+crMjJSx44dU0REhHcO+uKL0rhx5vPTp/lyBgACWLX0I6gQv/sMHKXIb7hB+uUXX7embGX9lVsaR+250hLqnrj6aum99yq+n6f7+suVQG3ctza0kffn+9fxx/dXhStvv+tHgpC3PoONG6WLLzbLmmZmmr8icXGlf/FosZi/OpmZXLYDQG1Hf+57/vwZOBK648ZJ27ZJL7wg/eMf5k1y3syqlHe5XNaI9fK2SWaCX6pYQr28pKzj/vImTSqW7K0NlwjV1SYApSv6/1VFL88r0o+QFK+kaums5841ewuLRbLbvXNMAIBf8ueLvmDht5+BY2iaVPZV9n33SQsW1Mzocm/ydpl4AKiKKlx5+20/EkS89Rl8+qk5oqljR+mHH8x71Pr3L3+/1aulfv0q/bIAAD9Af+57teEzePRR6ZFHpBEjzMt1d9VkvKG6EqoNG0q//ur94wKAN1X25uOK9CMhVWwjvMlRMp3S6QAABC9HnbY2bVzXt2ghpaScSZhv3HjmeW1CQhyAP3H8n5SSwpCOIFZ8TvGcHM/28zQOAADUbomJ5uP//iddd520dKkUUiyzYrG4n0u8Iqrrz1ES4gBqA8OQsrLMCh3VhaS4PyEpDgAAJDMxvnevOQRtwQLzMSdHev55qVcvM2btWik11f3+kZFSs2ZnRkC6Q71XADDVxJU3/FrxOcVbtfJsP0/jAABA7XbxxeZX9tnZ5qV6x45modfQUOnVV82R2IZhVpCJifF1awGgdqvOm49JivsTkuIAAMDBajWvqEeMMB+tVrO0+n33lb5P377m47nnSi+/XPbxr7zSWy0FgMDAsN+gVXykeGKi+YV2afeWWSxSbOyZUWMAACCw1a8v9expPv/f/6T33zefX3GFNHq0NHiwufz++2fm6AYAVE513nxMUtyfkBQHAAClsdmkCRNKLz9usUi7dpnP16+XeveWbrml9OO995732wgAtRnDfoNW8ZHiVuuZL7SLJ8Ydy6mpFF0BANQ+s2fPVlxcnMLDw9WrVy9t2rSpzPilS5eqU6dOCg8PV9euXfW+Ixv8h1tvvVUWi8XlZ+DAgdX5Fnzm0kvNx//9T1q+3Hx+1VXm4zXXmI+LFkm//MLX+wBQGTVx8zFJcX/imIjEZpPWrGFOOwAAcMa6ddL+/aVvNwzpwAGpc2fz+T/+Ia1aZW67+25zvtyyNGzotaYCQK3CsN+gV1BgPh45cuZSPDlZSk+X2rRxjY2JMdcnJ9d4MwEAqJLFixdr0qRJmjZtmr766it169ZNSUlJOnjwoNv49evXa8SIEbr99tv19ddfa8iQIRoyZIi2bt3qEjdw4EDl5OQ4fxYuXFgTb6fGOZLi77wjffaZ+TwpyXwsLDQfs7KkMWPMKjRWq/TII+VfigMAau7mY5Li/iIjQ/rrX83n+flS//5SXJy5HgAAwNOyvs2amY+pqWaSXDLnJX/jjbL3+/XXSjcNAGothv0GvYwM6c47zec//OB6KZ6cbM4bunq12ZWuXi1lZpIQBwDUTjNnztSYMWM0evRodenSRXPmzFH9+vX16quvuo1PS0vTwIEDde+996pz58567LHHdMEFF2jWrFkucWFhYYqOjnb+NGnSpMx2FBQUKD8/3+WnNvjlF/Px55/PFHDr29ec4WzUqJLxNpuZFC/vUhyoquKXMWVd1pQXW5V9g6lNFYn1xzZVJLamXqembj6mkIc/yMiQhg0rWQ41O9tcz23oAADA07K+n35acl1tnSf36qvNMu8WS+ll4yu779VXSxs3SocOnVlntbpW6ilvuShvxtbGfWtDG3l/vn8df3x/MTFmQpzrraDk6aV4v34+aR4AAF5TWFiozZs3a/Lkyc51ISEhGjBggDZs2OB2nw0bNmjSpEku65KSkrRs2TKXdWvWrFHLli3VpEkTXXbZZXr88cfVzHGzthszZszQo48+Wvk34wMZGe4T3/v3S888U/a+P/9cPW2qrWrDJUJ1tSkmxqwk0LGjOfvd3LmuBQFbtJBuvllq0qTktqL7tmxprjt40PyqqHdvcxa9nJySyxWJrcq+wdQm2l89r5OYWDP3qVsMo6LfMEKS8vPzFRkZqWPHjikiIqLyB7LZzNvQSyuHarGY/+NlZjJyAQACiNf6EVRarfsMHH8zZGeXniAu6+qrulgsUtOmZ26bL9q2ognp4slpx+jMe+6RFi50/VsoNvZMkiojw5xL3d12qfRt5e2bnGyeq3XrPPvLvzZccdSWK53atm9taCPvr/KxVbjyrnX9SACqymfApTgAQAqe/vzAgQNq06aN1q9fr4SEBOf6++67T2vXrtXGjRtL7BMaGqp58+ZpxIgRznUvvviiHn30UeXl5UmSFi1apPr16ys+Pl67d+/Wgw8+qIYNG2rDhg2yltKBFhQUqMAxd4nMzyA2NtZvP4Py/mbwFatVstvLvn+8rHvEy7qHfPhws0S8u6TskSPS/Pmu95d7muwdPLh2XCJUV5uKX3oU/0qi6PaytgFwVZG+nKR4JXntD6Y1a8z6bOVZvZrb0wEggATLhbc/q5WfgWNIm1R68rk6lZbYTk83HyubvC7vaq8qV4pcSQKoJrWyHwkwVfkMuBQHAEjB059XV1K8uD179qh9+/b6+OOPdfnll3vUNn//DDz9m6G6lHV/+bPPms+9ff95eZfpXIYD8CcV6Ucon+5rnpYzra1lTwEAgPckJ5sJ6OJXrjEx0tChZxLQFVXeaG/J/RV18bLDgweXfuVb1jarteyMQ1nbq7IvACBocSkOAAgmzZs3l9VqLZHMzsvLU3R0tNt9oqOjKxQvSWeddZaaN2+uH3/80eOkuL+rib8FKlJYrehl+MUXu/96wLF9xozSL8OTkyt/mc5lOIDaiqS4r3k6P6incQAAILCVduW6bl3lkuKOq+2XXzYfK3tFLVXtqhkAgBrEpTgAIJiEhoaqR48eWrVqlYYMGSJJstvtWrVqlcaPH+92n4SEBK1atUopKSnOdStXrnQZaV7c/v379fPPP6tVAHWgVXkr3rj/vLoS255sB4BAQ1Lc1xITzV6utPlBHROZJSbWfNsAAIB/cnfl6snfFE2bSvXqVX60N1fMAIAAwaU4ACDYTJo0SaNGjVLPnj110UUXKTU1VSdOnNDo0aMlSSNHjlSbNm00Y8YMSdKECRPUt29fPffccxo0aJAWLVqkL7/8Ui//cUP1r7/+qkcffVRDhw5VdHS0du/erfvuu08dOnRQUlKSz96nt5X3N4NDaaO9q3r/OYltAPAekuK+ZrVKaWnm/KCl9ZypqUy6AQAAyubJ3xQvv1x20ttxHK6oAQABjktxAECwGT58uA4dOqSpU6cqNzdX3bt314oVKxQVFSVJ2rdvn0JCQpzxvXv31oIFCzRlyhQ9+OCD6tixo5YtW6Zzzz1XkmS1WvXtt99q3rx5Onr0qFq3bq0rrrhCjz32mMLCwnzyHquDJ38zVHW2MS7DAaBmWAyjrPubUJqKTNzukYyMkreLxca69pwAgIDh9X4EFRawnwF/UwBAjQjYfqQW8cZnQLcJAMGN/tz3astnUN7fDDZb2fefAwCqR0X6EZLilVQtnTU9JwAEjdpy0RfIAvoz4G8KAKh2Ad2P1BLe+gzoNgEgeNGf+15t+gz4mwEA/E9F+hHKp/sT6qQAAABv4G8KAAA8RrcJAAA8wd8MAFC7hZQfAgAAAAAAAAAAAABA7URSHAAAAAAAAAAAAAAQsEiKAwAAAAAAAAAAAAACFnOKV5JhGJLMCdwBAKgoR//h6E9Q8+jLAQBVQV/ue/TlAICqoj/3PfpzAEBVVKQvJyleScePH5ckxcbG+rglAIDa7Pjx44qMjPR1M4ISfTkAwBvoy32HvhwA4C30575Dfw4A8AZP+nKLwW1wlWK323XgwAE1atRIFoul0sfJz89XbGyssrKyFBER4cUWBh7OlWc4T57jXHmOc+WZipwnwzB0/PhxtW7dWiEhzGbiC/TlNY9z5TnOlWc4T57jXHnO03NFX+573urLJf6NeIrzVD7OkWc4T57hPHmmKueJ/tz3uDavWZwnz3CePMN58gznqXw11ZczUrySQkJCFBMT47XjRURE8I/BQ5wrz3CePMe58hznyjOenifuQvct+nLf4Vx5jnPlGc6T5zhXnvPkXNGX+5a3+3KJfyOe4jyVj3PkGc6TZzhPnqnseaI/9y2uzX2D8+QZzpNnOE+e4TyVr7r7cm5/AwAAAAAAAAAAAAAELJLiAAAAAAAAAAAAAICARVLcx8LCwjRt2jSFhYX5uil+j3PlGc6T5zhXnuNceYbzFJz43D3HufIc58oznCfPca48x7kKTnzunuE8lY9z5BnOk2c4T57hPEHi98BTnCfPcJ48w3nyDOepfDV1jiyGYRjV+goAAAAAAAAAAAAAAPgII8UBAAAAAAAAAAAAAAGLpDgAAAAAAAAAAAAAIGCRFAcAAAAAAAAAAAAABCyS4gAAAAAAAAAAAACAgEVSHAAAAAAAAAAAAAAQsEiK+9js2bMVFxen8PBw9erVS5s2bfJ1k3xqxowZuvDCC9WoUSO1bNlSQ4YM0c6dO11iTp48qXHjxqlZs2Zq2LChhg4dqry8PB+12D889dRTslgsSklJca7jPJ2RnZ2tW265Rc2aNVO9evXUtWtXffnll87thmFo6tSpatWqlerVq6cBAwZo165dPmyxb9hsNj388MOKj49XvXr11L59ez322GMyDMMZE6zn6n//+5+uueYatW7dWhaLRcuWLXPZ7sl5+eWXX3TzzTcrIiJCjRs31u23365ff/21Bt8Fqgt9uSv68sqjPy8b/Xn56MtLR1+OstCXu6Ivrzj68LLRh5eN/rt09N/wFH25K/ryyqE/Lx19efnoz93zu77cgM8sWrTICA0NNV599VXj+++/N8aMGWM0btzYyMvL83XTfCYpKcl47bXXjK1btxpbtmwxrrrqKqNt27bGr7/+6oy58847jdjYWGPVqlXGl19+aVx88cVG7969fdhq39q0aZMRFxdnnHfeecaECROc6zlPpl9++cVo166dceuttxobN2409uzZY3z44YfGjz/+6Ix56qmnjMjISGPZsmXGN998Y1x77bVGfHy88fvvv/uw5TXviSeeMJo1a2a89957RmZmprF06VKjYcOGRlpamjMmWM/V+++/bzz00ENGRkaGIcl4++23XbZ7cl4GDhxodOvWzfj888+NdevWGR06dDBGjBhRw+8E3kZfXhJ9eeXQn5eN/twz9OWloy9HaejLS6Ivrxj68LLRh5eP/rt09N/wBH15SfTlFUd/Xjr6cs/Qn7vnb305SXEfuuiii4xx48Y5l202m9G6dWtjxowZPmyVfzl48KAhyVi7dq1hGIZx9OhRo27dusbSpUudMdu3bzckGRs2bPBVM33m+PHjRseOHY2VK1caffv2dXbYnKcz7r//fuOSSy4pdbvdbjeio6ONZ555xrnu6NGjRlhYmLFw4cKaaKLfGDRokHHbbbe5rEtOTjZuvvlmwzA4Vw7FO29Pzsu2bdsMScYXX3zhjPnggw8Mi8ViZGdn11jb4X305eWjLy8f/Xn56M89Q1/uGfpyFEVfXj768tLRh5ePPrx89N+eof9GaejLy0dfXjb687LRl3uG/rx8/tCXUz7dRwoLC7V582YNGDDAuS4kJEQDBgzQhg0bfNgy/3Ls2DFJUtOmTSVJmzdv1qlTp1zOW6dOndS2bdugPG/jxo3ToEGDXM6HxHkq6t1331XPnj11/fXXq2XLljr//PM1d+5c5/bMzEzl5ua6nKvIyEj16tUr6M5V7969tWrVKv3www+SpG+++UaffvqprrzySkmcq9J4cl42bNigxo0bq2fPns6YAQMGKCQkRBs3bqzxNsM76Ms9Q19ePvrz8tGfe4a+vHLoy4MXfbln6MtLRx9ePvrw8tF/Vw79NyT6ck/Rl5eN/rxs9OWeoT+vOF/05XWq3mxUxuHDh2Wz2RQVFeWyPioqSjt27PBRq/yL3W5XSkqK+vTpo3PPPVeSlJubq9DQUDVu3NglNioqSrm5uT5ope8sWrRIX331lb744osS2zhPZ+zZs0cvvfSSJk2apAcffFBffPGF/v73vys0NFSjRo1yng93/xaD7Vw98MADys/PV6dOnWS1WmWz2fTEE0/o5ptvliTOVSk8OS+5ublq2bKly/Y6deqoadOmQX3uajv68vLRl5eP/twz9OeeoS+vHPry4EVfXj768tLRh3uGPrx89N+VQ/8Nib7cE/TlZaM/Lx99uWfozyvOF305SXH4rXHjxmnr1q369NNPfd0Uv5OVlaUJEyZo5cqVCg8P93Vz/JrdblfPnj315JNPSpLOP/98bd26VXPmzNGoUaN83Dr/smTJEs2fP18LFizQOeecoy1btiglJUWtW7fmXAGoFPrystGfe47+3DP05QC8jb7cPfpwz9GHl4/+G0B1oi8vHf25Z+jLPUN/XjtQPt1HmjdvLqvVqry8PJf1eXl5io6O9lGr/Mf48eP13nvvafXq1YqJiXGuj46OVmFhoY4ePeoSH2znbfPmzTp48KAuuOAC1alTR3Xq1NHatWv1z3/+U3Xq1FFUVBTn6Q+tWrVSly5dXNZ17txZ+/btkyTn+eDfonTvvffqgQce0I033qiuXbvqL3/5iyZOnKgZM2ZI4lyVxpPzEh0drYMHD7psP336tH755ZegPne1HX152ejLy0d/7jn6c8/Ql1cOfXnwoi8vG3156ejDPUcfXj7678qh/4ZEX14e+vKy0Z97hr7cM/TnFeeLvpykuI+EhoaqR48eWrVqlXOd3W7XqlWrlJCQ4MOW+ZZhGBo/frzefvttffLJJ4qPj3fZ3qNHD9WtW9flvO3cuVP79u0LqvN2+eWX67vvvtOWLVucPz179tTNN9/sfM55MvXp00c7d+50WffDDz+oXbt2kqT4+HhFR0e7nKv8/Hxt3Lgx6M7Vb7/9ppAQ127BarXKbrdL4lyVxpPzkpCQoKNHj2rz5s3OmE8++UR2u129evWq8TbDO+jL3aMv9xz9uefozz1DX1459OXBi77cPfry8tGHe44+vHz035VD/w2Jvrw09OWeoT/3DH25Z+jPK84nfbkBn1m0aJERFhZmvP7668a2bduMsWPHGo0bNzZyc3N93TSfueuuu4zIyEhjzZo1Rk5OjvPnt99+c8bceeedRtu2bY1PPvnE+PLLL42EhAQjISHBh632D3379jUmTJjgXOY8mTZt2mTUqVPHeOKJJ4xdu3YZ8+fPN+rXr2+8+eabzpinnnrKaNy4sfHOO+8Y3377rTF48GAjPj7e+P33333Y8po3atQoo02bNsZ7771nZGZmGhkZGUbz5s2N++67zxkTrOfq+PHjxtdff218/fXXhiRj5syZxtdff2389NNPhmF4dl4GDhxonH/++cbGjRuNTz/91OjYsaMxYsQIX70leAl9eUn05VVDf+4e/bln6MtLR1+O0tCXl0RfXjn04e7Rh5eP/rt09N/wBH15SfTllUd/XhJ9uWfoz93zt76cpLiPvfDCC0bbtm2N0NBQ46KLLjI+//xzXzfJpyS5/XnttdecMb///rvxf//3f0aTJk2M+vXrG9ddd52Rk5Pju0b7ieIdNufpjP/+97/Gueeea4SFhRmdOnUyXn75ZZftdrvdePjhh42oqCgjLCzMuPzyy42dO3f6qLW+k5+fb0yYMMFo27atER4ebpx11lnGQw89ZBQUFDhjgvVcrV692u3/TaNGjTIMw7Pz8vPPPxsjRowwGjZsaERERBijR482jh8/7oN3A2+jL3dFX1419Oeloz8vH3156ejLURb6clf05ZVDH146+vCy0X+Xjv4bnqIvd0VfXnn05+7Rl5eP/tw9f+vLLYZhGBUfXw4AAAAAAAAAAAAAgP9jTnEAAAAAAAAAAAAAQMAiKQ4AAAAAAAAAAAAACFgkxQEAAAAAAAAAAAAAAYukOAAAAAAAAAAAAAAgYJEUBwAAAAAAAAAAAAAELJLiAAAAAAAAAAAAAICARVIcAAAAAAAAAAAAABCwSIoDAAAAAAAAAAAAAAIWSXEAAAAAAAAAAAAAQMAiKQ4AAAAAAAAAAAAACFgkxQEAAAAAAAAAAAAAAYukOAAAAAAAAAAAAAAgYJEUBwAAAAAAAAAAAAAELJLiAAAAAAAAAAAAAICARVIcAAAAAAAAAAAAABCwSIoDAAAAAAAAAAAAAAIWSXEAAAAAAAAAAAAAQMAiKQ4AAAAAAAC/Y7FY9Mgjj/i6GT7Xr18/9evXz7m8d+9eWSwWvf766z5rU3HF24iqu/XWWxUXF+frZgAAAAQMkuIAAAAAAAAB7sUXX5TFYlGvXr0qfYwDBw7okUce0ZYtW7zXMD+3Zs0aWSwW50/dunV11llnaeTIkdqzZ4+vm1ch69ev1yOPPKKjR4/6rA2FhYVKS0vT+eefr4iICDVu3FjnnHOOxo4dqx07dlTLa5b1e7tgwQKlpqZWy+uWpl+/fi6/U02bNtWFF16oV199VXa73Suv8eSTT2rZsmVeORYAAECgqOPrBgAAAAAAAKB6zZ8/X3Fxcdq0aZN+/PFHdejQocLHOHDggB599FHFxcWpe/fu3m+kH/v73/+uCy+8UKdOndJXX32ll19+WcuXL9d3332n1q1b12hb2rVrp99//11169at0H7r16/Xo48+qltvvVWNGzeunsaVY+jQofrggw80YsQIjRkzRqdOndKOHTv03nvvqXfv3urUqZPXX7Os39sFCxZo69atSklJ8frrliUmJkYzZsyQJB06dEj/+c9/dPvtt+uHH37QU089VeXjP/nkkxo2bJiGDBlS5WMBAAAECpLiAAAAAAAAASwzM1Pr169XRkaG/vrXv2r+/PmaNm2ar5tVqyQmJmrYsGGSpNGjR+tPf/qT/v73v2vevHmaPHmy231OnDihBg0aeL0tFotF4eHhXj9udfviiy/03nvv6YknntCDDz7osm3WrFk+HcHuTXa7XYWFhWV+RpGRkbrlllucy3/961919tlna9asWXrssccqfMMDAAAAykf5dAAAAAAAgAA2f/58NWnSRIMGDdKwYcM0f/58t3FHjx7VxIkTFRcXp7CwMMXExGjkyJE6fPiw1qxZowsvvFCSmRR2lH52zGsdFxenW2+9tcQxi881XVhYqKlTp6pHjx6KjIxUgwYNlJiYqNWrV1f4feXl5alOnTp69NFHS2zbuXOnLBaLZs2aJUk6deqUHn30UXXs2FHh4eFq1qyZLrnkEq1cubLCrytJl112mSTzhgNJeuSRR2SxWLRt2zbddNNNatKkiS655BJn/JtvvqkePXqoXr16atq0qW688UZlZWWVOO7LL7+s9u3bq169errooou0bt26EjGlzSm+Y8cO3XDDDWrRooXq1auns88+Ww899JCzfffee68kKT4+3vn57d27t1ra6M7u3bslSX369CmxzWq1qlmzZi7rsrOzdfvtt6t169YKCwtTfHy87rrrLhUWFkqSfvnlF91zzz3q2rWrGjZsqIiICF155ZX65ptvnMco6/e2X79+Wr58uX766Sfn+qJzeBcUFGjatGnq0KGDwsLCFBsbq/vuu08FBQUu7bRYLBo/frzmz5+vc845R2FhYVqxYoVH58Shfv36uvjii3XixAkdOnSo1LgTJ07o7rvvVmxsrMLCwnT22Wfr2WeflWEYLu05ceKE5s2b53xf7v5tAgAABBtGigMAAAAAAASw+fPnKzk5WaGhoRoxYoReeuklffHFF85koST9+uuvSkxM1Pbt23Xbbbfpggsu0OHDh/Xuu+9q//796ty5s6ZPn66pU6dq7NixSkxMlCT17t27Qm3Jz8/Xv//9b2f57OPHj+uVV15RUlKSNm3aVKGy7FFRUerbt6+WLFlSYuT74sWLZbVadf3110syk8IzZszQHXfcoYsuukj5+fn68ssv9dVXX+nPf/5zhd6DdCbBWzyRe/3116tjx4568sknnYnKJ554Qg8//LBuuOEG3XHHHTp06JBeeOEFXXrppfr666+dpcxfeeUV/fWvf1Xv3r2VkpKiPXv26Nprr1XTpk0VGxtbZnu+/fZbJSYmqm7duho7dqzi4uK0e/du/fe//9UTTzyh5ORk/fDDD1q4cKGef/55NW/eXJLUokWLGmtju3btJJm/j3369FGdOqV/LXngwAFddNFFOnr0qMaOHatOnTopOztb6enp+u233xQaGqo9e/Zo2bJluv766xUfH6+8vDz961//Ut++fbVt2za1bt26zN/bNm3a6NixY9q/f7+ef/55SVLDhg0lmaO9r732Wn366acaO3asOnfurO+++07PP/+8fvjhhxLzdX/yySdasmSJxo8fr+bNm7sk1z21Z88eWa3WUkvbG4aha6+9VqtXr9btt9+u7t2768MPP9S9996r7Oxs53t44403nL/nY8eOlSS1b9++wu0BAAAIOAYAAAAAAAAC0pdffmlIMlauXGkYhmHY7XYjJibGmDBhgkvc1KlTDUlGRkZGiWPY7XbDMAzjiy++MCQZr732WomYdu3aGaNGjSqxvm/fvkbfvn2dy6dPnzYKCgpcYo4cOWJERUUZt912m8t6Sca0adPKfH//+te/DEnGd99957K+S5cuxmWXXeZc7tatmzFo0KAyj+XO6tWrDUnGq6++ahw6dMg4cOCAsXz5ciMuLs6wWCzGF198YRiGYUybNs2QZIwYMcJl/7179xpWq9V44oknXNZ/9913Rp06dZzrCwsLjZYtWxrdu3d3OT8vv/yyIcnlHGZmZpb4HC699FKjUaNGxk8//eTyOo7PzjAM45lnnjEkGZmZmdXeRnfsdrvRt29fQ5IRFRVljBgxwpg9e3aJNhuGYYwcOdIICQlxnl937+nkyZOGzWZz2ZaZmWmEhYUZ06dPd64r6/d20KBBRrt27Uqsf+ONN4yQkBBj3bp1LuvnzJljSDI+++wz5zpJRkhIiPH999+X+f4d+vbta3Tq1Mk4dOiQcejQIWP79u3G3//+d0OScc011zjjRo0a5dK2ZcuWGZKMxx9/3OV4w4YNMywWi/Hjjz861zVo0MDtv0cAAIBgRvl0AAAAAACAADV//nxFRUWpf//+kszSysOHD9eiRYtks9mccW+99Za6deum6667rsQxLBaL19pjtVoVGhoqyRyN+8svv+j06dPq2bOnvvrqqwofLzk5WXXq1NHixYud67Zu3apt27Zp+PDhznWNGzfW999/r127dlWq3bfddptatGih1q1ba9CgQc7y1D179nSJu/POO12WMzIyZLfbdcMNN+jw4cPOn+joaHXs2NFZNv7LL7/UwYMHdeeddzrPjyTdeuutioyMLLNthw4d0v/+9z/ddtttatu2rcs2Tz67mmijoy0ffvihHn/8cTVp0kQLFy7UuHHj1K5dOw0fPtw5p7jdbteyZct0zTXXlDi/Rd9TWFiYQkLMrzZtNpt+/vlnNWzYUGeffXalfpeKWrp0qTp37qxOnTq5nBNH2fzi5f779u2rLl26eHz8HTt2qEWLFmrRooU6d+6sF154QYMGDdKrr75a6j7vv/++rFar/v73v7usv/vuu2UYhj744IMKvEMAAIDgQ/l0AAAAAACAAGSz2bRo0SL179/fOfe1JPXq1UvPPfecVq1apSuuuEKSWQ586NChNdKuefPm6bnnntOOHTt06tQp5/r4+PgKH6t58+a6/PLLtWTJEj322GOSzNLpderUUXJysjNu+vTpGjx4sP70pz/p3HPP1cCBA/WXv/xF5513nkevM3XqVCUmJspqtap58+bq3Lmz2/Lfxd/Drl27ZBiGOnbs6Pa4devWlST99NNPklQirm7dujrrrLPKbNuePXskSeeee65H76W4mmijQ1hYmB566CE99NBDysnJ0dq1a5WWlqYlS5aobt26evPNN3Xo0CHl5+eX+37sdrvS0tL04osvKjMz0+Umj+Jl7Stq165d2r59u7O8fHEHDx50Wa7o725cXJzmzp0ri8Wi8PBwdezYUS1btixzn59++kmtW7dWo0aNXNZ37tzZuR0AAAClIykOAAAAAAAQgD755BPl5ORo0aJFWrRoUYnt8+fPdybFq6q0Eck2m01Wq9W5/Oabb+rWW2/VkCFDdO+996ply5ayWq2aMWOGc57uirrxxhs1evRobdmyRd27d9eSJUt0+eWXO+fNlqRLL71Uu3fv1jvvvKOPPvpI//73v/X8889rzpw5uuOOO8p9ja5du2rAgAHlxtWrV89l2W63y2Kx6IMPPnA5Dw6OOax9yVdtbNWqlW688UYNHTpU55xzjpYsWaLXX3/d4/2ffPJJPfzww7rtttv02GOPqWnTpgoJCVFKSorsdnuV2ma329W1a1fNnDnT7fbi86cX/9zL06BBA49+nwAAAOA9JMUBAAAAAAAC0Pz589WyZUvNnj27xLaMjAy9/fbbmjNnjurVq6f27dtr69atZR6vrFLcTZo0cZa/Luqnn35yGUWcnp6us846SxkZGS7HmzZtmgfvyL0hQ4bor3/9q7OE+g8//KDJkyeXiGvatKlGjx6t0aNH69dff9Wll16qRx55xKOkeGW1b99ehmEoPj5ef/rTn0qNa9eunSRzhLKjRLcknTp1SpmZmerWrVup+zrOb2U/v5poY1nq1q2r8847T7t27dLhw4fVsmVLRURElPt+0tPT1b9/f73yyisu648ePepyQ0RZv7dlnZNvvvlGl19+uVenD6iKdu3a6eOPP9bx48ddRovv2LHDud3BX9oMAADgT5hTHAAAAAAAIMD8/vvvysjI0NVXX61hw4aV+Bk/fryOHz+ud999V5I0dOhQffPNN3r77bdLHMswDEnm6FZJbpPf7du31+eff67CwkLnuvfee09ZWVkucY6RyI5jStLGjRu1YcOGSr/Xxo0bKykpSUuWLNGiRYsUGhqqIUOGuMT8/PPPLssNGzZUhw4dVFBQUOnX9URycrKsVqseffRRl/csmefA0a6ePXuqRYsWmjNnjss5fP31192e76JatGihSy+9VK+++qr27dtX4jUcSvv8aqKNkplML94+R3s2bNigJk2aqEWLFgoJCdGQIUP03//+V19++WWJeEcbrVZrifYuXbpU2dnZLuvK+r1t0KCBjh07VmL9DTfcoOzsbM2dO7fEtt9//10nTpwo/Y1Wk6uuuko2m02zZs1yWf/888/LYrHoyiuvdK5r0KCBR58JAABAMGGkOAAAAAAAQIB59913dfz4cV177bVut1988cVq0aKF5s+fr+HDh+vee+9Venq6rr/+et12223q0aOHfvnlF7377ruaM2eOunXrpvbt26tx48aaM2eOGjVqpAYNGqhXr16Kj4/XHXfcofT0dA0cOFA33HCDdu/erTfffFPt27d3ed2rr75aGRkZuu666zRo0CBlZmZqzpw56tKli3799ddKv9/hw4frlltu0YsvvqikpCQ1btzYZXuXLl3Ur18/9ejRQ02bNtWXX36p9PR0jR8/vtKv6Yn27dvr8ccf1+TJk7V3714NGTJEjRo1UmZmpt5++22NHTtW99xzj+rWravHH39cf/3rX3XZZZdp+PDhyszM1GuvvebRfN3//Oc/dckll+iCCy7Q2LFjFR8fr71792r58uXasmWLJKlHjx6SpIceekg33nij6tatq2uuuabG2vjNN9/opptu0pVXXqnExEQ1bdpU2dnZmjdvng4cOKDU1FTnTRNPPvmkPvroI/Xt21djx45V586dlZOTo6VLl+rTTz9V48aNdfXVV2v69OkaPXq0evfure+++07z588v0Zayfm979OihxYsXa9KkSbrwwgvVsGFDXXPNNfrLX/6iJUuW6M4779Tq1avVp08f2Ww27dixQ0uWLNGHH36onj17VvC3oWquueYa9e/fXw899JD27t2rbt266aOPPtI777yjlJQUl39rPXr00Mcff6yZM2eqdevWio+PV69evWq0vQAAAH7HAAAAAAAAQEC55pprjPDwcOPEiROlxtx6661G3bp1jcOHDxuGYRg///yzMX78eKNNmzZGaGioERMTY4waNcq53TAM45133jG6dOli1KlTx5BkvPbaa85tzz33nNGmTRsjLCzM6NOnj/Hll18affv2Nfr27euMsdvtxpNPPmm0a9fOCAsLM84//3zjvffeM0aNGmW0a9fOpX2SjGnTpnn0fvPz84169eoZkow333yzxPbHH3/cuOiii4zGjRsb9erVMzp16mQ88cQTRmFhYZnHXb16tSHJWLp0aZlx06ZNMyQZhw4dcrv9rbfeMi655BKjQYMGRoMGDYxOnToZ48aNM3bu3OkS9+KLLxrx8fFGWFiY0bNnT+N///tfiXOYmZlZ4twbhmFs3brVuO6664zGjRsb4eHhxtlnn208/PDDLjGPPfaY0aZNGyMkJMSQZGRmZlZLG93Jy8sznnrqKaNv375Gq1atjDp16hhNmjQxLrvsMiM9Pb1E/E8//WSMHDnSaNGihREWFmacddZZxrhx44yCggLDMAzj5MmTxt133220atXKqFevntGnTx9jw4YNbttS2u/tr7/+atx0001G48aNDUkuv4OFhYXGP/7xD+Occ84xwsLCjCZNmhg9evQwHn30UePYsWPOOEnGuHHjynzvRfXt29c455xzyo1z92/i+PHjxsSJE43WrVsbdevWNTp27Gg888wzht1ud4nbsWOHcemllzr/TYwaNcrj9gEAAAQqi2EUqzMEAAAAAAAAAAAAAECAYE5xAAAAAAAAAAAAAEDAIikOAAAAAAAAAAAAAAhYJMUBAAAAAAAAAAAAAAGLpDgAAAAAAAAAAAAAIGCRFAcAAAAAAAAAAAAABKw6vm5AbWW323XgwAE1atRIFovF180BANQyhmHo+PHjat26tUJCuEfNF+jLAQBVQV/ue/TlAICqoj8HACB4kBSvpAMHDig2NtbXzQAA1HJZWVmKiYnxdTOCEn05AMAb6Mt9h74cAOAt9OcAAAQ+kuKV1KhRI0nmH0wRERE+bg0AoLbJz89XbGyssz9BzaMvBwBUBX2579GXAwCqiv4cAIDgQVK8khyl2SIiIrj4BgBUGqU+fYe+HADgDfTlvkNfDgDwFvpzAAACHxOlAAAAAAAAAAAAAAACFklxAAAAAAAAAAAAAEDAIikOAAAAAAAAAAAAAAhYJMUBAAAAAAAAAAAAAAGrjq8bAADwHpvdpnX71inneI5aNWql3jG9tX7/euUcz1HLBi0lSQdPHCyxjdjKxSa2TZQ1xFpzHzBQRcX/j+B3GACAWsBmk9atk3JypFatpMREyUr/DQAAAAAVQVIcQLUrKwkTLEncmnjNXb/s0tzNc7X/+H7nubdarLIZNrefS/FtxFY8NiYiRmkD05TcOdltPOALpf2fm7E9QxNWTND+/DP/RxT/Ha7I/9ck1AEAqAEZGdKECdL+M/23YmKktDQpmb9BAQAAAMBTJMVRLfhSvWrKO0eVPb9lJaCrK4nrLlHbvH5z3XLeLWoS3iSokrg18ZrFlRVXfBuxFY/Nzs/WsCXDlH5DOolx+IXSEt8jzh2hZ9c/K0OGS3zR32FJpSbNy9qW3DmZvh0AgOqQkSENGyYZrv23srPN9enpJMYBAAAAwEMWwyh+dQVP5OfnKzIyUseOHVNERISvm+MTlRmJJpX9pXpZx63Ktuo6bnW8prvz16ZRG43tMVYdm3ascJLZse+R349o/nfzdei3Q85tvkgGA4HGIotiImKUOSGzQklA+hHfC7TPIGN7hoYtGVYi8V0eiyxqWq+pfvn9lxL7WmQp9XgWWSRJ9/S+Rwu3LmQEOoCgE2j9SG0U0J+BzSbFxbmOEC/KYjFHjGdmmsullVen9DoAlCmg+xIAAOCCpHglBfsfTBUdiebJl+pVGaVW1rbkzsmVTtR7+zXLS15f0vYSLf5+sdvzBMC/rR61Wv3i+nkcH+z9iD8IpM/AZrcpLi3Opc/xJW/07eWNQPfFzXCebAcQPAKpH6mtAvozWLNG6t+//LhHH5XmznVfXl2i9DoAlCOg+xIAAOCCpHglBfMfTJUdiVaWqoxS82QEW2US9ZXZ5nD1n67Wez+8V2YMgMCyIHmBRnQd4XF8MPcj/iKQPoM1e9eo/zwPvjivQdU5Al3y7s1wZVVV8bRay+CzB9fItCTE1o72EVt7YqtyY0sg9SO1VUB/BgsXSjfdVLl9LZaSJdeLbpPM0uuDBzOKHEDQC+i+BAAAuCApXknB8AeTu5FQkvxqJJonKOUNoCYwUrz2CaTPYOF3C3VTRiW/OA8wvrwxraamJSG2drSP2NoRW3y6h4oIpH6ktgroz8DTkeKVYbFITZtK9eqVPYq8rNLrlGVHceX9ThTd3tK8QUkHD5qxvXtL69ef2bfockViq7KvP8TSpsrFVvH/n4DuSwAAgIs6vm4A/FNpI6zGXDCmViXEJZEQB1CtHHOKO24cQnDxl1LarRq1qvHX9Fe+rNRS/G+Osv4GIbbqsf7ePmJrR2x2fraGLRmm9BvSK5UYB6pNYqKZpM7OLn3Ud2UZhvTzzyXXZ2dLw4aZo8il0kuvl7Wtqgn1iiRWa2rf2tAmXydL33lHmj9fOnSm2o7atJHGjpU6dpR27SpZ5r8oq9V8T6UtVyS2Kvv6Qyxtqngs00IAAAAPMVK8kgL5LsLSyqN7UjYcAIJJ0XmTK/pFeiD3I7VFVT+Dskp013RixTGneHZ+dqX66mb1munn3918OQ4AQcBxg1vmhMwK3dhEX+57Af8ZZGSYSWrJNTFeVnn0qnKMIv/ll5Kv4WlZdqlyCfWytiUnm+ejpvf19nHLSxQ3by7dcovUpEnJbY59jxwpmYD2x2QpUFOK/v9TicR4wPclAADAiaR4JQXqH0yOL9Vr22hwAO75e8nS2h4bGxGr1IGplFytJtnZ2br//vv1wQcf6LffflOHDh302muvqWfPnpIkwzA0bdo0zZ07V0ePHlWfPn300ksvqWPHjh4dvyqfQVk3kEmVu1Giqspr07iLxmnWplku20IsIVo0dJEK7YW6JeOWGmsrAPgjpkKpfYLiM3CXdI2Nle64Q5o2zXftcqcqCfXyku333CM9+2zlEvWV2dcTV18tvee7CjUAirBYzBtSMjMrXEo9KPoSAAAgifLpKGbdvnXVkhD3ZJQ5o9Qg+UeiszbPfRrTKEZjeoxRx6Yd1apRK/WO6a31+9cr53iOWjYwS+EdPHGwxDZiKxfrq1LZweDIkSPq06eP+vfvrw8++EAtWrTQrl271KRJE2fM008/rX/+85+aN2+e4uPj9fDDDyspKUnbtm1TeHi45y924oT7L06sVqnocU6ckGTeQPbAO39TvcIz/ZrdIp2sKxkyZJFFk9/5uwbHDHD/+xESYs7h6fDbb2V/mVu/folYm92mz7I+U+7xXEU3ilaf2D5KbjdQ85PnO+cWDz8lhRhS03qNNevKWTplO6VXC6V2EW31cN+Hdeeau5VfkK/Mo5nal7NT9QslqyVENsNeohm/hZ55HnZKspbRpVcotq70R85eoaelOiVfulKxv9eRjBDzed3TUl0vxZ6sI9krEVvHJoWWMYiqwCrZrBWPtdqksDJiC63S6UrEhtil8NOlx54KkU7VqXisxS7V81Ls6RCp0HElY0j1T3kn1maRCuqeWa5f6J1Yx/8RlYmtV+j81S/BkPR7aOViHf9HlOa3SsbW5v8jDuZlSi0udA2uV8/8f1uSCgulU0V+gf7oF4BqlZwsDR5csoy2ZI4kro7y6pVVWll2x7ay9itv28yZ7uOqa19PkBAH/IdhSFlZ5v+V/fr5ujUAAMBPMVK8kgL1LsKF3y10fpleUY6RaPf0vkczN8x0Sdo5yslK0oi3RqjQduabwEahjfT6kNclSUOXDHV7XMq2V4+aSgY7ErVHfj+i+d/N16HfDpXYFuhJ3Jp6TZK0tUeg9iPe8sADD+izzz7TunXr3G43DEOtW7fW3XffrXvuuUeSdOzYMUVFRen111/XjTfeWO5rOD8DSW4/gauukpYvP7PcoIGZlHZjTTup/+gzywefllq4D5V69pS++OLMclyc9NNP7mO7dJG+//7M8jnnSNu2uQ090bqFvtv4rhJeSVCT8Cba+LKhjnuOuj9u8+a66vkL9cHuDyRJq1+T+pXShBN1pYYPnVlesdCqpJ2lZ1ctj5x5vmSJdL375kqSGjx4JkH22tvSrd+UHtviXulwA/P5rOXSuC9Kj42bIP30x/0TT38k3bu+9Nhz/k/a9sf0mdNWS4+sLT32wjHSl23M5/d8Jj2zsvTYfqOktfHm8//bJM1+v/TYQTdJ7//JfD7qa+n1d0qPvf56Kf0c8/mw76WlS0uPvXWwNO988/lVP0jLF5QeO+4q6cWLzOd9M6U180qPvffP0rN9zOc9s6Uv5pYe+0hf6dH+5vMuB6XvXyw99pne0n1XmM/bHZH2ppUeO/tCafwg83nzE9KhZ0qPfb2bNPo683n9QunEk6XHLu0i3XDDmWXjkdJjl3eUrr75zPKvT0gNSkm4V+T/iC9aSxeNPbOc+bwUd8x97PctpHPHnVneOls655D72L2RUvzEM8ubXpYuPOA+9lB9qeV9Z5Yr8n/Ee/OlQbvcx0q17/8Ibd1q/t8rSY88Ij36qHNTvqRIib7ch4L+7ylPyqtXZ6l1APA3CxZII0ZUaJeg70sAAAgijBSHi1aNWnkUd3+f+/WPz/7hsi4mIkapA1PVL66fnllvfjNZr049/X76dy0euli92/bWydMn5bgPY2jnoXpr+1tqF9lOyZ2Tdcp2SvXr1Ndvp12/Iaxft75u7X6r5m6eq0J7GcNqAtTwc4brs32faf/xInPWephk3vXLLs3dPNdl3xb1W+jm827W4LMH+2Q07bNXPKt1+9aVOdK2rLKVxbfVttiaeE0gELz77rtKSkrS9ddfr7Vr16pNmzb6v//7P40ZM0aSlJmZqdzcXA0YMMC5T2RkpHr16qUNGza4TYoXFBSooKDAuZyfn1/9b8TL8gvy3SfwJR06cUj//urfkqTesb3VutEeSUfdxhbYCp0J8Yo6bWfeSAAA/EJysjmHrrs5rVNTzefutv3+u/sS5wBQ27Xy7HtNAAAQnBgpXkmBehehY07x7Pxst6OzLbIoJiJGi4YuUp/X+jjXd4vqps1jN8saYtWavWvUf15/xTeOV9eornp357t69s/P6u7ed+vTfZ8q8bVERTWI0vf/971aPttSdsOun1J+0o+//KjL/3O5mtdrrkXDFukfn/5DKzNdh2CFKERT+07V0ZNHlboxtbpPR4WVNqr96j9drY37N1YoeV10rmKb3VZqIrmsbZ5sB+AbgdqPeIuj/PmkSZN0/fXX64svvtCECRM0Z84cjRo1SuvXr1efPn104MABtSryxccNN9wgi8WixYsXlzjmI488okeLjPBzOHbggPvPoJTy6f/76X+6cv5VLqHuSiN/cPP7urTdpSWPW8ny6Ta7TZ2eaasD+aUM7ZSkBvX126nfNK3vNE296F79Ka2Dcn7N1ahuIzXvm/8o3BqmvRP2qsfcHtpVcOY4wVIauaqxlE83UT694rGUT69kbA38HxH6x7/l+cnzNbjT4JLBZZRPz8/PV2Tr1n7Vl7/00kt66aWXtHfvXknSOeeco6lTp+rKK6+UJPXr109r17qWxPjrX/+qOXPmOJf37dunu+66S6tXr1bDhg01atQozZgxQ3XqnLmnfs2aNZo0aZK+//57xcbGasqUKbr11ltdjjt79mw988wzys3NVbdu3fTCCy/ooosucm4/efKk7r77bi1atEgFBQVKSkrSiy++qKioKI/fL39P/cFmK1le3TE1jLtt77xT9gjzZs1ImgOoXZhTHAAAeICR4nBhDbEqbWCahi0ZViLB6yiPnjowVZlHMyVJTes11S+//6J9x/YpxGJ+WfRNrlnX8Lyo89Q7trfe3fmuPsv6THfLTIpL0iVtL1Gz+s2UEJOgz7I+0/u73tcPP/8gSbr67Kt1rOCYPs78uET77LLrkbWPqFm9ZtV3EtywyOJ8r5Lcnpd7et+jhVsXuszJ7mliW5IeSnyo1O3WEGupI4PL2ubJdgDwR3a7XT179tSTT5p1js8//3xt3brVmRSvjMmTJ2vSpEnO5fz8fMXGxppl0Rs0KP8Af8T06XSFmjaPKfMGsmbNY9Sn0xWSJzchFZ0zvAzr9q3TjycPSKFlBJ0yq61c2PpChdRvoPYx52n3nly9tP0/Uqj0mwp01qtddbjgsMtuRRNw5SmoptjCOtKpMm4ue++H95x/mxTWkYrnFEu7Me1UHam0HGjKxSlqEt7EeWOaI9ZRVaXoNoeyqrWUNtXI6SIJZ2/G2qzSb9UQaw9xTVx6K9bwcqyTRSoI83Cal4rEyj9iC6sp9lRo9cSeDrWqoBpibXWtKqyG2Kim5t/rgzsnu93uIjTU/HG+kP9VzoiJidFTTz2ljh07yjAMzZs3T4MHD9bXX3+tc/4oAz9mzBhNnz7duU/9Iv2QzWbToEGDFB0drfXr1ysnJ0cjR45U3bp1nX1yZmamBg0apDvvvFPz58/XqlWrdMcdd6hVq1ZKSkqSJC1evFiTJk3SnDlz1KtXL6WmpiopKUk7d+5Uy5ZmlamJEydq+fLlWrp0qSIjIzV+/HglJyfrs88+q6nTVWuVzHNbZS1tDl2rteT8up6MMB82rGTp9bLKspNQB+Arlj/uiktNrXBCHAAABBeS4ighuXOy0m9I1/8t/z/lnchzrm/TqI3SrkxTcudkTV9rfolyVcertGjrIh05eURZ+VlqG9lW3+Z9K8kcPd4n1hxN/lnWZzIMwyUpLkmDOg7SZ1mfad6Wec5E+8D2AzVhxYQy5xH/+fefvf/G/1DazQAvX/OyJGnCigkuiW9H2fjkzsmacfmMSiW2PdkOAMGkVatW6tKli8u6zp0766233pIkRUdHS5Ly8vJcRorn5eWpe/fubo8ZFhamsLCwKrfN0xvIvF2VI+d4jsexPVv3VMb2DH2056MS2w7/dtjNHt7l7rw4lks7Z+XdXJaxPaNEH+zYLpXsnz3ZlvxHEqysG9PK2lZ8SpCampaEWP9vH7G1JzbQqihdc801LstPPPGEXnrpJX3++efOpHj9+vWd/WhxH330kbZt26aPP/5YUVFR6t69ux577DHdf//9euSRRxQaGqo5c+YoPj5ezz33nCSzf/7000/1/PPPO5PiM2fO1JgxYzR69GhJ0pw5c7R8+XK9+uqreuCBB3Ts2DG98sorWrBggS677DJJ0muvvabOnTvr888/18UXX1wt5ycQZGS4z2WnpZm5bo8lJ0uDB5c+wrwyZdnLSqgXxTznKM5qdb3RqPhyRWKrsq8/xNKmisc6/v+p0H+CAAAgGFE+vZKCobTO8h+W6+qFVzuXv7jjC/Vs01OSNGrZKP3nm//oicue0OLvF+vbvG/1zo3v6Nqzr1XPl3tqc85mvXXDWxrUcZAin4pUga1AO8bt0MWvXKyjJ4/qizFfqGfrnpq5Yabu/uhul9dtVq9ZtSa9pcp/IS9RjhyAdwRDP1IVN910k7KysrRu3TrnuokTJ2rjxo1av369DMNQ69atdc899+juu81+JD8/Xy1bttTrr7/udk7x4qr6GZSVpE32ZMRhBTmmJylPi/otlHN3juLS4lza5g1VrZwilZ2grsqUIFWZagQAKsPf+3KbzaalS5dq1KhR+vrrr9WlSxf169dP33//vQzDUHR0tK655ho9/PDDztHiU6dO1bvvvqstW7Y4j5OZmamzzjpLX331lc4//3xdeumluuCCC5TqSIDKTGinpKTo2LFjKiwsVP369ZWenq4hQ4Y4Y0aNGqWjR4/qnXfe0SeffKLLL79cR44cUePGjZ0x7dq1U0pKiiZOnOj2PRUUFKigoMC57Kj64q+fgbdlZJj55uLf4jgGSaanezknVJGy7L17S+vXm8u7dklz57omzYsqK7mFyvGXZGmLFtLNN0tNmpT8HYiJkcaMkTp2lP6oGKGDB0v+/hRfrkhsVfb1h1jaVLnYov83VYK/9+cAAMB7GCmOUhUdJS5JP/zygzMp/uMvP0qSOjTtoO7R3fVt3rfakrtFV3W8St8f+l6SWT49rE6Yerbuqc+yPtPcr+bq6MmjalC3gbpHd1fG9gzd89E9JV63uhLiZX1Z7+lob4kR3QBQEyZOnKjevXvrySef1A033KBNmzbp5Zdf1ssvm1U7LBaLUlJS9Pjjj6tjx46Kj4/Xww8/rNatW7t8AV+dkjsna/DZgzVk0RC9t+s9je42WnOvnVttydbEtomKiSi9bLtDn9g+WrdvXZUT4tVVOWXw2YOrpapKVaYaAYBA8t133ykhIUEnT55Uw4YN9fbbbzurr9x0001q166dWrdurW+//Vb333+/du7cqYyMDElSbm5uiTm9Hcu5ubllxuTn5+v333/XkSNHZLPZ3Mbs2LHDeYzQ0FCXhLgjxvE67syYMUOPPvpoBc9IYLDZzMHZ7oY1GIaZGE9JMQd/e616sLvS6+62ZWRI7du7JkDbtJGGD5cWLy65rz8nxBs2lH791fsj3VNSyk4UHzkizZ8vHTpUclvHju5vNHAkoAcP9o9kafHk5EMPlX5ThTvFf9dK+93zJLYq+/pDLG2qeCwAAIAHSIqjVAeOH3BZ3nF4h/P57l92S5LaN2mvblHdJElbcrdo18+7dPL0STWo20BnNTlLklkq/bOszzT7i9mSpLObnS273V5uifTKcoxiq1ennuscoF4qcw4AqH4XXnih3n77bU2ePFnTp09XfHy8UlNTdfPNNztj7rvvPp04cUJjx47V0aNHdckll2jFihUKDw+vsXZaQ6xqG9lWkhQbGVuto4+Llm0vrmgC+8I2F1ao1Hrx40jl30AmVT65TT8LANXr7LPP1pYtW3Ts2DGlp6dr1KhRWrt2rbp06aKxY8c647p27apWrVrp8ssv1+7du9W+fXsfttozkydP1qRJk5zLjpHiwWDdutIHXktmjjYry4yrtryRu5Hj77zjfvh6drb7hHhNsFolu73sxLW7OdElad4887F4efjY2NJLx3uyzTGEv6xE8bPPlp1ELi/J7G/J0rJuqgAAAAB8gKQ4SuVIikeERSi/IF/bD2+XJP1a+KtzFHn7pu11rOCYJOmbvG+c84l3jeqqEEuIpDNfsJ88fVKS9FXuV2rzfJtKz2nqSenWl695uUoj0QAAvnf11Vfr6quvLnW7xWLR9OnTNX369BpsVUl1rXUlSaftp6v9tZI7Jyv9hnTdsPQG2Ywzo6zq1a2nuiF1dazgmC6IvkDhdT27MaBF/RY69NuZEUlUTgGA2i80NFQdOnSQJPXo0UNffPGF0tLS9K9//atEbK9evSRJP/74o9q3b6/o6Ght2rTJJSYvz7z2c8xDHh0d7VxXNCYiIkL16tWT1WqV1Wp1G1P0GIWFhTp69KjLaPGiMe6EhYUpLCzMk9MQcHI8vN/N07gKczeZeZs20smTvpsfvLTE9qRJZoK5tO333CMtXOh+TnRH8rqs+dYru03yfPR9ZbYDAAAAKBNJ8SBX1hyb2cezJUn94vrp3Z3vavshMym+58geSVLTek3VOLyxc6T4niN7tG6fOferY13G9gz947N/lHjdqiTEJc9KtzraDgBAdaoTYv45VRNJcUm69uxrZTfskqRLYi/Rp1mf6rdTvzm33/7f25WalFpmqXWLLIqJiNGPf/tR6/ev5wYyAAhgdrvdZR7uohxzh7dq1UqSlJCQoCeeeEIHDx5Uyz/KKK9cuVIRERHOEuwJCQl6//33XY6zcuVKJSQkSDKT8j169NCqVaucU5rY7XatWrVK48ePl2Qm6+vWratVq1Zp6NChkqSdO3dq3759zuPA1R8fkdfi3CptDvHSJjPPzq7Ci3mosontiy8umcQvun3GjOpJXpO4BgAAAPwWSfEglrE9w21SOW1gmpI7JztHil8ef7ne3fmudv2yS6ftp13mE5ekZvWbKTYiVln5WVq0dZEkcz5xm91W5RLpZY1gk8ou3QoAQE2o6aR47q+5MmQoxBKiz7I+K7E953iOhqcP1z2979Gz658tdW7w1IGpCq0TSuIbAALI5MmTdeWVV6pt27Y6fvy4FixYoDVr1ujDDz/U7t27tWDBAl111VVq1qyZvv32W02cOFGXXnqpzjvvPEnSFVdcoS5duugvf/mLnn76aeXm5mrKlCkaN26cc4T2nXfeqVmzZum+++7Tbbfdpk8++URLlizR8uXLne2YNGmSRo0apZ49e+qiiy5SamqqTpw4odGjR0uSIiMjdfvtt2vSpElq2rSpIiIi9Le//U0JCQm6+OKLa/7E1QKJiWZONzvb/cBsi8XcnphYzoHKSny7SyLPnGmOvK7O0eCVTXyXldhOTi571DbJawAAACDokBQPUhnbMzRsybASCevs/GwNWzJM6TekO5PiCTEJCq8TrpOnTyrzSKbLfOIO3aK6KSs/Sz///rMk6dwW52rdvnUuCfeK8GQEm8QoNgCA79V0UjzrWJYks6+0y15iuyFDFlm0aOsiLRm2RBM/mlhmVRUAQOA4ePCgRo4cqZycHEVGRuq8887Thx9+qD//+c/KysrSxx9/7ExQx8bGaujQoZoyZYpzf6vVqvfee0933XWXEhIS1KBBA40aNcplqpL4+HgtX75cEydOVFpammJiYvTvf/9bSUlJzpjhw4fr0KFDmjp1qnJzc9W9e3etWLFCUVFRzpjnn39eISEhGjp0qAoKCpSUlKQXX3yxZk5ULWS1Smlp5oDt0nLIqamug51LKC3xPWKEWW7c3UjwG27w1ltw5cjiz5wpTZxYucQ35cYBAAAAVABJ8SBU1ghuxxfpE1ZMUM5xczKymIgYnd3sbH2T9412HN6h3Udck+IZ2zO09qe1LscZkTFCN5xTuYtnRrABAGqTmk6KOxLcRecUL86Qoaz8LDVv0Fx7J+ylqgoABIlXXnml1G2xsbFau3Ztqdsd2rVrV6I8enH9+vXT119/XWbM+PHjneXS3QkPD9fs2bM1e/bsctsEU3KylJ5edlXwCpdA379feuYZ9y/ordHhZWXxk5Ol665jRDcAAACAakdSPAiVN4LbkOHcbrVY1bJBS3Vu0Vnf5H2j7Ye3O5PiHZp2KHXEec7xHKV+nupRe8orkQ4AgD+r8ZHi+Vkex+Ycz6GqCgAAAaTMquC+LIFenKcl0CUS3wAAAABqBEnxIOQYAe6J6IbRsoZY1alZJ0nSjsM7nHOKxzWO0y1v31LqiHPJTKrbDbvbGE9LpAMA4M8cSfFT9lM18noVmZqkVaNW1dgSAADgC25zyKWNBK/OEuiSmfxu2lSqV69yJdABAAAAoIaQFA9CFfmCvHWj1pKkzi06S5K+zftW+47tkyQd/u1wuV/MO0q7WmRxSYxTIh0AECh8NVK8cVhjHSs4VuaNZ4ltE2ukTQAAoAYVL5Heu7c5QtzdSHBvjg4vrQz6yy+XMXxdjAQHAAAA4BdCfN0A1LzEtomKiYhxJqaLs8iiJuFNJBVJijc3k+Jf5Xwlu2FX/br1VWAr8Oj1UnqlqE1EG5d1MRExSr8hnRLpAIBar25IXUk1P6f4mB5jJKlEf170xjMqrwAAEGAyMqS4OKl/f+mmm8zHNm1cR2l7k8UixcZKS5ear1NUTIw5yXly8pnE94gR5iMjwQEAAAD4GUaKByFriFVpA9M0bMmwEtscX6RfftblSt+W7kyKd2zWUSGWENkNuySpfZP2zm3lGdxpsJ694lmt27eOEukAgIBT4yPFj5kjxa/vcr0ujrlYE1ZMcKncEhMRo9SBqdx4BgBAoCmtRPrhw945fmkjwR1l0K+7jjLoAAAAAGotkuJBKrlzstJvSNcd796hIyePONc7vkhf/sNySWdGiofXCVdcZJz2HN0jSYoIi1DvmN6KiYhRdn52uaVbrSFWSqQDAAJSTSbFT9tPK+fXHElmn31hmws1+OzB3HgGAECgs9lKL5FeEaUlvu+5R1q4sPR5wSXKoAMAAACo1SifHsSSOyfr4Usfdi7XCamjXX/bpeTOyTrw6wFJUptGZnm0jO0ZznWS9FnWZ2r/QnuNOHeEJEq3AgCCV00mxXOO58hu2FUnpI6iGkZJkvPGsxFdR6hfXD/6XQAAAtG6dZUvke5JCfSnn5b27pVWr5YWLDAfMzPPJMQBAAAAoJZjpHiQO1ZwzPn8tP209h7dq7Obn60Dx80EeOtGrZWxPUPDlgwrMRo8Oz9bz65/Vvf0vkcLty6kdCsAICjVZFI8K98snd6mURuFWLi3EQCAoJGTU7n9KlICnZHgAAAAAAKYX3ybOnv2bMXFxSk8PFy9evXSpk2byoxfunSpOnXqpPDwcHXt2lXvv/++y3bDMDR16lS1atVK9erV04ABA7Rr1y63xyooKFD37t1lsVi0ZcsWb72lWuPI70dclrcd2iZJzqR4VIMoTVgxwW15dMe6RVsXafffdmv1qNVakLxAq0etVuaETBLiAICgUJNJcccNaLGRsdX+WgAAwI+0auVZXIsWrsuOkeDFS6CPGGE+Mic4AAAAgCDh86T44sWLNWnSJE2bNk1fffWVunXrpqSkJB08eNBt/Pr16zVixAjdfvvt+vrrrzVkyBANGTJEW7dudcY8/fTT+uc//6k5c+Zo48aNatCggZKSknTy5MkSx7vvvvvUunXrant//q7ofOKSmRQvOF2gw78dliT9dOwnlxHgxRkylJWfpfX711O6FQAQlBxJ8VP2U9X+WlnHzJHisREkxQEACCqJiWaC22Jxv91RIn3/fkqgAwAAAIAbPk+Kz5w5U2PGjNHo0aPVpUsXzZkzR/Xr19err77qNj4tLU0DBw7Uvffeq86dO+uxxx7TBRdcoFmzZkkyR4mnpqZqypQpGjx4sM477zz95z//0YEDB7Rs2TKXY33wwQf66KOP9Oyzz1b32/RbjqR4h6YdJEnbDm9Tzq9mWbYwa5hOnDrh0XFyjleylBsAALWcL0aKx0TEVPtrAQAAP2K1Smlp5vPiifGiJdJDQxkJDgAAAABu+DQpXlhYqM2bN2vAgAHOdSEhIRowYIA2bNjgdp8NGza4xEtSUlKSMz4zM1O5ubkuMZGRkerVq5fLMfPy8jRmzBi98cYbql+/frltLSgoUH5+vstPIHCUT+8T20eSOVK86HzirRt5Noq+VSMPS7kBABBg6lrrSqrZOcUZKQ4AQICz2aQ1a6SFC81Hm80c8Z2eLrVp4xpbvEQ6AAAAAKAEnybFDx8+LJvNpqioKJf1UVFRys3NdbtPbm5umfGOx7JiDMPQrbfeqjvvvFM9e/b0qK0zZsxQZGSk8yc2NjC+jHaMFL+k7SWSpB2HdzhLs7Zu1FqJbRMVExEji9yXaLPIotiIWCW2TayZBgMA4GdqcqS4IynOSHEAAAJYRoYUFyf17y/ddJP5GBdnrk9OlvbuLbVEurtcOgAAAADAD8qn+8ILL7yg48ePa/LkyR7vM3nyZB07dsz5k5WVVY0trDmOkeLnR5+venXq6eTpk/os6zNJZlLcGmJV2kCzRFvxxLhjOXVgKnOIAwCCli/Kp8dGBsbNeQAAoJiMDGnYMHNu8KKys831GRlmSXQ3JdLLyqUDAAAAQLDzaVK8efPmslqtysvLc1mfl5en6Ohot/tER0eXGe94LCvmk08+0YYNGxQWFqY6deqoQwdzPu2ePXtq1KhRbl83LCxMERERLj+BwDFSvFn9ZurUvJMkaeWelZLkLJ2e3DlZ6Tekq02Ea4m2mIgYpd+QruTOlGgDAASvmkqKn7KdUs7xHEmMFAcAICDZbNKECZJhlNzmWJeS4nb4tye5dAAAAAAIZj5NioeGhqpHjx5atWqVc53dbteqVauUkJDgdp+EhASXeElauXKlMz4+Pl7R0dEuMfn5+dq4caMz5p///Ke++eYbbdmyRVu2bNH7778vSVq8eLGeeOIJr75Hf3by9EmdPH1SktQkvIm6tOgiySyhLsllPvHkzsnaO2GvVo9arQXJC7R61GplTsgkIQ4ACHo1lRTP+TVHhgzVDamrlg1aVutrAQAAH1i3rmRWuyjDkLKyzLgiqpBLBwAAAICgUcfXDZg0aZJGjRqlnj176qKLLlJqaqpOnDih0aNHS5JGjhypNm3aaMaMGZKkCRMmqG/fvnruuec0aNAgLVq0SF9++aVefvllSZLFYlFKSooef/xxdezYUfHx8Xr44YfVunVrDRkyRJLUtm1blzY0bNhQktS+fXvFxATPyCtH6fQQS4gahTVyJsUd2jRyHRluDbGqX1y/mmoeAAC1Qk0lxbOOmVO3tIlooxBLUM6AAwBAYMvJqVRcRXLp/fpVvnkAAAAAUJv5PCk+fPhwHTp0SFOnTlVubq66d++uFStWKCoqSpK0b98+hYSc+eK3d+/eWrBggaZMmaIHH3xQHTt21LJly3Tuuec6Y+677z6dOHFCY8eO1dGjR3XJJZdoxYoVCg8Pr/H3588cpdMbhzdWiCWkRFK86EhxAADgniMpfsp2qlpfxzmfeATziQMAEJBatapUXCVz6QAAAAAQVHyeFJek8ePHa/z48W63rVmzpsS666+/Xtdff32px7NYLJo+fbqmT5/u0evHxcXJcFdnLMA5Roo3CW8iSSWS4ln5WbLZbbKGWGu8bQAA1BY1NlI83xwpznziAAAEqMREKSbGnAjc3XcUFou5PTHRZXUlc+kAAAAAEFSovRnEHCPFm9Qzk+Lf5H7jsn3UslGKS4tTxvaMGm8bAAC1RU0kxW12mz7f/7kkyTAM2exMCgoAQMCxWqW0NPO5xeK6zbGcmmrGFeHIpRffpeiusbElcukAAAAAEFRIigexoiPFM7ZnaHj68BIx2fnZGrZkGIlxAABKUTekrqTqS4pnbM9QXFqc3tr+liRp0feLuGkNAIBAlZwspadLbdq4ro+JMdcnJ5fYpZK5dAAAAAAIKiTFg5hjpHhkeKQmrJggQyXLsznWpaxIYVQaAABuVOdI8YztGRq2ZJhzPnEHbloDALjz0ksv6bzzzlNERIQiIiKUkJCgDz74wLn95MmTGjdunJo1a6aGDRtq6NChysvLcznGvn37NGjQINWvX18tW7bUvffeq9OnXfu4NWvW6IILLlBYWJg6dOig119/vURbZs+erbi4OIWHh6tXr17atGmTy3ZP2hK0kpOlvXul1aulBQvMx8xMtwnxortUMJcOAAAAAEGFpHgQc4wULzhdUOLL9qIMGcrKz9K6fetqqmkAANQa1ZUUt9lt3LQGAKiQmJgYPfXUU9q8ebO+/PJLXXbZZRo8eLC+//57SdLEiRP13//+V0uXLtXatWt14MABJRfJltpsNg0aNEiFhYVav3695s2bp9dff11Tp051xmRmZmrQoEHq37+/tmzZopSUFN1xxx368MMPnTGLFy/WpEmTNG3aNH311Vfq1q2bkpKSdPDgQWdMeW0Jelar1K+fNGKE+ejBMO9K5NIBAAAAIGhYDMMo+U0rypWfn6/IyEgdO3ZMERERvm5OpaSsSFHaxjRd+6dr9e4P75YbvyB5gUZ0HVEDLQOAwBcI/Uht563PIOtYltqmtlWYNUwnp5z0WvvW7F2j/vP6lxu3etRq9Yvr57XXBQB4prb05U2bNtUzzzyjYcOGqUWLFlqwYIGGDRsmSdqxY4c6d+6sDRs26OKLL9YHH3ygq6++WgcOHFBUVJQkac6cObr//vt16NAhhYaG6v7779fy5cu1detW52vceOONOnr0qFasWCFJ6tWrly688ELNmjVLkmS32xUbG6u//e1veuCBB3Ts2LFy2+KJ2vIZAAD8F30JAADBg5HiQcxRPj26YbRH8a0atarO5gAAUCtV10jxnOM5Xo0DAAQXm82mRYsW6cSJE0pISNDmzZt16tQpDRgwwBnTqVMntW3bVhs2bJAkbdiwQV27dnUmxCUpKSlJ+fn5ztHmGzZscDmGI8ZxjMLCQm3evNklJiQkRAMGDHDGeNIWdwoKCpSfn+/yAwAAAACAJ0iKBzFH+fQLWl2gmIgYWWRxG2eRRbERsUpsm1iTzQMAoFZwJMVthk3eLMDj6c1o3LQGACjqu+++U8OGDRUWFqY777xTb7/9trp06aLc3FyFhoaqcePGLvFRUVHKzc2VJOXm5rokxB3bHdvKisnPz9fvv/+uw4cPy2azuY0peozy2uLOjBkzFBkZ6fyJjY317KTUBjabtGaNtHCh+WhjehQAAAAA8CaS4kHMMVK8Wf1mShuYJkklEuOO5dSBqbKGlD+HGQAAwcaRFJe8O1o8sW0iN60BACrs7LPP1pYtW7Rx40bdddddGjVqlLZt2+brZnnF5MmTdezYMedPVlaWr5vkHRkZUlyc1L+/dNNN5mNcnLkeAAAAAOAVJMWDmGOkeJPwJkrunKz0G9LVJqKNS0xMRIzSb0hXcudkXzQRAAC/V11JcWuI1XnTWnHctAYAKE1oaKg6dOigHj16aMaMGerWrZvS0tIUHR2twsJCHT161CU+Ly9P0dHmlFrR0dHKy8srsd2xrayYiIgI1atXT82bN5fVanUbU/QY5bXFnbCwMEVERLj81HoZGdKwYdL+/a7rs7PN9STGAQAAAMArSIoHMcdI8Sb1mkiSkjsna++EvVo9arUWJC/Q6lGrlTkhk4Q4AABlqGut63zu7XnFkzsna+HQhSXWc9MaAMBTdrtdBQUF6tGjh+rWratVq1Y5t+3cuVP79u1TQkKCJCkhIUHfffedDh486IxZuXKlIiIi1KVLF2dM0WM4YhzHCA0NVY8ePVxi7Ha7Vq1a5YzxpC1BwWaTJkyQ3E2/4liXkkIpdQAAAADwgjrlhyBQFR0p7mANsapfXD8ftQgAgNqnukaKO5zV5CxJUkRohF66+iW1btRaiW0TGSEOAChh8uTJuvLKK9W2bVsdP35cCxYs0Jo1a/Thhx8qMjJSt99+uyZNmqSmTZsqIiJCf/vb35SQkKCLL75YknTFFVeoS5cu+stf/qKnn35aubm5mjJlisaNG6ewsDBJ0p133qlZs2bpvvvu02233aZPPvlES5Ys0fLly53tmDRpkkaNGqWePXvqoosuUmpqqk6cOKHRo0dLkkdtCQrr1pUcIV6UYUhZWWZcv3411iwAAAAACEQkxYNUwekC/X76d0lnRooDAICKs1rOJKerIyn+xYEvJEm92/bWTV1v8vrxAQCB4+DBgxo5cqRycnIUGRmp8847Tx9++KH+/Oc/S5Kef/55hYSEaOjQoSooKFBSUpJefPFF5/5Wq1Xvvfee7rrrLiUkJKhBgwYaNWqUpk+f7oyJj4/X8uXLNXHiRKWlpSkmJkb//ve/lZSU5IwZPny4Dh06pKlTpyo3N1fdu3fXihUrFBUV5Ywpry1BISfHu3EesNnMHHtOjtSqlZSYKFm5zw4AAABAECApHqQcpdMtsigiLADmYQMAwEcsFousFqtshq1akuKbsjdJki5sfaHXjw0ACCyvvPJKmdvDw8M1e/ZszZ49u9SYdu3a6f333y/zOP369dPXX39dZsz48eM1fvz4KrUl4LVq5d24cmRkmNXaiw5Oj4mR0tKkZGZkAQAAABDgmFM8SDlKpzcOb6wQC78GAABUhaOEenWOFL+ozUVePzYAAPChxEQzK22xuN9usUixsWZcFWVkSMOGlazWnp1trs/IqPJLAAAAAIBfIxsapBwjxSmdDgBA1TmS4qfsp7x63OMFx7X90HZJjBQHACDgWK3mMG2pZGLcsZyaWuX65jabOULcMEpuc6xLSTHjAAAAACBQkRQPUo6R4k3CSYoDAFBV1TVS/Kucr2TIUGxErKIaRpW/AwAAqF2Sk6X0dKlNG9f1MTHmei/UNV+3ruQI8aIMQ8rKMuMAAAAAIFAxp3iQYqQ4AADeU11Jced84m0YJQ4AQMBKTpYGDzaz0jk55hziiYlVHiHukJPj3TgAAAAAqI1IigcpRooDAOA9da11JXk/Ke6cT7w184kDABDQrFapX79qOXSrVt6NAwAAAIDaiPLpQco5UpykOAAAVebtkeI2u01r9q7R6r2rJUkXtLrAK8cFAADBJzHRrMZefNpyB4tFio014wAAAAAgUJEUD1LOkeKUTwcAoMq8mRTP2J6huLQ49Z/XX4d/OyxJuvWdW5WxPaPKxwYAAMHHapXS0sznxRPjjuXUVK9VawcAAAAAv0RSPEgxUhwA4M8eeeQRWSwWl59OnTo5t588eVLjxo1Ts2bN1LBhQw0dOlR5eXk+a6+3kuIZ2zM0bMkw7c/f77I+53iOhi0ZRmIcAABUSnKylJ4utWnjuj4mxlyfnOybdgEAAABATSEpHqScSXFGigMA/NQ555yjnJwc58+nn37q3DZx4kT997//1dKlS7V27VodOHBAyT78NtcbSXGb3aYJKybIkFFim2NdyooU2ey2Sr8GAAAIXsnJ0t690urV0oIF5mNmJglxAAAAAMGhjq8bAN9wlk9npDgAwE/VqVNH0dHRJdYfO3ZMr7zyihYsWKDLLrtMkvTaa6+pc+fO+vzzz3XxxRe7PV5BQYEKCgqcy/n5+d5r6x9J8VO2U5U+xrp960qMEC/KkKGs/Cyt27dO/eL6Vfp1AABA8LJapX79fN0KAAAAAKh5jBQPUowUBwD4u127dql169Y666yzdPPNN2vfvn2SpM2bN+vUqVMaMGCAM7ZTp05q27atNmzYUOrxZsyYocjISOdPbGys19rqjZHiOcdzvBoHAABQETabtGaNtHCh+WijOA0AAACAAEJSPEgxUhwA4M969eql119/XStWrNBLL72kzMxMJSYm6vjx48rNzVVoaKgaN27ssk9UVJRyc3NLPebkyZN17Ngx509WVpbX2uuNpHirRq28GgcAAOCpjAwpLk7q31+66SbzMS7OXA8AAAAAgYDy6UGKkeIAAH925ZVXOp+fd9556tWrl9q1a6clS5aoXr16lTpmWFiYwsLCvNVEF3VD6kqqWlI8sW2iYiJilJ2f7XZecYssiomIUWLbxEq/BgAA8BM2m7RunZSTI7VqJSUmmrXNfSAjQxo2TDKK/fmRnW2uT09n3nEAAAAAtR8jxYNQoa1Qv536TRIjxQEAtUPjxo31pz/9ST/++KOio6NVWFioo0ePusTk5eW5nYO8JnhjpLg1xKq0gWlut1lkkSSlDkyVNcQ3X5gDAAAv8aNh2TabNGFCyYS4dGZdSgql1AEAAADUfiTFg5CjdLpFFkWGR/q4NQAAlO/XX3/V7t271apVK/Xo0UN169bVqlWrnNt37typffv2KSEhwSft80ZSXJKSOycr/YZ0NQ5v7LI+JiJG6TekK7kzw7QAAKjVHMOy9+93Xe8Yll3DifF160o2pSjDkLKyzDgAAAAAqM0onx6EHKXTI8MjFWLhvggAgP+55557dM0116hdu3Y6cOCApk2bJqvVqhEjRigyMlK33367Jk2apKZNmyoiIkJ/+9vflJCQoIsvvtgn7fVWUlwyE+OrM1dr1hezdHXHq3V377uV2DaREeIAANR25Q3LtljMYdmDB8sma41UV8/J8W4cAAAAAPgrkuJByDFSnNLpAAB/tX//fo0YMUI///yzWrRooUsuuUSff/65WrRoIUl6/vnnFRISoqFDh6qgoEBJSUl68cUXfdZebybFJWnP0T2SpGvPvlb94vp55ZgAAMDHPByW/b8n1unmuf1cQmNipLQ078/t3aqVd+MAAAAAwF+RFA9CjpHiTeqRFAcA+KdFixaVuT08PFyzZ8/W7Nmza6hFZfN2UnzXz7skSR2advDK8QAAgB/wcLj1nGk5Kp46d1RXT0/3bmI8MdFMuGdnux/AbrGY2xMTvfeaAAAAAOAL1M4OQowUBwDAuxxJ8VP2U1U+1mn7aWUezZQkdWzWscrHAwAAfsLD4dYHVDLOkbBOSTGrsHuL1WqOQJfMBHhRjuXU1Oop3Q4AAAAANYmkeJCx2W3alL1JkvnFvc3uxatpAACClDdHiv909Cedtp9WeJ1wtW7UusrHAwAAfsIxLLt49vkPhizap1itk/th2X9UV9e6dd5tVnKyOQK9TRvX9TExriPTbTZpzRpp4ULz0ZvJeQAAAACobiTFg0jG9gzFpcXpn5v+KUn630//U1xanDK2Z/i4ZQAA1G51rXUleScpvuuXM6XTQyz8qQYAQMDwYFh2ilJlV9nDsj2swl4hycnS3r3S6tXSggXmY2bmmYR4RoYUFyf17y/ddJP5GBdnrgcAAACA2oBvWoNExvYMDVsyTPvzXWcmy87P1rAlw0iMAwBQBd4cKf7jLz9KYj5xAEDFzZgxQxdeeKEaNWqkli1basiQIdq5c6dLTL9+/WSxWFx+7rzzTpeYffv2adCgQapfv75atmype++9V6dPu/Zxa9as0QUXXKCwsDB16NBBr7/+eon2zJ49W3FxcQoPD1evXr20adMml+0nT57UuHHj1KxZMzVs2FBDhw5VXl6ed06GvypjWPb3j6brbZU/YbiHVdgrzGqV+vWTRowwHx0l0zMyzPnM9xeb6NwxzzmJcQAAAAC1AUnxIGCz2zRhxQQZMkpsc6xLWZFCKXUAACqpjsV7SfFdP5sjxTs2ZT5xAEDFrF27VuPGjdPnn3+ulStX6tSpU7riiit04sQJl7gxY8YoJyfH+fP00087t9lsNg0aNEiFhYVav3695s2bp9dff11Tp051xmRmZmrQoEHq37+/tmzZopSUFN1xxx368MMPnTGLFy/WpEmTNG3aNH311Vfq1q2bkpKSdPDgQWfMxIkT9d///ldLly7V2rVrdeDAASUnl58UrvVKGZbd+aHksqqry2KRYmPNKuw1xWaTJkw4M6d5UdU1zzkAMOFrwwAAiN5JREFUAAAAVIc6vm4Aqt+6fetKjBAvypChrPwsrdu3Tv3i+tVcwwAACBBeHSl+hJHiAIDKWbFihcvy66+/rpYtW2rz5s269NJLnevr16+v6Ohot8f46KOPtG3bNn388ceKiopS9+7d9dhjj+n+++/XI488otDQUM2ZM0fx8fF67rnnJEmdO3fWp59+queff15JSUmSpJkzZ2rMmDEaPXq0JGnOnDlavny5Xn31VT3wwAM6duyYXnnlFS1YsECXXXaZJOm1115T586d9fnnn+viiy8u0baCggIVFBQ4l/Pz86twtnzMMSy76CqZ1dWHDTMT4EUT0Y5EeWrqmRHcNWHdupIjxIsqOs95sbcDAAAAAH6FkeJBIOe4ZxOOeRoHAABceTMpzkhxAIC3HDt2TJLUtGlTl/Xz589X8+bNde6552ry5Mn67bffnNs2bNigrl27KioqyrkuKSlJ+fn5+v77750xAwYMcDlmUlKSNmzYIEkqLCzU5s2bXWJCQkI0YMAAZ8zmzZt16tQpl5hOnTqpbdu2zpjiZsyYocjISOdPbGxshc+JvyujurrS08/M8V1TPJ2/vDrmOQcAAAAAb2KkeBBo1cizCcc8jQMAAK68lRQ/bT+tzKOZkqSOzUiKAwAqz263KyUlRX369NG5557rXH/TTTepXbt2at26tb799lvdf//92rlzpzL+mBg6NzfXJSEuybmcm5tbZkx+fr5+//13HTlyRDabzW3Mjh07nMcIDQ1V48aNS8Q4Xqe4yZMna9KkSc7l/Pz8gE2MDx5sjr7OyTHnEE9MrNkR4g6ezl/esqW0Zo3v2wsAAAAApSEpHgQS2yYqJiJG2fnZbucVt8iimIgYJbatwYnJAAAIII6k+CnbqSod56ejP+m0/bTC64SrdaPW3mgaACBIjRs3Tlu3btWnn37qsn7s2LHO5127dlWrVq10+eWXa/fu3Wrfvn1NN7NCwsLCFBYW5utm1Ag31dV9IjHRHKWene1+XnGLRWraVLr1Vtcy6zExZin4YJgiHgAAAEDt4Bfl02fPnq24uDiFh4erV69e2rRpU5nxS5cuVadOnRQeHq6uXbvq/fffd9luGIamTp2qVq1aqV69ehowYIB27drlEnPttdeqbdu2Cg8PV6tWrfSXv/xFBw4c8Pp78wfWEKvSBqa53WaROTFZ6sBUWUO4jRsAgMrw1kjxH385M594iMUv/kwDANRC48eP13vvvafVq1crJiamzNhevXpJkn780eyDoqOjlZeX5xLjWHbMQ15aTEREhOrVq6fmzZvLarW6jSl6jMLCQh09erTUmIBjs5nDqRcuNB9tNl+3qFxWq5ncls7Ma+7gmPf8559LzjuenW3Ojf5HAQIAAAAA8Dmff9u6ePFiTZo0SdOmTdNXX32lbt26KSkpSQcPHnQbv379eo0YMUK33367vv76aw0ZMkRDhgzR1q1bnTFPP/20/vnPf2rOnDnauHGjGjRooKSkJJ08edIZ079/fy1ZskQ7d+7UW2+9pd27d2vYsGHV/n59JblzshYPW+xMgjvERMQo/YZ0JXfm9m0AACrLW0nxXb+YN/F1aNqhym0CAAQfwzA0fvx4vf322/rkk08UHx9f7j5btmyRJLX6o052QkKCvvvuO5dr8pUrVyoiIkJdunRxxqxatcrlOCtXrlRCQoIkKTQ0VD169HCJsdvtWrVqlTOmR48eqlu3rkvMzp07tW/fPmdMQMnIkOLipP79pZtuMh/j4mpF1ri0ec7btJGaNXO/j2NUeUpKrcj9AwAAAAgCPi+fPnPmTI0ZM0ajR4+WJM2ZM0fLly/Xq6++qgceeKBEfFpamgYOHKh7771XkvTYY49p5cqVmjVrlubMmSPDMJSamqopU6Zo8ODBkqT//Oc/ioqK0rJly3TjjTdKkiZOnOg8Zrt27fTAAw9oyJAhOnXqlOrWrVvdb9sn2ka2lSFDDeo20L+u/pfaRLRRYttERogDAFBFda3m3w7eGinesSnziQMAKm7cuHFasGCB3nnnHTVq1Mg5N3dkZKTq1aun3bt3a8GCBbrqqqvUrFkzffvtt5o4caIuvfRSnXfeeZKkK664Ql26dNFf/vIXPf3008rNzdWUKVM0btw4Z+nyO++8U7NmzdJ9992n2267TZ988omWLFmi5cuXO9syadIkjRo1Sj179tRFF12k1NRUnThxwnntHxkZqdtvv12TJk1S06ZNFRERob/97W9KSEjQxRdfXMNnrpplZJjDpovXH3cMp05P9/s64+7mObfZpAEDSt/HMKSsLHMffygFDwAAACC4+TQpXlhYqM2bN2vy5MnOdSEhIRowYIA2bNjgdp8NGzZo0qRJLuuSkpK0bNkySVJmZqZyc3M1oMiVWWRkpHr16qUNGzY4k+JF/fLLL5o/f7569+5dakK8oKBABQUFzuX8/HyP36e/WJVp3oF/RfsrdPN5N/u4NQAABA5vjBS32W36fP/nzuc2u40b1wAAFfLSSy9JkvoVy0C+9tpruvXWWxUaGqqPP/7YmaCOjY3V0KFDNWXKFGes1WrVe++9p7vuuksJCQlq0KCBRo0apenTpztj4uPjtXz5ck2cOFFpaWmKiYnRv//9byUlJTljhg8frkOHDmnq1KnKzc1V9+7dtWLFCkVFRTljnn/+eYWEhGjo0KEqKChQUlKSXnzxxWo6Oz5is0kTJrifkNswzBrkKSlmxtnq3/1+8XnOFy70bL/sbLNavCOZnpjo928VAAAAQADyaVL88OHDstlsLhfFkhQVFaUdO3a43Sc3N9dtvOMOeMdjWTEO999/v2bNmqXffvtNF198sd57771S2zpjxgw9+uijnr0xP+VIil8ef7mPWwIAQGCpalI8Y3uGJqyYoP355oScMz+fqSXblihtYBpTnAAAPGa4S7wWERsbq7Vr15Z7nHbt2un9998vM6Zfv376+uuvy4wZP368xo8fX+r28PBwzZ49W7Nnzy63TbXWunUlJ9wuqhYPp/6j4n65Jk6UDh06sxwTY85T7ueD4wEAAAAEGJ/PKe5L9957r77++mt99NFHslqtGjlyZKlfIkyePFnHjh1z/mRlZdVwa6vm91O/67N9n0mSBpxVRn0zAABQYc6kuFHxpHjG9gwNWzLMmRB3yM7P1rAlw5Sx3f/nGgUAAKXIyfFunB9JTDQT3BZL2XFFE+LSmarxtWA6dQAAAAABxKdJ8ebNm8tqtSovL89lfV5enqKjo93uEx0dXWa849GTYzZv3lx/+tOf9Oc//1mLFi3S+++/r88//9zt64aFhSkiIsLlp7aw2W168YsXVWArUPN6zdW+SXtfNwkAgIBS2ZHiNrtNE1ZMkKGSN+U51qWsSJHNbqt6IwEAQM3zdDi1p3F+xGo1R3xL5SfGi3KMRUhJMavL22xmefWFC81HG3/2AAAAAKgGPk2Kh4aGqkePHlq1apVznd1u16pVq5SQkOB2n4SEBJd4SVq5cqUzPj4+XtHR0S4x+fn52rhxY6nHdLyuJJd5wwNBxvYMxaXF6Z6V90iSDv9+WPH/jGfUGQAAXuRIip+ynarQfuv2rSsxQrwoQ4ay8rO0bt+6KrUPAAD4SHnDqS0WKTbWjKuFkpOl9HSpTRvX9S1alL2fo2r8E09IcXFS//7STTeZj3FxjCIHAAAA4H0+L58+adIkzZ07V/PmzdP27dt111136cSJExo9erQkaeTIkZo8ebIzfsKECVqxYoWee+457dixQ4888oi+/PJL5zxlFotFKSkpevzxx/Xuu+/qu+++08iRI9W6dWsNGTJEkrRx40bNmjVLW7Zs0U8//aRPPvlEI0aMUPv27ctMnNc2lGMFAKBmVHakeM5xz0qlehoHAAD8TFnDqR3LqalmXC2VnCzt3SutXi0tWGA+Pv+8Z/tOm1ZyynXKqwMAAACoDnV83YDhw4fr0KFDmjp1qnJzc9W9e3etWLFCUVFRkqR9+/YpJORM7r53795asGCBpkyZogcffFAdO3bUsmXLdO655zpj7rvvPp04cUJjx47V0aNHdckll2jFihUKDw+XJNWvX18ZGRmaNm2aTpw4oVatWmngwIGaMmWKwsLCavYEVJPyyrFaZFHKihQNPnuwrCG19+IbAAB/UNmkeKtGnpVK9TQOAAD4Icdw6gkTXDPAMTFmQjw52WdN8xarVerX78zymjWVP5ZhmPcLpKRIV18trV9vTrneqpU5oL4W3z8AAAAAwIcshmGUzJqiXPn5+YqMjNSxY8f8cn7xNXvXqP+8/uXGrR61Wv3i+lV/gwAALvy9HwkG3vwM5m2Zp1vfuVVXdrhS79/8vsf72ew2xaXFKTs/2+2NbBZZFBMRo8wJmdzEBgB+hr7c92rdZ2CzSevWBUWG12Yzy6BnZ5+ZQ7wyWrSQDh06sxwTYw68D4D7CAD4iVrXlwAAgErzefl0VA/KsQIAUHMqO1LcGmJV2sA0t9ssMkuqpg5MJSEOAEAgcAynHjHCfAzQhLjkWdV4TxRNiEuupdVtNnNE+sKF5qPNVpUWAwAAAAh0JMUDFOVYAQCoOZVNiktScudkpd+Q7kyCO8RExCj9hnQld2YoFAAAqH0cVePbtHFdHxMjPfpo5Y7pGHU+dqw5Er1/f+mmm8zHuDjXechJmgMAAAAoyudziqN6JLZNVExETLnlWBPbJvqgdQAABJaqJMUl6bL4y5z99avXvqr4JvFKbJvICHEAAFCrJSdLgweXrBovSXPnVq68umFIP/9ccr1jFHl6urnsbgp3Sq8DAAAAwYukeIBylGMdtmRYiW2UYwUAwLuqmhTPPJIpSWrZoKVGnz/aa+0CAADwNUfV+OLS0swktsVStXnHHQzDPNbYsdIvv5Q8ZtGkubtEfQBXswcAAAAgyqcHNEc51oiwCJf1lGMFAMC7HEnxU/ZTldo/86iZFI9vHO+1NgEAAPiz0sqrt2hR+WM6RpG7S7JTeh0AAAAIbowUD3DJnZO1+cBmPfnpk0pqn6QHLnmAcqwAAHiZt0aKxzchKQ4AAIKHu/LqvXtL7dtXrrR6ebxRet1mK32UeVnbAAAAAPgWSfEg4Bi1dm7Lc9Uvrp9vGwMAQACqclKckeIAACBIuSuv7u3S6uXxtPT6PfeYo8fdJcyl8ucxJ6EOAAAA+A5J8SBQaCuUJIVZw3zcEgAAAlNda11JlU+K7zmyRxJJcQAAAOlMaXV3Sebff3efuK6q0kaRO7ZJ0jPPlNyWnS0NHep+P09HoJe1raoJdZLtAAAAgImkeBAoOF0gSQq1hvq4JQAABCavjRSnfDoAAIAk96XVExOld95xP4rcsdysWfUkzUtT1us4to0aJf36a8nt+/eXnlB3bEtJkZo0kebOdU2aN28u3XKL+21t2pij3o8ckebPlw4dKrmtY8cz5erXrzfPccuWZszBgyW3lbdc3r4VSdSTyAcAAEB1ICkeBJwjxeswUhwAgOpQlaS4YRjae3SvJEaKA0CwysrKksViUUxMjCRp06ZNWrBggbp06aKxY8f6uHWA77grrV7WKPLUVPN5TZZe94S7hLinHO+puMOHS9+WnS1Nm+bZNqvVTEK7U3xbectl7etpon7XrtJvABg82LuJen+LpU2Vi+WmCQAA4CmS4kGgwMZIcQAAqlNVkuK5/9/evYdFVa59HP8Nw1kFPAIKKqblWUvTsEgrdmjW1lArs+0hy12poexOlnkqM60MLNPaO7PeMjMjKyuLyAPlMcvKNMvCRAW0DFBMwGG9f0wzMnJGYGD4fq5rLpi17lnzzEJ5mLnXfT8n03X6zGm5mdzU2r91VQ8NAFAH3HrrrZowYYL+9a9/KT09Xf/4xz/UpUsXvfHGG0pPT9eMGTOcPUSgVrBVEOfmSsuXW7cVl0SbNatoYtXNTSoocMaoa7eSktrF7Svrfmn7KpKoP5ftAoC4uKpN1NfGWMZU8dhzlxoAAAAoCUnxesBWKU5SHACA6nE+SXFb6/QQvxD72uQAgPpl9+7d6tOnjyRp1apV6tq1q7788kt9+umnuuuuu0iKo94orW12QkLJ624fPy5dcEHRFuKzZ1srk+PiSIi7iqpM1NfGWMZU8djDh63dIVavJjEOAABKR1K8HrBVinuZaZ8OAKh+OTk52rhxow4ePKi8vDyHfffee6+TRlW9bEnxfEt+hR+b8uff64nTOh0A6q38/Hx5eVnfr3322Wf65z//KUnq2LGj0tLSnDk0oMqVlPguLektWZNe57ZDP3y45DW5jxyxVh83bVo9rwNA7WAY1uUSpkyxttinlToAACgJSfF6gEpxAEBN+eabb3Tdddfp1KlTysnJUZMmTfT777/L19dXLVq0cPmk+PlUioc1JikOAPVVly5dtHTpUg0ePFiJiYl67LHHJElHjhxRUzJ6cCElJb5HjpSefrrkpHfTpsWvD17amuG2fX/8cf7jBlC7GYaUmmq94GbAAGePBgAA1FZuzh4Aqp8tKe7lTqU4AKB6TZ06VTfccIP+/PNP+fj4aOvWrfrtt9/Uq1cvPf30084eXrU5r6Q4leIAUO/Nnz9fL774ogYMGKCRI0eqR48ekqT333/f3lYdqEssFmnDBunNN61fLRZrQnz4cMeEuGS9/9RTpSe9SWwDKA+aqwAAgNJQKV4P5J6xtk+nUhxwLovFovz8irdWRt1kNpvl7u4uk8nk7KHUqF27dunFF1+Um5ubzGazcnNz1a5dOy1YsEBjxoxRtIsu8ubhZl0L/LwqxUmKA0C9NWDAAP3+++/Kzs5W48aN7dsnTJggX1/fch9n3rx5SkhI0I8//igfHx/169dP8+fP10UXXWSPOX36tP7zn/9o5cqVys3NVVRUlF544QUFBgbaYw4ePKi7775b69evV8OGDTVmzBjNmzdP7u5nP0LYsGGDYmNj9cMPPyg0NFTTp0/X2LFjHcazePFiPfXUU0pPT1ePHj303HPPOST5yzMW1D3FVYO3aiWdPl16ZXddYzK51usBXEFwsLNHAAAAajOS4vWAvVKcNcUBpzl58qQOHTokg09N6hVfX18FBwfL07P+XJTk4eEhNzdrI5oWLVro4MGD6tSpk/z9/ZWamurk0VUf2qcDAM6XYRjauXOnfvnlF916661q1KiRPD09K5QU37hxoyZOnKhLL71UZ86c0cMPP6xrr71We/bsUYMGDSRZu7p8+OGHevvtt+Xv769JkyYpOjpaX375pSTrhZyDBw9WUFCQNm/erLS0NI0ePVoeHh564oknJEkpKSkaPHiw7rrrLr3xxhtKSkrSHXfcoeDgYEVFRUmS3nrrLcXGxmrp0qXq27ev4uLiFBUVpX379qlFixblGgtqr9LWBS9p7e+66tzkt+2a1/vus7Z8l4rut90vKXF+/fXS2rWlJ9ZJugPlZzJZl2KIiHD2SAAAQG1GUrweyLVQKQ44k8Vi0aFDh+Tr66vmzZvXu8rh+sgwDOXl5enYsWNKSUlRhw4d7IliV3fxxRdrx44d6tChg/r3768ZM2bo999/1//93/+pa9euzh5etbElxS2GRYZhlPv/+ZmCM0rNsl4sQKU4ANRfv/32mwYOHKiDBw8qNzdX//jHP9SoUSPNnz9fubm5Wrp0abmOs27dOof7y5cvV4sWLbRz505deeWVysrK0ssvv6wVK1bo6quvliS98sor6tSpk7Zu3arLLrtMn376qfbs2aPPPvtMgYGB6tmzpx577DE9+OCDmjVrljw9PbV06VKFhYXpmWeekSR16tRJX3zxhZ599ll7UnzhwoW68847NW7cOEnS0qVL9eGHH2rZsmV66KGHyjWWc+Xm5io3N9d+Pzs7u4JnGlWhpHXBFy6UYmNrVyLXZJKaNJGOH7feL2/yunDi+803i77WuDgpOlq67LLiz0VcnPX7c/eFhp59bHHn0ba/uMeGhEh33in9+af0xhvSsWNF93XoIP38s/Tf/zo+tnlzadQoqXHjovvMZutFDsU5d19Z90t7LFBdbP9f4+Ks/+4AAABKQlK8HmBNccC58vPzZRiGmjdvLh8fH2cPBzXEx8dHHh4e+u2335SXlydvb29nD6lGPPHEEzpx4oQkae7cuRo9erTuvvtudejQQcuWLXPy6KqPLSkuWRPj7qby/YmVmpUqi2GRl9lLwY3o9QcA9VVMTIx69+6tb7/9Vk2bNrVvv/HGG3XnnXdW+rhZWVmSpCZNmkiSdu7cqfz8fEVGRtpjOnbsqNatW2vLli267LLLtGXLFnXr1s2hhXlUVJTuvvtu/fDDD7r44ou1ZcsWh2PYYqZMmSJJysvL086dOzVt2jT7fjc3N0VGRmrLli3lHsu55s2bp9mzZ1f6fKBiiqsGf++9kivBb7qpesZxvontl16yfq1I8rpw4nvevOKr4iXr/iFDSt5f2r7zeezTT5e8T5IeeaTk/efu69dP2rzZev/vJg46erTovrLul/bYiibqS7sAoCoT9bUxljFVPLbw/1cAAIDSkBSvB1hTHKgdqBCvf+pLdXhhvXv3tn/fokWLIhVrrqpwUvxMwRmH+6WxtU5vE9BGbqb69+8FAGCVnJyszZs3F1lypW3btjpcyb7TBQUFmjJlii6//HJ7t5b09HR5enoqICDAITYwMFDp6en2mHPX9LbdLysmOztbf/31l/78809ZLJZiY3788cdyj+Vc06ZNU2xsrP1+dna2QkNDyzoVqISKrgteVdXh1ZXYliqfgDabpQEDSh5zafur67FVfdzSjlVWbHkfW5FEfWkXAFRVor42xjKmysWee1EIAABASUiK1wO2SnGS4gAAVI/CSfB8S7683cvXGSDlz7/XE6d1OgDUawUFBbIUUwJ36NAhNWrUqFLHnDhxonbv3q0vvvjifIdXa3h5ecnLiw5o1a2m1wUvb6tyqfKJben8ksw4f1V5AUBVJeprayxjqngsAABAeZAUrwdsa4p7mfnwAABQvTIyMnTfffcpKSlJR48elXHOp6nFfeDvCs6tFC8PS4FFGw5skGS9cM1SYJHZjRIHAKiPrr32WsXFxemlv8thTSaTTp48qZkzZ+q6666r8PEmTZqktWvXatOmTQoJCbFvDwoKUl5enjIzMx0qtDMyMhQUFGSP2b59u8PxMjIy7PtsX23bCsf4+fnJx8dHZrNZZrO52JjCxyhrLKhexbVHl6wV19WxLritDbqPT+ValUsktgEAAABUXqX6dLq5udnf5BZ3Q+1CpTgAoKaMHTtWX3/9tR599FGtXr1aCQkJDrfKevLJJ2UymexrlUrS6dOnNXHiRDVt2lQNGzbUsGHDinz4XlMKJ7PLkxRP2JugtvFt9fr3r0uSPvjpA7WNb6uEvZU/RwCAuuuZZ57Rl19+qc6dO+v06dO69dZb7a3T58+fX+7jGIahSZMm6d1339Xnn3+usDDHTiS9evWSh4eHkpKS7Nv27dungwcPKjw8XJIUHh6u77//XkePHrXHJCYmys/PT507d7bHFD6GLcZ2DE9PT/Xq1cshpqCgQElJSfaY8owF1SchQWrbVrrqKunWW61f27aV5s51TFhX1rkrRxVug37ggLR+vbRihfVrSsrZSnBbYnvkSOtXPmICAAAAUFUqVSn+7rvvOtzPz8/XN998o1dffVWzZ8+ukoGh6tiS4l7uVIoDqJj09HTNnTtXH374oQ4fPqwWLVqoZ8+emjJliq655hpnD6+I5cuXa8qUKcrMzHT2UOqtL774QsnJyerZs2eVHXPHjh168cUX1b17d4ftU6dO1Ycffqi3335b/v7+mjRpkqKjo/Xll19W2XOXl5vJTW4mNxUYBWUmxRP2Jmj4quEy5FiCdTj7sIavGq7VN61WdKfo6hwuAKCWCQkJ0bfffquVK1fqu+++08mTJzV+/HiNGjVKPj4+5T7OxIkTtWLFCr333ntq1KiRfW1uf39/+fj4yN/fX+PHj1dsbKyaNGkiPz8/TZ48WeHh4brsssskWavWO3furH/9619asGCB0tPTNX36dE2cONHeuvyuu+7S888/rwceeEC33367Pv/8c61atUoffvihfSyxsbEaM2aMevfurT59+iguLk45OTkaN26cfUxljQXVo7T26DNnVv64JpO16nvhQmnq1NLboFPRDQAAAKCmVSopPmTIkCLbhg8fri5duuitt97S+PHjz3tgqBqGYSj3jLV9OpXiACriwIEDuvzyyxUQEKCnnnpK3bp1U35+vj755BNNnDhRP/74Y6WOm5eXJ0/Por+P8vPz5eHhcb7DhpOFhoYWaZl+Pk6ePKlRo0bpv//9rx5//HH79qysLL388stasWKFrr76aknSK6+8ok6dOmnr1q1O+TDdw81DuZbcUpPilgKLYtbFFEmIS5IhQyaZNGXdFA25aAit1AGgnnF3d9dtt912XsdYsmSJJGnAORnHV155RWPHjpUkPfvss3Jzc9OwYcOUm5urqKgovfDCC/ZYs9mstWvX6u6771Z4eLgaNGigMWPGaM6cOfaYsLAwffjhh5o6dari4+MVEhKi//3vf4qKirLH3HzzzTp27JhmzJih9PR09ezZU+vWrVNgYKA9pqyx4Pyd2yK9X7+S26Ofz59wtkpwW+L7xhtLb4MOAAAAADWtUu3TS3LZZZcVaaEG57IYFvsH76wpDtQyOTkl306fLn/sX3+VL7aC7rnnHplMJm3fvl3Dhg3ThRdeqC5duig2NlZbt261xx08eFBDhgxRw4YN5efnp5tuusmhhfWsWbPUs2dP/e9//1NYWJi8vb0lWdfKXLJkif75z3+qQYMGmjt3riTpvffe0yWXXCJvb2+1a9dOs2fP1pkzZ5OMmZmZ+ve//63AwEB5e3ura9euWrt2rTZs2KBx48YpKytLJpNJJpNJs2bNKva12ca0bNkytW7dWg0bNtQ999wji8WiBQsWKCgoSC1atLCPSbJeJGAymbRr1y6HsZhMJm3YsKHC59dVxcXF6aGHHtKBAweq5HgTJ07U4MGDFRkZ6bB9586dys/Pd9jesWNHtW7dWlu2bCn2WLm5ucrOzna4VSXbuuKlJcWTDybrUHbJPUkNGUrNTlXyweQqHRsAoHZ77bXXSr2Vl2EYxd5sCXFJ8vb21uLFi3X8+HHl5OQoISGhyBrebdq00UcffaRTp07p2LFjevrpp+Xu7nhN/YABA/TNN98oNzdXv/zyi8Nz2EyaNEm//fabcnNztW3bNvXt29dhf3nGgsorrkV6q1bn1x7dZJKaNrVWfhcWEiKtXk0bdAAAAAC1V6UqxYvz119/adGiRWrVqlVVHRJVwFYlLlEpDtQ6DRuWvO+666RC7SfVooV06lTxsf37S4WTsm3bSr//XjSuAqUfx48f17p16zR37lw1aNCgyP6AgABJ1rUhbQnxjRs36syZM5o4caJuvvlmh0Tx/v379c477yghIUHmQp+IzZo1S08++aTi4uLk7u6u5ORkjR49WosWLVJERIR++eUXTZgwQZI0c+ZMFRQUaNCgQTpx4oRef/11XXDBBdqzZ4/MZrP69eunuLg4zZgxQ/v27ZMkNSzlHP/yyy/6+OOPtW7dOv3yyy8aPny4fv31V1144YXauHGjNm/erNtvv12RkZFFPsCFo8aNG8tUaOHInJwcXXDBBfL19S1S/X/8+PFyH3flypX6+uuvtWPHjiL70tPT5enpaf+3aBMYGGhvFXuuefPmVesyL+VJiqedSCvXscobBwBwDTExMQ738/PzderUKXl6esrX11ejR4920shQV5XUIr24twklMZkcH194XfAhQ6gEBwAAAFC3VCopfu6H34Zh6MSJE/Lx8dEbb7xRZYPD+bOtJy6xpjiA8tu/f78Mw1DHjh1LjUtKStL333+vlJQUhYaGSrJWOnXp0kU7duzQpZdeKsnaMv21115T8+bNHR5/66232teVlKTbb79dDz30kMaMGSNJateunR577DE98MADmjlzpj777DNt375de/fu1YUXXmiPsfH395fJZCpXhVFBQYGWLVumRo0aqXPnzrrqqqu0b98+ffTRR3Jzc9NFF12k+fPna/369STFyxAXF1flx0xNTVVMTIwSExPt3QXO17Rp0xQbG2u/n52dbf93WxXKkxQPbhRcrmOVNw4A4Br+/PPPItt+/vln3X333br//vudMCJUiXN7l9dQ5thiKblFennNni3997+sCw4AAADAdVQqKf7ss886JMXd3NzUvHlz9e3bV40bN66yweH85VqsleImmWQ2cdk2UKucPFnyvnM/LDt6tORYt3NWwqiCttXlXRN67969Cg0NdUgsdu7cWQEBAdq7d689Kd6mTZsiCXFJ6t27t8P9b7/9Vl9++aVD23KLxaLTp0/r1KlT2rVrl0JCQuwJ8fPRtm1bNWrUyH4/MDBQZrNZboXOZ2BgoI6Wdu4hSfaLGKrSzp07dfToUV1yySX2bRaLRZs2bdLzzz+vTz75RHl5ecrMzHSoFs/IyCjxoggvLy95eVXfBWK2pHh+QX6JMRGtIxTiF6LD2YeLXVfcJJNC/EIU0Tqi2sYJAKgbOnTooCeffFK33XabfvzxR2cPBxWVkGDNTJ+bVY6PP5tVriLn5t4tlsq3SDeZrMN85BHrjWpwAAAAAK6iUknxsWPH6vTp0/ruu+909OhRFRQUKC8vT8nJ1vUv//nPf1bpIFF5tkpxT7Onw4UMAGqBYtqS13hsCTp06CCTyVRlH8AW14K9uO0nT57U7NmzFV3MB4Xe3t7y8fGpkvFIKtLW22QyFbutoKBAkuzJ8sIXDOTnl5z8rM8sFoveffdd7d27V5L1QokhQ4YUWYu0NNdcc42+//57h23jxo1Tx44d9eCDDyo0NFQeHh5KSkrSsGHDJEn79u3TwYMHFR4eXnUvpgLKUyludjMrfmC8hq8aXmSfSdZ5Om5gnMxufOIMAJDc3d115MgRZw8DFVVS7/LDh63bCy++XQVPdW7uvUmTyh3L9pFBXNzZ5DfV4AAAAABcRaWS4uvWrdPo0aP1xx9/FKkmNJlMslgsVTI4nD/bmuK0TgdQEU2aNFFUVJQWL16se++9t0jy2lad26lTJ6Wmpio1NdVeLb5nzx5lZmaqc+fOFX7eSy65RPv27VP79u2L3d+9e3cdOnRIP/30U7HV4p6entU2B9kq3dPS0nTxxRdLknbt2lUtz1WX/fDDD/rnP/+p9PR0XXTRRZKk+fPnq3nz5vrggw/UtWvXch2nUaNGRWIbNGigpk2b2rePHz9esbGxatKkifz8/DR58mSFh4frsssuq9oXVU7lSYpLUnSnaK2+abVuf+92ZeVm2beH+IUobmCcojtVbfUYAKD2e//99x3uG4ahtLQ0Pf/887r88sudNCpUSmm9yw3DmnmeMsW6KPd5ll2XlHs/frx8j2/eXDp27Oz9c9ujAwAAAIArqVRSfPLkyRoxYoRmzJihwMDAqh4TqlDhSnEAqIjFixfr8ssvV58+fTRnzhx1795dZ86cUWJiopYsWaK9e/cqMjJS3bp106hRoxQXF6czZ87onnvuUf/+/Yu0Ri+PGTNm6Prrr1fr1q01fPhwubm56dtvv9Xu3bv1+OOPq3///rryyis1bNgwLVy4UO3bt9ePP/4ok8mkgQMHqm3btjp58qSSkpLUo0cP+fr6ytfXt0rOh4+Pjy677DI9+eSTCgsL09GjRzV9+vQqObYrueOOO9SlSxd99dVX9iVV/vzzT40dO1YTJkzQ5s2bq+y5nn32Wbm5uWnYsGHKzc1VVFSUXnjhhSo7fkWVNykuWRPj2w9v1/wv5yvqgig9dMVDimgdQYU4ANRTQ4cOdbhvMpnUvHlzXX311XrmmWecMyhUTnJy6b3LDUNKTbXGnUcZ9vmsG25rkb5/v7R5M+3RAQAAANQPlUqKZ2RkKDY2loR4HWBbU9zLTKU4gIpp166dvv76a82dO1f/+c9/lJaWpubNm6tXr15asmSJJOsHtu+9954mT56sK6+8Um5ubho4cKCee+65Sj1nVFSU1q5dqzlz5mj+/Pny8PBQx44ddccdd9hj3nnnHd13330aOXKkcnJy1L59ez355JOSpH79+umuu+7SzTffrD/++EMzZ87UrFmzzvtc2Cxbtkzjx49Xr169dNFFF2nBggW69tprq+z4rmDXrl0OCXFJaty4sebOnWtfY76yNmzY4HDf29tbixcv1uLFi8/ruFXFw2xtv1+epLgk/XHqD0nS5aGXa0DbAdU1LABAHWBbrgUuIC2tauNKUFbuvSSFW6R7etIeHQAAAED9Uamk+PDhw7VhwwZdcMEFVT0eVDEqxQGcj+DgYD3//PN6/vnnS4xp3bq13nvvvRL3z5o1q9jE9LnLb9hERUUpKiqqxOM1adJEy5YtK3H/kiVL7En7ioxp+fLlReLOTcJ26tSpSKVzSa+jvrrwwguVkZGhLl26OGw/evRoiW3xXUVFKsUl6dgpa7/SZr7Nqm1MAACghgUHV21cCcqbU2/SxLGdOi3SAQAAANRXlUqKP//88xoxYoSSk5PVrVs3eXh4OOy/9957q2RwOH+2pDhrigMAasK8efN07733atasWfa1vbdu3Wqv/s/OzrbH+vn5OWuY1aKiSfHfT/0uSWreoHm1jQkAUHvFxsaWO3bhwoXVOBJUqYgIa+b58OHie5vbepdHRJzX05Q3p75qlbUlOi3SAQAAANR3lUqKv/nmm/r000/l7e2tDRs2yGTrvyVrK12S4rVH7hlr+3QqxQEANeH666+XJN100032vw9s1fQ33HCD/b7JZJLFYnHOIKtJZSvFm/uSFAeA+uibb74pV1zh99uoA8xmKT5eGj7cmgAvnBgv3Lv8PDPT5c29DxhAEhwAAAAApEomxR955BHNnj1bDz30kNzc3Kp6TKhC9kpx1hQHANSA9evXO3sITlPhpHgO7dMBoD6rz3Omy4uOllavlmJiHBf+rsLe5TWUewcAAAAAl1GppHheXp5uvvlmEuJ1QK6FSnEAQM3p37+/s4fgNLakeL4lv8zYMwVn9OfpPyXRPh0AAJcUHS0NGSIlJ1db7/IayL0DAAAAgMuoVFJ8zJgxeuutt/Twww9X9XhQxWyV4iTFAecziutrCJdWX37m3333Xblju3fvXo0jca6KVIr/ceoPSZJJJjX1aVqt4wIA1A1fffWVVq1apYMHDyovL89hX0JCgpNGhfNiNlv7l58ni6Xk3HoN5N4BAAAAwCVUKilusVi0YMECffLJJ+revbs8PDwc9i9cuLBKBofzZ1tT3Mud9umAs5j//kQqLy9PPj4+Th4NatKpU6ckqcg86Wp69uwpk8lU5kUArriOeGEVSYrb1hNv4tNEZjc+tQaA+m7lypUaPXq0oqKi9Omnn+raa6/VTz/9pIyMDN14443OHh6cKCGh+Erw+PizleBVlHsHAAAAAJdWqaT4999/r4svvliStHv3bod9JtviVRWwePFiPfXUU0pPT1ePHj303HPPqU+fPiXGv/3223r00Ud14MABdejQQfPnz9d1111n328YhmbOnKn//ve/yszM1OWXX64lS5aoQ4cOkqQDBw7oscce0+eff6709HS1bNlSt912mx555BF5erpWRTWV4oDzubu7y9fXV8eOHZOHhwdLT9QDhmHo1KlTOnr0qAICAuwXRriqlJQUZw+hVvBws178UK6kOOuJAwAKeeKJJ/Tss89q4sSJatSokeLj4xUWFqZ///vfCg4Odvbw4CQJCdY1w8+97vDwYev21atpkQ4AAAAA5VWppPj69eurbABvvfWWYmNjtXTpUvXt21dxcXGKiorSvn371KJFiyLxmzdv1siRIzVv3jxdf/31WrFihYYOHaqvv/5aXbt2lSQtWLBAixYt0quvvqqwsDA9+uijioqK0p49e+Tt7a0ff/xRBQUFevHFF9W+fXvt3r1bd955p3JycvT0009X2WurDWxrinuZqRQHnMVkMik4OFgpKSn67bffnD0c1KCAgAAFBQU5exjVrk2bNkW27dmzp0j7V5PJVGysq6hIpfjvp36XxHriAACrX375RYMHD5YkeXp6KicnRyaTSVOnTtXVV1+t2bNnO3mEqGkWi7VCvLhGPIYhmUzSlCnW1ukufv0lAAAAAFSJSiXFq9LChQt15513aty4cZKkpUuX6sMPP9SyZcv00EMPFYmPj4/XwIEDdf/990uSHnvsMSUmJur555/X0qVLZRiG4uLiNH36dA0ZMkSS9NprrykwMFBr1qzRLbfcooEDB2rgwIH2Y7Zr10779u3TkiVLSkyK5+bmKjc3134/Ozu7ys5BdaJSHKgdPD091aFDhyLrQ8J1eXh4uHyFeHF+/fVX3Xjjjfr+++8dWqrbOsnQPt3K1j69uS9JcQCA1LhxY504cUKS1KpVK+3evVvdunVTZmamfTkW1C/JyY4t089lGFJqqjWO1ukAAAAAUDanJsXz8vK0c+dOTZs2zb7Nzc1NkZGR2rJlS7GP2bJli2JjYx22RUVFac2aNZKsLVzT09MVGRlp3+/v76++fftqy5YtuuWWW4o9blZWlpo0aVLiWOfNm1cnr863JcWpFAecz83NTd7e3s4eBlCtYmJiFBYWpqSkJIWFhWnbtm06fvy4/vOf/7hcN5ZzVSgpTvt0AICsy5F17dpVV155pRITE9WtWzeNGDFCMTEx+vzzz5WYmKhrrrnG2cOEE6SlVW0cAAAAANR3Tl3Y9vfff5fFYlFgYKDD9sDAQKWnpxf7mPT09FLjbV8rcsz9+/frueee07///e8Sxzpt2jRlZWXZb6mpqaW/uFoi94y1up1KcQBATdiyZYvmzJmjZs2ayc3NTWazWVdccYXmzZune++919nDq1aVap9OpTgA1Gvdu3dX37597clwSXrkkUcUGxurjIwMDRs2TC+//LKTRwlnKO9S8iw5DwAAAADl4/T26c52+PBhDRw4UCNGjNCdd95ZYpyXl5e8vOpetbW9Uty97o0dAFD3WCwWNWrUSJLUrFkzHTlyRBdddJHatGmjffv2OXl01cuWFM8vyC8z1t4+nTXFAaBe27hxo1555RXNmzdPc+fO1bBhw3THHXcUu5QY6peICCkkRDp8uPh1xU0m6/6IiJofGwAAAADURU6tFG/WrJnMZrMyMjIctmdkZCgoKKjYxwQFBZUab/tanmMeOXJEV111lfr166eXXnrpvF5LbZVroVIcAFBzunbtqm+//VaS1LdvXy1YsEBffvml5syZo3bt2jl5dNWLNcUBABUVERGhZcuWKS0tTc8995wOHDig/v3768ILL9T8+fNL7HZWmk2bNumGG25Qy5YtZTKZ7EuN2YwdO1Ymk8nhNnDgQIeY48ePa9SoUfLz81NAQIDGjx+vkydPOsR89913ioiIkLe3t0JDQ7VgwYIiY3n77bfVsWNHeXt7q1u3bvroo48c9huGoRkzZig4OFg+Pj6KjIzUzz//XOHX7IrMZik+3vq9yeS4z3Y/Ls4aBwAAAAAom1OT4p6enurVq5eSkpLs2woKCpSUlKTw8PBiHxMeHu4QL0mJiYn2+LCwMAUFBTnEZGdna9u2bQ7HPHz4sAYMGKBevXrplVdekZubU09FtbFVipMUBwDUhOnTp6ugoECSNGfOHKWkpCgiIkIfffSRFi1a5OTRVS/WFAcAVFaDBg00btw4bdy4UT/99JNGjBihxYsXq3Xr1vrnP/9ZoWPl5OSoR48eWrx4cYkxAwcOVFpamv325ptvOuwfNWqUfvjhByUmJmrt2rXatGmTJkyYYN+fnZ2ta6+9Vm3atNHOnTv11FNPadasWQ4Xm2/evFkjR47U+PHj9c0332jo0KEaOnSodu/ebY9ZsGCBFi1apKVLl2rbtm1q0KCBoqKidPr06Qq95rrIYpE2bJDefNP61WIpGhMdLa1eLbVq5bg9JMS6PTq6JkYKAAAAAK7B6e3TY2NjNWbMGPXu3Vt9+vRRXFyccnJyNG7cOEnS6NGj1apVK82bN0+SFBMTo/79++uZZ57R4MGDtXLlSn311Vf2N98mk0lTpkzR448/rg4dOigsLEyPPvqoWrZsqaFDh0o6mxBv06aNnn76aR07dsw+npIq1Osq25riXmbapwMAql9UVJT9+/bt2+vHH3/U8ePH1bhxY5nOLXNyMR5uHpIquKY47dMBAOdo3769Hn74YbVp00bTpk3Thx9+WKHHDxo0SIMGDSo1xsvLq8T3vnv37tW6deu0Y8cO9e7dW5L03HPP6brrrtPTTz+tli1b6o033lBeXp6WLVsmT09PdenSRbt27dLChQvtyfP4+HgNHDhQ999/vyTpscceU2Jiop5//nktXbpUhmEoLi5O06dP15AhQyRJr732mgIDA7VmzRrdcsstFXrddUlCghQTIx06dHZbSIi1MvzcRHd0tDRkiJScLKWlWdcQj4igQhwAAAAAKsrpSfGbb75Zx44d04wZM5Senq6ePXtq3bp1CgwMlCQdPHjQoYq7X79+WrFihaZPn66HH35YHTp00Jo1a9S1a1d7zAMPPKCcnBxNmDBBmZmZuuKKK7Ru3Tp5e3tLslaW79+/X/v371dISIjDeIziFuuqw/IKqBQHADhXkyZNnD2EGlHeSnHDMM4mxWmfDgAoZNOmTVq2bJneeecdubm56aabbtL48eOr/Hk2bNigFi1aqHHjxrr66qv1+OOPq2nTppKkLVu2KCAgwJ4Ql6TIyEi5ublp27ZtuvHGG7VlyxZdeeWV8vQ8+z4zKipK8+fP159//qnGjRtry5Ytio2NdXjeqKgoezv3lJQUpaenKzIy0r7f399fffv21ZYtW4pNiufm5io3N9d+Pzs7u0rOR01KSJCGDy+6TvihQ9KwYdKUKdYkeOHEt9ksDRhQ0yMFAAAAANfi9KS4JE2aNEmTJk0qdt+GDRuKbBsxYoRGjBhR4vFMJpPmzJmjOXPmFLt/7NixGjt2bGWGWufYK8XdqRQHAKA6lTcpnpWbpfyCfEm0TwcASEeOHNHy5cu1fPly7d+/X/369dOiRYt00003qUGDBlX+fAMHDlR0dLTCwsL0yy+/6OGHH9agQYO0ZcsWmc1mpaenq0WLFg6PcXd3V5MmTexrnKenpyssLMwhxnZhe3p6uho3bqz09HT7tsIxhY9R+HHFxZxr3rx5mj17diVfufNZLNYK8dKuxY+Ls95KqhwHAAAAAFROrUiKo/qwpjgAADWjvElxW5V4A48G8vHwqfZxAQBqr0GDBumzzz5Ts2bNNHr0aN1+++266KKLqvU5C1dgd+vWTd27d9cFF1ygDRs26JprrqnW5z5f06ZNc6g+z87OVmhoqBNHVDHJyY4t00tz+LC1opy1wwEAAACgariVHYK6LNfCmuIAANSE8ibFj+Uck8R64gAAycPDQ6tXr9ahQ4c0f/78ak+IF6ddu3Zq1qyZ9u/fL0kKCgrS0aNHHWLOnDmj48eP29chDwoKUkZGhkOM7X5ZMYX3F35ccTHn8vLykp+fn8OtLklLK3+srZp8yhRrhTkAAAAA4PyQFHdxVIoDAFAzbEnxfEt+qXHHTv2dFGc9cQCo995//30NGTJEZtvi0U5w6NAh/fHHHwoODpYkhYeHKzMzUzt37rTHfP755yooKFDfvn3tMZs2bVJ+/tk5LzExURdddJEaN25sj0lKSnJ4rsTERIWHh0uSwsLCFBQU5BCTnZ2tbdu22WNczd+nuNwMQ0pNtVaYAwAAAADOD0lxF2dLirOmOAAA1auileKsJw4AqA4nT57Url27tGvXLklSSkqKdu3apYMHD+rkyZO6//77tXXrVh04cEBJSUkaMmSI2rdvr6ioKElSp06dNHDgQN15553avn27vvzyS02aNEm33HKLWrZsKUm69dZb5enpqfHjx+uHH37QW2+9pfj4eIfW5jExMVq3bp2eeeYZ/fjjj5o1a5a++uorTZo0SZJkMpk0ZcoUPf7443r//ff1/fffa/To0WrZsqWGDh1ao+espkREWNcKN5kq9riKVJgDAAAAAIpHUtzF5Z6xtk+nUhwAgOpV0TXFaZ8OAKgOX331lS6++GJdfPHFkqTY2FhdfPHFmjFjhsxms7777jv985//1IUXXqjx48erV69eSk5OlpfX2Qup33jjDXXs2FHXXHONrrvuOl1xxRV66aWX7Pv9/f316aefKiUlRb169dJ//vMfzZgxQxMmTLDH9OvXTytWrNBLL72kHj16aPXq1VqzZo26du1qj3nggQc0efJkTZgwQZdeeqlOnjypdevWydvbuwbOVM0zm6X4eOv3FUmMV7TCHAAAAABQlLuzB4DqRft0AABqhj0pbpRRKU77dABANRowYIAM24LUxfjkk0/KPEaTJk20YsWKUmO6d++u5DL6eo8YMUIjRowocb/JZNKcOXM0Z86cMsfkKqKjpdWrpZgY6dCh0mNNJmtleUREzYwNAAAAAFwZleIuLtdirRT3MtM+HQCA6uRh9pBUjvbpJMUBAKjXoqOlAwek9eulKVOs286tHLfdj4uzVpgDAAAAAM4PSXEXR6U4AAA1o7j26ZYCizYc2KA3v39TGw5skKXAYm+fzpriAADUX2azNGCA9Oyz0jvvSK1aOe4PCbFWlEdHO2V4AAAAAOByaJ/u4mxrinu5UykOAEB1OjcpnrA3QTHrYnQo+2xv1BC/EHv3FtYUBwAAkjXxPWSIlJwspaVZ1xCPiKBCHAAAAACqEklxF0elOAAANaNwUjxhb4KGrxouQ45ruh7OPmzfRvt0AADqF4ul5MS3rXIcAAAAAFA9SIq7ONYUBwCgZtiS4nln8hSzLqZIQlySw7bG3o1rbGwAAMC5EhKkmBjp0NkGMgoJkeLjaZEOAAAAADWBNcVdHJXiAADUDFtS/NipYw4t00uy/8/91T0kAABQCyQkSMOHOybEJenwYev2hATnjAsAAAAA6hOS4i6ONcUBAKgZtqT4X/l/lSs+Oze7OocDAABqAYvFWiFuFG0gY982ZYo1DgAAAABQfUiKuzDDMJRfkC+JSnEAAKqbLSludjOXK75lo5bVORwAAFALJCcXrRAvzDCk1FRrHAAAAACg+pAUd2G2hLhEUhwAgOrm4eYhSWrg0UAhfiEyyVRqbETriJoaGgAAcJK0tKqNAwAAAABUDklxF2ZrnS5JXmbapwMAUJ1sleIWw6L4gfGlxrbya1UTQwIAAE4WHFy1cQAAAACAyiEp7sLyLHn276kUBwCgetmS4mcKzii6U7RW37RaDT0bFht7IPOA2sa3VcLehJocIgAAqGEREVJIiGQqoYGMySSFhlrjAAAAAADVh6S4C8u1WCvFzSZzudc3BQAAlVM4KS5J0Z2iNaLziBLjD2cf1vBVw0mMAwDgwsxmKf7vBjLnJsZt9+PirHEAAAAAgOpDUtyF2SrFqRIHAKD62ZLi+QX59m0n806WGG/IkCRNWTdFlgJL9Q4OAABUPYtF2rBBevNN61dL8fN5dLS0erXU6pzVU0JCrNujo6t9pAAAAABQ77k7ewCoPrY1xb3cWU8cAIDqdm6luCSlZqeW+hhDhlKzU5V8MFkD2g6ozuEBAICqlJAgxcRIhw6d3RYSYi0LLybLHR0tDRkiJSdLaWnWNcQjIqgQBwAAAICaQlLchVEpDgBAzSkuKZ51Oqtcj007kVYtYwIAANUgIUEaPlwyDMfthw9bt5dQ/m02SwMG1MwQAQAAAACOaJ/uwmxrinuZqRQHAKC6FZcULzAKyvXY4EbB1TImAABQxSwWa4X4uQlx6ey2KVNKbKUOAAAAAHAOkuIujEpxAABqjofZQ5JjUtwkU6mPMcmkUL9QRbSOqNaxAQCAKpKc7Ngy/VyGIaWmWuMAAAAAALUGSXEXZkuKs6Y4AADVr7hK8VNnTtm/PzdBbrsfNzBOZjcWFAUAoE5IK+eSJ+WNAwAAAADUCJLiLiz3jLV9OpXiAABUv+KS4ifzTkqS4qLi1MqvlUN8iF+IVt+0WtGdiq45CgAAaqngci55Ehwsi0XasEF6803rVzqqAwAAAIDzkBR3YbRPBwDUVUuWLFH37t3l5+cnPz8/hYeH6+OPP7bvP336tCZOnKimTZuqYcOGGjZsmDIyMpw44uKT4jl5OZKkoR2H6kDMAa0fs14roldo/Zj1SolJISEOAEBdExEhhYRIphKWSDGZpNBQJRyLUNu20lVXSbfeav3atq2UkFCTgwUAAAAA2JAUd2G5FmuluJeZ9ukAgLolJCRETz75pHbu3KmvvvpKV199tYYMGaIffvhBkjR16lR98MEHevvtt7Vx40YdOXJE0dHOTTDbkuL5lnxJ1uS4bS5u4NlAZjezBrQdoJHdRmpA2wG0TAcAoC4ym6X4eOv35ybG/76/9ZY4Db/ZXGTp8cOHpeHDSYwDAAAAgDOQFHdhVIoDAOqqG264Qdddd506dOigCy+8UHPnzlXDhg21detWZWVl6eWXX9bChQt19dVXq1evXnrllVe0efNmbd26tcRj5ubmKjs72+FWlc6tFLdViUtSQ8+GVfpcAACUZNOmTbrhhhvUsmVLmUwmrVmzxmG/YRiaMWOGgoOD5ePjo8jISP38888OMcePH9eoUaPk5+engIAAjR8/XidPnnSI+e677xQRESFvb2+FhoZqwYIFRcby9ttvq2PHjvL29la3bt300UcfVXgstVJ0tLR6tdTKcWkUhYTIsmq1RrwZLcMo+jDbtilTaKUOAAAAADWNpLgLs60p7uVOpTgAoO6yWCxauXKlcnJyFB4erp07dyo/P1+RkZH2mI4dO6p169basmVLiceZN2+e/P397bfQ0NAqHactKW4xLDIMQzn51qS4m8mNri0AgBqTk5OjHj16aPHixcXuX7BggRYtWqSlS5dq27ZtatCggaKionT69Gl7zKhRo/TDDz8oMTFRa9eu1aZNmzRhwgT7/uzsbF177bVq06aNdu7cqaeeekqzZs3SSy+9ZI/ZvHmzRo4cqfHjx+ubb77R0KFDNXToUO3evbtCY6m1oqOlAwek9eulFSusX1NSlNwsukiFeGGGIaWmSsnJNTZSAAAAAIAkd2cPANWHSnEAQF32/fffKzw8XKdPn1bDhg317rvvqnPnztq1a5c8PT0VEBDgEB8YGKj09PQSjzdt2jTFxsba72dnZ1dpYtyWFJesifGTedaKuoaeDWUqad1RAACq2KBBgzRo0KBi9xmGobi4OE2fPl1DhgyRJL322msKDAzUmjVrdMstt2jv3r1at26dduzYod69e0uSnnvuOV133XV6+umn1bJlS73xxhvKy8vTsmXL5OnpqS5dumjXrl1auHChPXkeHx+vgQMH6v7775ckPfbYY0pMTNTzzz+vpUuXlmsstZ7ZLA0Y4LApLa18Dy1vHAAAAACgalAp7sJYUxwAUJdddNFF2rVrl7Zt26a7775bY8aM0Z49eyp9PC8vL/n5+TncqpKHm4f9+zMFZ+zt0xt4NKjS5wEAoLJSUlKUnp7u0G3F399fffv2tXdb2bJliwICAuwJcUmKjIyUm5ubtm3bZo+58sor5el59gLsqKgo7du3T3/++ac9pvDz2GJsz1OesZyrupdCqQrBwVUbBwAAAACoGiTFXRiV4gCAuszT01Pt27dXr169NG/ePPXo0UPx8fEKCgpSXl6eMjMzHeIzMjIUFBTknMHKsVL8TMEZh0pxAABqA1tHlcDAQIfthbutpKenq0WLFg773d3d1aRJE4eY4o5R+DlKiim8v6yxnKu6l0KpChERUkiIVFKTGJNJCg21xgEAAAAAag5JcRdmX1OcSnEAgAsoKChQbm6uevXqJQ8PDyUlJdn37du3TwcPHlR4eLjTxnduUty2pngDTyrFAQCoCtOmTVNWVpb9lpqa6uwhFWE2S/Hx1u/PTYzb7sfFWeMAAAAAADWHNcVdGJXiAIC6atq0aRo0aJBat26tEydOaMWKFdqwYYM++eQT+fv7a/z48YqNjVWTJk3k5+enyZMnKzw8XJdddpnTxmx2O/vpduFKcdqnAwBqC1tHlYyMDAUX6t+dkZGhnj172mOOHj3q8LgzZ87o+PHj9scHBQUpIyPDIcZ2v6yYwvvLGsu5vLy85OVV+y/6jo6WVq+WYmKkQ4fObg8JsSbEo6OdNjQAAAAAqLeoFHdhJMUBAHXV0aNHNXr0aF100UW65pprtGPHDn3yySf6xz/+IUl69tlndf3112vYsGG68sorFRQUpISEBKeO2c3kJjeT9U+rwmuK0z4dAFBbhIWFKSgoyKHbSnZ2trZt22bvthIeHq7MzEzt3LnTHvP555+roKBAffv2tcds2rRJ+fn59pjExERddNFFaty4sT2m8PPYYmzPU56x1GXR0dKBA9L69dKKFdavKSkkxAEAAADAWagUd2G5lr/bp7vX/ivpAQAo7OWXXy51v7e3txYvXqzFixfX0IjKx93NXXmWPOVb8mmfDgBwipMnT2r//v32+ykpKdq1a5eaNGmi1q1ba8qUKXr88cfVoUMHhYWF6dFHH1XLli01dOhQSVKnTp00cOBA3XnnnVq6dKny8/M1adIk3XLLLWrZsqUk6dZbb9Xs2bM1fvx4Pfjgg9q9e7fi4+P17LPP2p83JiZG/fv31zPPPKPBgwdr5cqV+uqrr/TSSy9JkkwmU5ljqevMZmnAAGePAgAAAAAgkRR3aVSKAwBQs2xJ8cLt06kUBwDUpK+++kpXXXWV/X5sbKwkacyYMVq+fLkeeOAB5eTkaMKECcrMzNQVV1yhdevWydvb2/6YN954Q5MmTdI111wjNzc3DRs2TIsWLbLv9/f316effqqJEyeqV69eatasmWbMmKEJEybYY/r166cVK1Zo+vTpevjhh9WhQwetWbNGXbt2tceUZywAAAAAAFQFkuIuLPfM35XiZirFAQCoCe5u1j+tCrdPZ01xAEBNGjBggAzDKHG/yWTSnDlzNGfOnBJjmjRpohUrVpT6PN27d1dycnKpMSNGjNCIESPOayx1isUiJSdLaWlScLAUEWEtFwcAAAAAOB1JcReWV0ClOAAANcnDzUOSqBQHAKC+SUiQYmKkQ4fObgsJkeLjWUgcAAAAAGoBN2cPANXHXinOmuIAANQIh0rxfCrFAQCoFxISpOHDHRPiknT4sHV7QoJzxgUAAAAAsHN6Unzx4sVq27atvL291bdvX23fvr3U+LffflsdO3aUt7e3unXrpo8++shhv2EYmjFjhoKDg+Xj46PIyEj9/PPPDjFz585Vv3795Ovrq4CAgKp+SbUGa4oDAFCzCifFbZXiDTxJigMA4LIsFmuFeHEt623bpkyxxgEAAAAAnMapSfG33npLsbGxmjlzpr7++mv16NFDUVFROnr0aLHxmzdv1siRIzV+/Hh98803Gjp0qIYOHardu3fbYxYsWKBFixZp6dKl2rZtmxo0aKCoqCidPn3aHpOXl6cRI0bo7rvvrvbX6Ey5FtYUBwCgJhVXKU77dAAAXFhyctEK8cIMQ0pNtcYBAAAAAJzGqUnxhQsX6s4779S4cePUuXNnLV26VL6+vlq2bFmx8fHx8Ro4cKDuv/9+derUSY899pguueQSPf/885KsVeJxcXGaPn26hgwZou7du+u1117TkSNHtGbNGvtxZs+eralTp6pbt27lHmtubq6ys7MdbrUdleIAANQsh6R4Hu3TAQBwZRaLtCcprXzBaeWMAwAAAABUC6clxfPy8rRz505FRkaeHYybmyIjI7Vly5ZiH7NlyxaHeEmKioqyx6ekpCg9Pd0hxt/fX3379i3xmOU1b948+fv722+hoaHndbyaQFIcAICaZUuK5xfk29unUykOAIDrSUiQ2raV7nk8uHwPCC5nHAAAAACgWjgtKf7777/LYrEoMDDQYXtgYKDS09OLfUx6enqp8bavFTlmeU2bNk1ZWVn2W2pq6nkdrybknvm7fbo77dMBAKgJxbVPZ01xAABcS0KCNHy4tWt6siKUqhAVyFR8sMkkhYZKERE1O0gAAAAAgAOntk+vS7y8vOTn5+dwq+2oFAcAoGYVTopTKQ4AgOuxWKSYGOtS4ZJUILNiFP/39+ckxk1/34+Lk8zmmhskAAAAAKAIpyXFmzVrJrPZrIyMDIftGRkZCgoKKvYxQUFBpcbbvlbkmK4s1/J3pbiZSnEAAGoCa4oDAODakpOtFeKFvatoDddqHVYrxx0hIdLq1VJ0dM0NEAAAAABQLKclxT09PdWrVy8lJSXZtxUUFCgpKUnh4eHFPiY8PNwhXpISExPt8WFhYQoKCnKIyc7O1rZt20o8piujUhwAgJrlYfaQRKU4AACuKi2t+O3vKlptdUADtF4jtUJJ09dLKSkkxAEAAACglnB35pPHxsZqzJgx6t27t/r06aO4uDjl5ORo3LhxkqTRo0erVatWmjdvniQpJiZG/fv31zPPPKPBgwdr5cqV+uqrr/TSSy9Jkkwmk6ZMmaLHH39cHTp0UFhYmB599FG1bNlSQ4cOtT/vwYMHdfz4cR08eFAWi0W7du2SJLVv314NG7rOB9esKQ4AQM2yVYrnWfJ0Kv+UJNYUBwDAlQQHl7yvQGZt1ABJ0r+vkUTHdAAAAACoNZyaFL/55pt17NgxzZgxQ+np6erZs6fWrVunwMBASdbktZvb2WL2fv36acWKFZo+fboefvhhdejQQWvWrFHXrl3tMQ888IBycnI0YcIEZWZm6oorrtC6devk7e1tj5kxY4ZeffVV+/2LL75YkrR+/XoNGDCgml91zaFSHACAmmVLip/IPSFD1sVGaZ8OAIDriIiwdkU/fPjsuuKFmUzW/RERNT82AAAAAEDJTIZR3Ns4lCU7O1v+/v7KysqSn5+fs4dTrMbzGyvzdKZ+nPijLmp2kbOHAwAopC7MI66uOn4G//i/f+izXz/Ts1HPauonUyVJZx49I7MbpWIA4GqYy53PWT+DhARp+HDr94U/UTGZrF9ZRhwA6g7mcwAA6g+nrSmO6kelOAAANctWKZ55OlOS5OPuQ0IcAAAXEx1tTXy3auW4PSSEhDgAAAAA1FZObZ+O6mVbU5ykOAAANePcpHhDz4ZOHA0AAKgu0dHSkCFScrKUlmZdazwiQjJzLRzgciwWi/Lz8509DFSSh4eHzPxyBgAAIinusiwFFlkMiyTJy93LyaMBAKB+sCXFs3KzJEkNPFlPHAAAV2U2SwMGOHsUAKqLYRhKT09XZmams4eC8xQQEKCgoCCZbOtcAACAeomkuIvKLzh7BSuV4gAA1AwqxQEAAADXYEuIt2jRQr6+viRU6yDDMHTq1CkdPXpUkhQcHOzkEQEAAGciKe6ibK3TJcnLTKU4AAA1wcPNQ5KUdfrvSnEPKsUBAACAusZisdgT4k2bNnX2cHAefHx8JElHjx5VixYtaKUOAEA9RlLcReVZ8uzfe5g9nDgSAADqj3MrxWmfDgBAHWexlHvh8AqEAqjlbGuI+/r6OnkkqAq2n2N+fj5JcQAA6jGS4i4q12KtFPdw85Cbyc3JowEAoH44d01x2qcDAFCHJSRIMTHSoUNnt4WESPHxUnR0ZUMB1CG0THcN/BwBAIAkkS11UbZKcdYTBwCg5hSpFKd9OgAAdVNCgjR8uGOWW5IOH7ZuT0ioTCgAAAAAwElIirso25riXu6sJw4AQE2xV4qfplIcAFA7zZo1SyaTyeHWsWNH+/7Tp09r4sSJatq0qRo2bKhhw4YpIyPD4RgHDx7U4MGD5evrqxYtWuj+++/XmTNnHGI2bNigSy65RF5eXmrfvr2WL19eZCyLFy9W27Zt5e3trb59+2r79u3V8porzGKxln0bRtF9tm1TpkgWS0VCAaDeM5lMWrNmjbOHAQAA6imS4i6KSnEAAGqeLSluMayffFMpDgCojbp06aK0tDT77YsvvrDvmzp1qj744AO9/fbb2rhxo44cOaLoQv2/LRaLBg8erLy8PG3evFmvvvqqli9frhkzZthjUlJSNHjwYF111VXatWuXpkyZojvuuEOffPKJPeatt95SbGysZs6cqa+//lo9evRQVFSUjh49WjMnoTTJyUXLvgszDCk1VUpOrkgoANSoLVu2yGw2a/DgwRV6XNu2bRUXF1c9gwIAAHAikuIuyramOElxAABqji0pbkOlOACgNnJ3d1dQUJD91qxZM0lSVlaWXn75ZS1cuFBXX321evXqpVdeeUWbN2/W1q1bJUmffvqp9uzZo9dff109e/bUoEGD9Nhjj2nx4sXKy7NenL106VKFhYXpmWeeUadOnTRp0iQNHz5czz77rH0MCxcu1J133qlx48apc+fOWrp0qXx9fbVs2bISx52bm6vs7GyHW7VISyt3XAVCAdRTFou0YYP05pvWrzXVOeLll1/W5MmTtWnTJh05cqRmnhQAAKAWIynuomyV4l5m2qcDAFBTzk2KN/CkUhwAUPv8/PPPatmypdq1a6dRo0bp4MGDkqSdO3cqPz9fkZGR9tiOHTuqdevW2rJliyRr5WG3bt0UGBhoj4mKilJ2drZ++OEHe0zhY9hibMfIy8vTzp07HWLc3NwUGRlpjynOvHnz5O/vb7+Fhoae55koQXBwueMqEAqgHkpIkNq2la66Srr1VuvXtm2t26vTyZMn9dZbb+nuu+/W4MGDiyxh8cEHH+jSSy+Vt7e3mjVrphtvvFGSNGDAAP3222+aOnWqfYkNybr0Rs+ePR2OERcXp7Zt29rv79ixQ//4xz/UrFkz+fv7q3///vr666+r82UCAABUCElxF2VbU5xKcQAAao6Hm4fDfSrFAQC1Td++fbV8+XKtW7dOS5YsUUpKiiIiInTixAmlp6fL09NTAQEBDo8JDAxUenq6JCk9Pd0hIW7bb9tXWkx2drb++usv/f7777JYLMXG2I5RnGnTpikrK8t+S01NrdQ5KFNEhBQSIv2dDCrCZJJCQ6WIiIqEAqhnEhKk4cOLLrFw+LB1e3UmxletWqWOHTvqoosu0m233aZly5bJMAxJ0ocffqgbb7xR1113nb755hslJSWpT58+f485QSEhIZozZ459iY3yOnHihMaMGaMvvvhCW7duVYcOHXTdddfpxIkT1fIaAQAAKsq97BDURfZKcXcqxQEAqClFKsVZUxwAUMsMGjTI/n337t3Vt29ftWnTRqtWrZKPj48TR1Y2Ly8veXnVwHtcs1mKj7dmrUwm68LgNrbsd1ycZDbLrHKHAqhHLBYpJsbxd4KNYVh/P0yZIg0ZUj2/H15++WXddtttkqSBAwcqKytLGzdu1IABAzR37lzdcsstmj17tj2+R48ekqQmTZrIbDarUaNGCgoKqtBzXn311Q73X3rpJQUEBGjjxo26/vrrz/MVAQAAnD8qxV2ULSlOpTgAADWH9ukAgLomICBAF154ofbv36+goCDl5eUpMzPTISYjI8OeHAkKClJGRkaR/bZ9pcX4+fnJx8dHzZo1k9lsLjamokmYahMdLa1eLbVq5bg9JMS6PTq6MqEA6onk5KIV4oUZhpSaao2ravv27dP27ds1cuRISZK7u7tuvvlmvfzyy5KkXbt26Zprrqny583IyNCdd96pDh06yN/fX35+fjp58qR9iQ4AAABnIynuonIt1vbprCkOAEDNOTcpTvt0AEBtd/LkSf3yyy8KDg5Wr1695OHhoaSkJPv+ffv26eDBgwoPD5ckhYeH6/vvv9fRo0ftMYmJifLz81Pnzp3tMYWPYYuxHcPT01O9evVyiCkoKFBSUpI9plaIjpYOHJDWr5dWrLB+TUkpNstdgVAA9UB5u45XoDt5ub388ss6c+aMWrZsKXd3d7m7u2vJkiV65513lJWVVamuIG5ubvb26zb5+fkO98eMGaNdu3YpPj5emzdv1q5du9S0aVPl5eWd1+sBAACoKrRPd1FUigMAUPNonw4AqO3uu+8+3XDDDWrTpo2OHDmimTNnymw2a+TIkfL399f48eMVGxurJk2ayM/PT5MnT1Z4eLguu+wySdK1116rzp0761//+pcWLFig9PR0TZ8+XRMnTrS3Nr/rrrv0/PPP64EHHtDtt9+uzz//XKtWrdKHH35oH0dsbKzGjBmj3r17q0+fPoqLi1NOTo7GjRvnlPNSIrNZGjCgqkMBuLjg4KqNK68zZ87otdde0zPPPKNrr73WYd/QoUP15ptvqnv37kpKSirx962np6csFovDtubNmys9PV2GYcj099oQu3btcoj58ssv9cILL+i6666TJKWmpur333+volcGAABw/kiKu6jcM39XirOmOAAANYZKcQBAbXfo0CGNHDlSf/zxh5o3b64rrrhCW7duVfPmzSVJzz77rNzc3DRs2DDl5uYqKipKL7zwgv3xZrNZa9eu1d13363w8HA1aNBAY8aM0Zw5c+wxYWFh+vDDDzV16lTFx8crJCRE//vf/xQVFWWPufnmm3Xs2DHNmDFD6enp6tmzp9atW6fAwMCaOxnlYLFY2xunpVmTVxERrA8OoGwREdYlFA4fLn5dcZPJuj8iomqfd+3atfrzzz81fvx4+fv7O+wbNmyYXn75ZT311FO65pprdMEFF+iWW27RmTNn9NFHH+nBBx+UJLVt21abNm3SLbfcIi8vLzVr1kwDBgzQsWPHtGDBAg0fPlzr1q3Txx9/LD8/P/vxO3TooP/7v/9T7969lZ2drfvvv79SVekAAADVhfbpLopKcQAAah5rigMAaruVK1fqyJEjys3N1aFDh7Ry5UpdcMEF9v3e3t5avHixjh8/rpycHCUkJBRZ57tNmzb66KOPdOrUKR07dkxPP/203N0d58ABAwbom2++UW5urn755ReNHTu2yFgmTZqk3377Tbm5udq2bZv69u1bLa+5shISpLZtpauukm691fq1bVvrdgAojdksxcdbv/+7sNrOdj8uruovsnn55ZcVGRlZJCEuWZPiX331lZo0aaK3335b77//vnr27Kmrr75a27dvt8fNmTNHBw4c0AUXXGC/YKpTp0564YUXtHjxYvXo0UPbt2/XfffdV+S5//zzT11yySX617/+pXvvvVctWrSo2hcIAABwHqgUd1G2NcVJigMAUHOoFAcAwDUkJEjDhxet8Dx82Lp99WrWCwdQuuho6++KmBjp0KGz20NCrAnx6vgd8sEHH5S4r0+fPvZ1wbt3767oEgZw2WWX6dtvvy2y/a677tJdd93lsO3hhx+2f3/xxRdrx44dDvuHDx/ucP/cdckBAABqEklxF2WrFPcy0z4dAICa4mH2cLjPmuIAANQ9Fos1iVVc7sYwrFWeU6ZIQ4bQSh1A6aKjrb8rWIYBAADA+UiKuyjbmuJUigMAUHNonw4AQN2XnOxY1Xkuw5BSU61xAwbU2LAA1FFmM78rAAAAagOS4i6KSnEAAGpe4aS4h5sHF6cBtYzFYlF+fr6zh4E6xGw2y93dXaZzF4SFS0tLq9o4AAAAAIDzkRR3UbakOB/GAwBQcwonxakSB2qXkydP6tChQ6xliQrz9fVVcHCwPD15b1VfBAdXbRwAAAAAwPlIiruoXIu1fbqXO5XiAADUlMJJ8YaeDZ04EgCFWSwWHTp0SL6+vmrevDlVvygXwzCUl5enY8eOKSUlRR06dJCbm5uzh4UaEBEhhYRIhw8Xv664yWTdHxFR82MDAAAAAFQOSXEXRaU4AAA1z6FS3INKcaC2yM/Pl2EYat68uXx8fJw9HNQhPj4+8vDw0G+//aa8vDx5e3s7e0ioAWazFB8vDR9uTYCfmxg3DGnYMOua4hER1ngAAAAAQO3GZe4uKvfM35XirCkOAECNoVIcqN2oEEdlUB1eP0VHS6tXS61aOW63JcDj4qSrrpLatpUSEmp6dAAAAACAiuLdvYvKK6BSHABQd82bN0+XXnqpGjVqpBYtWmjo0KHat2+fQ8zp06c1ceJENW3aVA0bNtSwYcOUkZHhpBFbsaY4AACuIzpaOnBAWr9emjLFus1icYw5fNhaUU5iHAAAAABqN5LiLspWKU5SHABQF23cuFETJ07U1q1blZiYqPz8fF177bXKycmxx0ydOlUffPCB3n77bW3cuFFHjhxRdHS0E0dNpTgAAK7GbLa2SF+9uvj9ttbqU6YUTZgDAAAAAGoPkuIuyramuJc77dMBAHXPunXrNHbsWHXp0kU9evTQ8uXLdfDgQe3cuVOSlJWVpZdfflkLFy7U1VdfrV69eumVV17R5s2btXXr1mKPmZubq+zsbIdbVfNw87B/z5riAHB+2rZtq7i4uHLHHzhwQCaTSbt27aq2MaF+Sk6WDh0qeb9hSKmp1jgAqC/Gjh2roUOH2u8PGDBAU2xtNWrQhg0bZDKZlJmZWePPDQAA6haS4i4q10KlOADAdWRlZUmSmjRpIknauXOn8vPzFRkZaY/p2LGjWrdurS1bthR7jHnz5snf399+Cw0NrfJx0j4dQFVLT0/X5MmT1a5dO3l5eSk0NFQ33HCDkpKSnD20Yi1fvlwBAQHOHgZQpdLSzn7vJov6a4Nu0Zvqrw1yk6XYOABwlrFjx8pkMslkMsnT01Pt27fXnDlzdObMmWp93oSEBD322GPliiWRDQAAnMG97BDURfZKcTOV4gCAuq2goEBTpkzR5Zdfrq5du0qyJok8PT2LJF4CAwOVnp5e7HGmTZum2NhY+/3s7OwqT4w7tE/3oH06gPNz4MABXX755QoICNBTTz2lbt26KT8/X5988okmTpyoH3/8sVLHzcvLk6dn0Ytn8/Pz5eHhUcwjgPotONj69UYlKF4xCtXZsvFUhShG8XpX0fY4AHBgsVhbSaSlWX+hRERY12aoRgMHDtQrr7yi3NxcffTRR5o4caI8PDw0bdo0h7iS/iaoDNsFzAAAALUVleIuijXFAQCuYuLEidq9e7dWrlx5Xsfx8vKSn5+fw62qUSkO1DE5OSXfTp8uf+xff5UvtoLuuecemUwmbd++XcOGDdOFF16oLl26KDY21mGpiIMHD2rIkCFq2LCh/Pz8dNNNNykjI8O+f9asWerZs6f+97//KSwsTN7e3pIkk8mkJUuW6J///KcaNGiguXPnSpLee+89XXLJJfL29la7du00e/Zsh+qyzMxM/fvf/1ZgYKC8vb3VtWtXrV27Vhs2bNC4ceOUlZVlr1CbNWtWsa/tl19+0ZAhQxQYGKiGDRvq0ksv1WeffVbq+bCNd9CgQfLx8VG7du20upiFnn/99VddddVV8vX1VY8ePRw6iPzxxx8aOXKkWrVqJV9fX3Xr1k1vvvlm2T8M1GsREdIdTRO0WsPVSo591FvpsFZruO5smqCICCcNEEDtlZAgtW0rXXWVdOut1q9t21q3VyMvLy8FBQWpTZs2uvvuuxUZGan333/f3vJ87ty5atmypS666CJJUmpqqm666SYFBASoSZMmGjJkiA4cOGA/nsViUWxsrAICAtS0aVM98MADMgzD4TnPbZ+em5urBx98UKGhofLy8lL79u318ssv68CBA7rqqqskSY0bN5bJZNLYsWMlWS+InjdvnsLCwuTj46MePXoUmes/+ugjXXjhhfLx8dFVV13lME4AAIDSkBR3UawpDgBwBZMmTdLatWu1fv16hYSE2LcHBQUpLy+vSLu9jIwMBQUF1fAoz3KoFPekUhyo9Ro2LPk2bJhjbIsWJccOGuQY27Zt8XEVcPz4ca1bt04TJ05UgwZFL7KxdcooKCjQkCFDdPz4cW3cuFGJiYn69ddfdfPNNzvE79+/X++8844SEhIc1tyeNWuWbrzxRn3//fe6/fbblZycrNGjRysmJkZ79uzRiy++qOXLl9sT5gUFBRo0aJC+/PJLvf7669qzZ4+efPJJmc1m9evXT3FxcfLz81NaWprS0tJ03333Ffv6Tp48qeuuu05JSUn65ptvNHDgQN1www06ePBgqefl0Ucf1bBhw/Ttt99q1KhRuuWWW7R3716HmEceeUT33Xefdu3apQsvvFAjR460J/VPnz6tXr166cMPP9Tu3bs1YcIE/etf/9L27dtLfV7Ub2ZZFK8YSUaRD1HcZE0KxWmKzIVaqQOAEhKk4cOlQ44X0+jwYev2ak6MF+bj46O8POtnhUlJSdq3b58SExO1du1a5efnKyoqSo0aNVJycrK+/PJLNWzYUAMHDrQ/5plnntHy5cu1bNkyffHFFzp+/LjefffdUp9z9OjRevPNN7Vo0SLt3btXL774oho2bKjQ0FC98847kqR9+/YpLS1N8fHxkqxLXr322mtaunSpfvjhB02dOlW33XabNm7cKMmavI+OjtYNN9ygXbt26Y477tBDDz1UXacNAAC4GNqnuyhbUpxKcQBAXWQYhiZPnqx3331XGzZsUFhYmMP+Xr16ycPDQ0lJSRr2d+Jq3759OnjwoMLDw50xZEnnVIp7UCkOoPL2798vwzDUsWPHUuOSkpL0/fffKyUlxb4kxGuvvaYuXbpox44duvTSSyVZ26O+9tprat68ucPjb731Vo0bN85+//bbb9dDDz2kMWPGSJLatWunxx57TA888IBmzpypzz77TNu3b9fevXt14YUX2mNs/P39ZTKZyrxAqUePHurRo4f9/mOPPaZ3331X77//viZNmlTi40aMGKE77rjD/pjExEQ999xzeuGFF+wx9913nwYPHixJmj17trp06aL9+/erY8eOatWqlUOifvLkyfrkk0+0atUq9enTp9Qxo34otstxcrJ8/zhU4mPcZMj3j1TrAwcMqLnBAqi9LBYpJkY6p5paknWbySRNmSINGVKtrdQNw1BSUpI++eQTTZ48WceOHVODBg30v//9z942/fXXX1dBQYH+97//yWQySZJeeeUVBQQEaMOGDbr22msVFxenadOmKTo6WpK0dOlSffLJJyU+708//aRVq1YpMTFRkZGRkhz/XrC1Wm/RooX9Qr/c3Fw98cQT+uyzz+zv6dq1a6cvvvhCL774ovr3768lS5boggsu0DPPPCNJuuiii/T9999r/vz5VXjWAACAqyIp7qJyLdb26awpDgCoiyZOnKgVK1bovffeU6NGjezrhPv7+8vHx0f+/v4aP368YmNj1aRJE/n5+Wny5MkKDw/XZZdd5rRxUykO1DEnT5a879wPqI8eLTnW7Zza0Spo43luS9KS7N27V6GhofaEuCR17txZAQEB2rt3rz0p3qZNmyIJcUnq3bu3w/1vv/1WX375pb0yXLK2TD19+rROnTqlXbt2KSQkxJ4Qr6yTJ09q1qxZ+vDDD5WWlqYzZ87or7/+KrNS/NwLn8LDwx0q3yWpe/fu9u+D/17k+ejRo+rYsaMsFoueeOIJrVq1SocPH1ZeXp5yc3Pl6+t7Xq8HriEhwZrDKlzUGRIivTM8TeW6ZCItrbqGBqCuSU4uWiFemGFIqdV3Mc3atWvVsGFD5efnq6CgQLfeeqtmzZqliRMnqlu3bg7riH/77bfav3+/GjVq5HCM06dP65dfflFWVpbS0tLUt29f+z53d3f17t27xL9Xdu3aJbPZrP79+5d7zPv379epU6f0j3/8w2F7Xl6eLr74YknWv3sKj0Mq+rcBAABASUiKuygqxQEAddmSJUskWdelK+yVV16xrzf37LPPys3NTcOGDVNubq6ioqIcKgWdgTXFgTqmmLbkNR5bgg4dOshkMunHH38872NJKrYFe3HbT548qdmzZ9srwQrz9vaWj49PlYznvvvuU2Jiop5++mm1b99ePj4+Gj58uL1N6/nw8PCwf2+reCsoKJAkPfXUU4qPj1dcXJy6deumBg0aaMqUKVXyvKjbbF2OTYZF/ZWsYKUpTcH64lCEHowL1vryHOTvizAAoNwXyVTTxTRXXXWVlixZIk9PT7Vs2VLu7oXepxQz9/fq1UtvvPFGkeMUd0FdeVTm74WTf1+s+OGHH6pVq1YO+7y8KPoBAADnj6S4i8o9Y60UJykOAKiLylMh6e3trcWLF2vx4sU1MKLy8TCfTcTQPh3A+WjSpImioqK0ePFi3XvvvUU+wM7MzFRAQIA6deqk1NRUpaam2qvF9+zZo8zMTHXu3LnCz3vJJZdo3759at++fbH7u3fvrkOHDumnn34qtlrc09NTFkvZ6yp/+eWXGjt2rG688UZJ1g/CD5Sjwn7r1q0aPXq0w31b9Vh5fPnllxoyZIhuu+02SdZk+U8//VSpcwXXkZcn3XWXNNRIULxiFKqz1Z2pClGsFuqIOUTBBYdlKu5vFJPJWlIeEVGDowZQq5X3IplqupimQYMGJc7l57rkkkv01ltvqUWLFvLz8ys2Jjg4WNu2bdOVV14pSTpz5ox27typSy65pNj4bt26qaCgQBs3brS3Ty/MVqle+G+Gzp07y8vLSwcPHiyxwrxTp056//33HbZt3bq17BcJAAAgya3sEFQXS4FFGw5s0Jvfv6kNBzYo70ye/X7Sr0lK+jWp2H3liT2ZZ7268ruM72QpKPtDKQAAcP5MMtm/3398P3MwgPOyePFiWSwW9enTR++8845+/vln7d27V4sWLbK3Co2MjFS3bt00atQoff3119q+fbtGjx6t/v37F2mNXh4zZszQa6+9ptmzZ+uHH37Q3r17tXLlSk2fPl2S1L9/f1155ZUaNmyYEhMTlZKSoo8//ljr1q2TJLVt21YnT55UUlKSfv/9d506darY5+nQoYMSEhK0a9cuffvtt7r11lvt1dylefvtt7Vs2TL99NNPmjlzprZv317qGuTFPW9iYqI2b96svXv36t///rcyMjLK/Xi4noQEKbSlRf8+NkfvaJhC5NjuuJUO6y3drP+zjJQMWRPghdnux8VV67rAAOqYiAjrxTLn/s6wMZmk0NBacTHNqFGj1KxZMw0ZMkTJyclKSUnRhg0bdO+99+rQ3y3gY2Ji9OSTT2rNmjX68ccfdc899ygzM7PEY7Zt21ZjxozR7bffrjVr1tiPuWrVKknWZV1MJpPWrl2rY8eO6eTJk2rUqJHuu+8+TZ06Va+++qp++eUXff3113ruuef06quvSpLuuusu/fzzz7r//vu1b98+rVixQsuXL6/uUwQAAFwEleJOkrA3QTHrYnQo++wbbrPJLItR/Ifn5+4rb+zt79+uGRtmKH5gvKI7FW2BCAAAqkbC3gRN+uhsYua+xPsUty2OORhApbVr105ff/215s6dq//85z9KS0tT8+bN1atXL/syEyaTSe+9954mT56sK6+8Um5ubho4cKCee+65Sj1nVFSU1q5dqzlz5mj+/Pny8PBQx44ddccdd9hj3nnnHd13330aOXKkcnJy1L59ez355JOSpH79+umuu+7SzTffrD/++EMzZ87UrFmzijzPwoULdfvtt6tfv35q1qyZHnzwQWVnZ5c5vtmzZ2vlypW65557FBwcrDfffLNCVd7Tp0/Xr7/+qqioKPn6+mrChAkaOnSosrKyyn0MuI6EBOmNYQn6SvcqVIeLjXGToQKZNFIr9WXMKl3xztSii47HxUnFLDkAoB4zm6X4+L/XZTBZ1xC3qWUX0/j6+mrTpk168MEHFR0drRMnTqhVq1a65ppr7JXjtr9DxowZIzc3N91+++268cYbS50/lyxZoocfflj33HOP/vjjD7Vu3VoPP/ywJKlVq1aaPXu2HnroIY0bN06jR4/W8uXL9dhjj6l58+aaN2+efv31VwUEBOiSSy6xP65169Z65513NHXqVD333HPq06ePnnjiCd1+++3Vf6IAAECdZzLK05+0mi1evFhPPfWU0tPT1aNHD/sfNSV5++239eijj+rAgQPq0KGD5s+fr+uuu86+3zAMzZw5U//973+VmZmpyy+/XEuWLFGHDh3sMcePH9fkyZP1wQcf2NcjjY+PV8OGDcs15uzsbPn7+ysrK6vE1kIlSdiboOGrhstQzZx6W9Xa6ptW86E8ANQS5zOPoGpU5c+gpLmdORioHU6fPq2UlBSFhYXJ29vb2cNBJZlMJr377rsaOnRojT5vSf9+mMurTkU/E7A5n5+BxSLdFZigF/8YLskoVxu9Xc+uV8/JEVJysnUd4OBga5VnLUhqAahaVfa3Q0KCFBPjeDFNaCgX09Sw0n6ezOcAANQfTq8Uf+uttxQbG6ulS5eqb9++iouLU1RUlPbt26cWLVoUid+8ebNGjhypefPm6frrr9eKFSs0dOhQff311+rataskacGCBVq0aJFeffVVhYWF6dFHH1VUVJT27Nlj/8Nn1KhRSktLU2JiovLz8zVu3DhNmDBBK1asqNgLyMkp/g2w2SwV/iMrJ0eStWX6Q+9Nlk/e2Q/NC0zS6bNLkMo3r+SnOzfWJ08qoRGTDEl/eUqGDJlk0kPv36shIZEyuxUzXpNJ8vU9e/+vv6TS2hcWXtOwIrGnT1s/faiKWF/fs1fX5uZKZ85UTayPj+T290cieXlSfn7VxHp7n/23UpHY/HxrfEm8vCR394rHnjljPRcl8fSUPDwqHmuxWH92JfHwsMZXNLagwPpvrSpi3d2t50KyXq1dQlvPCseW8P/+vGPd3Kz/1ioTe+qU4xXphZ37/74isfyOsH5/Pr8jSvs5ok6xFFgUsy6m2IvdbHPwlHVTNOSiIcXPwQAA1GMV/UygqiRvsGjGHzEqb0Jckro3T7P+HT9gQLWNC4CLiY6WhgzhYhoAAIDawHCyPn36GBMnTrTft1gsRsuWLY158+YVG3/TTTcZgwcPdtjWt29f49///rdhGIZRUFBgBAUFGU899ZR9f2ZmpuHl5WW8+eabhmEYxp49ewxJxo4dO+wxH3/8sWEymYzDhw8X+7ynT582srKy7LfU1FRDkpFlTSEVvV13neMBfH2Lj5OM9W1kaNbZ21HfEo4pGdtbOsam+Jccu7u5Y+zu5iXHGm3aOI63d++SY5s1c4zt37/kWF9fx9jrris59tx/jsOHlx578uTZ2DFjSo89evRs7D33lB6bknI29r77So/dvfts7MyZpcdu3342dsGC0mPXrz8b+/zzpceuXXs29pVXSo9dteps7KpVpce+8srZ2LVrS499/vmzsevXlx67YMHZ2O3bS4+dOfNs7O7dpcfed9/Z2JSU0mPvueds7NGjpceOGXM29uTJ0mOHDzcclBZbgd8RRv/+jrHNmpUc27u3Y2ybNiXHdu7sGNu5c8mx/I44e6ui3xFZkiHJyMrKMuAcWVlZVfIzWJ+y3mG+Lem2PmV91QwcQIX99ddfxp49e4y//vrL2UPBeZBkvPvuuzX+vCX9+6mqeaS+q8hnAiW+L6/Ez+Cz6etL/zuuuFvh92kAXBp/O7iW0n6ezOcAANQf5b0gulrk5eVp586dioyMtG9zc3NTZGSktmzZUuxjtmzZ4hAvWde9s8WnpKQoPT3dIcbf3199+/a1x2zZskUBAQHq3bu3PSYyMlJubm7atm1bsc87b948+fv722+hoaGVe9EAAMClpJ1Iq9I4AEDxDMOo8dbpqF4V/UygKt+XB6v887Ihk7XdcUREpZ8PAAAAAOBcTl1T/MiRI2rVqpU2b96s8PBw+/YHHnhAGzduLDZB7enpqVdffVUjR460b3vhhRc0e/ZsZWRkaPPmzbr88st15MgRBQcH22NuuukmmUwmvfXWW3riiSf06quvat++fQ7HbtGihWbPnq277767yPPm5uYqt1D76OzsbIWGhirryJHi15spoTXypt82adAb1zmEVnf79MKx60Z9pCvbXFk0mNbIZ9E+3Yr26RWPpX36WfyOKDM2Oztb/i1bsm6ZE1XV2nEbDmzQVa9eVWbc+jHrNaDtgEo/D4DKY01xnA/WFK8+Ff1MoMT35ZVZUzxpg8yRZc/fhqzr2Wv1atb/BeoR/nZwLawpDgAApFqwpnhd4eXlJS9bYqywBg0ckzQl+Tvm8o7XqkmzEB3OPlzs2qOSdMqz2M3F+qucsSaZ1KxZiC7veK1UnvVMCyfVqjK2Im8kKhLr5XU2cVmVsZ6eZxOtzor18DibcK7KWHf3swnyqow1m8v3f6KisW5u1RNrMlVPrFQ7Ygsnsqsylt8RVufz/760hD7qlIjWEQrxK3luN8mkEL8QRbSmugxwNideD4w6jH83tUeJ78srwTwgQqeahsj7j8NyK+G9uSSZQkKk+HgS4kA9xRzgGvg5AgAASXJq+/RmzZrJbDYrIyPDYXtGRoaCgoKKfUxQUFCp8bavZcUcPXrUYf+ZM2d0/PjxEp+3qpjdzIofGC/J+iF5TbA9T9zAOJnLkxAHAADlVtrczhwM1A7mvzvw5JXWUQcowam/OwV5lPfiU5RbZT4TqDJms3xfipdJUsE583eBrBXimj1bOnCAhDhQD9l+558qrVsc6gzmcgAAIDm5UtzT01O9evVSUlKSfW24goICJSUladKkScU+Jjw8XElJSZoyZYp9W2Jior3VWlhYmIKCgpSUlKSePXtKsrbB2bZtm70tenh4uDIzM7Vz50716tVLkvT555+roKBAffv2rZ4XW0h0p2itvmm1YtbF6FD2Ift2s8ksi1F85eC5+yoSG+IXoriBcYruxBt5AACqQ0lzO3MwUDu4u7vL19dXx44dk4eHh9zcnHptMOoIwzB06tQpHT16VAEBAfaLK1B1KvOZQJWKjpbpndVSTIx06Oz8bQoJlSk+jmQ4UI+ZzWYFBATYi2p8fX2tSymgTmEuBwAAhTm9fXpsbKzGjBmj3r17q0+fPoqLi1NOTo7GjRsnSRo9erRatWqlefPmSZJiYmLUv39/PfPMMxo8eLBWrlypr776Si+99JIk61pfU6ZM0eOPP64OHTooLCxMjz76qFq2bGl/k92pUycNHDhQd955p5YuXar8/HxNmjRJt9xyi1q2bFkjrzu6U7SGXDREyQeTlXYiTcGNgtUvpJ82H9qstBNpatGghSTpaM7RIvsqGhvROoLqNAAAqllxcztzMFA7mEwmBQcHKyUlRb/99puzh4M6JiAgoPqrluuxsj4TqHbR0TINGSIlJ0tpaVJwsEwREdalngDUa7bf/ed2m0Tdw1wOAACkWpAUv/nmm3Xs2DHNmDFD6enp6tmzp9atW6fAwEBJ0sGDBx0qOfr166cVK1Zo+vTpevjhh9WhQwetWbNGXbt2tcc88MADysnJ0YQJE5SZmakrrrhC69atk3eh9WffeOMNTZo0Sddcc43c3Nw0bNgwLVq0qOZeuKztVge0HeCw7dz7pe2rSCwAAKh+xc3tAGoHT09PdejQgRbqqBAPDw+qyqpZWZ8J1AizWRowoOaeD0CdYLuorkWLFsrPz3f2cFBJzOUAAMDGZBiG4exB1EXZ2dny9/dXVlaW/Pz8nD0cAEAdwzzifPwMAADng3nE+fgZAADOF3MJAAD1B4vpAQAAAAAAAAAAAABcFklxAAAAAAAAAAAAAIDLIikOAAAAAAAAAAAAAHBZ7s4eQF1lW4o9OzvbySMBANRFtvnDNp+g5jGXAwDOB3O58zGXAwDOF/M5AAD1B0nxSjpx4oQkKTQ01MkjAQDUZSdOnJC/v7+zh1EvMZcDAKoCc7nzMJcDAKoK8zkAAK7PZHAZXKUUFBToyJEjatSokUwmU6WPk52drdDQUKWmpsrPz68KR+g6OEdl4xyVD+epbJyjslXVOTIMQydOnFDLli3l5sZqJs7AXF6zOE9l4xyVjXNUNs5R2ZjLXUdVzeUS/3fKi/NUNs5R+XCeyofzVD7nc56YzwEAqD+oFK8kNzc3hYSEVNnx/Pz8+OO2DJyjsnGOyofzVDbOUdmq4hxxFbpzMZc7B+epbJyjsnGOysY5Khtzed1X1XO5xP+d8uI8lY1zVD6cp/LhPJVPZc8T8zkAAPUDl78BAAAAAAAAAAAAAFwWSXEAAAAAAAAAAAAAgMsiKe5kXl5emjlzpry8vJw9lFqLc1Q2zlH5cJ7KxjkqG+cI5+LfRPlwnsrGOSob56hsnKOycY5QHP5dlA/nqWyco/LhPJUP56l8OE8AAKA8TIZhGM4eBAAAAAAAAAAAAAAA1YFKcQAAAAAAAAAAAACAyyIpDgAAAAAAAAAAAABwWSTFAQAAAAAAAAAAAAAui6Q4AAAAAAAAAAAAAMBlkRR3ssWLF6tt27by9vZW3759tX37dmcPySnmzZunSy+9VI0aNVKLFi00dOhQ7du3zyHm9OnTmjhxopo2baqGDRtq2LBhysjIcNKIne/JJ5+UyWTSlClT7Ns4R1aHDx/WbbfdpqZNm8rHx0fdunXTV199Zd9vGIZmzJih4OBg+fj4KDIyUj///LMTR1yzLBaLHn30UYWFhcnHx0cXXHCBHnvsMRmGYY+pb+do06ZNuuGGG9SyZUuZTCatWbPGYX95zsfx48c1atQo+fn5KSAgQOPHj9fJkydr8FXAWZjLz2I+rzjm8+Ixl5eOubx4zOeoLOZyR8znFcd8Xjrm9dIxr5eMuR0AAFQlkuJO9NZbbyk2NlYzZ87U119/rR49eigqKkpHjx519tBq3MaNGzVx4kRt3bpViYmJys/P17XXXqucnBx7zNSpU/XBBx/o7bff1saNG3XkyBFFR0c7cdTOs2PHDr344ovq3r27w3bOkfTnn3/q8ssvl4eHhz7++GPt2bNHzzzzjBo3bmyPWbBggRYtWqSlS5dq27ZtatCggaKionT69GknjrzmzJ8/X0uWLNHzzz+vvXv3av78+VqwYIGee+45e0x9O0c5OTnq0aOHFi9eXOz+8pyPUaNG6YcfflBiYqLWrl2rTZs2acKECTX1EuAkzOWOmM8rhvm8eMzlZWMuLx7zOSqDubwo5vOKYT4vHfN62ZjXS8bcDgAAqpQBp+nTp48xceJE+32LxWK0bNnSmDdvnhNHVTscPXrUkGRs3LjRMAzDyMzMNDw8PIy3337bHrN3715DkrFlyxZnDdMpTpw4YXTo0MFITEw0+vfvb8TExBiGwTmyefDBB40rrriixP0FBQVGUFCQ8dRTT9m3ZWZmGl5eXsabb75ZE0N0usGDBxu33367w7bo6Ghj1KhRhmFwjiQZ7777rv1+ec7Hnj17DEnGjh077DEff/yxYTKZjMOHD9fY2FHzmMtLx3xeMubzkjGXl425vGzM5ygv5vKyMZ+XjPm8bMzrZWNeLx/mdgAAcL6oFHeSvLw87dy5U5GRkfZtbm5uioyM1JYtW5w4stohKytLktSkSRNJ0s6dO5Wfn+9wvjp27KjWrVvXu/M1ceJEDR482OFcSJwjm/fff1+9e/fWiBEj1KJFC1188cX673//a9+fkpKi9PR0h/Pk7++vvn371pvz1K9fPyUlJemnn36SJH377bf64osvNGjQIEmco3OV53xs2bJFAQEB6t27tz0mMjJSbm5u2rZtW42PGTWDubxszOclYz4vGXN52ZjLK475HMVhLi8f5vOSMZ+XjXm9bMzrlcPcDgAAKsrd2QOor37//XdZLBYFBgY6bA8MDNSPP/7opFHVDgUFBZoyZYouv/xyde3aVZKUnp4uT09PBQQEOMQGBgYqPT3dCaN0jpUrV+rrr7/Wjh07iuzjHFn9+uuvWrJkiWJjY/Xwww9rx44duvfee+Xp6akxY8bYz0Vx//fqy3l66KGHlJ2drY4dO8psNstisWju3LkaNWqUJHGOzlGe85Genq4WLVo47Hd3d1eTJk3q5TmrL5jLS8d8XjLm89Ixl5eNubzimM9RHObysjGfl4z5vHyY18vGvF45zO0AAKCiSIqj1pk4caJ2796tL774wtlDqVVSU1MVExOjxMREeXt7O3s4tVZBQYF69+6tJ554QpJ08cUXa/fu3Vq6dKnGjBnj5NHVDqtWrdIbb7yhFStWqEuXLtq1a5emTJmili1bco4AVBnm8+Ixn5eNubxszOUAagrzefGYz8uPeb1szOsAAAA1g/bpTtKsWTOZzWZlZGQ4bM/IyFBQUJCTRuV8kyZN0tq1a7V+/XqFhITYtwcFBSkvL0+ZmZkO8fXpfO3cuVNHjx7VJZdcInd3d7m7u2vjxo1atGiR3N3dFRgYWO/PkSQFBwerc+fODts6deqkgwcPSpL9XNTn/3v333+/HnroId1yyy3q1q2b/vWvf2nq1KmaN2+eJM7RucpzPoKCgnT06FGH/WfOnNHx48fr5TmrL5jLS8Z8XjLm87Ixl5eNubzimM9RHOby0jGfl4z5vPyY18vGvF45zO0AAKCiSIo7iaenp3r16qWkpCT7toKCAiUlJSk8PNyJI3MOwzA0adIkvfvuu/r8888VFhbmsL9Xr17y8PBwOF/79u3TwYMH6835uuaaa/T9999r165d9lvv3r01atQo+/f1/RxJ0uWXX659+/Y5bPvpp5/Upk0bSVJYWJiCgoIczlN2dra2bdtWb87TqVOn5Obm+OvfbDaroKBAEufoXOU5H+Hh4crMzNTOnTvtMZ9//rkKCgrUt2/fGh8zagZzeVHM52VjPi8bc3nZmMsrjvkcxWEuLx7zedmYz8uPeb1szOuVw9wOAAAqzIDTrFy50vDy8jKWL19u7Nmzx5gwYYIREBBgpKenO3toNe7uu+82/P39jQ0bNhhpaWn226lTp+wxd911l9G6dWvj888/N7766isjPDzcCA8Pd+Kona9///5GTEyM/T7nyDC2b99uuLu7G3PnzjV+/vln44033jB8fX2N119/3R7z5JNPGgEBAcZ7771nfPfdd8aQIUOMsLAw46+//nLiyGvOmDFjjFatWhlr1641UlJSjISEBKNZs2bGAw88YI+pb+foxIkTxjfffGN88803hiRj4cKFxjfffGP89ttvhmGU73wMHDjQuPjii41t27YZX3zxhdGhQwdj5MiRznpJqCHM5Y6YzyuH+dwRc3nZmMuLx3yOymAuL4r5vHKYz4vHvF425vWSMbcDAICqRFLcyZ577jmjdevWhqenp9GnTx9j69atzh6SU0gq9vbKK6/YY/766y/jnnvuMRo3bmz4+voaN954o5GWlua8QdcC577p5hxZffDBB0bXrl0NLy8vo2PHjsZLL73ksL+goMB49NFHjcDAQMPLy8u45pprjH379jlptDUvOzvbiImJMVq3bm14e3sb7dq1Mx555BEjNzfXHlPfztH69euL/R00ZswYwzDKdz7++OMPY+TIkUbDhg0NPz8/Y9y4ccaJEyec8GpQ05jLz2I+rxzm86KYy0vHXF485nNUFnO5I+bzymE+LxnzeumY10vG3A4AAKqSyTAMo3pr0QEAAAAAAAAAAAAAcA7WFAcAAAAAAAAAAAAAuCyS4gAAAAAAAAAAAAAAl0VSHAAAAAAAAAAAAADgskiKAwAAAAAAAAAAAABcFklxAAAAAAAAAAAAAIDLIikOAAAAAAAAAAAAAHBZJMUBAAAAAAAAAAAAAC6LpDgAAAAAAAAAAAAAwGWRFAcAAAAAAABckMlk0po1a5w9DAAAAMDpSIoDAAAAAAAAtczYsWM1dOhQZw8DAAAAcAkkxQEAAAAAAAAAAAAALoukOAAAAAAAAFCLDRgwQPfee68eeOABNWnSREFBQZo1a5ZDzM8//6wrr7xS3t7e6ty5sxITE4scJzU1VTfddJMCAgLUpEkTDRkyRAcOHJAk/fjjj/L19dWKFSvs8atWrZKPj4/27NlTnS8PAAAAqHYkxQEAAAAAAIBa7tVXX1WDBg20bds2LViwQHPmzLEnvgsKChQdHS1PT09t27ZNS5cu1YMPPujw+Pz8fEVFRalRo0ZKTk7Wl19+qYYNG2rgwIHKy8tTx44d9fTTT+uee+7RwYMHdejQId11112aP3++Onfu7IyXDAAAAFQZk2EYhrMHAQAAAAAAAOCssWPHKjMzU2vWrNGAAQNksViUnJxs39+nTx9dffXVevLJJ/Xpp59q8ODB+u2339SyZUtJ0rp16zRo0CC9++67Gjp0qF5//XU9/vjj2rt3r0wmkyQpLy9PAQEBWrNmja699lpJ0vXXX6/s7Gx5enrKbDZr3bp19ngAAACgrnJ39gAAAAAAAAAAlK579+4O94ODg3X06FFJ0t69exUaGmpPiEtSeHi4Q/y3336r/fv3q1GjRg7bT58+rV9++cV+f9myZbrwwgvl5uamH374gYQ4AAAAXAJJcQAAAAAAAKCW8/DwcLhvMplUUFBQ7sefPHlSvXr10htvvFFkX/Pmze3ff/vtt8rJyZGbm5vS0tIUHBxc+UEDAAAAtQRJcQAAAAAAAKAO69Spk1JTUx2S2Fu3bnWIueSSS/TWW2+pRYsW8vPzK/Y4x48f19ixY/XII48oLS1No0aN0tdffy0fH59qfw0AAABAdXJz9gAAAAAAAAAAVF5kZKQuvPBCjRkzRt9++62Sk5P1yCOPOMSMGjVKzZo105AhQ5ScnKyUlBRt2LBB9957rw4dOiRJuuuuuxQaGqrp06dr4cKFslgsuu+++5zxkgAAAIAqRVIcAAAAAAAAqMPc3Nz07rvv6q+//lKfPn10xx13aO7cuQ4xvr6+2rRpk1q3bq3o6Gh16tRJ48eP1+nTp+Xn56fXXntNH330kf7v//5P7u7uatCggV5//XX997//1ccff+ykVwYAAABUDZNhGIazBwEAAAAAAAAAAAAAQHWgUhwAAAAAAAAAAAAA4LJIigMAAAAAAAAAAAAAXBZJcQAAAAAAAAAAAACAyyIpDgAAAAAAAAAAAABwWSTFAQAAAAAAAAAAAAAui6Q4AAAAAAAAAAAAAMBlkRQHAAAAAAAAAAAAALgskuIAAAAAAAAAAAAAAJdFUhwAAAAAAAAAAAAA4LJIigMAAAAAAAAAAAAAXBZJcQAAAAAAAAAAAACAy/p/R3qPybjDPmMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=100\n",
    "p=0.4\n",
    "la=0.05\n",
    "# This is where the sigma is defined. Note that the scope of this definition extends to gvamp\n",
    "sigma=1\n",
    "omega=1\n",
    "h2=0.9\n",
    "gam1 = 1e-2\n",
    "tau1 = 1e-1\n",
    "mu=np.full((n,1), 0) \n",
    "maxiter = 100\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, True, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23fd1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weibull\n",
      "gam1 =  0.01\n",
      "tau1 =  0.1\n",
      "alpha =  21.3610066663135\n",
      "s.shape =  (800,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.]\n",
      "B / (A+B) =  [0.04976421]\n",
      "gam1 / (gam1 + 1/sigma) =  0.009900990099009901\n",
      "alpha1 part I =  [0.00049271]\n",
      "alpha2 part II =  [0.]\n",
      "alpha1 =  0.0004927149309449356\n",
      "true gam2 =  16.495735851994617\n",
      "gam2 =  20.28571131693099\n",
      "corr(z1_hat, X*beta_true) =  0.032437375494478796\n",
      "l2 error for z1_hat =  0.9994786709641467\n",
      "v1 =  0.642190379494197\n",
      "true tau2 =  26.01344837018179\n",
      "tau2 = 0.055717063339943154\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[-0.06388917]]\n",
      "l2 error for x2_hat =  1.0000468474923223\n",
      "alpha2 =  0.9979581889231127\n",
      "true gam1 =  14.712490678934254\n",
      "gam1 =  0.04150433407850765\n",
      "corr(z2_hat, beta_true) =  [[0.9255022]]\n",
      "l2 error for z2_hat =  0.9929889721125841\n",
      "true tau1 =  30.819569569750513\n",
      "tau1 =  27.23234301755808\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00013211]\n",
      "corr(x1_hat, beta_true) =  -0.06389025933547711\n",
      "l2 error for x1_hat =  1.0000448318393242\n",
      "B / (A+B) =  [0.04904299]\n",
      "gam1 / (gam1 + 1/sigma) =  0.039850370968671445\n",
      "alpha1 part I =  [0.00195438]\n",
      "alpha2 part II =  [1.31866464e-09]\n",
      "alpha1 =  0.0019544163747322076\n",
      "true gam2 =  16.495735856081993\n",
      "gam2 =  21.194673695894522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanders/vampW/tteVAMP/em.py:31: RuntimeWarning: overflow encountered in exp\n",
      "  out = n / alpha + np.sum(res) - np.exp(-emc) * np.sum( np.exp(alpha * res + (alpha**2)/2/xi) * (res + alpha/xi) )\n",
      "/Users/alexanders/vampW/tteVAMP/em.py:37: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  alpha_new = scipy.optimize.fsolve(update_Weibull_alpha_eq, x0 = alpha_old, args=(y, mu, z_hat, xi))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr(z1_hat, X*beta_true) =  0.9934623836293804\n",
      "l2 error for z1_hat =  0.12155999329776622\n",
      "v1 =  0.15095392135790509\n",
      "true tau2 =  279.4037271263297\n",
      "tau2 = 153.16935024479443\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.85432185]]\n",
      "l2 error for x2_hat =  0.528875657421918\n",
      "alpha2 =  0.41178848104208504\n",
      "true gam1 =  36.34989206753095\n",
      "gam1 =  30.275133429983804\n",
      "corr(z2_hat, beta_true) =  [[0.99282061]]\n",
      "l2 error for z2_hat =  0.15876654045839275\n",
      "true tau1 =  112.42836726765331\n",
      "tau1 =  107.22906989521192\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00204916]\n",
      "corr(x1_hat, beta_true) =  0.9763459070781174\n",
      "l2 error for x1_hat =  0.23033698279243225\n",
      "B / (A+B) =  [0.01016108]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9680257159497427\n",
      "alpha1 part I =  [0.00983618]\n",
      "alpha2 part II =  [0.00169163]\n",
      "alpha1 =  0.10485072723367689\n",
      "true gam2 =  275.2631966914324\n",
      "gam2 =  258.46996380249175\n",
      "corr(z1_hat, X*beta_true) =  0.9937372934312128\n",
      "l2 error for z1_hat =  0.13124445735094364\n",
      "v1 =  0.37066081736805884\n",
      "true tau2 =  301.6807617089731\n",
      "tau2 = 182.06255433583158\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97930988]]\n",
      "l2 error for x2_hat =  0.21144723201405013\n",
      "alpha2 =  0.7886171529156321\n",
      "true gam1 =  100.12214263344295\n",
      "gam1 =  69.2809135996682\n",
      "corr(z2_hat, beta_true) =  [[0.99818167]]\n",
      "l2 error for z2_hat =  0.08553281503033054\n",
      "true tau1 =  804.1950026263358\n",
      "tau1 =  679.2303880530374\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00170844]\n",
      "corr(x1_hat, beta_true) =  0.9895500116527345\n",
      "l2 error for x1_hat =  0.14422569492148854\n",
      "B / (A+B) =  [0.00829519]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9857713858744613\n",
      "alpha1 part I =  [0.00817716]\n",
      "alpha2 part II =  [0.00465377]\n",
      "alpha1 =  0.09028421149405558\n",
      "true gam2 =  692.8897066299025\n",
      "gam2 =  698.0837502012637\n",
      "corr(z1_hat, X*beta_true) =  0.9981511912004849\n",
      "l2 error for z1_hat =  0.08658058364860884\n",
      "v1 =  0.8422793165005475\n",
      "true tau2 =  359.66578032554276\n",
      "tau2 = 127.18902026754652\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98960512]]\n",
      "l2 error for x2_hat =  0.14382658324710137\n",
      "alpha2 =  0.9241182993373832\n",
      "true gam1 =  135.39130144015303\n",
      "gam1 =  57.321429743563556\n",
      "corr(z2_hat, beta_true) =  [[0.99864104]]\n",
      "l2 error for z2_hat =  0.07781478914214812\n",
      "true tau1 =  1666.9336831801575\n",
      "tau1 =  1548.959763390466\n",
      "\n",
      "\n",
      "**** iteration =  4  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00114068]\n",
      "corr(x1_hat, beta_true) =  0.9887890400452237\n",
      "l2 error for x1_hat =  0.1497703368955842\n",
      "B / (A+B) =  [0.00913654]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9828536439453396\n",
      "alpha1 part I =  [0.00897988]\n",
      "alpha2 part II =  [0.00518084]\n",
      "alpha1 =  0.07708498192778286\n",
      "true gam2 =  641.2640671555594\n",
      "gam2 =  686.2920253035583\n",
      "corr(z1_hat, X*beta_true) =  0.9987026530145581\n",
      "l2 error for z1_hat =  0.07569622229188422\n",
      "v1 =  0.8878280652293594\n",
      "true tau2 =  406.92813942649855\n",
      "tau2 = 195.70209632480598\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98910668]]\n",
      "l2 error for x2_hat =  0.1476511304322337\n",
      "alpha2 =  0.8903219353555315\n",
      "true gam1 =  153.0905915090115\n",
      "gam1 =  84.54377919619479\n",
      "corr(z2_hat, beta_true) =  [[0.99887604]]\n",
      "l2 error for z2_hat =  0.06400000923362036\n",
      "true tau1 =  1693.5989542434818\n",
      "tau1 =  1588.6300484772771\n",
      "\n",
      "\n",
      "**** iteration =  5  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00119258]\n",
      "corr(x1_hat, beta_true) =  0.9907112460466452\n",
      "l2 error for x1_hat =  0.1366607372327101\n",
      "B / (A+B) =  [0.00854076]\n",
      "gam1 / (gam1 + 1/sigma) =  0.988310079243676\n",
      "alpha1 part I =  [0.00844092]\n",
      "alpha2 part II =  [0.00693986]\n",
      "alpha1 =  0.08154439200248743\n",
      "true gam2 =  784.5558139721204\n",
      "gam2 =  952.2384828337418\n",
      "corr(z1_hat, X*beta_true) =  0.9988973740364043\n",
      "l2 error for z1_hat =  0.062899637111335\n",
      "v1 =  0.8761459890218378\n",
      "true tau2 =  402.37127307595443\n",
      "tau2 = 224.57239538813755\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99081479]]\n",
      "l2 error for x2_hat =  0.13591270057638924\n",
      "alpha2 =  0.905910562771025\n",
      "true gam1 =  156.7436055940863\n",
      "gam1 =  98.90113510051393\n",
      "corr(z2_hat, beta_true) =  [[0.9990881]]\n",
      "l2 error for z2_hat =  0.054534286540441214\n",
      "true tau1 =  2101.904706778614\n",
      "tau1 =  2162.2246989724194\n",
      "\n",
      "\n",
      "**** iteration =  6  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00084418]\n",
      "corr(x1_hat, beta_true) =  0.9917176215105817\n",
      "l2 error for x1_hat =  0.12929810117887103\n",
      "B / (A+B) =  [0.00677081]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9899901037261102\n",
      "alpha1 part I =  [0.00670304]\n",
      "alpha2 part II =  [0.00343787]\n",
      "alpha1 =  0.08153607651685502\n",
      "true gam2 =  881.0659881464175\n",
      "gam2 =  1114.07279405426\n",
      "corr(z1_hat, X*beta_true) =  0.9991002331233514\n",
      "l2 error for z1_hat =  0.053803734213885845\n",
      "v1 =  0.8920178425903935\n",
      "true tau2 =  419.3736966482939\n",
      "tau2 = 261.74553540471214\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99180794]]\n",
      "l2 error for x2_hat =  0.12857438006330132\n",
      "alpha2 =  0.9062020605594111\n",
      "true gam1 =  164.8364974715502\n",
      "gam1 =  115.31394268139408\n",
      "corr(z2_hat, beta_true) =  [[0.99919541]]\n",
      "l2 error for z2_hat =  0.04819532887494442\n",
      "true tau1 =  2335.597904223226\n",
      "tau1 =  2528.7798958122535\n",
      "\n",
      "\n",
      "**** iteration =  7  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00089818]\n",
      "corr(x1_hat, beta_true) =  0.9926532571845049\n",
      "l2 error for x1_hat =  0.12167195570690897\n",
      "B / (A+B) =  [0.00597042]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9914025784274273\n",
      "alpha1 part I =  [0.00591909]\n",
      "alpha2 part II =  [0.00244335]\n",
      "alpha1 =  0.08326297238199237\n",
      "true gam2 =  998.3525478348078\n",
      "gam2 =  1269.622715024733\n",
      "corr(z1_hat, X*beta_true) =  0.9991907703859155\n",
      "l2 error for z1_hat =  0.048997851134883114\n",
      "v1 =  0.9099674926066501\n",
      "true tau2 =  408.7506349732833\n",
      "tau2 = 250.19838237703595\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99266601]]\n",
      "l2 error for x2_hat =  0.12156709652141581\n",
      "alpha2 =  0.9189302456351419\n",
      "true gam1 =  164.53291668655143\n",
      "gam1 =  112.0085035093801\n",
      "corr(z2_hat, beta_true) =  [[0.99920392]]\n",
      "l2 error for z2_hat =  0.056864579903827865\n",
      "true tau1 =  2586.953588651818\n",
      "tau1 =  2836.0127988115346\n",
      "\n",
      "\n",
      "**** iteration =  8  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00090247]\n",
      "corr(x1_hat, beta_true) =  0.992907879205485\n",
      "l2 error for x1_hat =  0.11957145325608078\n",
      "B / (A+B) =  [0.00603253]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9911511083772825\n",
      "alpha1 part I =  [0.00597915]\n",
      "alpha2 part II =  [0.00242041]\n",
      "alpha1 =  0.0833282187192275\n",
      "true gam2 =  1030.4551021918717\n",
      "gam2 =  1232.1760384258093\n",
      "corr(z1_hat, X*beta_true) =  0.9992209236907379\n",
      "l2 error for z1_hat =  0.0562340803655217\n",
      "v1 =  0.8920380876653757\n",
      "true tau2 =  399.5946749825\n",
      "tau2 = 343.2379955507226\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99301681]]\n",
      "l2 error for x2_hat =  0.1186895273123794\n",
      "alpha2 =  0.892347712722331\n",
      "true gam1 =  160.92510884286648\n",
      "gam1 =  148.64897054602582\n",
      "corr(z2_hat, beta_true) =  [[0.99926621]]\n",
      "l2 error for z2_hat =  0.05259289324373764\n",
      "true tau1 =  2710.044485752083\n",
      "tau1 =  2845.1568284756754\n",
      "\n",
      "\n",
      "**** iteration =  9  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00105048]\n",
      "corr(x1_hat, beta_true) =  0.9942171494712928\n",
      "l2 error for x1_hat =  0.10851124711436608\n",
      "B / (A+B) =  [0.00535534]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9933176954284999\n",
      "alpha1 part I =  [0.00531955]\n",
      "alpha2 part II =  [0.0023735]\n",
      "alpha1 =  0.09482042847106857\n",
      "true gam2 =  1253.556749155258\n",
      "gam2 =  1419.0403232371311\n",
      "corr(z1_hat, X*beta_true) =  0.9992580361353871\n",
      "l2 error for z1_hat =  0.053438565858340364\n",
      "v1 =  0.9030617683254811\n",
      "true tau2 =  390.33269204328656\n",
      "tau2 = 305.410417606904\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99423255]]\n",
      "l2 error for x2_hat =  0.10838034224975793\n",
      "alpha2 =  0.9127435933655691\n",
      "true gam1 =  161.24297731987144\n",
      "gam1 =  135.65733068415113\n",
      "corr(z2_hat, beta_true) =  [[0.99930376]]\n",
      "l2 error for z2_hat =  0.05972599294149182\n",
      "true tau1 =  3105.8924358073104\n",
      "tau1 =  3194.7385042533588\n",
      "\n",
      "\n",
      "**** iteration =  10  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00086537]\n",
      "corr(x1_hat, beta_true) =  0.9944889551143066\n",
      "l2 error for x1_hat =  0.106096305143282\n",
      "B / (A+B) =  [0.00541447]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9926824269507265\n",
      "alpha1 part I =  [0.00537485]\n",
      "alpha2 part II =  [0.0020306]\n",
      "alpha1 =  0.09290803863997706\n",
      "true gam2 =  1303.6736150987078\n",
      "gam2 =  1324.467462282683\n",
      "corr(z1_hat, X*beta_true) =  0.9993085028989868\n",
      "l2 error for z1_hat =  0.059448989948667555\n",
      "v1 =  0.8976462780745099\n",
      "true tau2 =  384.3556382227942\n",
      "tau2 = 364.27865237788245\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99450151]]\n",
      "l2 error for x2_hat =  0.10598584701606902\n",
      "alpha2 =  0.8934374072086472\n",
      "true gam1 =  158.7130112116805\n",
      "gam1 =  157.97266345673106\n",
      "corr(z2_hat, beta_true) =  [[0.99935453]]\n",
      "l2 error for z2_hat =  0.05695745959670085\n",
      "true tau1 =  3253.873465540509\n",
      "tau1 =  3054.1690677440547\n",
      "\n",
      "\n",
      "**** iteration =  11  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00110567]\n",
      "corr(x1_hat, beta_true) =  0.9945425269183811\n",
      "l2 error for x1_hat =  0.10573195139988405\n",
      "B / (A+B) =  [0.00497355]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9937096103301296\n",
      "alpha1 part I =  [0.00494227]\n",
      "alpha2 part II =  [0.00177204]\n",
      "alpha1 =  0.10331753845179271\n",
      "true gam2 =  1314.3458798067957\n",
      "gam2 =  1371.0287609281527\n",
      "corr(z1_hat, X*beta_true) =  0.9993497607031258\n",
      "l2 error for z1_hat =  0.05766533279373474\n",
      "v1 =  0.9034284231732864\n",
      "true tau2 =  376.1238123883987\n",
      "tau2 = 326.4740351332113\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99454458]]\n",
      "l2 error for x2_hat =  0.10572592555200891\n",
      "alpha2 =  0.905164428086929\n",
      "true gam1 =  156.01016368249353\n",
      "gam1 =  143.64494739004877\n",
      "corr(z2_hat, beta_true) =  [[0.99930293]]\n",
      "l2 error for z2_hat =  0.06445157260029913\n",
      "true tau1 =  3214.138234155157\n",
      "tau1 =  3116.0531574319025\n",
      "\n",
      "\n",
      "**** iteration =  12  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00090284]\n",
      "corr(x1_hat, beta_true) =  0.9946059268343159\n",
      "l2 error for x1_hat =  0.10524573063115351\n",
      "B / (A+B) =  [0.00516245]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930865196604247\n",
      "alpha1 part I =  [0.00512676]\n",
      "alpha2 part II =  [0.0017383]\n",
      "alpha1 =  0.10076750963624889\n",
      "true gam2 =  1320.3318685593886\n",
      "gam2 =  1281.8636109595532\n",
      "corr(z1_hat, X*beta_true) =  0.99930362165704\n",
      "l2 error for z1_hat =  0.06434052828532741\n",
      "v1 =  0.8953209406143181\n",
      "true tau2 =  368.4476764761647\n",
      "tau2 = 364.3224442979585\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99458982]]\n",
      "l2 error for x2_hat =  0.10540868777374529\n",
      "alpha2 =  0.8906112444950597\n",
      "true gam1 =  152.7130611443544\n",
      "gam1 =  157.44407674690248\n",
      "corr(z2_hat, beta_true) =  [[0.99932549]]\n",
      "l2 error for z2_hat =  0.06314924882306074\n",
      "true tau1 =  3245.2725673127397\n",
      "tau1 =  2966.206755126974\n",
      "\n",
      "\n",
      "**** iteration =  13  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00107653]\n",
      "corr(x1_hat, beta_true) =  0.9943738228653753\n",
      "l2 error for x1_hat =  0.10756676408061087\n",
      "B / (A+B) =  [0.00491665]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9936886249045624\n",
      "alpha1 part I =  [0.00488562]\n",
      "alpha2 part II =  [0.0016232]\n",
      "alpha1 =  0.10874615434291744\n",
      "true gam2 =  1266.3044640350147\n",
      "gam2 =  1290.3687465960013\n",
      "corr(z1_hat, X*beta_true) =  0.9993218837079731\n",
      "l2 error for z1_hat =  0.06379181968182954\n",
      "v1 =  0.899671457750208\n",
      "true tau2 =  361.7388398764537\n",
      "tau2 = 330.7820840482881\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99437641]]\n",
      "l2 error for x2_hat =  0.10754114661417873\n",
      "alpha2 =  0.8993020981515818\n",
      "true gam1 =  150.12295474018637\n",
      "gam1 =  144.48695900972862\n",
      "corr(z2_hat, beta_true) =  [[0.99926025]]\n",
      "l2 error for z2_hat =  0.07013256716253827\n",
      "true tau1 =  3095.481225137996\n",
      "tau1 =  2954.1134100625864\n",
      "\n",
      "\n",
      "**** iteration =  14  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00093986]\n",
      "corr(x1_hat, beta_true) =  0.9944575216302233\n",
      "l2 error for x1_hat =  0.1067265449564176\n",
      "B / (A+B) =  [0.00522695]\n",
      "gam1 / (gam1 + 1/sigma) =  0.993126531705614\n",
      "alpha1 part I =  [0.00519102]\n",
      "alpha2 part II =  [0.00191886]\n",
      "alpha1 =  0.1055630508375523\n",
      "true gam2 =  1279.2069713002452\n",
      "gam2 =  1224.2396727364032\n",
      "corr(z1_hat, X*beta_true) =  0.9992598820413349\n",
      "l2 error for z1_hat =  0.07012174280482908\n",
      "v1 =  0.8926356308914375\n",
      "true tau2 =  353.5534727407667\n",
      "tau2 = 355.3146564738549\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99444388]]\n",
      "l2 error for x2_hat =  0.10686241733152942\n",
      "alpha2 =  0.8887754018565325\n",
      "true gam1 =  146.5068609690423\n",
      "gam1 =  153.20582156860448\n",
      "corr(z2_hat, beta_true) =  [[0.99927154]]\n",
      "l2 error for z2_hat =  0.06976152098591856\n",
      "true tau1 =  3131.0315087135086\n",
      "tau1 =  2839.2543723621766\n",
      "\n",
      "\n",
      "**** iteration =  15  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00105742]\n",
      "corr(x1_hat, beta_true) =  0.9943044722423361\n",
      "l2 error for x1_hat =  0.10824614377423512\n",
      "B / (A+B) =  [0.00502907]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9935151605184043\n",
      "alpha1 part I =  [0.00499646]\n",
      "alpha2 part II =  [0.00175095]\n",
      "alpha1 =  0.11172519788142005\n",
      "true gam2 =  1242.18932569744\n",
      "gam2 =  1218.0678434036433\n",
      "corr(z1_hat, X*beta_true) =  0.9992679829143318\n",
      "l2 error for z1_hat =  0.07037057548542025\n",
      "v1 =  0.8965068653126181\n",
      "true tau2 =  348.0014660621156\n",
      "tau2 = 327.7647350398721\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99430837]]\n",
      "l2 error for x2_hat =  0.10820610236401094\n",
      "alpha2 =  0.8952891489295396\n",
      "true gam1 =  144.16367925741386\n",
      "gam1 =  142.46226562318554\n",
      "corr(z2_hat, beta_true) =  [[0.99921677]]\n",
      "l2 error for z2_hat =  0.07603114906065969\n",
      "true tau1 =  3036.9894310534505\n",
      "tau1 =  2802.4240819655192\n",
      "\n",
      "\n",
      "**** iteration =  16  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00103381]\n",
      "corr(x1_hat, beta_true) =  0.994391790683788\n",
      "l2 error for x1_hat =  0.10736521903979543\n",
      "B / (A+B) =  [0.00529967]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930295259477738\n",
      "alpha1 part I =  [0.00526273]\n",
      "alpha2 part II =  [0.00201728]\n",
      "alpha1 =  0.10871020518446142\n",
      "true gam2 =  1256.8267902938928\n",
      "gam2 =  1168.0151213107551\n",
      "corr(z1_hat, X*beta_true) =  0.9992161561628516\n",
      "l2 error for z1_hat =  0.07609989506522867\n",
      "v1 =  0.8907776598183669\n",
      "true tau2 =  339.7706338788776\n",
      "tau2 = 343.61808812768305\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99438211]]\n",
      "l2 error for x2_hat =  0.10746535310456855\n",
      "alpha2 =  0.8875765059588338\n",
      "true gam1 =  140.5822347669581\n",
      "gam1 =  147.94481393895984\n",
      "corr(z2_hat, beta_true) =  [[0.99922246]]\n",
      "l2 error for z2_hat =  0.07643982411543704\n",
      "true tau1 =  3079.2107412715554\n",
      "tau1 =  2712.8434732062847\n",
      "\n",
      "\n",
      "**** iteration =  17  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00116901]\n",
      "corr(x1_hat, beta_true) =  0.9942696780913193\n",
      "l2 error for x1_hat =  0.10860248310678347\n",
      "B / (A+B) =  [0.00519124]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9932861039363894\n",
      "alpha1 part I =  [0.00515639]\n",
      "alpha2 part II =  [0.00195592]\n",
      "alpha1 =  0.11397598745040587\n",
      "true gam2 =  1225.0131784089347\n",
      "gam2 =  1150.0901252479873\n",
      "corr(z1_hat, X*beta_true) =  0.9992184735001667\n",
      "l2 error for z1_hat =  0.07704090160171871\n",
      "v1 =  0.8941896772677361\n",
      "true tau2 =  334.7546314627488\n",
      "tau2 = 321.013371904679\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99427273]]\n",
      "l2 error for x2_hat =  0.10857297181722382\n",
      "alpha2 =  0.8921757481958928\n",
      "true gam1 =  138.32913735204065\n",
      "gam1 =  138.994595529992\n",
      "corr(z2_hat, beta_true) =  [[0.99916974]]\n",
      "l2 error for z2_hat =  0.08239305110935678\n",
      "true tau1 =  3001.294292782642\n",
      "tau1 =  2656.1774412334394\n",
      "\n",
      "\n",
      "**** iteration =  18  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00116331]\n",
      "corr(x1_hat, beta_true) =  0.9942964604899842\n",
      "l2 error for x1_hat =  0.10832022469546781\n",
      "B / (A+B) =  [0.00543778]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9928568671082323\n",
      "alpha1 part I =  [0.00539894]\n",
      "alpha2 part II =  [0.00221558]\n",
      "alpha1 =  0.11150724532990747\n",
      "true gam2 =  1226.4073826528297\n",
      "gam2 =  1107.5127064732092\n",
      "corr(z1_hat, X*beta_true) =  0.9991686388207436\n",
      "l2 error for z1_hat =  0.08253289521338118\n",
      "v1 =  0.889074577650558\n",
      "true tau2 =  326.27448055709135\n",
      "tau2 = 331.3980760562068\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99428745]]\n",
      "l2 error for x2_hat =  0.10841184280271011\n",
      "alpha2 =  0.8860590103196333\n",
      "true gam1 =  134.720729803388\n",
      "gam1 =  142.41838567119504\n",
      "corr(z2_hat, beta_true) =  [[0.99916555]]\n",
      "l2 error for z2_hat =  0.08353669047068367\n",
      "true tau1 =  3013.6816364306605\n",
      "tau1 =  2577.108133920223\n",
      "\n",
      "\n",
      "**** iteration =  19  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00131749]\n",
      "corr(x1_hat, beta_true) =  0.9942010763286871\n",
      "l2 error for x1_hat =  0.10928298906545324\n",
      "B / (A+B) =  [0.00537554]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930273932779259\n",
      "alpha1 part I =  [0.00533806]\n",
      "alpha2 part II =  [0.00219612]\n",
      "alpha1 =  0.11600789506943608\n",
      "true gam2 =  1200.8097558919922\n",
      "gam2 =  1085.2427626148854\n",
      "corr(z1_hat, X*beta_true) =  0.9991610520498722\n",
      "l2 error for z1_hat =  0.08414308527428749\n",
      "v1 =  0.8918776028154721\n",
      "true tau2 =  321.0904425041897\n",
      "tau2 = 312.4230369319528\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99420396]]\n",
      "l2 error for x2_hat =  0.10925602659176986\n",
      "alpha2 =  0.8894903088306653\n",
      "true gam1 =  132.41724883989863\n",
      "gam1 =  134.8298473290708\n",
      "corr(z2_hat, beta_true) =  [[0.99911225]]\n",
      "l2 error for z2_hat =  0.08934029350385334\n",
      "true tau1 =  2948.6744616505707\n",
      "tau1 =  2514.6868176528815\n",
      "\n",
      "\n",
      "**** iteration =  20  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00132507]\n",
      "corr(x1_hat, beta_true) =  0.9942020858686271\n",
      "l2 error for x1_hat =  0.10925440180944689\n",
      "B / (A+B) =  [0.0056327]\n",
      "gam1 / (gam1 + 1/sigma) =  0.992637847868758\n",
      "alpha1 part I =  [0.00559123]\n",
      "alpha2 part II =  [0.00251991]\n",
      "alpha1 =  0.11421390350020619\n",
      "true gam2 =  1196.6447370545286\n",
      "gam2 =  1045.6730791717066\n",
      "corr(z1_hat, X*beta_true) =  0.9991105843096482\n",
      "l2 error for z1_hat =  0.08954335138652904\n",
      "v1 =  0.8874224645231041\n",
      "true tau2 =  312.2851215285324\n",
      "tau2 = 319.01068064547417\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99419416]]\n",
      "l2 error for x2_hat =  0.10933447922438914\n",
      "alpha2 =  0.8843092234900197\n",
      "true gam1 =  128.68616700638216\n",
      "gam1 =  136.80138948174405\n",
      "corr(z2_hat, beta_true) =  [[0.99910008]]\n",
      "l2 error for z2_hat =  0.09107949811930477\n",
      "true tau1 =  2945.6353892969128\n",
      "tau1 =  2438.431963176301\n",
      "\n",
      "\n",
      "**** iteration =  21  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00148603]\n",
      "corr(x1_hat, beta_true) =  0.9941202393030328\n",
      "l2 error for x1_hat =  0.11007374965667803\n",
      "B / (A+B) =  [0.00560403]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9927431791235133\n",
      "alpha1 part I =  [0.00556336]\n",
      "alpha2 part II =  [0.00253038]\n",
      "alpha1 =  0.11834296966110597\n",
      "true gam2 =  1173.6674293498465\n",
      "gam2 =  1019.1725553457071\n",
      "corr(z1_hat, X*beta_true) =  0.9990949624252253\n",
      "l2 error for z1_hat =  0.09170479044402624\n",
      "v1 =  0.889636506200064\n",
      "true tau2 =  306.6213123198458\n",
      "tau2 = 302.49868229784005\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99412218]]\n",
      "l2 error for x2_hat =  0.11005588533639776\n",
      "alpha2 =  0.8867865340628301\n",
      "true gam1 =  126.18665238822206\n",
      "gam1 =  130.11480547646028\n",
      "corr(z2_hat, beta_true) =  [[0.99904444]]\n",
      "l2 error for z2_hat =  0.09688956487575033\n",
      "true tau1 =  2887.975662726224\n",
      "tau1 =  2369.433316195324\n",
      "\n",
      "\n",
      "**** iteration =  22  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00151849]\n",
      "corr(x1_hat, beta_true) =  0.9941020706405973\n",
      "l2 error for x1_hat =  0.11022810708930694\n",
      "B / (A+B) =  [0.0058397]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9923730962619661\n",
      "alpha1 part I =  [0.00579517]\n",
      "alpha2 part II =  [0.00282601]\n",
      "alpha1 =  0.1170280501541433\n",
      "true gam2 =  1165.7277877885958\n",
      "gam2 =  981.7109944499657\n",
      "corr(z1_hat, X*beta_true) =  0.9990422420536589\n",
      "l2 error for z1_hat =  0.097149416773987\n",
      "v1 =  0.8855353704649542\n",
      "true tau2 =  297.35513104009055\n",
      "tau2 = 306.2738268759264\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99409479]]\n",
      "l2 error for x2_hat =  0.11030204212198717\n",
      "alpha2 =  0.8822611598589757\n",
      "true gam1 =  122.29283365945967\n",
      "gam1 =  131.01054324856167\n",
      "corr(z2_hat, beta_true) =  [[0.99902536]]\n",
      "l2 error for z2_hat =  0.09912690786591113\n",
      "true tau1 =  2875.7016644889263\n",
      "tau1 =  2295.0243217136135\n",
      "\n",
      "\n",
      "**** iteration =  23  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00170117]\n",
      "corr(x1_hat, beta_true) =  0.9940259358153335\n",
      "l2 error for x1_hat =  0.11099026190165631\n",
      "B / (A+B) =  [0.00585217]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9924248474751209\n",
      "alpha1 part I =  [0.00580784]\n",
      "alpha2 part II =  [0.00289625]\n",
      "alpha1 =  0.12108730516283525\n",
      "true gam2 =  1143.37882075929\n",
      "gam2 =  950.9405586640781\n",
      "corr(z1_hat, X*beta_true) =  0.9990194850885771\n",
      "l2 error for z1_hat =  0.09978522606490894\n",
      "v1 =  0.887372922802374\n",
      "true tau2 =  291.22701930662583\n",
      "tau2 = 291.2888987369233\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99402788]]\n",
      "l2 error for x2_hat =  0.11097233072297022\n",
      "alpha2 =  0.8839400588461197\n",
      "true gam1 =  119.58712497918663\n",
      "gam1 =  124.85700152956186\n",
      "corr(z2_hat, beta_true) =  [[0.99896519]]\n",
      "l2 error for z2_hat =  0.10509310686039836\n",
      "true tau1 =  2818.852487848124\n",
      "tau1 =  2218.525390680235\n",
      "\n",
      "\n",
      "**** iteration =  24  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0017482]\n",
      "corr(x1_hat, beta_true) =  0.9939936767752909\n",
      "l2 error for x1_hat =  0.11127220838638065\n",
      "B / (A+B) =  [0.0060931]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9920544746192359\n",
      "alpha1 part I =  [0.00604469]\n",
      "alpha2 part II =  [0.00321451]\n",
      "alpha1 =  0.1200985109184515\n",
      "true gam2 =  1132.550111584806\n",
      "gam2 =  914.7645605923984\n",
      "corr(z1_hat, X*beta_true) =  0.9989623314314546\n",
      "l2 error for z1_hat =  0.10540853197128801\n",
      "v1 =  0.8833827013390692\n",
      "true tau2 =  281.36985324243597\n",
      "tau2 = 292.87242967248375\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99398637]]\n",
      "l2 error for x2_hat =  0.11134580537324971\n",
      "alpha2 =  0.8798566935188216\n",
      "true gam1 =  115.482132820579\n",
      "gam1 =  124.90993109552566\n",
      "corr(z2_hat, beta_true) =  [[0.99893913]]\n",
      "l2 error for z2_hat =  0.1077830514121661\n",
      "true tau1 =  2799.011278495779\n",
      "tau1 =  2144.820008219301\n",
      "\n",
      "\n",
      "**** iteration =  25  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00196171]\n",
      "corr(x1_hat, beta_true) =  0.9939212833271901\n",
      "l2 error for x1_hat =  0.11199347264944022\n",
      "B / (A+B) =  [0.00613021]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9920578147307434\n",
      "alpha1 part I =  [0.00608152]\n",
      "alpha2 part II =  [0.00331037]\n",
      "alpha1 =  0.12417896723187055\n",
      "true gam2 =  1110.398019794647\n",
      "gam2 =  880.9764430622674\n",
      "corr(z1_hat, X*beta_true) =  0.9989323866359168\n",
      "l2 error for z1_hat =  0.10848897434875504\n",
      "v1 =  0.8849768994589088\n",
      "true tau2 =  274.7733024588578\n",
      "tau2 = 278.76868605134445\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99392371]]\n",
      "l2 error for x2_hat =  0.11197129490796648\n",
      "alpha2 =  0.8809497804883081\n",
      "true gam1 =  112.58942133354223\n",
      "gam1 =  119.05382265156767\n",
      "corr(z2_hat, beta_true) =  [[0.99887298]]\n",
      "l2 error for z2_hat =  0.1140275232297659\n",
      "true tau1 =  2742.7287811339575\n",
      "tau1 =  2062.8371269809163\n",
      "\n",
      "\n",
      "**** iteration =  26  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00203284]\n",
      "corr(x1_hat, beta_true) =  0.9938807663450265\n",
      "l2 error for x1_hat =  0.11234913530435775\n",
      "B / (A+B) =  [0.00639041]\n",
      "gam1 / (gam1 + 1/sigma) =  0.991670402675121\n",
      "alpha1 part I =  [0.00633718]\n",
      "alpha2 part II =  [0.00367554]\n",
      "alpha1 =  0.12348549028902997\n",
      "true gam2 =  1097.774106145221\n",
      "gam2 =  845.0580124548115\n",
      "corr(z1_hat, X*beta_true) =  0.9988693850950419\n",
      "l2 error for z1_hat =  0.11439895586821601\n",
      "v1 =  0.8810225529196707\n",
      "true tau2 =  264.29853522005556\n",
      "tau2 = 278.5752694949323\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99387356]]\n",
      "l2 error for x2_hat =  0.1124215461227852\n",
      "alpha2 =  0.8770984486522618\n",
      "true gam1 =  108.25499504713179\n",
      "gam1 =  118.41195349178977\n",
      "corr(z2_hat, beta_true) =  [[0.99883992]]\n",
      "l2 error for z2_hat =  0.117146336095418\n",
      "true tau1 =  2717.504275431817\n",
      "tau1 =  1988.0785395097257\n",
      "\n",
      "\n",
      "**** iteration =  27  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00228432]\n",
      "corr(x1_hat, beta_true) =  0.9938075764869848\n",
      "l2 error for x1_hat =  0.11307198359984859\n",
      "B / (A+B) =  [0.00646299]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9916256290031403\n",
      "alpha1 part I =  [0.00640886]\n",
      "alpha2 part II =  [0.00382745]\n",
      "alpha1 =  0.12773757461276997\n",
      "true gam2 =  1074.5563092320963\n",
      "gam2 =  808.5819545321385\n",
      "corr(z1_hat, X*beta_true) =  0.9988320311606087\n",
      "l2 error for z1_hat =  0.1179192995696214\n",
      "v1 =  0.8824423216740831\n",
      "true tau2 =  257.23372669357695\n",
      "tau2 = 264.8489217867111\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99381079]]\n",
      "l2 error for x2_hat =  0.1130424689966421\n",
      "alpha2 =  0.8777073442921812\n",
      "true gam1 =  105.1658446492732\n",
      "gam1 =  112.66128194118937\n",
      "corr(z2_hat, beta_true) =  [[0.99876523]]\n",
      "l2 error for z2_hat =  0.12382348780082926\n",
      "true tau1 =  2658.631230731706\n",
      "tau1 =  1900.84876671134\n",
      "\n",
      "\n",
      "**** iteration =  28  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0023822]\n",
      "corr(x1_hat, beta_true) =  0.9937595424941816\n",
      "l2 error for x1_hat =  0.11348875628534309\n",
      "B / (A+B) =  [0.00674247]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9912019292504776\n",
      "alpha1 part I =  [0.00668315]\n",
      "alpha2 part II =  [0.00422829]\n",
      "alpha1 =  0.1272502465238753\n",
      "true gam2 =  1060.2793236613325\n",
      "gam2 =  772.6908884379175\n",
      "corr(z1_hat, X*beta_true) =  0.9987608388824942\n",
      "l2 error for z1_hat =  0.12425236177173811\n",
      "v1 =  0.8783779535142356\n",
      "true tau2 =  246.07869748715964\n",
      "tau2 = 263.1954913513522\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9937522]]\n",
      "l2 error for x2_hat =  0.11356208668602555\n",
      "alpha2 =  0.8739507397412725\n",
      "true gam1 =  100.5860080904434\n",
      "gam1 =  111.44462778885256\n",
      "corr(z2_hat, beta_true) =  [[0.99872492]]\n",
      "l2 error for z2_hat =  0.12735487933026865\n",
      "true tau1 =  2628.7774910435287\n",
      "tau1 =  1824.8412873740413\n",
      "\n",
      "\n",
      "**** iteration =  29  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00269531]\n",
      "corr(x1_hat, beta_true) =  0.9936860248015029\n",
      "l2 error for x1_hat =  0.1142100145815682\n",
      "B / (A+B) =  [0.00685797]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9911067338683552\n",
      "alpha1 part I =  [0.00679698]\n",
      "alpha2 part II =  [0.00445803]\n",
      "alpha1 =  0.13185701683691792\n",
      "true gam2 =  1035.6802769743426\n",
      "gam2 =  733.7483734049208\n",
      "corr(z1_hat, X*beta_true) =  0.998715528866586\n",
      "l2 error for z1_hat =  0.12821960250716227\n",
      "v1 =  0.8797467766353069\n",
      "true tau2 =  238.60392403313713\n",
      "tau2 = 249.4388757808128\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99369102]]\n",
      "l2 error for x2_hat =  0.11416404695206585\n",
      "alpha2 =  0.8741418975899282\n",
      "true gam1 =  97.32666726584367\n",
      "gam1 =  105.64437899365156\n",
      "corr(z2_hat, beta_true) =  [[0.99863886]]\n",
      "l2 error for z2_hat =  0.13464775652062472\n",
      "true tau1 =  2566.0434281608213\n",
      "tau1 =  1732.466706810042\n",
      "\n",
      "\n",
      "**** iteration =  30  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00281963]\n",
      "corr(x1_hat, beta_true) =  0.9936302738901863\n",
      "l2 error for x1_hat =  0.11468401474025677\n",
      "B / (A+B) =  [0.00718122]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9906230407131019\n",
      "alpha1 part I =  [0.00711388]\n",
      "alpha2 part II =  [0.00494552]\n",
      "alpha1 =  0.1315222842825781\n",
      "true gam2 =  1019.5705490283594\n",
      "gam2 =  697.5988095649705\n",
      "corr(z1_hat, X*beta_true) =  0.9986335384631568\n",
      "l2 error for z1_hat =  0.13513712210017784\n",
      "v1 =  0.8754159697045225\n",
      "true tau2 =  226.70004232248402\n",
      "tau2 = 246.55442915895134\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99362261]]\n",
      "l2 error for x2_hat =  0.11475999280383488\n",
      "alpha2 =  0.870328126357904\n",
      "true gam1 =  92.46693064760765\n",
      "gam1 =  103.93659810275521\n",
      "corr(z2_hat, beta_true) =  [[0.99859037]]\n",
      "l2 error for z2_hat =  0.13858791208582175\n",
      "true tau1 =  2530.8841032343935\n",
      "tau1 =  1654.8172579615718\n",
      "\n",
      "\n",
      "**** iteration =  31  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00321662]\n",
      "corr(x1_hat, beta_true) =  0.9935544753891269\n",
      "l2 error for x1_hat =  0.11542015323458263\n",
      "B / (A+B) =  [0.00734212]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9904704362626584\n",
      "alpha1 part I =  [0.00727215]\n",
      "alpha2 part II =  [0.00526043]\n",
      "alpha1 =  0.13666523716933957\n",
      "true gam2 =  992.5804112872829\n",
      "gam2 =  656.5830501671933\n",
      "corr(z1_hat, X*beta_true) =  0.9985789792793667\n",
      "l2 error for z1_hat =  0.13957848279872875\n",
      "v1 =  0.8768394984888953\n",
      "true tau2 =  218.89669209984947\n",
      "tau2 = 232.43492537803303\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99356245]]\n",
      "l2 error for x2_hat =  0.11534660019303634\n",
      "alpha2 =  0.8701671635429628\n",
      "true gam1 =  89.07136209465898\n",
      "gam1 =  97.96513054541506\n",
      "corr(z2_hat, beta_true) =  [[0.99848904]]\n",
      "l2 error for z2_hat =  0.14673906320987165\n",
      "true tau1 =  2462.03719688118\n",
      "tau1 =  1557.828090672977\n",
      "\n",
      "\n",
      "**** iteration =  32  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00338164]\n",
      "corr(x1_hat, beta_true) =  0.9934940068735276\n",
      "l2 error for x1_hat =  0.11591579511691084\n",
      "B / (A+B) =  [0.00772502]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9898954309008757\n",
      "alpha1 part I =  [0.00764696]\n",
      "alpha2 part II =  [0.00586221]\n",
      "alpha1 =  0.13641225271048138\n",
      "true gam2 =  975.0519128120794\n",
      "gam2 =  620.1897902836859\n",
      "corr(z1_hat, X*beta_true) =  0.9984827289495419\n",
      "l2 error for z1_hat =  0.1472900969921872\n",
      "v1 =  0.8720739733865228\n",
      "true tau2 =  206.2007599516961\n",
      "tau2 = 228.5204740290136\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99348596]]\n",
      "l2 error for x2_hat =  0.11599510745900093\n",
      "alpha2 =  0.8661478022264599\n",
      "true gam1 =  83.92170464977039\n",
      "gam1 =  95.84249507161802\n",
      "corr(z2_hat, beta_true) =  [[0.99843193]]\n",
      "l2 error for z2_hat =  0.1510630516280112\n",
      "true tau1 =  2422.220108888249\n",
      "tau1 =  1478.7393082544236\n",
      "\n",
      "\n",
      "**** iteration =  33  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00389909]\n",
      "corr(x1_hat, beta_true) =  0.9934112082293078\n",
      "l2 error for x1_hat =  0.11670827635886707\n",
      "B / (A+B) =  [0.00796243]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9896739546078355\n",
      "alpha1 part I =  [0.00788021]\n",
      "alpha2 part II =  [0.00634709]\n",
      "alpha1 =  0.14238232504370832\n",
      "true gam2 =  943.9907138333557\n",
      "gam2 =  577.2922851210528\n",
      "corr(z1_hat, X*beta_true) =  0.9984177304381973\n",
      "l2 error for z1_hat =  0.1522309260042751\n",
      "v1 =  0.873713034124015\n",
      "true tau2 =  198.23817166208158\n",
      "tau2 = 213.73779864487787\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99342471]]\n",
      "l2 error for x2_hat =  0.11658423419794615\n",
      "alpha2 =  0.8656597464585788\n",
      "true gam1 =  80.4480669244479\n",
      "gam1 =  89.58900106876986\n",
      "corr(z2_hat, beta_true) =  [[0.99830862]]\n",
      "l2 error for z2_hat =  0.16043616771997118\n",
      "true tau1 =  2342.7116081027766\n",
      "tau1 =  1377.2804777868841\n",
      "\n",
      "\n",
      "**** iteration =  34  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0040947]\n",
      "corr(x1_hat, beta_true) =  0.993343036243373\n",
      "l2 error for x1_hat =  0.11723965282234872\n",
      "B / (A+B) =  [0.00842821]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9889611322765237\n",
      "alpha1 part I =  [0.00833518]\n",
      "alpha2 part II =  [0.00710616]\n",
      "alpha1 =  0.14193257251270455\n",
      "true gam2 =  924.7937869919913\n",
      "gam2 =  541.619180976621\n",
      "corr(z1_hat, X*beta_true) =  0.9983013452030965\n",
      "l2 error for z1_hat =  0.16104356927899063\n",
      "v1 =  0.868234907979774\n",
      "true tau2 =  184.69732242608507\n",
      "tau2 = 209.0188809794748\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99333402]]\n",
      "l2 error for x2_hat =  0.11732727201542602\n",
      "alpha2 =  0.8613906726305629\n",
      "true gam1 =  75.00395031844246\n",
      "gam1 =  87.15379995500915\n",
      "corr(z2_hat, beta_true) =  [[0.99824266]]\n",
      "l2 error for z2_hat =  0.1650679421038877\n",
      "true tau1 =  2297.664873779348\n",
      "tau1 =  1298.9523713618216\n",
      "\n",
      "\n",
      "**** iteration =  35  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00480357]\n",
      "corr(x1_hat, beta_true) =  0.9932567247604892\n",
      "l2 error for x1_hat =  0.11805710956076339\n",
      "B / (A+B) =  [0.00875966]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9886561895175209\n",
      "alpha1 part I =  [0.00866029]\n",
      "alpha2 part II =  [0.00781494]\n",
      "alpha1 =  0.1490684576253872\n",
      "true gam2 =  888.9328441384115\n",
      "gam2 =  497.5024133267358\n",
      "corr(z1_hat, X*beta_true) =  0.9982243937183898\n",
      "l2 error for z1_hat =  0.16649205443235987\n",
      "v1 =  0.8704300931849338\n",
      "true tau2 =  176.93575393558143\n",
      "tau2 = 193.35859253064905\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99328034]]\n",
      "l2 error for x2_hat =  0.11784139319651485\n",
      "alpha2 =  0.8606514207405442\n",
      "true gam1 =  71.60251176762347\n",
      "gam1 =  80.55090923521587\n",
      "corr(z2_hat, beta_true) =  [[0.99808837]]\n",
      "l2 error for z2_hat =  0.17620949698043623\n",
      "true tau1 =  2205.5065040580907\n",
      "tau1 =  1194.2306714447734\n",
      "\n",
      "\n",
      "**** iteration =  36  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00502128]\n",
      "corr(x1_hat, beta_true) =  0.9931744235040137\n",
      "l2 error for x1_hat =  0.11866420657928883\n",
      "B / (A+B) =  [0.00936791]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9877377210214087\n",
      "alpha1 part I =  [0.00925304]\n",
      "alpha2 part II =  [0.00887304]\n",
      "alpha1 =  0.14796895948072677\n",
      "true gam2 =  868.4137382559104\n",
      "gam2 =  463.8261649693761\n",
      "corr(z1_hat, X*beta_true) =  0.9980804346552481\n",
      "l2 error for z1_hat =  0.17684807388870938\n",
      "v1 =  0.8638775013669912\n",
      "true tau2 =  162.52767846882506\n",
      "tau2 = 188.17675270394523\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99316345]]\n",
      "l2 error for x2_hat =  0.11876961222859579\n",
      "alpha2 =  0.856111282704299\n",
      "true gam1 =  65.87766487139595\n",
      "gam1 =  77.95639804536894\n",
      "corr(z2_hat, beta_true) =  [[0.99801396]]\n",
      "l2 error for z2_hat =  0.1809324384106252\n",
      "true tau1 =  2154.960509903555\n",
      "tau1 =  1119.6169106256775\n",
      "\n",
      "\n",
      "**** iteration =  37  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00598195]\n",
      "corr(x1_hat, beta_true) =  0.9930693456303072\n",
      "l2 error for x1_hat =  0.11964803977396284\n",
      "B / (A+B) =  [0.00984071]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9873347819207078\n",
      "alpha1 part I =  [0.00971608]\n",
      "alpha2 part II =  [0.00995813]\n",
      "alpha1 =  0.15662212720111374\n",
      "true gam2 =  824.6579362172318\n",
      "gam2 =  419.77913548666834\n",
      "corr(z1_hat, X*beta_true) =  0.9979894863691087\n",
      "l2 error for z1_hat =  0.18274471428893532\n",
      "v1 =  0.8671775441241363\n",
      "true tau2 =  155.5262897846987\n",
      "tau2 = 171.4876829054075\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99311151]]\n",
      "l2 error for x2_hat =  0.11926678040307187\n",
      "alpha2 =  0.8553705530730272\n",
      "true gam1 =  62.77082548166393\n",
      "gam1 =  70.97792176595573\n",
      "corr(z2_hat, beta_true) =  [[0.99781154]]\n",
      "l2 error for z2_hat =  0.19478001426762312\n",
      "true tau1 =  2043.2163133235426\n",
      "tau1 =  1014.2161039036242\n",
      "\n",
      "\n",
      "**** iteration =  38  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00616845]\n",
      "corr(x1_hat, beta_true) =  0.9929759062258281\n",
      "l2 error for x1_hat =  0.1202856691826427\n",
      "B / (A+B) =  [0.01059817]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9861068508861424\n",
      "alpha1 part I =  [0.01045093]\n",
      "alpha2 part II =  [0.01129558]\n",
      "alpha1 =  0.1536973377356619\n",
      "true gam2 =  806.6333307697203\n",
      "gam2 =  390.8252741230187\n",
      "corr(z1_hat, X*beta_true) =  0.9978043753982878\n",
      "l2 error for z1_hat =  0.19536316441848472\n",
      "v1 =  0.8590135965778134\n",
      "true tau2 =  140.23972074306675\n",
      "tau2 = 166.45915891423485\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99295815]]\n",
      "l2 error for x2_hat =  0.12045222367787017\n",
      "alpha2 =  0.8508427134179799\n",
      "true gam1 =  56.82026912571926\n",
      "gam1 =  68.51376464362608\n",
      "corr(z2_hat, beta_true) =  [[0.99773748]]\n",
      "l2 error for z2_hat =  0.1989510599203505\n",
      "true tau1 =  1996.2957330055292\n",
      "tau1 =  949.5383409645298\n",
      "\n",
      "\n",
      "**** iteration =  39  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0075776]\n",
      "corr(x1_hat, beta_true) =  0.9928512773346069\n",
      "l2 error for x1_hat =  0.12146696206372994\n",
      "B / (A+B) =  [0.0112964]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9856143599022917\n",
      "alpha1 part I =  [0.01113389]\n",
      "alpha2 part II =  [0.01306203]\n",
      "alpha1 =  0.16481934403061282\n",
      "true gam2 =  753.3045067059556\n",
      "gam2 =  347.17630527256426\n",
      "corr(z1_hat, X*beta_true) =  0.9977027569449094\n",
      "l2 error for z1_hat =  0.20138453157932393\n",
      "v1 =  0.8646170110254413\n",
      "true tau2 =  134.98457568744874\n",
      "tau2 = 148.68009431512223\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99292828]]\n",
      "l2 error for x2_hat =  0.12078056788994836\n",
      "alpha2 =  0.8502410093919548\n",
      "true gam1 =  54.389369934628995\n",
      "gam1 =  61.1506296054011\n",
      "corr(z2_hat, beta_true) =  [[0.99745712]]\n",
      "l2 error for z2_hat =  0.2172117790563682\n",
      "true tau1 =  1860.5713347370984\n",
      "tau1 =  844.1156885053783\n",
      "\n",
      "\n",
      "**** iteration =  40  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00751861]\n",
      "corr(x1_hat, beta_true) =  0.9926935146533008\n",
      "l2 error for x1_hat =  0.12254768677418551\n",
      "B / (A+B) =  [0.01231263]\n",
      "gam1 / (gam1 + 1/sigma) =  0.983910058412134\n",
      "alpha1 part I =  [0.01211452]\n",
      "alpha2 part II =  [0.01494423]\n",
      "alpha1 =  0.15814469199596215\n",
      "true gam2 =  739.2650069810412\n",
      "gam2 =  325.5245653291367\n",
      "corr(z1_hat, X*beta_true) =  0.9974548583045665\n",
      "l2 error for z1_hat =  0.21749235290383592\n",
      "v1 =  0.8536437801546453\n",
      "true tau2 =  118.41915588230201\n",
      "tau2 = 144.72263976365582\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9926549]]\n",
      "l2 error for x2_hat =  0.12289720521485671\n",
      "alpha2 =  0.8460832662290492\n",
      "true gam1 =  48.076992089094695\n",
      "gam1 =  59.2183770292241\n",
      "corr(z2_hat, beta_true) =  [[0.99740168]]\n",
      "l2 error for z2_hat =  0.21918879756587867\n",
      "true tau1 =  1820.13421078148\n",
      "tau1 =  795.5431534217877\n",
      "\n",
      "\n",
      "**** iteration =  41  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00959528]\n",
      "corr(x1_hat, beta_true) =  0.9925482302741813\n",
      "l2 error for x1_hat =  0.12397456251778916\n",
      "B / (A+B) =  [0.01320006]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9833937736396533\n",
      "alpha1 part I =  [0.01298086]\n",
      "alpha2 part II =  [0.01739998]\n",
      "alpha1 =  0.1733473520947095\n",
      "true gam2 =  672.8384059551746\n",
      "gam2 =  282.3984767250215\n",
      "corr(z1_hat, X*beta_true) =  0.9973490651832025\n",
      "l2 error for z1_hat =  0.2226934851094862\n",
      "v1 =  0.8636283053854119\n",
      "true tau2 =  116.30305527821955\n",
      "tau2 = 125.62067187312338\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99268807]]\n",
      "l2 error for x2_hat =  0.12274713710786475\n",
      "alpha2 =  0.8460197007780863\n",
      "true gam1 =  46.829473629676116\n",
      "gam1 =  51.39809617428446\n",
      "corr(z2_hat, beta_true) =  [[0.99698502]]\n",
      "l2 error for z2_hat =  0.24532157368145935\n",
      "true tau1 =  1655.3740914136329\n",
      "tau1 =  690.2023425508263\n",
      "\n",
      "\n",
      "**** iteration =  42  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0091611]\n",
      "corr(x1_hat, beta_true) =  0.9923729472670617\n",
      "l2 error for x1_hat =  0.12499877302838594\n",
      "B / (A+B) =  [0.01442118]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9809153371398488\n",
      "alpha1 part I =  [0.01414596]\n",
      "alpha2 part II =  [0.01950042]\n",
      "alpha1 =  0.16032611815576495\n",
      "true gam2 =  675.9197458089653\n",
      "gam2 =  269.18657690030847\n",
      "corr(z1_hat, X*beta_true) =  0.9970006158321879\n",
      "l2 error for z1_hat =  0.24459416787180854\n",
      "v1 =  0.8475366488690023\n",
      "true tau2 =  97.54397681510362\n",
      "tau2 = 124.16048585531853\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99226406]]\n",
      "l2 error for x2_hat =  0.12594515855908198\n",
      "alpha2 =  0.8419180289632859\n",
      "true gam1 =  39.81077259681596\n",
      "gam1 =  50.54357216393857\n",
      "corr(z2_hat, beta_true) =  [[0.99702019]]\n",
      "l2 error for z2_hat =  0.24059329490201473\n",
      "true tau1 =  1648.820045413516\n",
      "tau1 =  661.2578957669768\n",
      "\n",
      "\n",
      "**** iteration =  43  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01274174]\n",
      "corr(x1_hat, beta_true) =  0.9921167625712093\n",
      "l2 error for x1_hat =  0.12752854780315037\n",
      "B / (A+B) =  [0.0160272]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9805989387615701\n",
      "alpha1 part I =  [0.01571625]\n",
      "alpha2 part II =  [0.0246917]\n",
      "alpha1 =  0.18466356519719448\n",
      "true gam2 =  579.6555451759372\n",
      "gam2 =  223.16267903924384\n",
      "corr(z1_hat, X*beta_true) =  0.9969314609860915\n",
      "l2 error for z1_hat =  0.2461843898345922\n",
      "v1 =  0.8655440286137212\n",
      "true tau2 =  100.46589169519127\n",
      "tau2 = 102.7216060338333\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99238053]]\n",
      "l2 error for x2_hat =  0.1252574789480991\n",
      "alpha2 =  0.8421519995475509\n",
      "true gam1 =  40.38677889426204\n",
      "gam1 =  41.82829546314856\n",
      "corr(z2_hat, beta_true) =  [[0.99631038]]\n",
      "l2 error for z2_hat =  0.2829653945172874\n",
      "true tau1 =  1415.7338134369218\n",
      "tau1 =  548.0411894364689\n",
      "\n",
      "\n",
      "**** iteration =  44  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01068637]\n",
      "corr(x1_hat, beta_true) =  0.9916615465524957\n",
      "l2 error for x1_hat =  0.13028945511500442\n",
      "B / (A+B) =  [0.01731325]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9766509502844808\n",
      "alpha1 part I =  [0.01690901]\n",
      "alpha2 part II =  [0.02606161]\n",
      "alpha1 =  0.15896825714870738\n",
      "true gam2 =  598.7073739645459\n",
      "gam2 =  221.2952753263339\n",
      "corr(z1_hat, X*beta_true) =  0.9963864066648653\n",
      "l2 error for z1_hat =  0.2790633550105539\n",
      "v1 =  0.8381767945147235\n",
      "true tau2 =  77.14523096422644\n",
      "tau2 = 105.80796628224381\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99133352]]\n",
      "l2 error for x2_hat =  0.13295069318554512\n",
      "alpha2 =  0.837773140666329\n",
      "true gam1 =  31.662575787179232\n",
      "gam1 =  42.85174083406136\n",
      "corr(z2_hat, beta_true) =  [[0.99661529]]\n",
      "l2 error for z2_hat =  0.2590367784818534\n",
      "true tau1 =  1442.1451638998155\n",
      "tau1 =  546.4142780294468\n",
      "\n",
      "\n",
      "**** iteration =  45  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01777667]\n",
      "corr(x1_hat, beta_true) =  0.9915199066729325\n",
      "l2 error for x1_hat =  0.13225370163601188\n",
      "B / (A+B) =  [0.01920136]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9771958882137864\n",
      "alpha1 part I =  [0.01876349]\n",
      "alpha2 part II =  [0.03317952]\n",
      "alpha1 =  0.20225311076627497\n",
      "true gam2 =  467.03259821649254\n",
      "gam2 =  169.02010959982945\n",
      "corr(z1_hat, X*beta_true) =  0.9964486066171514\n",
      "l2 error for z1_hat =  0.26913073491021366\n",
      "v1 =  0.8725804791294175\n",
      "true tau2 =  89.42936399832641\n",
      "tau2 = 79.79074385530811\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99192937]]\n",
      "l2 error for x2_hat =  0.12878263566355316\n",
      "alpha2 =  0.8392498034729757\n",
      "true gam1 =  35.62463519813288\n",
      "gam1 =  32.37417002989701\n",
      "corr(z2_hat, beta_true) =  [[0.99521757]]\n",
      "l2 error for z2_hat =  0.33980282994661404\n",
      "true tau1 =  1128.7351782041148\n",
      "tau1 =  416.5740854212409\n",
      "\n",
      "\n",
      "**** iteration =  46  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01336734]\n",
      "corr(x1_hat, beta_true) =  0.9899757765784711\n",
      "l2 error for x1_hat =  0.14201561170882426\n",
      "B / (A+B) =  [0.02152961]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9700367080558352\n",
      "alpha1 part I =  [0.02088451]\n",
      "alpha2 part II =  [0.03603766]\n",
      "alpha1 =  0.15425220427052463\n",
      "true gam2 =  495.1152207508053\n",
      "gam2 =  177.50399788995838\n",
      "corr(z1_hat, X*beta_true) =  0.9955148025085666\n",
      "l2 error for z1_hat =  0.3251882036200301\n",
      "v1 =  0.8197037465432457\n",
      "true tau2 =  57.463449223543186\n",
      "tau2 = 91.62669709069236\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98870845]]\n",
      "l2 error for x2_hat =  0.15108674007124842\n",
      "alpha2 =  0.8287014949397841\n",
      "true gam1 =  23.527685287759812\n",
      "gam1 =  36.691341413558085\n",
      "corr(z2_hat, beta_true) =  [[0.99631231]]\n",
      "l2 error for z2_hat =  0.2598833883475926\n",
      "true tau1 =  1150.4981442873934\n",
      "tau1 =  443.26820498964497\n",
      "\n",
      "\n",
      "**** iteration =  47  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02933401]\n",
      "corr(x1_hat, beta_true) =  0.9891357163712391\n",
      "l2 error for x1_hat =  0.1507019563363411\n",
      "B / (A+B) =  [0.02787381]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9734687075997702\n",
      "alpha1 part I =  [0.02713428]\n",
      "alpha2 part II =  [0.06369513]\n",
      "alpha1 =  0.2392192744946568\n",
      "true gam2 =  295.4429736158097\n",
      "gam2 =  116.68819495978553\n",
      "corr(z1_hat, X*beta_true) =  0.9959793134173087\n",
      "l2 error for z1_hat =  0.2800637245346221\n",
      "v1 =  0.8883638301425499\n",
      "true tau2 =  87.22792224095853\n",
      "tau2 = 55.70326362419607\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98912702]]\n",
      "l2 error for x2_hat =  0.15007080506343845\n",
      "alpha2 =  0.8379584884333106\n",
      "true gam1 =  32.95485750927015\n",
      "gam1 =  22.564759178732313\n",
      "corr(z2_hat, beta_true) =  [[0.9929221]]\n",
      "l2 error for z2_hat =  0.4466101350783431\n",
      "true tau1 =  686.675636652285\n",
      "tau1 =  288.05595637833375\n",
      "\n",
      "\n",
      "**** iteration =  48  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01378554]\n",
      "corr(x1_hat, beta_true) =  0.9842461585317441\n",
      "l2 error for x1_hat =  0.17682682109023826\n",
      "B / (A+B) =  [0.02412391]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9575637504964396\n",
      "alpha1 part I =  [0.02310018]\n",
      "alpha2 part II =  [0.03715897]\n",
      "alpha1 =  0.1369896741898677\n",
      "true gam2 =  339.6248040686053\n",
      "gam2 =  142.15392719070567\n",
      "corr(z1_hat, X*beta_true) =  0.9941812485840976\n",
      "l2 error for z1_hat =  0.38808231238509683\n",
      "v1 =  0.7691508690915566\n",
      "true tau2 =  41.91835449289077\n",
      "tau2 = 86.45568750572812\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97894503]]\n",
      "l2 error for x2_hat =  0.20501492753433848\n",
      "alpha2 =  0.8081937617264154\n",
      "true gam1 =  16.366306039728578\n",
      "gam1 =  33.736971653953695\n",
      "corr(z2_hat, beta_true) =  [[0.99610942]]\n",
      "l2 error for z2_hat =  0.2020458204038538\n",
      "true tau1 =  721.2600253883762\n",
      "tau1 =  364.2892323879161\n",
      "\n",
      "\n",
      "**** iteration =  49  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.07004906]\n",
      "corr(x1_hat, beta_true) =  0.973995333591811\n",
      "l2 error for x1_hat =  0.2357752656145282\n",
      "B / (A+B) =  [0.03368614]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9712122285741572\n",
      "alpha1 part I =  [0.03271639]\n",
      "alpha2 part II =  [0.0861135]\n",
      "alpha1 =  0.3251527556922747\n",
      "true gam2 =  106.30677633395767\n",
      "gam2 =  70.02032722584558\n",
      "corr(z1_hat, X*beta_true) =  0.9956844640622522\n",
      "l2 error for z1_hat =  0.23710468644396795\n",
      "v1 =  0.9221680870972131\n",
      "true tau2 =  117.14237102151122\n",
      "tau2 = 30.74637715548102\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.96279941]]\n",
      "l2 error for x2_hat =  0.28186417970596095\n",
      "alpha2 =  0.8474693306618581\n",
      "true gam1 =  32.64996192340073\n",
      "gam1 =  12.602517864207385\n",
      "corr(z2_hat, beta_true) =  [[0.98651215]]\n",
      "l2 error for z2_hat =  0.696845528253114\n",
      "true tau1 =  230.73233435976658\n",
      "tau1 =  170.8286719077343\n",
      "\n",
      "\n",
      "**** iteration =  50  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02609933]\n",
      "corr(x1_hat, beta_true) =  0.9492854012122423\n",
      "l2 error for x1_hat =  0.31485536572844874\n",
      "B / (A+B) =  [0.0581585]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9264841987356383\n",
      "alpha1 part I =  [0.05388293]\n",
      "alpha2 part II =  [0.14868511]\n",
      "alpha1 =  0.12089804596880402\n",
      "true gam2 =  126.73449082020267\n",
      "gam2 =  91.63835520548045\n",
      "corr(z1_hat, X*beta_true) =  0.9925835466724017\n",
      "l2 error for z1_hat =  0.4411510468920591\n",
      "v1 =  0.5691293544712669\n",
      "true tau2 =  62.868187749061455\n",
      "tau2 = 129.3292281648032\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.94123739]]\n",
      "l2 error for x2_hat =  0.34330110788919527\n",
      "alpha2 =  0.682996768281256\n",
      "true gam1 =  21.332765816175975\n",
      "gam1 =  42.53263865747156\n",
      "corr(z2_hat, beta_true) =  [[0.99325195]]\n",
      "l2 error for z2_hat =  0.1547435164233878\n",
      "true tau1 =  288.01891995593786\n",
      "tau1 =  278.64525040312657\n",
      "\n",
      "\n",
      "**** iteration =  51  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04955305]\n",
      "corr(x1_hat, beta_true) =  0.9783399372416959\n",
      "l2 error for x1_hat =  0.217433011797125\n",
      "B / (A+B) =  [0.02841323]\n",
      "gam1 / (gam1 + 1/sigma) =  0.977028729917607\n",
      "alpha1 part I =  [0.02776054]\n",
      "alpha2 part II =  [0.07007908]\n",
      "alpha1 =  0.25051671562140565\n",
      "true gam2 =  198.51493053916533\n",
      "gam2 =  127.24700479653721\n",
      "corr(z1_hat, X*beta_true) =  0.9932118777627019\n",
      "l2 error for z1_hat =  0.18355218507501725\n",
      "v1 =  0.9397487965634365\n",
      "true tau2 =  167.2769323242175\n",
      "tau2 = 17.865105792170777\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.96747831]]\n",
      "l2 error for x2_hat =  0.2670778095724194\n",
      "alpha2 =  0.939337062775013\n",
      "true gam1 =  51.63685864047101\n",
      "gam1 =  8.217686036187866\n",
      "corr(z2_hat, beta_true) =  [[0.98369026]]\n",
      "l2 error for z2_hat =  0.8579292554497088\n",
      "true tau1 =  337.4432586778509\n",
      "tau1 =  276.63276406718995\n",
      "\n",
      "\n",
      "**** iteration =  52  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02313948]\n",
      "corr(x1_hat, beta_true) =  0.918329064659388\n",
      "l2 error for x1_hat =  0.399741840000094\n",
      "B / (A+B) =  [0.03801402]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8915129029049066\n",
      "alpha1 part I =  [0.03388999]\n",
      "alpha2 part II =  [0.05372475]\n",
      "alpha1 =  0.12275336668163497\n",
      "true gam2 =  82.22862688494178\n",
      "gam2 =  58.72700361538572\n",
      "corr(z1_hat, X*beta_true) =  0.9907458125846881\n",
      "l2 error for z1_hat =  0.5413794532653253\n",
      "v1 =  0.45313120634230414\n",
      "true tau2 =  192.4157122667878\n",
      "tau2 = 333.8587672934116\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.93371348]]\n",
      "l2 error for x2_hat =  0.36881592420055465\n",
      "alpha2 =  0.4491783044335165\n",
      "true gam1 =  51.153683289137454\n",
      "gam1 =  72.01618463688212\n",
      "corr(z2_hat, beta_true) =  [[0.99329045]]\n",
      "l2 error for z2_hat =  0.2942340189063574\n",
      "true tau1 =  262.8649048769064\n",
      "tau1 =  272.25164916369624\n",
      "\n",
      "\n",
      "**** iteration =  53  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00724865]\n",
      "corr(x1_hat, beta_true) =  0.9828948982884279\n",
      "l2 error for x1_hat =  0.18849981091676976\n",
      "B / (A+B) =  [0.00733951]\n",
      "gam1 / (gam1 + 1/sigma) =  0.986304406276867\n",
      "alpha1 part I =  [0.00723899]\n",
      "alpha2 part II =  [0.00262517]\n",
      "alpha1 =  0.16734859803690927\n",
      "true gam2 =  376.252251457589\n",
      "gam2 =  358.3201640488638\n",
      "corr(z1_hat, X*beta_true) =  0.9911104985282012\n",
      "l2 error for z1_hat =  0.3176708441412295\n",
      "v1 =  0.9469441951063499\n",
      "true tau2 =  258.79105710327286\n",
      "tau2 = 15.25383486656393\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97879134]]\n",
      "l2 error for x2_hat =  0.2104658973352468\n",
      "alpha2 =  0.9792227353510866\n",
      "true gam1 =  99.29387546637307\n",
      "gam1 =  7.602879925797508\n",
      "corr(z2_hat, beta_true) =  [[0.98894824]]\n",
      "l2 error for z2_hat =  0.6080669316703566\n",
      "true tau1 =  711.6148272021281\n",
      "tau1 =  718.906080999054\n",
      "\n",
      "\n",
      "**** iteration =  54  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.14905601]\n",
      "corr(x1_hat, beta_true) =  0.8354984730040123\n",
      "l2 error for x1_hat =  0.683291388303222\n",
      "B / (A+B) =  [0.19706139]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8837598561615054\n",
      "alpha1 part I =  [0.17415495]\n",
      "alpha2 part II =  [0.73154352]\n",
      "alpha1 =  0.4583234935587619\n",
      "true gam2 =  17.917111669945587\n",
      "gam2 =  8.985577861437303\n",
      "corr(z1_hat, X*beta_true) =  0.9905793216622726\n",
      "l2 error for z1_hat =  0.5516189806976931\n",
      "v1 =  0.8222574528286317\n",
      "true tau2 =  99.0028037159478\n",
      "tau2 = 155.40169027861492\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.82369803]]\n",
      "l2 error for x2_hat =  0.6919393763959967\n",
      "alpha2 =  0.29228461236631026\n",
      "true gam1 =  19.74316226031963\n",
      "gam1 =  21.756984289511603\n",
      "corr(z2_hat, beta_true) =  [[0.98881903]]\n",
      "l2 error for z2_hat =  0.33748002586715886\n",
      "true tau1 =  72.73383761171223\n",
      "tau1 =  64.18049345518025\n",
      "\n",
      "\n",
      "**** iteration =  55  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04246751]\n",
      "corr(x1_hat, beta_true) =  0.9164600894498212\n",
      "l2 error for x1_hat =  0.41985787099437194\n",
      "B / (A+B) =  [0.01466479]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9560574464842037\n",
      "alpha1 part I =  [0.01402038]\n",
      "alpha2 part II =  [0.0082707]\n",
      "alpha1 =  0.28204495362251103\n",
      "true gam2 =  64.78077795118969\n",
      "gam2 =  55.38314536028582\n",
      "corr(z1_hat, X*beta_true) =  0.9879398354277498\n",
      "l2 error for z1_hat =  0.4251782867644644\n",
      "v1 =  0.8050915764506581\n",
      "true tau2 =  48.613689607626576\n",
      "tau2 = 15.537758893363234\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.90505827]]\n",
      "l2 error for x2_hat =  0.44532297774852575\n",
      "alpha2 =  0.8917353679783818\n",
      "true gam1 =  33.16517188398427\n",
      "gam1 =  6.724008117144116\n",
      "corr(z2_hat, beta_true) =  [[0.9801216]]\n",
      "l2 error for z2_hat =  0.8177950502711697\n",
      "true tau1 =  148.82415344518776\n",
      "tau1 =  127.97872108008433\n",
      "\n",
      "\n",
      "**** iteration =  56  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0251023]\n",
      "corr(x1_hat, beta_true) =  0.9203317207200198\n",
      "l2 error for x1_hat =  0.3916393489917433\n",
      "B / (A+B) =  [0.03091415]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8705335384383645\n",
      "alpha1 part I =  [0.02691181]\n",
      "alpha2 part II =  [0.02719954]\n",
      "alpha1 =  0.12264768248206945\n",
      "true gam2 =  85.57127246072841\n",
      "gam2 =  48.099760103075916\n",
      "corr(z1_hat, X*beta_true) =  0.9854108764765944\n",
      "l2 error for z1_hat =  0.6948609997354129\n",
      "v1 =  0.7273835201192221\n",
      "true tau2 =  69.22208284762321\n",
      "tau2 = 47.96521707665026\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.93419219]]\n",
      "l2 error for x2_hat =  0.3569043836201914\n",
      "alpha2 =  0.738140789474944\n",
      "true gam1 =  20.895713010251747\n",
      "gam1 =  17.063635266647992\n",
      "corr(z2_hat, beta_true) =  [[0.99009333]]\n",
      "l2 error for z2_hat =  0.39098148539617616\n",
      "true tau1 =  274.049152989638\n",
      "tau1 =  135.20656053802605\n",
      "\n",
      "\n",
      "**** iteration =  57  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.12094964]\n",
      "corr(x1_hat, beta_true) =  0.9693913056538035\n",
      "l2 error for x1_hat =  0.26942924216894165\n",
      "B / (A+B) =  [0.02488753]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9446401576848509\n",
      "alpha1 part I =  [0.02350976]\n",
      "alpha2 part II =  [0.03315838]\n",
      "alpha1 =  0.14210072398479373\n",
      "true gam2 =  194.20016379480325\n",
      "gam2 =  103.01763376667502\n",
      "corr(z1_hat, X*beta_true) =  0.9874424282107173\n",
      "l2 error for z1_hat =  0.4414181571364084\n",
      "v1 =  0.9237544789549125\n",
      "true tau2 =  163.7021818794487\n",
      "tau2 = 11.159777724270317\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9643493]]\n",
      "l2 error for x2_hat =  0.2885068409970269\n",
      "alpha2 =  0.9517013914276978\n",
      "true gam1 =  62.6355911181505\n",
      "gam1 =  5.228119254798232\n",
      "corr(z2_hat, beta_true) =  [[0.98268156]]\n",
      "l2 error for z2_hat =  1.021537879982761\n",
      "true tau1 =  419.99561040711814\n",
      "tau1 =  219.89817723864178\n",
      "\n",
      "\n",
      "**** iteration =  58  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.08482861]\n",
      "corr(x1_hat, beta_true) =  0.842222530629797\n",
      "l2 error for x1_hat =  0.6070149392937819\n",
      "B / (A+B) =  [0.09982787]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8394378850036331\n",
      "alpha1 part I =  [0.0837993]\n",
      "alpha2 part II =  [0.25041569]\n",
      "alpha1 =  0.24962645023740915\n",
      "true gam2 =  33.07877364881966\n",
      "gam2 =  15.715651927406174\n",
      "corr(z1_hat, X*beta_true) =  0.986504911427156\n",
      "l2 error for z1_hat =  0.7883419271611487\n",
      "v1 =  0.7491425294520482\n",
      "true tau2 =  37.75256524947851\n",
      "tau2 = 73.63498713727986\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.80456256]]\n",
      "l2 error for x2_hat =  0.6943335501042707\n",
      "alpha2 =  0.4804394286039957\n",
      "true gam1 =  11.602214583204706\n",
      "gam1 =  16.995343448370676\n",
      "corr(z2_hat, beta_true) =  [[0.9788994]]\n",
      "l2 error for z2_hat =  0.2385978362412565\n",
      "true tau1 =  71.74542572145604\n",
      "tau1 =  68.09052320972441\n",
      "\n",
      "\n",
      "**** iteration =  59  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01929541]\n",
      "corr(x1_hat, beta_true) =  0.8645317764015125\n",
      "l2 error for x1_hat =  0.5460500944644381\n",
      "B / (A+B) =  [0.02679346]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9444300686525356\n",
      "alpha1 part I =  [0.02530455]\n",
      "alpha2 part II =  [0.03925752]\n",
      "alpha1 =  0.2120190824548677\n",
      "true gam2 =  49.637764875481864\n",
      "gam2 =  63.164155647605554\n",
      "corr(z1_hat, X*beta_true) =  0.980573822343132\n",
      "l2 error for z1_hat =  0.31777097628445417\n",
      "v1 =  0.9296508067786253\n",
      "true tau2 =  65.43832108601512\n",
      "tau2 = 5.152594220214615\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.85212857]]\n",
      "l2 error for x2_hat =  0.5766980347454028\n",
      "alpha2 =  0.962523113627351\n",
      "true gam1 =  19.340055596882756\n",
      "gam1 =  2.4593652355096687\n",
      "corr(z2_hat, beta_true) =  [[0.96130916]]\n",
      "l2 error for z2_hat =  2.0638232416813427\n",
      "true tau1 =  89.43200980077798\n",
      "tau1 =  132.33466043002835\n",
      "\n",
      "\n",
      "**** iteration =  60  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.41656799]\n",
      "corr(x1_hat, beta_true) =  0.619195732501755\n",
      "l2 error for x1_hat =  1.3938648074945248\n",
      "B / (A+B) =  [0.20686735]\n",
      "gam1 / (gam1 + 1/sigma) =  0.7109296267028393\n",
      "alpha1 part I =  [0.14706813]\n",
      "alpha2 part II =  [0.51815108]\n",
      "alpha1 =  0.6978922989840237\n",
      "true gam2 =  3.5158808107420825\n",
      "gam2 =  1.064624410299518\n",
      "corr(z1_hat, X*beta_true) =  0.9762666377257321\n",
      "l2 error for z1_hat =  1.2326106472196992\n",
      "v1 =  0.3686473201563153\n",
      "true tau2 =  221.38457764819896\n",
      "tau2 = 226.63895254487483\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.7179363]]\n",
      "l2 error for x2_hat =  0.9728068031722497\n",
      "alpha2 =  0.09463765335018832\n",
      "true gam1 =  14.897942637428153\n",
      "gam1 =  10.184855818886652\n",
      "corr(z2_hat, beta_true) =  [[0.98536784]]\n",
      "l2 error for z2_hat =  0.7581247807424676\n",
      "true tau1 =  40.53207329733139\n",
      "tau1 =  23.690601565174024\n",
      "\n",
      "\n",
      "**** iteration =  61  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01230432]\n",
      "corr(x1_hat, beta_true) =  0.8845687761404422\n",
      "l2 error for x1_hat =  0.4929897078946667\n",
      "B / (A+B) =  [0.01918405]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9105933937645035\n",
      "alpha1 part I =  [0.01746887]\n",
      "alpha2 part II =  [0.00745022]\n",
      "alpha1 =  0.2029001498590292\n",
      "true gam2 =  56.86850998953037\n",
      "gam2 =  40.011537953926606\n",
      "corr(z1_hat, X*beta_true) =  0.9738730978820154\n",
      "l2 error for z1_hat =  0.8524851838125262\n",
      "v1 =  0.8909052034413452\n",
      "true tau2 =  173.55698405623517\n",
      "tau2 = 2.9010060196319953\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.86405739]]\n",
      "l2 error for x2_hat =  0.5320181975003261\n",
      "alpha2 =  0.9663044771724648\n",
      "true gam1 =  37.836543064333455\n",
      "gam1 =  1.3952224400701991\n",
      "corr(z2_hat, beta_true) =  [[0.9713388]]\n",
      "l2 error for z2_hat =  1.2989749611475734\n",
      "true tau1 =  123.81107425538171\n",
      "tau1 =  83.19369666476624\n",
      "\n",
      "\n",
      "**** iteration =  62  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.1765627]\n",
      "corr(x1_hat, beta_true) =  0.6972132739775192\n",
      "l2 error for x1_hat =  0.7423166370148102\n",
      "B / (A+B) =  [0.12430666]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5825022414324524\n",
      "alpha1 part I =  [0.07240891]\n",
      "alpha2 part II =  [0.18120898]\n",
      "alpha1 =  0.2402004732199807\n",
      "true gam2 =  32.008193557032286\n",
      "gam2 =  4.413352461413965\n",
      "corr(z1_hat, X*beta_true) =  0.9738575442611054\n",
      "l2 error for z1_hat =  1.2403889531224184\n",
      "v1 =  0.8496808967188226\n",
      "true tau2 =  101.07142757428284\n",
      "tau2 = 14.717998168002012\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.86983084]]\n",
      "l2 error for x2_hat =  0.4937040687651197\n",
      "alpha2 =  0.5372655647217992\n",
      "true gam1 =  21.83629994601261\n",
      "gam1 =  3.8011186515806625\n",
      "corr(z2_hat, beta_true) =  [[0.9780081]]\n",
      "l2 error for z2_hat =  0.9332361020754376\n",
      "true tau1 =  138.56658090179184\n",
      "tau1 =  17.0885782307339\n",
      "\n",
      "\n",
      "**** iteration =  63  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04940265]\n",
      "corr(x1_hat, beta_true) =  0.8676676900290644\n",
      "l2 error for x1_hat =  0.5038413425788805\n",
      "B / (A+B) =  [0.03571565]\n",
      "gam1 / (gam1 + 1/sigma) =  0.7917152079399722\n",
      "alpha1 part I =  [0.02827662]\n",
      "alpha2 part II =  [0.02361657]\n",
      "alpha1 =  0.11124747194762165\n",
      "true gam2 =  49.60516172510427\n",
      "gam2 =  30.367016453281163\n",
      "corr(z1_hat, X*beta_true) =  0.9740302216331997\n",
      "l2 error for z1_hat =  1.0783964193605862\n",
      "v1 =  0.815037928708356\n",
      "true tau2 =  47.389371804536594\n",
      "tau2 = 3.8780266704825253\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.83812102]]\n",
      "l2 error for x2_hat =  0.5468361251097006\n",
      "alpha2 =  0.944155181799096\n",
      "true gam1 =  19.38791687652881\n",
      "gam1 =  1.7961459576019159\n",
      "corr(z2_hat, beta_true) =  [[0.95911285]]\n",
      "l2 error for z2_hat =  1.7199907837367692\n",
      "true tau1 =  104.37977222752795\n",
      "tau1 =  65.56488308223912\n",
      "\n",
      "\n",
      "**** iteration =  64  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.09404697]\n",
      "corr(x1_hat, beta_true) =  0.7999485474813698\n",
      "l2 error for x1_hat =  0.659205655793681\n",
      "B / (A+B) =  [0.08955704]\n",
      "gam1 / (gam1 + 1/sigma) =  0.6423648782420359\n",
      "alpha1 part I =  [0.0575283]\n",
      "alpha2 part II =  [0.11936591]\n",
      "alpha1 =  0.19702709115307585\n",
      "true gam2 =  32.81458856175628\n",
      "gam2 =  7.320092561122598\n",
      "corr(z1_hat, X*beta_true) =  0.9643633974473743\n",
      "l2 error for z1_hat =  1.5908477515673378\n",
      "v1 =  0.8451290940912469\n",
      "true tau2 =  31.192128355764307\n",
      "tau2 = 12.01484235928048\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.8816552]]\n",
      "l2 error for x2_hat =  0.5305211051500885\n",
      "alpha2 =  0.657966500401238\n",
      "true gam1 =  7.925189157699978\n",
      "gam1 =  3.805234574314682\n",
      "corr(z2_hat, beta_true) =  [[0.98562215]]\n",
      "l2 error for z2_hat =  0.9173069990678525\n",
      "true tau1 =  124.22277523841792\n",
      "tau1 =  23.112834822560014\n",
      "\n",
      "\n",
      "**** iteration =  65  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.10699817]\n",
      "corr(x1_hat, beta_true) =  0.9255074483594281\n",
      "l2 error for x1_hat =  0.48813303963059956\n",
      "B / (A+B) =  [0.04664001]\n",
      "gam1 / (gam1 + 1/sigma) =  0.7918936142378401\n",
      "alpha1 part I =  [0.03693393]\n",
      "alpha2 part II =  [0.05012389]\n",
      "alpha1 =  0.12992373028216905\n",
      "true gam2 =  64.46585716870021\n",
      "gam2 =  25.482983721530527\n",
      "corr(z1_hat, X*beta_true) =  0.9772676164320351\n",
      "l2 error for z1_hat =  1.0959423251532199\n",
      "v1 =  0.910082676399141\n",
      "true tau2 =  50.989102405087316\n",
      "tau2 = 2.2835774177090946\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.89770358]]\n",
      "l2 error for x2_hat =  0.5441992976854817\n",
      "alpha2 =  0.9592211024049615\n",
      "true gam1 =  21.14957601062508\n",
      "gam1 =  1.0833456238513954\n",
      "corr(z2_hat, beta_true) =  [[0.96102538]]\n",
      "l2 error for z2_hat =  2.8876500381393884\n",
      "true tau1 =  116.79518453620754\n",
      "tau1 =  53.71542089721675\n",
      "\n",
      "\n",
      "**** iteration =  66  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.2656968]\n",
      "corr(x1_hat, beta_true) =  0.566470535871011\n",
      "l2 error for x1_hat =  0.9530615843982136\n",
      "B / (A+B) =  [0.15779803]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5200028317186559\n",
      "alpha1 part I =  [0.08205542]\n",
      "alpha2 part II =  [0.22621877]\n",
      "alpha1 =  0.30005444368268147\n",
      "true gam2 =  21.431177834389818\n",
      "gam2 =  2.5271512265037783\n",
      "corr(z1_hat, X*beta_true) =  0.9685390905483993\n",
      "l2 error for z1_hat =  1.9985724257895743\n",
      "v1 =  0.7741838013696384\n",
      "true tau2 =  12.762548855730119\n",
      "tau2 = 15.667871290228572\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.5166765]]\n",
      "l2 error for x2_hat =  1.164953787785151\n",
      "alpha2 =  0.4354761115957922\n",
      "true gam1 =  4.229550884713464\n",
      "gam1 =  3.276040175300309\n",
      "corr(z2_hat, beta_true) =  [[0.01970228]]\n",
      "l2 error for z2_hat =  1.1194234178927196\n",
      "true tau1 =  25.42031511469325\n",
      "tau1 =  12.086262081378429\n",
      "\n",
      "\n",
      "**** iteration =  67  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.06496713]\n",
      "corr(x1_hat, beta_true) =  0.651295865379075\n",
      "l2 error for x1_hat =  0.8019726006090602\n",
      "B / (A+B) =  [0.04005138]\n",
      "gam1 / (gam1 + 1/sigma) =  0.7661387734904128\n",
      "alpha1 part I =  [0.03068491]\n",
      "alpha2 part II =  [0.02911638]\n",
      "alpha1 =  0.1544654102797548\n",
      "true gam2 =  23.841372212772495\n",
      "gam2 =  17.93285163657537\n",
      "corr(z1_hat, X*beta_true) =  0.6656173360809531\n",
      "l2 error for z1_hat =  0.7565110227497082\n",
      "v1 =  0.9810900175450985\n",
      "true tau2 =  73.22345824716876\n",
      "tau2 = 0.23295620158901614\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.35128692]]\n",
      "l2 error for x2_hat =  1.742769143969508\n",
      "alpha2 =  0.9927724851810033\n",
      "true gam1 =  0.2830732835652797\n",
      "gam1 =  0.13055352851221294\n",
      "corr(z2_hat, beta_true) =  [[0.9326542]]\n",
      "l2 error for z2_hat =  17.636993209797698\n",
      "true tau1 =  10.59467353224039\n",
      "tau1 =  31.998897682226715\n",
      "\n",
      "\n",
      "**** iteration =  68  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.7660868]\n",
      "corr(x1_hat, beta_true) =  0.085392559777024\n",
      "l2 error for x1_hat =  28.58347839467187\n",
      "B / (A+B) =  [1.]\n",
      "gam1 / (gam1 + 1/sigma) =  0.11547752956378714\n",
      "alpha1 part I =  [0.11547753]\n",
      "alpha2 part II =  [5.68281201e-11]\n",
      "alpha1 =  0.1154775298339559\n",
      "true gam2 =  16.495735850084863\n",
      "gam2 =  0.9999999973549811\n",
      "corr(z1_hat, X*beta_true) =  0.9420161723880499\n",
      "l2 error for z1_hat =  8.517169783081766\n",
      "v1 =  0.09217281280935292\n",
      "true tau2 =  288.9112430736986\n",
      "tau2 = 315.16309843057644\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.53581807]]\n",
      "l2 error for x2_hat =  1.5445919135172126\n",
      "alpha2 =  0.07852624260322004\n",
      "true gam1 =  7.160729492594661\n",
      "gam1 =  11.734596287963466\n",
      "corr(z2_hat, beta_true) =  [[0.94387856]]\n",
      "l2 error for z2_hat =  7.59392962196951\n",
      "true tau1 =  15.125485015251916\n",
      "tau1 =  26.857600369280412\n",
      "\n",
      "\n",
      "**** iteration =  69  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0083106]\n",
      "corr(x1_hat, beta_true) =  0.760775818619716\n",
      "l2 error for x1_hat =  0.7467834645544013\n",
      "B / (A+B) =  [0.07737893]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9214737572053867\n",
      "alpha1 part I =  [0.07130265]\n",
      "alpha2 part II =  [0.22868246]\n",
      "alpha1 =  0.28093645420887653\n",
      "true gam2 =  24.050356471620816\n",
      "gam2 =  30.03497868943972\n",
      "corr(z1_hat, X*beta_true) =  0.9417113583249985\n",
      "l2 error for z1_hat =  7.6078976795928694\n",
      "v1 =  0.998054525941043\n",
      "true tau2 =  276.763623506356\n",
      "tau2 = 0.05235261545956286\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68446789]]\n",
      "l2 error for x2_hat =  0.8844204801563865\n",
      "alpha2 =  0.9985774555143911\n",
      "true gam1 =  0.2563272890893657\n",
      "gam1 =  0.04278695966356737\n",
      "corr(z2_hat, beta_true) =  [[0.9484808]]\n",
      "l2 error for z2_hat =  3.6778252852698543\n",
      "true tau1 =  41.704293988057564\n",
      "tau1 =  36.74974109000066\n",
      "\n",
      "\n",
      "**** iteration =  70  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.62354211]\n",
      "corr(x1_hat, beta_true) =  0.09388790440675204\n",
      "l2 error for x1_hat =  7.692702614874521\n",
      "B / (A+B) =  [0.70292216]\n",
      "gam1 / (gam1 + 1/sigma) =  0.041031352825290086\n",
      "alpha1 part I =  [0.02884185]\n",
      "alpha2 part II =  [0.06557539]\n",
      "alpha1 =  0.09352706467260404\n",
      "true gam2 =  16.48968446955656\n",
      "gam2 =  0.4146951586232105\n",
      "corr(z1_hat, X*beta_true) =  0.9484451436868819\n",
      "l2 error for z1_hat =  3.6933973544458762\n",
      "v1 =  0.9969926650128051\n",
      "true tau2 =  274.70988691106055\n",
      "tau2 = 0.11085215170453823\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.19825852]]\n",
      "l2 error for x2_hat =  1.306796244135352\n",
      "alpha2 =  0.8958444628720091\n",
      "true gam1 =  0.5702674069521562\n",
      "gam1 =  0.04821461624298602\n",
      "corr(z2_hat, beta_true) =  [[0.93146636]]\n",
      "l2 error for z2_hat =  9.512143916323447\n",
      "true tau1 =  18.02093879070587\n",
      "tau1 =  0.9534422176703542\n",
      "\n",
      "\n",
      "**** iteration =  71  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.46873322]\n",
      "corr(x1_hat, beta_true) =  0.11077568726520001\n",
      "l2 error for x1_hat =  2.354293340312378\n",
      "B / (A+B) =  [0.27908624]\n",
      "gam1 / (gam1 + 1/sigma) =  0.045996893666486925\n",
      "alpha1 part I =  [0.0128371]\n",
      "alpha2 part II =  [0.03736915]\n",
      "alpha1 =  0.050290354037698846\n",
      "true gam2 =  16.583707256644928\n",
      "gam2 =  0.9105103155171523\n",
      "corr(z1_hat, X*beta_true) =  0.9463220442301224\n",
      "l2 error for z1_hat =  5.272534661784444\n",
      "v1 =  0.4990097438144023\n",
      "true tau2 =  33.64200281433671\n",
      "tau2 = 0.9572263203471517\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.76977988]]\n",
      "l2 error for x2_hat =  0.6492991184860395\n",
      "alpha2 =  0.7300177268157413\n",
      "true gam1 =  5.920362651336687\n",
      "gam1 =  0.33673380208626574\n",
      "corr(z2_hat, beta_true) =  [[0.9688685]]\n",
      "l2 error for z2_hat =  1.1068727576248034\n",
      "true tau1 =  64.61372706445817\n",
      "tau1 =  2.5882891279721516\n",
      "\n",
      "\n",
      "**** iteration =  72  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.14096538]\n",
      "corr(x1_hat, beta_true) =  0.47840295686135526\n",
      "l2 error for x1_hat =  0.8904078625249772\n",
      "B / (A+B) =  [0.09830165]\n",
      "gam1 / (gam1 + 1/sigma) =  0.2519078978632237\n",
      "alpha1 part I =  [0.02476296]\n",
      "alpha2 part II =  [0.03899999]\n",
      "alpha1 =  0.07508648235714072\n",
      "true gam2 =  21.058989446293776\n",
      "gam2 =  4.147879027219386\n",
      "corr(z1_hat, X*beta_true) =  0.9511238792384792\n",
      "l2 error for z1_hat =  1.5201724075655263\n",
      "v1 =  0.9602872244139711\n",
      "true tau2 =  209.1274036922851\n",
      "tau2 = 0.1070389594671995\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.21721657]]\n",
      "l2 error for x2_hat =  1.2858439643561144\n",
      "alpha2 =  0.9867841432616867\n",
      "true gam1 =  0.7606725215703575\n",
      "gam1 =  0.055551941491877435\n",
      "corr(z2_hat, beta_true) =  [[0.93084086]]\n",
      "l2 error for z2_hat =  10.884510373777264\n",
      "true tau1 =  19.00327473694053\n",
      "tau1 =  7.992243711847593\n",
      "\n",
      "\n",
      "**** iteration =  73  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.46434247]\n",
      "corr(x1_hat, beta_true) =  0.11429234694504196\n",
      "l2 error for x1_hat =  2.312994257053576\n",
      "B / (A+B) =  [0.27694021]\n",
      "gam1 / (gam1 + 1/sigma) =  0.05262833528908337\n",
      "alpha1 part I =  [0.0145749]\n",
      "alpha2 part II =  [0.0424024]\n",
      "alpha1 =  0.05676692597416806\n",
      "true gam2 =  16.626256768983716\n",
      "gam2 =  0.9230450238811726\n",
      "corr(z1_hat, X*beta_true) =  0.9394393263980958\n",
      "l2 error for z1_hat =  7.704337830721028\n",
      "v1 =  0.43602540335871537\n",
      "true tau2 =  228.00766335413968\n",
      "tau2 = 10.337522513429937\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.71529754]]\n",
      "l2 error for x2_hat =  0.8138217621612707\n",
      "alpha2 =  0.34834136203300053\n",
      "true gam1 =  16.66966736388554\n",
      "gam1 =  1.7267839211917553\n",
      "corr(z2_hat, beta_true) =  [[0.94880246]]\n",
      "l2 error for z2_hat =  5.251924899641056\n",
      "true tau1 =  54.247977308876585\n",
      "tau1 =  5.525878830685196\n",
      "\n",
      "\n",
      "**** iteration =  74  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.05713719]\n",
      "corr(x1_hat, beta_true) =  0.7773993617681231\n",
      "l2 error for x1_hat =  0.6312379777446855\n",
      "B / (A+B) =  [0.05146133]\n",
      "gam1 / (gam1 + 1/sigma) =  0.6332676042907923\n",
      "alpha1 part I =  [0.03258879]\n",
      "alpha2 part II =  [0.03288442]\n",
      "alpha1 =  0.11625764865879477\n",
      "true gam2 =  34.25822635084533\n",
      "gam2 =  13.126294057872686\n",
      "corr(z1_hat, X*beta_true) =  0.9440779805260336\n",
      "l2 error for z1_hat =  5.269692403007277\n",
      "v1 =  0.986369917310467\n",
      "true tau2 =  283.2679274352668\n",
      "tau2 = 0.07635896439334774\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.60781555]]\n",
      "l2 error for x2_hat =  0.824419444826676\n",
      "alpha2 =  0.9962953793594744\n",
      "true gam1 =  0.3756039034735241\n",
      "gam1 =  0.04880875783210651\n",
      "corr(z2_hat, beta_true) =  [[0.93893127]]\n",
      "l2 error for z2_hat =  5.192983119368417\n",
      "true tau1 =  46.93804077644621\n",
      "tau1 =  20.535458493524505\n",
      "\n",
      "\n",
      "**** iteration =  75  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.27815131]\n",
      "corr(x1_hat, beta_true) =  0.0983770940940126\n",
      "l2 error for x1_hat =  6.1434978632413335\n",
      "B / (A+B) =  [0.60045787]\n",
      "gam1 / (gam1 + 1/sigma) =  0.04653732862890512\n",
      "alpha1 part I =  [0.02794371]\n",
      "alpha2 part II =  [0.07537593]\n",
      "alpha1 =  0.10215453189696419\n",
      "true gam2 =  16.526121769517445\n",
      "gam2 =  0.42898460997791227\n",
      "corr(z1_hat, X*beta_true) =  0.9398289875610184\n",
      "l2 error for z1_hat =  5.212146230740366\n",
      "v1 =  0.9689121248371352\n",
      "true tau2 =  12.956242433526462\n",
      "tau2 = 0.6588871722151184\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.6119321]]\n",
      "l2 error for x2_hat =  1.015889680268233\n",
      "alpha2 =  0.6690320207259759\n",
      "true gam1 =  2.1058284740606683\n",
      "gam1 =  0.21221730067565428\n",
      "corr(z2_hat, beta_true) =  [[0.94798124]]\n",
      "l2 error for z2_hat =  5.929404838104696\n",
      "true tau1 =  33.70178952796136\n",
      "tau1 =  1.3319011018057785\n",
      "\n",
      "\n",
      "**** iteration =  76  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.40107277]\n",
      "corr(x1_hat, beta_true) =  0.2975651480219489\n",
      "l2 error for x1_hat =  1.5653116197218289\n",
      "B / (A+B) =  [0.21093426]\n",
      "gam1 / (gam1 + 1/sigma) =  0.1750653950882986\n",
      "alpha1 part I =  [0.03692729]\n",
      "alpha2 part II =  [0.10031427]\n",
      "alpha1 =  0.13756579520855916\n",
      "true gam2 =  17.499691099069473\n",
      "gam2 =  1.330443070341126\n",
      "corr(z1_hat, X*beta_true) =  0.9483170569640392\n",
      "l2 error for z1_hat =  5.457858719193263\n",
      "v1 =  0.9887300809906355\n",
      "true tau2 =  0.005121961769879598\n",
      "tau2 = 0.015181511956018452\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.02154579]]\n",
      "l2 error for x2_hat =  2.565697737704385\n",
      "alpha2 =  0.993530448667631\n",
      "true gam1 =  0.005765024241119007\n",
      "gam1 =  0.008663418166911198\n",
      "corr(z2_hat, beta_true) =  [[-0.92770254]]\n",
      "l2 error for z2_hat =  27.818626161829894\n",
      "true tau1 =  5.90544654988119\n",
      "tau1 =  2.331428194973881\n",
      "\n",
      "\n",
      "**** iteration =  77  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04501056]\n",
      "corr(x1_hat, beta_true) =  0.2716105062241582\n",
      "l2 error for x1_hat =  0.9661337929218579\n",
      "B / (A+B) =  [0.0586262]\n",
      "gam1 / (gam1 + 1/sigma) =  0.008589007998977114\n",
      "alpha1 part I =  [0.00050354]\n",
      "alpha2 part II =  [0.00016363]\n",
      "alpha1 =  0.0007982411220683627\n",
      "true gam2 =  16.931689187172122\n",
      "gam2 =  10.844470963663706\n",
      "corr(z1_hat, X*beta_true) =  -0.9287045274462818\n",
      "l2 error for z1_hat =  26.890584940786383\n",
      "v1 =  0.9999999867124635\n",
      "true tau2 =  47.58690323949256\n",
      "tau2 = 3.0978937685678794e-08\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.08244243]]\n",
      "l2 error for x2_hat =  9.070675028795035\n",
      "alpha2 =  0.9999999968030638\n",
      "true gam1 =  2.217163941646517e-15\n",
      "gam1 =  3.466908147328229e-08\n",
      "corr(z2_hat, beta_true) =  [[0.92895097]]\n",
      "l2 error for z2_hat =  103.47547650557294\n",
      "true tau1 =  0.42205985738790497\n",
      "tau1 =  9.690195873126635\n",
      "\n",
      "\n",
      "**** iteration =  78  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  3.466908027133712e-08\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanders/vampW/tteVAMP/denoisers.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio = gam1 * r / (gam1 + 1/prior.sigmas[0]) * B / (A + B)\n",
      "/Users/alexanders/vampW/tteVAMP/denoisers.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  print(\"B / (A+B) = \", B[1] / (A[1]+B[1]))\n",
      "/Users/alexanders/vampW/tteVAMP/denoisers.py:30: RuntimeWarning: invalid value encountered in divide\n",
      "  BoverAplusBder = ( Bder * A - Ader * B ) / (A+B) / (A+B)\n",
      "/Users/alexanders/vampW/tteVAMP/denoisers.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  print(\"alpha1 part I = \", gam1 / (gam1 + 1/prior.sigmas[0]) * B[1] / (A[1] + B[1]))\n",
      "/Users/alexanders/vampW/tteVAMP/denoisers.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio = gam1 / (gam1 + 1/prior.sigmas[0]) * B / (A + B) + BoverAplusBder * r * gam1 / (gam1 + 1.0/prior.sigmas[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr(z1_hat, X*beta_true) =  -0.9185912429719091\n",
      "l2 error for z1_hat =  14.423507577329502\n",
      "v1 =  1.100229943419886e-08\n",
      "true tau2 =  248.75619691163973\n",
      "tau2 = 880742777.8589447\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  79  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  80  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  81  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  82  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  83  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  84  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  85  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  86  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  87  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  88  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  89  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  90  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  91  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  92  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  93  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  94  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  95  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  96  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  97  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  98  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "**** iteration =  99  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [nan]\n",
      "corr(x1_hat, beta_true) =  nan\n",
      "l2 error for x1_hat =  nan\n",
      "B / (A+B) =  [nan]\n",
      "gam1 / (gam1 + 1/sigma) =  nan\n",
      "alpha1 part I =  [nan]\n",
      "alpha2 part II =  [nan]\n",
      "alpha1 =  nan\n",
      "true gam2 =  nan\n",
      "gam2 =  nan\n",
      "corr(z1_hat, X*beta_true) =  nan\n",
      "l2 error for z1_hat =  nan\n",
      "v1 =  nan\n",
      "true tau2 =  nan\n",
      "tau2 = nan\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[nan]]\n",
      "l2 error for x2_hat =  nan\n",
      "alpha2 =  nan\n",
      "true gam1 =  nan\n",
      "gam1 =  nan\n",
      "corr(z2_hat, beta_true) =  [[nan]]\n",
      "l2 error for z2_hat =  nan\n",
      "true tau1 =  nan\n",
      "tau1 =  nan\n",
      "\n",
      "\n",
      "Saving results!!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=800\n",
    "p=0.4\n",
    "la=0.05\n",
    "# This is where the sigma is defined. Note that the scope of this definition extends to gvamp\n",
    "sigma=1\n",
    "omega=1\n",
    "h2=0.9\n",
    "gam1 = 1e-2\n",
    "tau1 = 1e-1\n",
    "mu=np.full((n,1), 0) \n",
    "maxiter = 100\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, True, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954a1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weibull\n",
      "gam1 =  0.01\n",
      "tau1 =  0.1\n",
      "alpha =  21.3610066663135\n",
      "s.shape =  (800,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.]\n",
      "B / (A+B) =  [0.04976421]\n",
      "gam1 / (gam1 + 1/sigma) =  0.009900990099009901\n",
      "alpha1 part I =  [0.00049271]\n",
      "alpha2 part II =  [0.]\n",
      "alpha1 =  0.0004927149309449356\n",
      "true gam2 =  16.495735851994617\n",
      "gam2 =  20.28571131693099\n",
      "corr(z1_hat, X*beta_true) =  0.032437375494478796\n",
      "l2 error for z1_hat =  0.9994786709641467\n",
      "v1 =  0.642190379494197\n",
      "true tau2 =  26.01344837018179\n",
      "tau2 = 0.055717063339943154\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[-0.06388917]]\n",
      "l2 error for x2_hat =  1.0000468474923223\n",
      "alpha2 =  0.9979581889231127\n",
      "true gam1 =  14.712490678934254\n",
      "gam1 =  0.04150433407850765\n",
      "corr(z2_hat, beta_true) =  [[0.9255022]]\n",
      "l2 error for z2_hat =  0.9929889721125841\n",
      "true tau1 =  30.819569569750513\n",
      "tau1 =  27.23234301755808\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00013211]\n",
      "corr(x1_hat, beta_true) =  -0.06389025933547711\n",
      "l2 error for x1_hat =  1.0000448318393242\n",
      "B / (A+B) =  [0.04904299]\n",
      "gam1 / (gam1 + 1/sigma) =  0.039850370968671445\n",
      "alpha1 part I =  [0.00195438]\n",
      "alpha2 part II =  [1.31866464e-09]\n",
      "alpha1 =  0.0019544163747322076\n",
      "true gam2 =  16.495735856081993\n",
      "gam2 =  21.194673695894522\n",
      "corr(z1_hat, X*beta_true) =  0.9934623836293804\n",
      "l2 error for z1_hat =  0.12155999329776622\n",
      "v1 =  0.15095392135790509\n",
      "true tau2 =  279.4037271263297\n",
      "tau2 = 153.16935024479443\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.85432185]]\n",
      "l2 error for x2_hat =  0.528875657421918\n",
      "alpha2 =  0.41178848104208504\n",
      "true gam1 =  36.34989206753095\n",
      "gam1 =  30.275133429983804\n",
      "corr(z2_hat, beta_true) =  [[0.99282061]]\n",
      "l2 error for z2_hat =  0.15876654045839275\n",
      "true tau1 =  112.42836726765331\n",
      "tau1 =  107.22906989521192\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00204916]\n",
      "corr(x1_hat, beta_true) =  0.9763459070781174\n",
      "l2 error for x1_hat =  0.23033698279243225\n",
      "B / (A+B) =  [0.01016108]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9680257159497427\n",
      "alpha1 part I =  [0.00983618]\n",
      "alpha2 part II =  [0.00169163]\n",
      "alpha1 =  0.10485072723367689\n",
      "true gam2 =  275.2631966914324\n",
      "gam2 =  258.46996380249175\n",
      "corr(z1_hat, X*beta_true) =  0.9937372934312128\n",
      "l2 error for z1_hat =  0.13124445735094364\n",
      "v1 =  0.37066081736805884\n",
      "true tau2 =  301.6807617089731\n",
      "tau2 = 182.06255433583158\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97930988]]\n",
      "l2 error for x2_hat =  0.21144723201405013\n",
      "alpha2 =  0.7886171529156321\n",
      "true gam1 =  100.12214263344295\n",
      "gam1 =  69.2809135996682\n",
      "corr(z2_hat, beta_true) =  [[0.99818167]]\n",
      "l2 error for z2_hat =  0.08553281503033054\n",
      "true tau1 =  804.1950026263358\n",
      "tau1 =  679.2303880530374\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00170844]\n",
      "corr(x1_hat, beta_true) =  0.9895500116527345\n",
      "l2 error for x1_hat =  0.14422569492148854\n",
      "B / (A+B) =  [0.00829519]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9857713858744613\n",
      "alpha1 part I =  [0.00817716]\n",
      "alpha2 part II =  [0.00465377]\n",
      "alpha1 =  0.09028421149405558\n",
      "true gam2 =  692.8897066299025\n",
      "gam2 =  698.0837502012637\n",
      "corr(z1_hat, X*beta_true) =  0.9981511912004849\n",
      "l2 error for z1_hat =  0.08658058364860884\n",
      "v1 =  0.8422793165005475\n",
      "true tau2 =  359.66578032554276\n",
      "tau2 = 127.18902026754652\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98960512]]\n",
      "l2 error for x2_hat =  0.14382658324710137\n",
      "alpha2 =  0.9241182993373832\n",
      "true gam1 =  135.39130144015303\n",
      "gam1 =  57.321429743563556\n",
      "corr(z2_hat, beta_true) =  [[0.99864104]]\n",
      "l2 error for z2_hat =  0.07781478914214812\n",
      "true tau1 =  1666.9336831801575\n",
      "tau1 =  1548.959763390466\n",
      "\n",
      "\n",
      "**** iteration =  4  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00114068]\n",
      "corr(x1_hat, beta_true) =  0.9887890400452237\n",
      "l2 error for x1_hat =  0.1497703368955842\n",
      "B / (A+B) =  [0.00913654]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9828536439453396\n",
      "alpha1 part I =  [0.00897988]\n",
      "alpha2 part II =  [0.00518084]\n",
      "alpha1 =  0.07708498192778286\n",
      "true gam2 =  641.2640671555594\n",
      "gam2 =  686.2920253035583\n",
      "corr(z1_hat, X*beta_true) =  0.9987026530145581\n",
      "l2 error for z1_hat =  0.07569622229188422\n",
      "v1 =  0.8878280652293594\n",
      "true tau2 =  406.92813942649855\n",
      "tau2 = 195.70209632480598\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98910668]]\n",
      "l2 error for x2_hat =  0.1476511304322337\n",
      "alpha2 =  0.8903219353555315\n",
      "true gam1 =  153.0905915090115\n",
      "gam1 =  84.54377919619479\n",
      "corr(z2_hat, beta_true) =  [[0.99887604]]\n",
      "l2 error for z2_hat =  0.06400000923362036\n",
      "true tau1 =  1693.5989542434818\n",
      "tau1 =  1588.6300484772771\n",
      "\n",
      "\n",
      "**** iteration =  5  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00119258]\n",
      "corr(x1_hat, beta_true) =  0.9907112460466452\n",
      "l2 error for x1_hat =  0.1366607372327101\n",
      "B / (A+B) =  [0.00854076]\n",
      "gam1 / (gam1 + 1/sigma) =  0.988310079243676\n",
      "alpha1 part I =  [0.00844092]\n",
      "alpha2 part II =  [0.00693986]\n",
      "alpha1 =  0.08154439200248743\n",
      "true gam2 =  784.5558139721204\n",
      "gam2 =  952.2384828337418\n",
      "corr(z1_hat, X*beta_true) =  0.9988973740364043\n",
      "l2 error for z1_hat =  0.062899637111335\n",
      "v1 =  0.8761459890218378\n",
      "true tau2 =  402.37127307595443\n",
      "tau2 = 224.57239538813755\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99081479]]\n",
      "l2 error for x2_hat =  0.13591270057638924\n",
      "alpha2 =  0.905910562771025\n",
      "true gam1 =  156.7436055940863\n",
      "gam1 =  98.90113510051393\n",
      "corr(z2_hat, beta_true) =  [[0.9990881]]\n",
      "l2 error for z2_hat =  0.054534286540441214\n",
      "true tau1 =  2101.904706778614\n",
      "tau1 =  2162.2246989724194\n",
      "\n",
      "\n",
      "**** iteration =  6  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00084418]\n",
      "corr(x1_hat, beta_true) =  0.9917176215105817\n",
      "l2 error for x1_hat =  0.12929810117887103\n",
      "B / (A+B) =  [0.00677081]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9899901037261102\n",
      "alpha1 part I =  [0.00670304]\n",
      "alpha2 part II =  [0.00343787]\n",
      "alpha1 =  0.08153607651685502\n",
      "true gam2 =  881.0659881464175\n",
      "gam2 =  1114.07279405426\n",
      "corr(z1_hat, X*beta_true) =  0.9991002331233514\n",
      "l2 error for z1_hat =  0.053803734213885845\n",
      "v1 =  0.8920178425903935\n",
      "true tau2 =  419.3736966482939\n",
      "tau2 = 261.74553540471214\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99180794]]\n",
      "l2 error for x2_hat =  0.12857438006330132\n",
      "alpha2 =  0.9062020605594111\n",
      "true gam1 =  164.8364974715502\n",
      "gam1 =  115.31394268139408\n",
      "corr(z2_hat, beta_true) =  [[0.99919541]]\n",
      "l2 error for z2_hat =  0.04819532887494442\n",
      "true tau1 =  2335.597904223226\n",
      "tau1 =  2528.7798958122535\n",
      "\n",
      "\n",
      "**** iteration =  7  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00089818]\n",
      "corr(x1_hat, beta_true) =  0.9926532571845049\n",
      "l2 error for x1_hat =  0.12167195570690897\n",
      "B / (A+B) =  [0.00597042]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9914025784274273\n",
      "alpha1 part I =  [0.00591909]\n",
      "alpha2 part II =  [0.00244335]\n",
      "alpha1 =  0.08326297238199237\n",
      "true gam2 =  998.3525478348078\n",
      "gam2 =  1269.622715024733\n",
      "corr(z1_hat, X*beta_true) =  0.9991907703859155\n",
      "l2 error for z1_hat =  0.048997851134883114\n",
      "v1 =  0.9099674926066501\n",
      "true tau2 =  408.7506349732833\n",
      "tau2 = 250.19838237703595\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99266601]]\n",
      "l2 error for x2_hat =  0.12156709652141581\n",
      "alpha2 =  0.9189302456351419\n",
      "true gam1 =  164.53291668655143\n",
      "gam1 =  112.0085035093801\n",
      "corr(z2_hat, beta_true) =  [[0.99920392]]\n",
      "l2 error for z2_hat =  0.056864579903827865\n",
      "true tau1 =  2586.953588651818\n",
      "tau1 =  2836.0127988115346\n",
      "\n",
      "\n",
      "**** iteration =  8  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00090247]\n",
      "corr(x1_hat, beta_true) =  0.992907879205485\n",
      "l2 error for x1_hat =  0.11957145325608078\n",
      "B / (A+B) =  [0.00603253]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9911511083772825\n",
      "alpha1 part I =  [0.00597915]\n",
      "alpha2 part II =  [0.00242041]\n",
      "alpha1 =  0.0833282187192275\n",
      "true gam2 =  1030.4551021918717\n",
      "gam2 =  1232.1760384258093\n",
      "corr(z1_hat, X*beta_true) =  0.9992209236907379\n",
      "l2 error for z1_hat =  0.0562340803655217\n",
      "v1 =  0.8920380876653757\n",
      "true tau2 =  399.5946749825\n",
      "tau2 = 343.2379955507226\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99301681]]\n",
      "l2 error for x2_hat =  0.1186895273123794\n",
      "alpha2 =  0.892347712722331\n",
      "true gam1 =  160.92510884286648\n",
      "gam1 =  148.64897054602582\n",
      "corr(z2_hat, beta_true) =  [[0.99926621]]\n",
      "l2 error for z2_hat =  0.05259289324373764\n",
      "true tau1 =  2710.044485752083\n",
      "tau1 =  2845.1568284756754\n",
      "\n",
      "\n",
      "**** iteration =  9  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00105048]\n",
      "corr(x1_hat, beta_true) =  0.9942171494712928\n",
      "l2 error for x1_hat =  0.10851124711436608\n",
      "B / (A+B) =  [0.00535534]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9933176954284999\n",
      "alpha1 part I =  [0.00531955]\n",
      "alpha2 part II =  [0.0023735]\n",
      "alpha1 =  0.09482042847106857\n",
      "true gam2 =  1253.556749155258\n",
      "gam2 =  1419.0403232371311\n",
      "corr(z1_hat, X*beta_true) =  0.9992580361353871\n",
      "l2 error for z1_hat =  0.053438565858340364\n",
      "v1 =  0.9030617683254811\n",
      "true tau2 =  390.33269204328656\n",
      "tau2 = 305.410417606904\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99423255]]\n",
      "l2 error for x2_hat =  0.10838034224975793\n",
      "alpha2 =  0.9127435933655691\n",
      "true gam1 =  161.24297731987144\n",
      "gam1 =  135.65733068415113\n",
      "corr(z2_hat, beta_true) =  [[0.99930376]]\n",
      "l2 error for z2_hat =  0.05972599294149182\n",
      "true tau1 =  3105.8924358073104\n",
      "tau1 =  3194.7385042533588\n",
      "\n",
      "\n",
      "**** iteration =  10  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00086537]\n",
      "corr(x1_hat, beta_true) =  0.9944889551143066\n",
      "l2 error for x1_hat =  0.106096305143282\n",
      "B / (A+B) =  [0.00541447]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9926824269507265\n",
      "alpha1 part I =  [0.00537485]\n",
      "alpha2 part II =  [0.0020306]\n",
      "alpha1 =  0.09290803863997706\n",
      "true gam2 =  1303.6736150987078\n",
      "gam2 =  1324.467462282683\n",
      "corr(z1_hat, X*beta_true) =  0.9993085028989868\n",
      "l2 error for z1_hat =  0.059448989948667555\n",
      "v1 =  0.8976462780745099\n",
      "true tau2 =  384.3556382227942\n",
      "tau2 = 364.27865237788245\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99450151]]\n",
      "l2 error for x2_hat =  0.10598584701606902\n",
      "alpha2 =  0.8934374072086472\n",
      "true gam1 =  158.7130112116805\n",
      "gam1 =  157.97266345673106\n",
      "corr(z2_hat, beta_true) =  [[0.99935453]]\n",
      "l2 error for z2_hat =  0.05695745959670085\n",
      "true tau1 =  3253.873465540509\n",
      "tau1 =  3054.1690677440547\n",
      "\n",
      "\n",
      "**** iteration =  11  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00110567]\n",
      "corr(x1_hat, beta_true) =  0.9945425269183811\n",
      "l2 error for x1_hat =  0.10573195139988405\n",
      "B / (A+B) =  [0.00497355]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9937096103301296\n",
      "alpha1 part I =  [0.00494227]\n",
      "alpha2 part II =  [0.00177204]\n",
      "alpha1 =  0.10331753845179271\n",
      "true gam2 =  1314.3458798067957\n",
      "gam2 =  1371.0287609281527\n",
      "corr(z1_hat, X*beta_true) =  0.9993497607031258\n",
      "l2 error for z1_hat =  0.05766533279373474\n",
      "v1 =  0.9034284231732864\n",
      "true tau2 =  376.1238123883987\n",
      "tau2 = 326.4740351332113\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99454458]]\n",
      "l2 error for x2_hat =  0.10572592555200891\n",
      "alpha2 =  0.905164428086929\n",
      "true gam1 =  156.01016368249353\n",
      "gam1 =  143.64494739004877\n",
      "corr(z2_hat, beta_true) =  [[0.99930293]]\n",
      "l2 error for z2_hat =  0.06445157260029913\n",
      "true tau1 =  3214.138234155157\n",
      "tau1 =  3116.0531574319025\n",
      "\n",
      "\n",
      "**** iteration =  12  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00090284]\n",
      "corr(x1_hat, beta_true) =  0.9946059268343159\n",
      "l2 error for x1_hat =  0.10524573063115351\n",
      "B / (A+B) =  [0.00516245]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930865196604247\n",
      "alpha1 part I =  [0.00512676]\n",
      "alpha2 part II =  [0.0017383]\n",
      "alpha1 =  0.10076750963624889\n",
      "true gam2 =  1320.3318685593886\n",
      "gam2 =  1281.8636109595532\n",
      "corr(z1_hat, X*beta_true) =  0.99930362165704\n",
      "l2 error for z1_hat =  0.06434052828532741\n",
      "v1 =  0.8953209406143181\n",
      "true tau2 =  368.4476764761647\n",
      "tau2 = 364.3224442979585\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99458982]]\n",
      "l2 error for x2_hat =  0.10540868777374529\n",
      "alpha2 =  0.8906112444950597\n",
      "true gam1 =  152.7130611443544\n",
      "gam1 =  157.44407674690248\n",
      "corr(z2_hat, beta_true) =  [[0.99932549]]\n",
      "l2 error for z2_hat =  0.06314924882306074\n",
      "true tau1 =  3245.2725673127397\n",
      "tau1 =  2966.206755126974\n",
      "\n",
      "\n",
      "**** iteration =  13  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00107653]\n",
      "corr(x1_hat, beta_true) =  0.9943738228653753\n",
      "l2 error for x1_hat =  0.10756676408061087\n",
      "B / (A+B) =  [0.00491665]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9936886249045624\n",
      "alpha1 part I =  [0.00488562]\n",
      "alpha2 part II =  [0.0016232]\n",
      "alpha1 =  0.10874615434291744\n",
      "true gam2 =  1266.3044640350147\n",
      "gam2 =  1290.3687465960013\n",
      "corr(z1_hat, X*beta_true) =  0.9993218837079731\n",
      "l2 error for z1_hat =  0.06379181968182954\n",
      "v1 =  0.899671457750208\n",
      "true tau2 =  361.7388398764537\n",
      "tau2 = 330.7820840482881\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99437641]]\n",
      "l2 error for x2_hat =  0.10754114661417873\n",
      "alpha2 =  0.8993020981515818\n",
      "true gam1 =  150.12295474018637\n",
      "gam1 =  144.48695900972862\n",
      "corr(z2_hat, beta_true) =  [[0.99926025]]\n",
      "l2 error for z2_hat =  0.07013256716253827\n",
      "true tau1 =  3095.481225137996\n",
      "tau1 =  2954.1134100625864\n",
      "\n",
      "\n",
      "**** iteration =  14  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00093986]\n",
      "corr(x1_hat, beta_true) =  0.9944575216302233\n",
      "l2 error for x1_hat =  0.1067265449564176\n",
      "B / (A+B) =  [0.00522695]\n",
      "gam1 / (gam1 + 1/sigma) =  0.993126531705614\n",
      "alpha1 part I =  [0.00519102]\n",
      "alpha2 part II =  [0.00191886]\n",
      "alpha1 =  0.1055630508375523\n",
      "true gam2 =  1279.2069713002452\n",
      "gam2 =  1224.2396727364032\n",
      "corr(z1_hat, X*beta_true) =  0.9992598820413349\n",
      "l2 error for z1_hat =  0.07012174280482908\n",
      "v1 =  0.8926356308914375\n",
      "true tau2 =  353.5534727407667\n",
      "tau2 = 355.3146564738549\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99444388]]\n",
      "l2 error for x2_hat =  0.10686241733152942\n",
      "alpha2 =  0.8887754018565325\n",
      "true gam1 =  146.5068609690423\n",
      "gam1 =  153.20582156860448\n",
      "corr(z2_hat, beta_true) =  [[0.99927154]]\n",
      "l2 error for z2_hat =  0.06976152098591856\n",
      "true tau1 =  3131.0315087135086\n",
      "tau1 =  2839.2543723621766\n",
      "\n",
      "\n",
      "**** iteration =  15  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00105742]\n",
      "corr(x1_hat, beta_true) =  0.9943044722423361\n",
      "l2 error for x1_hat =  0.10824614377423512\n",
      "B / (A+B) =  [0.00502907]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9935151605184043\n",
      "alpha1 part I =  [0.00499646]\n",
      "alpha2 part II =  [0.00175095]\n",
      "alpha1 =  0.11172519788142005\n",
      "true gam2 =  1242.18932569744\n",
      "gam2 =  1218.0678434036433\n",
      "corr(z1_hat, X*beta_true) =  0.9992679829143318\n",
      "l2 error for z1_hat =  0.07037057548542025\n",
      "v1 =  0.8965068653126181\n",
      "true tau2 =  348.0014660621156\n",
      "tau2 = 327.7647350398721\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99430837]]\n",
      "l2 error for x2_hat =  0.10820610236401094\n",
      "alpha2 =  0.8952891489295396\n",
      "true gam1 =  144.16367925741386\n",
      "gam1 =  142.46226562318554\n",
      "corr(z2_hat, beta_true) =  [[0.99921677]]\n",
      "l2 error for z2_hat =  0.07603114906065969\n",
      "true tau1 =  3036.9894310534505\n",
      "tau1 =  2802.4240819655192\n",
      "\n",
      "\n",
      "**** iteration =  16  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00103381]\n",
      "corr(x1_hat, beta_true) =  0.994391790683788\n",
      "l2 error for x1_hat =  0.10736521903979543\n",
      "B / (A+B) =  [0.00529967]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930295259477738\n",
      "alpha1 part I =  [0.00526273]\n",
      "alpha2 part II =  [0.00201728]\n",
      "alpha1 =  0.10871020518446142\n",
      "true gam2 =  1256.8267902938928\n",
      "gam2 =  1168.0151213107551\n",
      "corr(z1_hat, X*beta_true) =  0.9992161561628516\n",
      "l2 error for z1_hat =  0.07609989506522867\n",
      "v1 =  0.8907776598183669\n",
      "true tau2 =  339.7706338788776\n",
      "tau2 = 343.61808812768305\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99438211]]\n",
      "l2 error for x2_hat =  0.10746535310456855\n",
      "alpha2 =  0.8875765059588338\n",
      "true gam1 =  140.5822347669581\n",
      "gam1 =  147.94481393895984\n",
      "corr(z2_hat, beta_true) =  [[0.99922246]]\n",
      "l2 error for z2_hat =  0.07643982411543704\n",
      "true tau1 =  3079.2107412715554\n",
      "tau1 =  2712.8434732062847\n",
      "\n",
      "\n",
      "**** iteration =  17  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00116901]\n",
      "corr(x1_hat, beta_true) =  0.9942696780913193\n",
      "l2 error for x1_hat =  0.10860248310678347\n",
      "B / (A+B) =  [0.00519124]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9932861039363894\n",
      "alpha1 part I =  [0.00515639]\n",
      "alpha2 part II =  [0.00195592]\n",
      "alpha1 =  0.11397598745040587\n",
      "true gam2 =  1225.0131784089347\n",
      "gam2 =  1150.0901252479873\n",
      "corr(z1_hat, X*beta_true) =  0.9992184735001667\n",
      "l2 error for z1_hat =  0.07704090160171871\n",
      "v1 =  0.8941896772677361\n",
      "true tau2 =  334.7546314627488\n",
      "tau2 = 321.013371904679\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99427273]]\n",
      "l2 error for x2_hat =  0.10857297181722382\n",
      "alpha2 =  0.8921757481958928\n",
      "true gam1 =  138.32913735204065\n",
      "gam1 =  138.994595529992\n",
      "corr(z2_hat, beta_true) =  [[0.99916974]]\n",
      "l2 error for z2_hat =  0.08239305110935678\n",
      "true tau1 =  3001.294292782642\n",
      "tau1 =  2656.1774412334394\n",
      "\n",
      "\n",
      "**** iteration =  18  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00116331]\n",
      "corr(x1_hat, beta_true) =  0.9942964604899842\n",
      "l2 error for x1_hat =  0.10832022469546781\n",
      "B / (A+B) =  [0.00543778]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9928568671082323\n",
      "alpha1 part I =  [0.00539894]\n",
      "alpha2 part II =  [0.00221558]\n",
      "alpha1 =  0.11150724532990747\n",
      "true gam2 =  1226.4073826528297\n",
      "gam2 =  1107.5127064732092\n",
      "corr(z1_hat, X*beta_true) =  0.9991686388207436\n",
      "l2 error for z1_hat =  0.08253289521338118\n",
      "v1 =  0.889074577650558\n",
      "true tau2 =  326.27448055709135\n",
      "tau2 = 331.3980760562068\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99428745]]\n",
      "l2 error for x2_hat =  0.10841184280271011\n",
      "alpha2 =  0.8860590103196333\n",
      "true gam1 =  134.720729803388\n",
      "gam1 =  142.41838567119504\n",
      "corr(z2_hat, beta_true) =  [[0.99916555]]\n",
      "l2 error for z2_hat =  0.08353669047068367\n",
      "true tau1 =  3013.6816364306605\n",
      "tau1 =  2577.108133920223\n",
      "\n",
      "\n",
      "**** iteration =  19  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00131749]\n",
      "corr(x1_hat, beta_true) =  0.9942010763286871\n",
      "l2 error for x1_hat =  0.10928298906545324\n",
      "B / (A+B) =  [0.00537554]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9930273932779259\n",
      "alpha1 part I =  [0.00533806]\n",
      "alpha2 part II =  [0.00219612]\n",
      "alpha1 =  0.11600789506943608\n",
      "true gam2 =  1200.8097558919922\n",
      "gam2 =  1085.2427626148854\n",
      "corr(z1_hat, X*beta_true) =  0.9991610520498722\n",
      "l2 error for z1_hat =  0.08414308527428749\n",
      "v1 =  0.8918776028154721\n",
      "true tau2 =  321.0904425041897\n",
      "tau2 = 312.4230369319528\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99420396]]\n",
      "l2 error for x2_hat =  0.10925602659176986\n",
      "alpha2 =  0.8894903088306653\n",
      "true gam1 =  132.41724883989863\n",
      "gam1 =  134.8298473290708\n",
      "corr(z2_hat, beta_true) =  [[0.99911225]]\n",
      "l2 error for z2_hat =  0.08934029350385334\n",
      "true tau1 =  2948.6744616505707\n",
      "tau1 =  2514.6868176528815\n",
      "\n",
      "\n",
      "**** iteration =  20  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00132507]\n",
      "corr(x1_hat, beta_true) =  0.9942020858686271\n",
      "l2 error for x1_hat =  0.10925440180944689\n",
      "B / (A+B) =  [0.0056327]\n",
      "gam1 / (gam1 + 1/sigma) =  0.992637847868758\n",
      "alpha1 part I =  [0.00559123]\n",
      "alpha2 part II =  [0.00251991]\n",
      "alpha1 =  0.11421390350020619\n",
      "true gam2 =  1196.6447370545286\n",
      "gam2 =  1045.6730791717066\n",
      "corr(z1_hat, X*beta_true) =  0.9991105843096482\n",
      "l2 error for z1_hat =  0.08954335138652904\n",
      "v1 =  0.8874224645231041\n",
      "true tau2 =  312.2851215285324\n",
      "tau2 = 319.01068064547417\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99419416]]\n",
      "l2 error for x2_hat =  0.10933447922438914\n",
      "alpha2 =  0.8843092234900197\n",
      "true gam1 =  128.68616700638216\n",
      "gam1 =  136.80138948174405\n",
      "corr(z2_hat, beta_true) =  [[0.99910008]]\n",
      "l2 error for z2_hat =  0.09107949811930477\n",
      "true tau1 =  2945.6353892969128\n",
      "tau1 =  2438.431963176301\n",
      "\n",
      "\n",
      "**** iteration =  21  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00148603]\n",
      "corr(x1_hat, beta_true) =  0.9941202393030328\n",
      "l2 error for x1_hat =  0.11007374965667803\n",
      "B / (A+B) =  [0.00560403]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9927431791235133\n",
      "alpha1 part I =  [0.00556336]\n",
      "alpha2 part II =  [0.00253038]\n",
      "alpha1 =  0.11834296966110597\n",
      "true gam2 =  1173.6674293498465\n",
      "gam2 =  1019.1725553457071\n",
      "corr(z1_hat, X*beta_true) =  0.9990949624252253\n",
      "l2 error for z1_hat =  0.09170479044402624\n",
      "v1 =  0.889636506200064\n",
      "true tau2 =  306.6213123198458\n",
      "tau2 = 302.49868229784005\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99412218]]\n",
      "l2 error for x2_hat =  0.11005588533639776\n",
      "alpha2 =  0.8867865340628301\n",
      "true gam1 =  126.18665238822206\n",
      "gam1 =  130.11480547646028\n",
      "corr(z2_hat, beta_true) =  [[0.99904444]]\n",
      "l2 error for z2_hat =  0.09688956487575033\n",
      "true tau1 =  2887.975662726224\n",
      "tau1 =  2369.433316195324\n",
      "\n",
      "\n",
      "**** iteration =  22  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00151849]\n",
      "corr(x1_hat, beta_true) =  0.9941020706405973\n",
      "l2 error for x1_hat =  0.11022810708930694\n",
      "B / (A+B) =  [0.0058397]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9923730962619661\n",
      "alpha1 part I =  [0.00579517]\n",
      "alpha2 part II =  [0.00282601]\n",
      "alpha1 =  0.1170280501541433\n",
      "true gam2 =  1165.7277877885958\n",
      "gam2 =  981.7109944499657\n",
      "corr(z1_hat, X*beta_true) =  0.9990422420536589\n",
      "l2 error for z1_hat =  0.097149416773987\n",
      "v1 =  0.8855353704649542\n",
      "true tau2 =  297.35513104009055\n",
      "tau2 = 306.2738268759264\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99409479]]\n",
      "l2 error for x2_hat =  0.11030204212198717\n",
      "alpha2 =  0.8822611598589757\n",
      "true gam1 =  122.29283365945967\n",
      "gam1 =  131.01054324856167\n",
      "corr(z2_hat, beta_true) =  [[0.99902536]]\n",
      "l2 error for z2_hat =  0.09912690786591113\n",
      "true tau1 =  2875.7016644889263\n",
      "tau1 =  2295.0243217136135\n",
      "\n",
      "\n",
      "**** iteration =  23  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00170117]\n",
      "corr(x1_hat, beta_true) =  0.9940259358153335\n",
      "l2 error for x1_hat =  0.11099026190165631\n",
      "B / (A+B) =  [0.00585217]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9924248474751209\n",
      "alpha1 part I =  [0.00580784]\n",
      "alpha2 part II =  [0.00289625]\n",
      "alpha1 =  0.12108730516283525\n",
      "true gam2 =  1143.37882075929\n",
      "gam2 =  950.9405586640781\n",
      "corr(z1_hat, X*beta_true) =  0.9990194850885771\n",
      "l2 error for z1_hat =  0.09978522606490894\n",
      "v1 =  0.887372922802374\n",
      "true tau2 =  291.22701930662583\n",
      "tau2 = 291.2888987369233\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99402788]]\n",
      "l2 error for x2_hat =  0.11097233072297022\n",
      "alpha2 =  0.8839400588461197\n",
      "true gam1 =  119.58712497918663\n",
      "gam1 =  124.85700152956186\n",
      "corr(z2_hat, beta_true) =  [[0.99896519]]\n",
      "l2 error for z2_hat =  0.10509310686039836\n",
      "true tau1 =  2818.852487848124\n",
      "tau1 =  2218.525390680235\n",
      "\n",
      "\n",
      "**** iteration =  24  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0017482]\n",
      "corr(x1_hat, beta_true) =  0.9939936767752909\n",
      "l2 error for x1_hat =  0.11127220838638065\n",
      "B / (A+B) =  [0.0060931]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9920544746192359\n",
      "alpha1 part I =  [0.00604469]\n",
      "alpha2 part II =  [0.00321451]\n",
      "alpha1 =  0.1200985109184515\n",
      "true gam2 =  1132.550111584806\n",
      "gam2 =  914.7645605923984\n",
      "corr(z1_hat, X*beta_true) =  0.9989623314314546\n",
      "l2 error for z1_hat =  0.10540853197128801\n",
      "v1 =  0.8833827013390692\n",
      "true tau2 =  281.36985324243597\n",
      "tau2 = 292.87242967248375\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99398637]]\n",
      "l2 error for x2_hat =  0.11134580537324971\n",
      "alpha2 =  0.8798566935188216\n",
      "true gam1 =  115.482132820579\n",
      "gam1 =  124.90993109552566\n",
      "corr(z2_hat, beta_true) =  [[0.99893913]]\n",
      "l2 error for z2_hat =  0.1077830514121661\n",
      "true tau1 =  2799.011278495779\n",
      "tau1 =  2144.820008219301\n",
      "\n",
      "\n",
      "**** iteration =  25  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00196171]\n",
      "corr(x1_hat, beta_true) =  0.9939212833271901\n",
      "l2 error for x1_hat =  0.11199347264944022\n",
      "B / (A+B) =  [0.00613021]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9920578147307434\n",
      "alpha1 part I =  [0.00608152]\n",
      "alpha2 part II =  [0.00331037]\n",
      "alpha1 =  0.12417896723187055\n",
      "true gam2 =  1110.398019794647\n",
      "gam2 =  880.9764430622674\n",
      "corr(z1_hat, X*beta_true) =  0.9989323866359168\n",
      "l2 error for z1_hat =  0.10848897434875504\n",
      "v1 =  0.8849768994589088\n",
      "true tau2 =  274.7733024588578\n",
      "tau2 = 278.76868605134445\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99392371]]\n",
      "l2 error for x2_hat =  0.11197129490796648\n",
      "alpha2 =  0.8809497804883081\n",
      "true gam1 =  112.58942133354223\n",
      "gam1 =  119.05382265156767\n",
      "corr(z2_hat, beta_true) =  [[0.99887298]]\n",
      "l2 error for z2_hat =  0.1140275232297659\n",
      "true tau1 =  2742.7287811339575\n",
      "tau1 =  2062.8371269809163\n",
      "\n",
      "\n",
      "**** iteration =  26  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00203284]\n",
      "corr(x1_hat, beta_true) =  0.9938807663450265\n",
      "l2 error for x1_hat =  0.11234913530435775\n",
      "B / (A+B) =  [0.00639041]\n",
      "gam1 / (gam1 + 1/sigma) =  0.991670402675121\n",
      "alpha1 part I =  [0.00633718]\n",
      "alpha2 part II =  [0.00367554]\n",
      "alpha1 =  0.12348549028902997\n",
      "true gam2 =  1097.774106145221\n",
      "gam2 =  845.0580124548115\n",
      "corr(z1_hat, X*beta_true) =  0.9988693850950419\n",
      "l2 error for z1_hat =  0.11439895586821601\n",
      "v1 =  0.8810225529196707\n",
      "true tau2 =  264.29853522005556\n",
      "tau2 = 278.5752694949323\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99387356]]\n",
      "l2 error for x2_hat =  0.1124215461227852\n",
      "alpha2 =  0.8770984486522618\n",
      "true gam1 =  108.25499504713179\n",
      "gam1 =  118.41195349178977\n",
      "corr(z2_hat, beta_true) =  [[0.99883992]]\n",
      "l2 error for z2_hat =  0.117146336095418\n",
      "true tau1 =  2717.504275431817\n",
      "tau1 =  1988.0785395097257\n",
      "\n",
      "\n",
      "**** iteration =  27  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00228432]\n",
      "corr(x1_hat, beta_true) =  0.9938075764869848\n",
      "l2 error for x1_hat =  0.11307198359984859\n",
      "B / (A+B) =  [0.00646299]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9916256290031403\n",
      "alpha1 part I =  [0.00640886]\n",
      "alpha2 part II =  [0.00382745]\n",
      "alpha1 =  0.12773757461276997\n",
      "true gam2 =  1074.5563092320963\n",
      "gam2 =  808.5819545321385\n",
      "corr(z1_hat, X*beta_true) =  0.9988320311606087\n",
      "l2 error for z1_hat =  0.1179192995696214\n",
      "v1 =  0.8824423216740831\n",
      "true tau2 =  257.23372669357695\n",
      "tau2 = 264.8489217867111\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99381079]]\n",
      "l2 error for x2_hat =  0.1130424689966421\n",
      "alpha2 =  0.8777073442921812\n",
      "true gam1 =  105.1658446492732\n",
      "gam1 =  112.66128194118937\n",
      "corr(z2_hat, beta_true) =  [[0.99876523]]\n",
      "l2 error for z2_hat =  0.12382348780082926\n",
      "true tau1 =  2658.631230731706\n",
      "tau1 =  1900.84876671134\n",
      "\n",
      "\n",
      "**** iteration =  28  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0023822]\n",
      "corr(x1_hat, beta_true) =  0.9937595424941816\n",
      "l2 error for x1_hat =  0.11348875628534309\n",
      "B / (A+B) =  [0.00674247]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9912019292504776\n",
      "alpha1 part I =  [0.00668315]\n",
      "alpha2 part II =  [0.00422829]\n",
      "alpha1 =  0.1272502465238753\n",
      "true gam2 =  1060.2793236613325\n",
      "gam2 =  772.6908884379175\n",
      "corr(z1_hat, X*beta_true) =  0.9987608388824942\n",
      "l2 error for z1_hat =  0.12425236177173811\n",
      "v1 =  0.8783779535142356\n",
      "true tau2 =  246.07869748715964\n",
      "tau2 = 263.1954913513522\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9937522]]\n",
      "l2 error for x2_hat =  0.11356208668602555\n",
      "alpha2 =  0.8739507397412725\n",
      "true gam1 =  100.5860080904434\n",
      "gam1 =  111.44462778885256\n",
      "corr(z2_hat, beta_true) =  [[0.99872492]]\n",
      "l2 error for z2_hat =  0.12735487933026865\n",
      "true tau1 =  2628.7774910435287\n",
      "tau1 =  1824.8412873740413\n",
      "\n",
      "\n",
      "**** iteration =  29  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00269531]\n",
      "corr(x1_hat, beta_true) =  0.9936860248015029\n",
      "l2 error for x1_hat =  0.1142100145815682\n",
      "B / (A+B) =  [0.00685797]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9911067338683552\n",
      "alpha1 part I =  [0.00679698]\n",
      "alpha2 part II =  [0.00445803]\n",
      "alpha1 =  0.13185701683691792\n",
      "true gam2 =  1035.6802769743426\n",
      "gam2 =  733.7483734049208\n",
      "corr(z1_hat, X*beta_true) =  0.998715528866586\n",
      "l2 error for z1_hat =  0.12821960250716227\n",
      "v1 =  0.8797467766353069\n",
      "true tau2 =  238.60392403313713\n",
      "tau2 = 249.4388757808128\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99369102]]\n",
      "l2 error for x2_hat =  0.11416404695206585\n",
      "alpha2 =  0.8741418975899282\n",
      "true gam1 =  97.32666726584367\n",
      "gam1 =  105.64437899365156\n",
      "corr(z2_hat, beta_true) =  [[0.99863886]]\n",
      "l2 error for z2_hat =  0.13464775652062472\n",
      "true tau1 =  2566.0434281608213\n",
      "tau1 =  1732.466706810042\n",
      "\n",
      "\n",
      "**** iteration =  30  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00281963]\n",
      "corr(x1_hat, beta_true) =  0.9936302738901863\n",
      "l2 error for x1_hat =  0.11468401474025677\n",
      "B / (A+B) =  [0.00718122]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9906230407131019\n",
      "alpha1 part I =  [0.00711388]\n",
      "alpha2 part II =  [0.00494552]\n",
      "alpha1 =  0.1315222842825781\n",
      "true gam2 =  1019.5705490283594\n",
      "gam2 =  697.5988095649705\n",
      "corr(z1_hat, X*beta_true) =  0.9986335384631568\n",
      "l2 error for z1_hat =  0.13513712210017784\n",
      "v1 =  0.8754159697045225\n",
      "true tau2 =  226.70004232248402\n",
      "tau2 = 246.55442915895134\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99362261]]\n",
      "l2 error for x2_hat =  0.11475999280383488\n",
      "alpha2 =  0.870328126357904\n",
      "true gam1 =  92.46693064760765\n",
      "gam1 =  103.93659810275521\n",
      "corr(z2_hat, beta_true) =  [[0.99859037]]\n",
      "l2 error for z2_hat =  0.13858791208582175\n",
      "true tau1 =  2530.8841032343935\n",
      "tau1 =  1654.8172579615718\n",
      "\n",
      "\n",
      "**** iteration =  31  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00321662]\n",
      "corr(x1_hat, beta_true) =  0.9935544753891269\n",
      "l2 error for x1_hat =  0.11542015323458263\n",
      "B / (A+B) =  [0.00734212]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9904704362626584\n",
      "alpha1 part I =  [0.00727215]\n",
      "alpha2 part II =  [0.00526043]\n",
      "alpha1 =  0.13666523716933957\n",
      "true gam2 =  992.5804112872829\n",
      "gam2 =  656.5830501671933\n",
      "corr(z1_hat, X*beta_true) =  0.9985789792793667\n",
      "l2 error for z1_hat =  0.13957848279872875\n",
      "v1 =  0.8768394984888953\n",
      "true tau2 =  218.89669209984947\n",
      "tau2 = 232.43492537803303\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99356245]]\n",
      "l2 error for x2_hat =  0.11534660019303634\n",
      "alpha2 =  0.8701671635429628\n",
      "true gam1 =  89.07136209465898\n",
      "gam1 =  97.96513054541506\n",
      "corr(z2_hat, beta_true) =  [[0.99848904]]\n",
      "l2 error for z2_hat =  0.14673906320987165\n",
      "true tau1 =  2462.03719688118\n",
      "tau1 =  1557.828090672977\n",
      "\n",
      "\n",
      "**** iteration =  32  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00338164]\n",
      "corr(x1_hat, beta_true) =  0.9934940068735276\n",
      "l2 error for x1_hat =  0.11591579511691084\n",
      "B / (A+B) =  [0.00772502]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9898954309008757\n",
      "alpha1 part I =  [0.00764696]\n",
      "alpha2 part II =  [0.00586221]\n",
      "alpha1 =  0.13641225271048138\n",
      "true gam2 =  975.0519128120794\n",
      "gam2 =  620.1897902836859\n",
      "corr(z1_hat, X*beta_true) =  0.9984827289495419\n",
      "l2 error for z1_hat =  0.1472900969921872\n",
      "v1 =  0.8720739733865228\n",
      "true tau2 =  206.2007599516961\n",
      "tau2 = 228.5204740290136\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99348596]]\n",
      "l2 error for x2_hat =  0.11599510745900093\n",
      "alpha2 =  0.8661478022264599\n",
      "true gam1 =  83.92170464977039\n",
      "gam1 =  95.84249507161802\n",
      "corr(z2_hat, beta_true) =  [[0.99843193]]\n",
      "l2 error for z2_hat =  0.1510630516280112\n",
      "true tau1 =  2422.220108888249\n",
      "tau1 =  1478.7393082544236\n",
      "\n",
      "\n",
      "**** iteration =  33  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00389909]\n",
      "corr(x1_hat, beta_true) =  0.9934112082293078\n",
      "l2 error for x1_hat =  0.11670827635886707\n",
      "B / (A+B) =  [0.00796243]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9896739546078355\n",
      "alpha1 part I =  [0.00788021]\n",
      "alpha2 part II =  [0.00634709]\n",
      "alpha1 =  0.14238232504370832\n",
      "true gam2 =  943.9907138333557\n",
      "gam2 =  577.2922851210528\n",
      "corr(z1_hat, X*beta_true) =  0.9984177304381973\n",
      "l2 error for z1_hat =  0.1522309260042751\n",
      "v1 =  0.873713034124015\n",
      "true tau2 =  198.23817166208158\n",
      "tau2 = 213.73779864487787\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99342471]]\n",
      "l2 error for x2_hat =  0.11658423419794615\n",
      "alpha2 =  0.8656597464585788\n",
      "true gam1 =  80.4480669244479\n",
      "gam1 =  89.58900106876986\n",
      "corr(z2_hat, beta_true) =  [[0.99830862]]\n",
      "l2 error for z2_hat =  0.16043616771997118\n",
      "true tau1 =  2342.7116081027766\n",
      "tau1 =  1377.2804777868841\n",
      "\n",
      "\n",
      "**** iteration =  34  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0040947]\n",
      "corr(x1_hat, beta_true) =  0.993343036243373\n",
      "l2 error for x1_hat =  0.11723965282234872\n",
      "B / (A+B) =  [0.00842821]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9889611322765237\n",
      "alpha1 part I =  [0.00833518]\n",
      "alpha2 part II =  [0.00710616]\n",
      "alpha1 =  0.14193257251270455\n",
      "true gam2 =  924.7937869919913\n",
      "gam2 =  541.619180976621\n",
      "corr(z1_hat, X*beta_true) =  0.9983013452030965\n",
      "l2 error for z1_hat =  0.16104356927899063\n",
      "v1 =  0.868234907979774\n",
      "true tau2 =  184.69732242608507\n",
      "tau2 = 209.0188809794748\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99333402]]\n",
      "l2 error for x2_hat =  0.11732727201542602\n",
      "alpha2 =  0.8613906726305629\n",
      "true gam1 =  75.00395031844246\n",
      "gam1 =  87.15379995500915\n",
      "corr(z2_hat, beta_true) =  [[0.99824266]]\n",
      "l2 error for z2_hat =  0.1650679421038877\n",
      "true tau1 =  2297.664873779348\n",
      "tau1 =  1298.9523713618216\n",
      "\n",
      "\n",
      "**** iteration =  35  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00480357]\n",
      "corr(x1_hat, beta_true) =  0.9932567247604892\n",
      "l2 error for x1_hat =  0.11805710956076339\n",
      "B / (A+B) =  [0.00875966]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9886561895175209\n",
      "alpha1 part I =  [0.00866029]\n",
      "alpha2 part II =  [0.00781494]\n",
      "alpha1 =  0.1490684576253872\n",
      "true gam2 =  888.9328441384115\n",
      "gam2 =  497.5024133267358\n",
      "corr(z1_hat, X*beta_true) =  0.9982243937183898\n",
      "l2 error for z1_hat =  0.16649205443235987\n",
      "v1 =  0.8704300931849338\n",
      "true tau2 =  176.93575393558143\n",
      "tau2 = 193.35859253064905\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99328034]]\n",
      "l2 error for x2_hat =  0.11784139319651485\n",
      "alpha2 =  0.8606514207405442\n",
      "true gam1 =  71.60251176762347\n",
      "gam1 =  80.55090923521587\n",
      "corr(z2_hat, beta_true) =  [[0.99808837]]\n",
      "l2 error for z2_hat =  0.17620949698043623\n",
      "true tau1 =  2205.5065040580907\n",
      "tau1 =  1194.2306714447734\n",
      "\n",
      "\n",
      "**** iteration =  36  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00502128]\n",
      "corr(x1_hat, beta_true) =  0.9931744235040137\n",
      "l2 error for x1_hat =  0.11866420657928883\n",
      "B / (A+B) =  [0.00936791]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9877377210214087\n",
      "alpha1 part I =  [0.00925304]\n",
      "alpha2 part II =  [0.00887304]\n",
      "alpha1 =  0.14796895948072677\n",
      "true gam2 =  868.4137382559104\n",
      "gam2 =  463.8261649693761\n",
      "corr(z1_hat, X*beta_true) =  0.9980804346552481\n",
      "l2 error for z1_hat =  0.17684807388870938\n",
      "v1 =  0.8638775013669912\n",
      "true tau2 =  162.52767846882506\n",
      "tau2 = 188.17675270394523\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99316345]]\n",
      "l2 error for x2_hat =  0.11876961222859579\n",
      "alpha2 =  0.856111282704299\n",
      "true gam1 =  65.87766487139595\n",
      "gam1 =  77.95639804536894\n",
      "corr(z2_hat, beta_true) =  [[0.99801396]]\n",
      "l2 error for z2_hat =  0.1809324384106252\n",
      "true tau1 =  2154.960509903555\n",
      "tau1 =  1119.6169106256775\n",
      "\n",
      "\n",
      "**** iteration =  37  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00598195]\n",
      "corr(x1_hat, beta_true) =  0.9930693456303072\n",
      "l2 error for x1_hat =  0.11964803977396284\n",
      "B / (A+B) =  [0.00984071]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9873347819207078\n",
      "alpha1 part I =  [0.00971608]\n",
      "alpha2 part II =  [0.00995813]\n",
      "alpha1 =  0.15662212720111374\n",
      "true gam2 =  824.6579362172318\n",
      "gam2 =  419.77913548666834\n",
      "corr(z1_hat, X*beta_true) =  0.9979894863691087\n",
      "l2 error for z1_hat =  0.18274471428893532\n",
      "v1 =  0.8671775441241363\n",
      "true tau2 =  155.5262897846987\n",
      "tau2 = 171.4876829054075\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99311151]]\n",
      "l2 error for x2_hat =  0.11926678040307187\n",
      "alpha2 =  0.8553705530730272\n",
      "true gam1 =  62.77082548166393\n",
      "gam1 =  70.97792176595573\n",
      "corr(z2_hat, beta_true) =  [[0.99781154]]\n",
      "l2 error for z2_hat =  0.19478001426762312\n",
      "true tau1 =  2043.2163133235426\n",
      "tau1 =  1014.2161039036242\n",
      "\n",
      "\n",
      "**** iteration =  38  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00616845]\n",
      "corr(x1_hat, beta_true) =  0.9929759062258281\n",
      "l2 error for x1_hat =  0.1202856691826427\n",
      "B / (A+B) =  [0.01059817]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9861068508861424\n",
      "alpha1 part I =  [0.01045093]\n",
      "alpha2 part II =  [0.01129558]\n",
      "alpha1 =  0.1536973377356619\n",
      "true gam2 =  806.6333307697203\n",
      "gam2 =  390.8252741230187\n",
      "corr(z1_hat, X*beta_true) =  0.9978043753982878\n",
      "l2 error for z1_hat =  0.19536316441848472\n",
      "v1 =  0.8590135965778134\n",
      "true tau2 =  140.23972074306675\n",
      "tau2 = 166.45915891423485\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99295815]]\n",
      "l2 error for x2_hat =  0.12045222367787017\n",
      "alpha2 =  0.8508427134179799\n",
      "true gam1 =  56.82026912571926\n",
      "gam1 =  68.51376464362608\n",
      "corr(z2_hat, beta_true) =  [[0.99773748]]\n",
      "l2 error for z2_hat =  0.1989510599203505\n",
      "true tau1 =  1996.2957330055292\n",
      "tau1 =  949.5383409645298\n",
      "\n",
      "\n",
      "**** iteration =  39  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0075776]\n",
      "corr(x1_hat, beta_true) =  0.9928512773346069\n",
      "l2 error for x1_hat =  0.12146696206372994\n",
      "B / (A+B) =  [0.0112964]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9856143599022917\n",
      "alpha1 part I =  [0.01113389]\n",
      "alpha2 part II =  [0.01306203]\n",
      "alpha1 =  0.16481934403061282\n",
      "true gam2 =  753.3045067059556\n",
      "gam2 =  347.17630527256426\n",
      "corr(z1_hat, X*beta_true) =  0.9977027569449094\n",
      "l2 error for z1_hat =  0.20138453157932393\n",
      "v1 =  0.8646170110254413\n",
      "true tau2 =  134.98457568744874\n",
      "tau2 = 148.68009431512223\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99292828]]\n",
      "l2 error for x2_hat =  0.12078056788994836\n",
      "alpha2 =  0.8502410093919548\n",
      "true gam1 =  54.389369934628995\n",
      "gam1 =  61.1506296054011\n",
      "corr(z2_hat, beta_true) =  [[0.99745712]]\n",
      "l2 error for z2_hat =  0.2172117790563682\n",
      "true tau1 =  1860.5713347370984\n",
      "tau1 =  844.1156885053783\n",
      "\n",
      "\n",
      "**** iteration =  40  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00751861]\n",
      "corr(x1_hat, beta_true) =  0.9926935146533008\n",
      "l2 error for x1_hat =  0.12254768677418551\n",
      "B / (A+B) =  [0.01231263]\n",
      "gam1 / (gam1 + 1/sigma) =  0.983910058412134\n",
      "alpha1 part I =  [0.01211452]\n",
      "alpha2 part II =  [0.01494423]\n",
      "alpha1 =  0.15814469199596215\n",
      "true gam2 =  739.2650069810412\n",
      "gam2 =  325.5245653291367\n",
      "corr(z1_hat, X*beta_true) =  0.9974548583045665\n",
      "l2 error for z1_hat =  0.21749235290383592\n",
      "v1 =  0.8536437801546453\n",
      "true tau2 =  118.41915588230201\n",
      "tau2 = 144.72263976365582\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9926549]]\n",
      "l2 error for x2_hat =  0.12289720521485671\n",
      "alpha2 =  0.8460832662290492\n",
      "true gam1 =  48.076992089094695\n",
      "gam1 =  59.2183770292241\n",
      "corr(z2_hat, beta_true) =  [[0.99740168]]\n",
      "l2 error for z2_hat =  0.21918879756587867\n",
      "true tau1 =  1820.13421078148\n",
      "tau1 =  795.5431534217877\n",
      "\n",
      "\n",
      "**** iteration =  41  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00959528]\n",
      "corr(x1_hat, beta_true) =  0.9925482302741813\n",
      "l2 error for x1_hat =  0.12397456251778916\n",
      "B / (A+B) =  [0.01320006]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9833937736396533\n",
      "alpha1 part I =  [0.01298086]\n",
      "alpha2 part II =  [0.01739998]\n",
      "alpha1 =  0.1733473520947095\n",
      "true gam2 =  672.8384059551746\n",
      "gam2 =  282.3984767250215\n",
      "corr(z1_hat, X*beta_true) =  0.9973490651832025\n",
      "l2 error for z1_hat =  0.2226934851094862\n",
      "v1 =  0.8636283053854119\n",
      "true tau2 =  116.30305527821955\n",
      "tau2 = 125.62067187312338\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99268807]]\n",
      "l2 error for x2_hat =  0.12274713710786475\n",
      "alpha2 =  0.8460197007780863\n",
      "true gam1 =  46.829473629676116\n",
      "gam1 =  51.39809617428446\n",
      "corr(z2_hat, beta_true) =  [[0.99698502]]\n",
      "l2 error for z2_hat =  0.24532157368145935\n",
      "true tau1 =  1655.3740914136329\n",
      "tau1 =  690.2023425508263\n",
      "\n",
      "\n",
      "**** iteration =  42  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0091611]\n",
      "corr(x1_hat, beta_true) =  0.9923729472670617\n",
      "l2 error for x1_hat =  0.12499877302838594\n",
      "B / (A+B) =  [0.01442118]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9809153371398488\n",
      "alpha1 part I =  [0.01414596]\n",
      "alpha2 part II =  [0.01950042]\n",
      "alpha1 =  0.16032611815576495\n",
      "true gam2 =  675.9197458089653\n",
      "gam2 =  269.18657690030847\n",
      "corr(z1_hat, X*beta_true) =  0.9970006158321879\n",
      "l2 error for z1_hat =  0.24459416787180854\n",
      "v1 =  0.8475366488690023\n",
      "true tau2 =  97.54397681510362\n",
      "tau2 = 124.16048585531853\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99226406]]\n",
      "l2 error for x2_hat =  0.12594515855908198\n",
      "alpha2 =  0.8419180289632859\n",
      "true gam1 =  39.81077259681596\n",
      "gam1 =  50.54357216393857\n",
      "corr(z2_hat, beta_true) =  [[0.99702019]]\n",
      "l2 error for z2_hat =  0.24059329490201473\n",
      "true tau1 =  1648.820045413516\n",
      "tau1 =  661.2578957669768\n",
      "\n",
      "\n",
      "**** iteration =  43  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01274174]\n",
      "corr(x1_hat, beta_true) =  0.9921167625712093\n",
      "l2 error for x1_hat =  0.12752854780315037\n",
      "B / (A+B) =  [0.0160272]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9805989387615701\n",
      "alpha1 part I =  [0.01571625]\n",
      "alpha2 part II =  [0.0246917]\n",
      "alpha1 =  0.18466356519719448\n",
      "true gam2 =  579.6555451759372\n",
      "gam2 =  223.16267903924384\n",
      "corr(z1_hat, X*beta_true) =  0.9969314609860915\n",
      "l2 error for z1_hat =  0.2461843898345922\n",
      "v1 =  0.8655440286137212\n",
      "true tau2 =  100.46589169519127\n",
      "tau2 = 102.7216060338333\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99238053]]\n",
      "l2 error for x2_hat =  0.1252574789480991\n",
      "alpha2 =  0.8421519995475509\n",
      "true gam1 =  40.38677889426204\n",
      "gam1 =  41.82829546314856\n",
      "corr(z2_hat, beta_true) =  [[0.99631038]]\n",
      "l2 error for z2_hat =  0.2829653945172874\n",
      "true tau1 =  1415.7338134369218\n",
      "tau1 =  548.0411894364689\n",
      "\n",
      "\n",
      "**** iteration =  44  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01068637]\n",
      "corr(x1_hat, beta_true) =  0.9916615465524957\n",
      "l2 error for x1_hat =  0.13028945511500442\n",
      "B / (A+B) =  [0.01731325]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9766509502844808\n",
      "alpha1 part I =  [0.01690901]\n",
      "alpha2 part II =  [0.02606161]\n",
      "alpha1 =  0.15896825714870738\n",
      "true gam2 =  598.7073739645459\n",
      "gam2 =  221.2952753263339\n",
      "corr(z1_hat, X*beta_true) =  0.9963864066648653\n",
      "l2 error for z1_hat =  0.2790633550105539\n",
      "v1 =  0.8381767945147235\n",
      "true tau2 =  77.14523096422644\n",
      "tau2 = 105.80796628224381\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99133352]]\n",
      "l2 error for x2_hat =  0.13295069318554512\n",
      "alpha2 =  0.837773140666329\n",
      "true gam1 =  31.662575787179232\n",
      "gam1 =  42.85174083406136\n",
      "corr(z2_hat, beta_true) =  [[0.99661529]]\n",
      "l2 error for z2_hat =  0.2590367784818534\n",
      "true tau1 =  1442.1451638998155\n",
      "tau1 =  546.4142780294468\n",
      "\n",
      "\n",
      "**** iteration =  45  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01777667]\n",
      "corr(x1_hat, beta_true) =  0.9915199066729325\n",
      "l2 error for x1_hat =  0.13225370163601188\n",
      "B / (A+B) =  [0.01920136]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9771958882137864\n",
      "alpha1 part I =  [0.01876349]\n",
      "alpha2 part II =  [0.03317952]\n",
      "alpha1 =  0.20225311076627497\n",
      "true gam2 =  467.03259821649254\n",
      "gam2 =  169.02010959982945\n",
      "corr(z1_hat, X*beta_true) =  0.9964486066171514\n",
      "l2 error for z1_hat =  0.26913073491021366\n",
      "v1 =  0.8725804791294175\n",
      "true tau2 =  89.42936399832641\n",
      "tau2 = 79.79074385530811\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99192937]]\n",
      "l2 error for x2_hat =  0.12878263566355316\n",
      "alpha2 =  0.8392498034729757\n",
      "true gam1 =  35.62463519813288\n",
      "gam1 =  32.37417002989701\n",
      "corr(z2_hat, beta_true) =  [[0.99521757]]\n",
      "l2 error for z2_hat =  0.33980282994661404\n",
      "true tau1 =  1128.7351782041148\n",
      "tau1 =  416.5740854212409\n",
      "\n",
      "\n",
      "**** iteration =  46  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01336734]\n",
      "corr(x1_hat, beta_true) =  0.9899757765784711\n",
      "l2 error for x1_hat =  0.14201561170882426\n",
      "B / (A+B) =  [0.02152961]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9700367080558352\n",
      "alpha1 part I =  [0.02088451]\n",
      "alpha2 part II =  [0.03603766]\n",
      "alpha1 =  0.15425220427052463\n",
      "true gam2 =  495.1152207508053\n",
      "gam2 =  177.50399788995838\n",
      "corr(z1_hat, X*beta_true) =  0.9955148025085666\n",
      "l2 error for z1_hat =  0.3251882036200301\n",
      "v1 =  0.8197037465432457\n",
      "true tau2 =  57.463449223543186\n",
      "tau2 = 91.62669709069236\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98870845]]\n",
      "l2 error for x2_hat =  0.15108674007124842\n",
      "alpha2 =  0.8287014949397841\n",
      "true gam1 =  23.527685287759812\n",
      "gam1 =  36.691341413558085\n",
      "corr(z2_hat, beta_true) =  [[0.99631231]]\n",
      "l2 error for z2_hat =  0.2598833883475926\n",
      "true tau1 =  1150.4981442873934\n",
      "tau1 =  443.26820498964497\n",
      "\n",
      "\n",
      "**** iteration =  47  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02933401]\n",
      "corr(x1_hat, beta_true) =  0.9891357163712391\n",
      "l2 error for x1_hat =  0.1507019563363411\n",
      "B / (A+B) =  [0.02787381]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9734687075997702\n",
      "alpha1 part I =  [0.02713428]\n",
      "alpha2 part II =  [0.06369513]\n",
      "alpha1 =  0.2392192744946568\n",
      "true gam2 =  295.4429736158097\n",
      "gam2 =  116.68819495978553\n",
      "corr(z1_hat, X*beta_true) =  0.9959793134173087\n",
      "l2 error for z1_hat =  0.2800637245346221\n",
      "v1 =  0.8883638301425499\n",
      "true tau2 =  87.22792224095853\n",
      "tau2 = 55.70326362419607\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98912702]]\n",
      "l2 error for x2_hat =  0.15007080506343845\n",
      "alpha2 =  0.8379584884333106\n",
      "true gam1 =  32.95485750927015\n",
      "gam1 =  22.564759178732313\n",
      "corr(z2_hat, beta_true) =  [[0.9929221]]\n",
      "l2 error for z2_hat =  0.4466101350783431\n",
      "true tau1 =  686.675636652285\n",
      "tau1 =  288.05595637833375\n",
      "\n",
      "\n",
      "**** iteration =  48  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01378554]\n",
      "corr(x1_hat, beta_true) =  0.9842461585317441\n",
      "l2 error for x1_hat =  0.17682682109023826\n",
      "B / (A+B) =  [0.02412391]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9575637504964396\n",
      "alpha1 part I =  [0.02310018]\n",
      "alpha2 part II =  [0.03715897]\n",
      "alpha1 =  0.1369896741898677\n",
      "true gam2 =  339.6248040686053\n",
      "gam2 =  142.15392719070567\n",
      "corr(z1_hat, X*beta_true) =  0.9941812485840976\n",
      "l2 error for z1_hat =  0.38808231238509683\n",
      "v1 =  0.7691508690915566\n",
      "true tau2 =  41.91835449289077\n",
      "tau2 = 86.45568750572812\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97894503]]\n",
      "l2 error for x2_hat =  0.20501492753433848\n",
      "alpha2 =  0.8081937617264154\n",
      "true gam1 =  16.366306039728578\n",
      "gam1 =  33.736971653953695\n",
      "corr(z2_hat, beta_true) =  [[0.99610942]]\n",
      "l2 error for z2_hat =  0.2020458204038538\n",
      "true tau1 =  721.2600253883762\n",
      "tau1 =  364.2892323879161\n",
      "\n",
      "\n",
      "**** iteration =  49  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.07004906]\n",
      "corr(x1_hat, beta_true) =  0.973995333591811\n",
      "l2 error for x1_hat =  0.2357752656145282\n",
      "B / (A+B) =  [0.03368614]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9712122285741572\n",
      "alpha1 part I =  [0.03271639]\n",
      "alpha2 part II =  [0.0861135]\n",
      "alpha1 =  0.3251527556922747\n",
      "true gam2 =  106.30677633395767\n",
      "gam2 =  70.02032722584558\n",
      "corr(z1_hat, X*beta_true) =  0.9956844640622522\n",
      "l2 error for z1_hat =  0.23710468644396795\n",
      "v1 =  0.9221680870972131\n",
      "true tau2 =  117.14237102151122\n",
      "tau2 = 30.74637715548102\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.96279941]]\n",
      "l2 error for x2_hat =  0.28186417970596095\n",
      "alpha2 =  0.8474693306618581\n",
      "true gam1 =  32.64996192340073\n",
      "gam1 =  12.602517864207385\n",
      "corr(z2_hat, beta_true) =  [[0.98651215]]\n",
      "l2 error for z2_hat =  0.696845528253114\n",
      "true tau1 =  230.73233435976658\n",
      "tau1 =  170.8286719077343\n",
      "\n",
      "\n",
      "**** iteration =  50  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02609933]\n",
      "corr(x1_hat, beta_true) =  0.9492854012122423\n",
      "l2 error for x1_hat =  0.31485536572844874\n",
      "B / (A+B) =  [0.0581585]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9264841987356383\n",
      "alpha1 part I =  [0.05388293]\n",
      "alpha2 part II =  [0.14868511]\n",
      "alpha1 =  0.12089804596880402\n",
      "true gam2 =  126.73449082020267\n",
      "gam2 =  91.63835520548045\n",
      "corr(z1_hat, X*beta_true) =  0.9925835466724017\n",
      "l2 error for z1_hat =  0.4411510468920591\n",
      "v1 =  0.5691293544712669\n",
      "true tau2 =  62.868187749061455\n",
      "tau2 = 129.3292281648032\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.94123739]]\n",
      "l2 error for x2_hat =  0.34330110788919527\n",
      "alpha2 =  0.682996768281256\n",
      "true gam1 =  21.332765816175975\n",
      "gam1 =  42.53263865747156\n",
      "corr(z2_hat, beta_true) =  [[0.99325195]]\n",
      "l2 error for z2_hat =  0.1547435164233878\n",
      "true tau1 =  288.01891995593786\n",
      "tau1 =  278.64525040312657\n",
      "\n",
      "\n",
      "**** iteration =  51  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04955305]\n",
      "corr(x1_hat, beta_true) =  0.9783399372416959\n",
      "l2 error for x1_hat =  0.217433011797125\n",
      "B / (A+B) =  [0.02841323]\n",
      "gam1 / (gam1 + 1/sigma) =  0.977028729917607\n",
      "alpha1 part I =  [0.02776054]\n",
      "alpha2 part II =  [0.07007908]\n",
      "alpha1 =  0.25051671562140565\n",
      "true gam2 =  198.51493053916533\n",
      "gam2 =  127.24700479653721\n",
      "corr(z1_hat, X*beta_true) =  0.9932118777627019\n",
      "l2 error for z1_hat =  0.18355218507501725\n",
      "v1 =  0.9397487965634365\n",
      "true tau2 =  167.2769323242175\n",
      "tau2 = 17.865105792170777\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.96747831]]\n",
      "l2 error for x2_hat =  0.2670778095724194\n",
      "alpha2 =  0.939337062775013\n",
      "true gam1 =  51.63685864047101\n",
      "gam1 =  8.217686036187866\n",
      "corr(z2_hat, beta_true) =  [[0.98369026]]\n",
      "l2 error for z2_hat =  0.8579292554497088\n",
      "true tau1 =  337.4432586778509\n",
      "tau1 =  276.63276406718995\n",
      "\n",
      "\n",
      "**** iteration =  52  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.02313948]\n",
      "corr(x1_hat, beta_true) =  0.918329064659388\n",
      "l2 error for x1_hat =  0.399741840000094\n",
      "B / (A+B) =  [0.03801402]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8915129029049066\n",
      "alpha1 part I =  [0.03388999]\n",
      "alpha2 part II =  [0.05372475]\n",
      "alpha1 =  0.12275336668163497\n",
      "true gam2 =  82.22862688494178\n",
      "gam2 =  58.72700361538572\n",
      "corr(z1_hat, X*beta_true) =  0.9907458125846881\n",
      "l2 error for z1_hat =  0.5413794532653253\n",
      "v1 =  0.45313120634230414\n",
      "true tau2 =  192.4157122667878\n",
      "tau2 = 333.8587672934116\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.93371348]]\n",
      "l2 error for x2_hat =  0.36881592420055465\n",
      "alpha2 =  0.4491783044335165\n",
      "true gam1 =  51.153683289137454\n",
      "gam1 =  72.01618463688212\n",
      "corr(z2_hat, beta_true) =  [[0.99329045]]\n",
      "l2 error for z2_hat =  0.2942340189063574\n",
      "true tau1 =  262.8649048769064\n",
      "tau1 =  272.25164916369624\n",
      "\n",
      "\n",
      "**** iteration =  53  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00724865]\n",
      "corr(x1_hat, beta_true) =  0.9828948982884279\n",
      "l2 error for x1_hat =  0.18849981091676976\n",
      "B / (A+B) =  [0.00733951]\n",
      "gam1 / (gam1 + 1/sigma) =  0.986304406276867\n",
      "alpha1 part I =  [0.00723899]\n",
      "alpha2 part II =  [0.00262517]\n",
      "alpha1 =  0.16734859803690927\n",
      "true gam2 =  376.252251457589\n",
      "gam2 =  358.3201640488638\n",
      "corr(z1_hat, X*beta_true) =  0.9911104985282012\n",
      "l2 error for z1_hat =  0.3176708441412295\n",
      "v1 =  0.9469441951063499\n",
      "true tau2 =  258.79105710327286\n",
      "tau2 = 15.25383486656393\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.97879134]]\n",
      "l2 error for x2_hat =  0.2104658973352468\n",
      "alpha2 =  0.9792227353510866\n",
      "true gam1 =  99.29387546637307\n",
      "gam1 =  7.602879925797508\n",
      "corr(z2_hat, beta_true) =  [[0.98894824]]\n",
      "l2 error for z2_hat =  0.6080669316703566\n",
      "true tau1 =  711.6148272021281\n",
      "tau1 =  718.906080999054\n",
      "\n",
      "\n",
      "**** iteration =  54  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.14905601]\n",
      "corr(x1_hat, beta_true) =  0.8354984730040123\n",
      "l2 error for x1_hat =  0.683291388303222\n",
      "B / (A+B) =  [0.19706139]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8837598561615054\n",
      "alpha1 part I =  [0.17415495]\n",
      "alpha2 part II =  [0.73154352]\n",
      "alpha1 =  0.4583234935587619\n",
      "true gam2 =  17.917111669945587\n",
      "gam2 =  8.985577861437303\n",
      "corr(z1_hat, X*beta_true) =  0.9905793216622726\n",
      "l2 error for z1_hat =  0.5516189806976931\n",
      "v1 =  0.8222574528286317\n",
      "true tau2 =  99.0028037159478\n",
      "tau2 = 155.40169027861492\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.82369803]]\n",
      "l2 error for x2_hat =  0.6919393763959967\n",
      "alpha2 =  0.29228461236631026\n",
      "true gam1 =  19.74316226031963\n",
      "gam1 =  21.756984289511603\n",
      "corr(z2_hat, beta_true) =  [[0.98881903]]\n",
      "l2 error for z2_hat =  0.33748002586715886\n",
      "true tau1 =  72.73383761171223\n",
      "tau1 =  64.18049345518025\n",
      "\n",
      "\n",
      "**** iteration =  55  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.04246751]\n",
      "corr(x1_hat, beta_true) =  0.9164600894498212\n",
      "l2 error for x1_hat =  0.41985787099437194\n",
      "B / (A+B) =  [0.01466479]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9560574464842037\n",
      "alpha1 part I =  [0.01402038]\n",
      "alpha2 part II =  [0.0082707]\n",
      "alpha1 =  0.28204495362251103\n",
      "true gam2 =  64.78077795118969\n",
      "gam2 =  55.38314536028582\n",
      "corr(z1_hat, X*beta_true) =  0.9879398354277498\n",
      "l2 error for z1_hat =  0.4251782867644644\n",
      "v1 =  0.8050915764506581\n",
      "true tau2 =  48.613689607626576\n",
      "tau2 = 15.537758893363234\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.90505827]]\n",
      "l2 error for x2_hat =  0.44532297774852575\n",
      "alpha2 =  0.8917353679783818\n",
      "true gam1 =  33.16517188398427\n",
      "gam1 =  6.724008117144116\n",
      "corr(z2_hat, beta_true) =  [[0.9801216]]\n",
      "l2 error for z2_hat =  0.8177950502711697\n",
      "true tau1 =  148.82415344518776\n",
      "tau1 =  127.97872108008433\n",
      "\n",
      "\n",
      "**** iteration =  56  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.0251023]\n",
      "corr(x1_hat, beta_true) =  0.9203317207200198\n",
      "l2 error for x1_hat =  0.3916393489917433\n",
      "B / (A+B) =  [0.03091415]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8705335384383645\n",
      "alpha1 part I =  [0.02691181]\n",
      "alpha2 part II =  [0.02719954]\n",
      "alpha1 =  0.12264768248206945\n",
      "true gam2 =  85.57127246072841\n",
      "gam2 =  48.099760103075916\n",
      "corr(z1_hat, X*beta_true) =  0.9854108764765944\n",
      "l2 error for z1_hat =  0.6948609997354129\n",
      "v1 =  0.7273835201192221\n",
      "true tau2 =  69.22208284762321\n",
      "tau2 = 47.96521707665026\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.93419219]]\n",
      "l2 error for x2_hat =  0.3569043836201914\n",
      "alpha2 =  0.738140789474944\n",
      "true gam1 =  20.895713010251747\n",
      "gam1 =  17.063635266647992\n",
      "corr(z2_hat, beta_true) =  [[0.99009333]]\n",
      "l2 error for z2_hat =  0.39098148539617616\n",
      "true tau1 =  274.049152989638\n",
      "tau1 =  135.20656053802605\n",
      "\n",
      "\n",
      "**** iteration =  57  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.12094964]\n",
      "corr(x1_hat, beta_true) =  0.9693913056538035\n",
      "l2 error for x1_hat =  0.26942924216894165\n",
      "B / (A+B) =  [0.02488753]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9446401576848509\n",
      "alpha1 part I =  [0.02350976]\n",
      "alpha2 part II =  [0.03315838]\n",
      "alpha1 =  0.14210072398479373\n",
      "true gam2 =  194.20016379480325\n",
      "gam2 =  103.01763376667502\n",
      "corr(z1_hat, X*beta_true) =  0.9874424282107173\n",
      "l2 error for z1_hat =  0.4414181571364084\n",
      "v1 =  0.9237544789549125\n",
      "true tau2 =  163.7021818794487\n",
      "tau2 = 11.159777724270317\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9643493]]\n",
      "l2 error for x2_hat =  0.2885068409970269\n",
      "alpha2 =  0.9517013914276978\n",
      "true gam1 =  62.6355911181505\n",
      "gam1 =  5.228119254798232\n",
      "corr(z2_hat, beta_true) =  [[0.98268156]]\n",
      "l2 error for z2_hat =  1.021537879982761\n",
      "true tau1 =  419.99561040711814\n",
      "tau1 =  219.89817723864178\n",
      "\n",
      "\n",
      "**** iteration =  58  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.08482861]\n",
      "corr(x1_hat, beta_true) =  0.842222530629797\n",
      "l2 error for x1_hat =  0.6070149392937819\n",
      "B / (A+B) =  [0.09982787]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8394378850036331\n",
      "alpha1 part I =  [0.0837993]\n",
      "alpha2 part II =  [0.25041569]\n",
      "alpha1 =  0.24962645023740915\n",
      "true gam2 =  33.07877364881966\n",
      "gam2 =  15.715651927406174\n",
      "corr(z1_hat, X*beta_true) =  0.986504911427156\n",
      "l2 error for z1_hat =  0.7883419271611487\n",
      "v1 =  0.7491425294520482\n",
      "true tau2 =  37.75256524947851\n",
      "tau2 = 73.63498713727986\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.80456256]]\n",
      "l2 error for x2_hat =  0.6943335501042707\n",
      "alpha2 =  0.4804394286039957\n",
      "true gam1 =  11.602214583204706\n",
      "gam1 =  16.995343448370676\n",
      "corr(z2_hat, beta_true) =  [[0.9788994]]\n",
      "l2 error for z2_hat =  0.2385978362412565\n",
      "true tau1 =  71.74542572145604\n",
      "tau1 =  68.09052320972441\n",
      "\n",
      "\n",
      "**** iteration =  59  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.01929541]\n",
      "corr(x1_hat, beta_true) =  0.8645317764015125\n",
      "l2 error for x1_hat =  0.5460500944644381\n",
      "B / (A+B) =  [0.02679346]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9444300686525356\n",
      "alpha1 part I =  [0.02530455]\n",
      "alpha2 part II =  [0.03925752]\n",
      "alpha1 =  0.2120190824548677\n",
      "true gam2 =  49.637764875481864\n",
      "gam2 =  63.164155647605554\n",
      "corr(z1_hat, X*beta_true) =  0.980573822343132\n",
      "l2 error for z1_hat =  0.31777097628445417\n",
      "v1 =  0.9296508067786253\n",
      "true tau2 =  65.43832108601512\n",
      "tau2 = 5.152594220214615\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.85212857]]\n",
      "l2 error for x2_hat =  0.5766980347454028\n",
      "alpha2 =  0.962523113627351\n",
      "true gam1 =  19.340055596882756\n",
      "gam1 =  2.4593652355096687\n",
      "corr(z2_hat, beta_true) =  [[0.96130916]]\n",
      "l2 error for z2_hat =  2.0638232416813427\n",
      "true tau1 =  89.43200980077798\n",
      "tau1 =  132.33466043002835\n",
      "\n",
      "\n",
      "Saving results!!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=800\n",
    "p=0.4\n",
    "la=0.05\n",
    "# This is where the sigma is defined. Note that the scope of this definition extends to gvamp\n",
    "sigma=1\n",
    "omega=1\n",
    "h2=0.9\n",
    "gam1 = 1e-2\n",
    "tau1 = 1e-1\n",
    "mu=np.full((n,1), 0) \n",
    "maxiter = 60\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, True, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a4b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weibull\n",
      "gam1 =  0.01\n",
      "tau1 =  0.1\n",
      "alpha =  47.26550503261578\n",
      "s.shape =  (200,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.]\n",
      "B / (A+B) =  [0.04976421]\n",
      "gam1 / (gam1 + 1/sigma) =  0.009900990099009901\n",
      "alpha1 part I =  [0.00049271]\n",
      "alpha2 part II =  [0.]\n",
      "alpha1 =  0.0004927149309449356\n",
      "true gam2 =  18.331264799965286\n",
      "gam2 =  20.28571131693099\n",
      "corr(z1_hat, X*beta_true) =  0.14163969999539625\n",
      "l2 error for z1_hat =  0.9899929478009614\n",
      "v1 =  0.15127352106067596\n",
      "true tau2 =  149.46728055412012\n",
      "tau2 = 0.561054223494209\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.26123121]]\n",
      "l2 error for x2_hat =  0.9994365052432236\n",
      "alpha2 =  0.9831149710279596\n",
      "true gam1 =  19.202936165062898\n",
      "gam1 =  0.3484076973689839\n",
      "corr(z2_hat, beta_true) =  [[0.79693406]]\n",
      "l2 error for z2_hat =  0.9909488596263176\n",
      "true tau1 =  151.06384163814323\n",
      "tau1 =  132.35058588639234\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.00079873]\n",
      "corr(x1_hat, beta_true) =  0.2612420929850279\n",
      "l2 error for x1_hat =  0.9996255599263869\n",
      "B / (A+B) =  [0.04335957]\n",
      "gam1 / (gam1 + 1/sigma) =  0.25838453610788326\n",
      "alpha1 part I =  [0.01120344]\n",
      "alpha2 part II =  [2.41185978e-08]\n",
      "alpha1 =  0.011204737136947307\n",
      "true gam2 =  18.331265697470535\n",
      "gam2 =  30.74627066149401\n",
      "corr(z1_hat, X*beta_true) =  0.9778774546099561\n",
      "l2 error for z1_hat =  0.21204683142455819\n",
      "v1 =  0.08527573514562257\n",
      "true tau2 =  1248.4278925818828\n",
      "tau2 = 1419.6804304441216\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.98088662]]\n",
      "l2 error for x2_hat =  0.1975935523370741\n",
      "alpha2 =  0.055686806512647964\n",
      "true gam1 =  478.98616848517264\n",
      "gam1 =  521.382188249338\n",
      "corr(z2_hat, beta_true) =  [[0.99129312]]\n",
      "l2 error for z2_hat =  0.1558977927078132\n",
      "true tau1 =  3806.4356944908864\n",
      "tau1 =  4593.919465163549\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.00014256]\n",
      "corr(x1_hat, beta_true) =  0.9985269202319207\n",
      "l2 error for x1_hat =  0.05679156270787137\n",
      "B / (A+B) =  [0.00234592]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9980856927695959\n",
      "alpha1 part I =  [0.00234143]\n",
      "alpha2 part II =  [9.76843305e-05]\n",
      "alpha1 =  0.10086154299680401\n",
      "true gam2 =  5234.717222779407\n",
      "gam2 =  4647.90407049706\n",
      "corr(z1_hat, X*beta_true) =  0.9921545115991132\n",
      "l2 error for z1_hat =  0.1437999244407399\n",
      "v1 =  0.756437086031196\n",
      "true tau2 =  1599.4120947821398\n",
      "tau2 = 1479.1823829577536\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99863946]]\n",
      "l2 error for x2_hat =  0.054485785911781194\n",
      "alpha2 =  0.8670672484540672\n",
      "true gam1 =  846.0519892280603\n",
      "gam1 =  712.5844945871534\n",
      "corr(z2_hat, beta_true) =  [[0.99872197]]\n",
      "l2 error for z2_hat =  0.062372812255253804\n",
      "true tau1 =  50012.758328212425\n",
      "tau1 =  43030.0108972745\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.72361546e-05]\n",
      "corr(x1_hat, beta_true) =  0.9995737271103661\n",
      "l2 error for x1_hat =  0.030781514261822143\n",
      "B / (A+B) =  [0.00199285]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9985986242588153\n",
      "alpha1 part I =  [0.00199006]\n",
      "alpha2 part II =  [5.32034249e-05]\n",
      "alpha1 =  0.07362708556366368\n",
      "true gam2 =  16935.165783048127\n",
      "gam2 =  8965.70833925044\n",
      "corr(z1_hat, X*beta_true) =  0.9987214421878138\n",
      "l2 error for z1_hat =  0.06243730878785148\n",
      "v1 =  0.9746931880600624\n",
      "true tau2 =  2029.508399109441\n",
      "tau2 = 1117.2258172011418\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995505]]\n",
      "l2 error for x2_hat =  0.03134640145233646\n",
      "alpha2 =  0.9399218734815213\n",
      "true gam1 =  1283.6770179341688\n",
      "gam1 =  573.0720553806292\n",
      "corr(z2_hat, beta_true) =  [[0.99917116]]\n",
      "l2 error for z2_hat =  0.056965867222828516\n",
      "true tau1 =  162104.50033752192\n",
      "tau1 =  73267.6381553802\n",
      "\n",
      "\n",
      "**** iteration =  4  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.48732824e-05]\n",
      "corr(x1_hat, beta_true) =  0.9993136474143236\n",
      "l2 error for x1_hat =  0.03704962864752272\n",
      "B / (A+B) =  [0.00234388]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9982580583907068\n",
      "alpha1 part I =  [0.00233979]\n",
      "alpha2 part II =  [0.0003138]\n",
      "alpha1 =  0.07720108493404758\n",
      "true gam2 =  11248.262828212102\n",
      "gam2 =  6850.03677618827\n",
      "corr(z1_hat, X*beta_true) =  0.9991868959158735\n",
      "l2 error for z1_hat =  0.05637442840615243\n",
      "v1 =  0.9764600033727646\n",
      "true tau2 =  2112.53458003567\n",
      "tau2 = 1766.2986185873901\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99934434]]\n",
      "l2 error for x2_hat =  0.036209976763075094\n",
      "alpha2 =  0.8882736262833185\n",
      "true gam1 =  1228.9136366029838\n",
      "gam1 =  861.5923586875894\n",
      "corr(z2_hat, beta_true) =  [[0.99960777]]\n",
      "l2 error for z2_hat =  0.03606702083302058\n",
      "true tau1 =  122724.85230420828\n",
      "tau1 =  61470.287688828765\n",
      "\n",
      "\n",
      "**** iteration =  5  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.18432296e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996092293520514\n",
      "l2 error for x1_hat =  0.02796545949778067\n",
      "B / (A+B) =  [0.00182525]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9988407038505169\n",
      "alpha1 part I =  [0.00182313]\n",
      "alpha2 part II =  [7.35129129e-05]\n",
      "alpha1 =  0.06783423017573342\n",
      "true gam2 =  20206.843656045632\n",
      "gam2 =  11839.846965611101\n",
      "corr(z1_hat, X*beta_true) =  0.9996089727838415\n",
      "l2 error for z1_hat =  0.035975241546628296\n",
      "v1 =  0.9739553318501813\n",
      "true tau2 =  2118.4608105650063\n",
      "tau2 = 1643.7850808703183\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99960775]]\n",
      "l2 error for x2_hat =  0.028020262928325986\n",
      "alpha2 =  0.9340481456806659\n",
      "true gam1 =  1339.3519795475302\n",
      "gam1 =  835.9953026513\n",
      "corr(z2_hat, beta_true) =  [[0.9997639]]\n",
      "l2 error for z2_hat =  0.02912705480388593\n",
      "true tau1 =  206470.42238522126\n",
      "tau1 =  98052.27943984681\n",
      "\n",
      "\n",
      "**** iteration =  6  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.24408317e-05]\n",
      "corr(x1_hat, beta_true) =  0.999603444427472\n",
      "l2 error for x1_hat =  0.028214409198436863\n",
      "B / (A+B) =  [0.0018718]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9988052501646875\n",
      "alpha1 part I =  [0.00186956]\n",
      "alpha2 part II =  [0.00011332]\n",
      "alpha1 =  0.06794951214932204\n",
      "true gam2 =  19903.468259136185\n",
      "gam2 =  11467.187990470267\n",
      "corr(z1_hat, X*beta_true) =  0.9997655926358853\n",
      "l2 error for z1_hat =  0.02898318267536361\n",
      "v1 =  0.9812400130562228\n",
      "true tau2 =  2165.797974319805\n",
      "tau2 = 1874.6274689409001\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99960789]]\n",
      "l2 error for x2_hat =  0.02805389721400674\n",
      "alpha2 =  0.9240909736508225\n",
      "true gam1 =  1352.499832788837\n",
      "gam1 =  941.9668627219954\n",
      "corr(z2_hat, beta_true) =  [[0.99982384]]\n",
      "l2 error for z2_hat =  0.022872080161595237\n",
      "true tau1 =  204072.11213197614\n",
      "tau1 =  96908.22137529077\n",
      "\n",
      "\n",
      "**** iteration =  7  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.31581755e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996605576099191\n",
      "l2 error for x1_hat =  0.026081360361587678\n",
      "B / (A+B) =  [0.00172904]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9989395173472869\n",
      "alpha1 part I =  [0.00172721]\n",
      "alpha2 part II =  [3.62031564e-05]\n",
      "alpha1 =  0.06735081304355989\n",
      "true gam2 =  23191.969623746765\n",
      "gam2 =  13044.009254786311\n",
      "corr(z1_hat, X*beta_true) =  0.9998231640470628\n",
      "l2 error for z1_hat =  0.022957201880106085\n",
      "v1 =  0.9817904374634446\n",
      "true tau2 =  2152.8721965114187\n",
      "tau2 = 1797.3859289146042\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99965901]]\n",
      "l2 error for x2_hat =  0.02614409918682051\n",
      "alpha2 =  0.9344748168501701\n",
      "true gam1 =  1372.5727630536453\n",
      "gam1 =  914.6432627354476\n",
      "corr(z2_hat, beta_true) =  [[0.99980152]]\n",
      "l2 error for z2_hat =  0.026687920136711795\n",
      "true tau1 =  234800.47759311696\n",
      "tau1 =  107924.45489705917\n",
      "\n",
      "\n",
      "**** iteration =  8  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.03199164e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996578132437257\n",
      "l2 error for x1_hat =  0.026265275513909135\n",
      "B / (A+B) =  [0.00178157]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9989078716125617\n",
      "alpha1 part I =  [0.00177962]\n",
      "alpha2 part II =  [9.15676441e-05]\n",
      "alpha1 =  0.07009566127591389\n",
      "true gam2 =  22773.271568771816\n",
      "gam2 =  12133.857116413343\n",
      "corr(z1_hat, X*beta_true) =  0.9998028111170196\n",
      "l2 error for z1_hat =  0.026562692541983318\n",
      "v1 =  0.9809375137942793\n",
      "true tau2 =  2162.089831786475\n",
      "tau2 = 2097.28795545541\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99966096]]\n",
      "l2 error for x2_hat =  0.026139873137952952\n",
      "alpha2 =  0.9203753354277379\n",
      "true gam1 =  1344.8741339787805\n",
      "gam1 =  1049.739454842252\n",
      "corr(z2_hat, beta_true) =  [[0.9998511]]\n",
      "l2 error for z2_hat =  0.02123629881492772\n",
      "true tau1 =  233752.49977640205\n",
      "tau1 =  103261.42051619153\n",
      "\n",
      "\n",
      "**** iteration =  9  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.97579593e-05]\n",
      "corr(x1_hat, beta_true) =  0.999724643459098\n",
      "l2 error for x1_hat =  0.023519876930155937\n",
      "B / (A+B) =  [0.00162618]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990482892829506\n",
      "alpha1 part I =  [0.00162464]\n",
      "alpha2 part II =  [1.02921206e-05]\n",
      "alpha1 =  0.07228349487872504\n",
      "true gam2 =  28070.4217545157\n",
      "gam2 =  13472.793754204593\n",
      "corr(z1_hat, X*beta_true) =  0.9998505503785329\n",
      "l2 error for z1_hat =  0.021306741876725547\n",
      "v1 =  0.9818619190184479\n",
      "true tau2 =  2155.462554484061\n",
      "tau2 = 1907.563549735346\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99972359]]\n",
      "l2 error for x2_hat =  0.023567512327408075\n",
      "alpha2 =  0.9329228786760444\n",
      "true gam1 =  1373.9748543977094\n",
      "gam1 =  968.693384930081\n",
      "corr(z2_hat, beta_true) =  [[0.99984183]]\n",
      "l2 error for z2_hat =  0.023956380892047737\n",
      "true tau1 =  284585.5931272917\n",
      "tau1 =  111845.88991303799\n",
      "\n",
      "\n",
      "**** iteration =  10  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.59165411e-05]\n",
      "corr(x1_hat, beta_true) =  0.999707546594399\n",
      "l2 error for x1_hat =  0.02428883517514991\n",
      "B / (A+B) =  [0.00170619]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9989687461876703\n",
      "alpha1 part I =  [0.00170443]\n",
      "alpha2 part II =  [3.7920752e-05]\n",
      "alpha1 =  0.07162290248634755\n",
      "true gam2 =  26400.987454528473\n",
      "gam2 =  12556.21766031455\n",
      "corr(z1_hat, X*beta_true) =  0.9998427287157854\n",
      "l2 error for z1_hat =  0.023853486204629605\n",
      "v1 =  0.9813824213827705\n",
      "true tau2 =  2163.2353195472397\n",
      "tau2 = 2121.8024728178953\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99970923]]\n",
      "l2 error for x2_hat =  0.024214127485174923\n",
      "alpha2 =  0.9219024032191495\n",
      "true gam1 =  1354.579205248546\n",
      "gam1 =  1063.6813837383331\n",
      "corr(z2_hat, beta_true) =  [[0.99987301]]\n",
      "l2 error for z2_hat =  0.019548776990592195\n",
      "true tau1 =  270158.8162323717\n",
      "tau1 =  106552.60290085222\n",
      "\n",
      "\n",
      "**** iteration =  11  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.87850925e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997422854479174\n",
      "l2 error for x1_hat =  0.02275261818441398\n",
      "B / (A+B) =  [0.0016114]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990607518687997\n",
      "alpha1 part I =  [0.00160989]\n",
      "alpha2 part II =  [1.98349389e-06]\n",
      "alpha1 =  0.07216867557082428\n",
      "true gam2 =  29897.57833250893\n",
      "gam2 =  13675.14228629655\n",
      "corr(z1_hat, X*beta_true) =  0.9998726037155038\n",
      "l2 error for z1_hat =  0.019605052838501173\n",
      "v1 =  0.9821221297086226\n",
      "true tau2 =  2157.8011351902505\n",
      "tau2 = 1939.609704584543\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9997413]]\n",
      "l2 error for x2_hat =  0.02279769598139048\n",
      "alpha2 =  0.9328214729733333\n",
      "true gam1 =  1379.3741808445257\n",
      "gam1 =  984.8357293333319\n",
      "corr(z2_hat, beta_true) =  [[0.99986093]]\n",
      "l2 error for z2_hat =  0.021978693524945362\n",
      "true tau1 =  302887.3160501594\n",
      "tau1 =  113550.25233508828\n",
      "\n",
      "\n",
      "**** iteration =  12  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.36123509e-05]\n",
      "corr(x1_hat, beta_true) =  0.999717483377589\n",
      "l2 error for x1_hat =  0.02385044368003176\n",
      "B / (A+B) =  [0.00168307]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9989856322202115\n",
      "alpha1 part I =  [0.00168136]\n",
      "alpha2 part II =  [1.9248762e-05]\n",
      "alpha1 =  0.07081886234080134\n",
      "true gam2 =  27371.32579236791\n",
      "gam2 =  12921.568536157558\n",
      "corr(z1_hat, X*beta_true) =  0.9998616055593508\n",
      "l2 error for z1_hat =  0.021894018985433\n",
      "v1 =  0.9817077657337038\n",
      "true tau2 =  2164.4481878148235\n",
      "tau2 = 2115.790349440825\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99971856]]\n",
      "l2 error for x2_hat =  0.023801323502257696\n",
      "alpha2 =  0.9239859658048956\n",
      "true gam1 =  1362.5264673826177\n",
      "gam1 =  1063.0254018049309\n",
      "corr(z2_hat, beta_true) =  [[0.99988081]]\n",
      "l2 error for z2_hat =  0.018489287560918142\n",
      "true tau1 =  279165.1836187913\n",
      "tau1 =  109221.03695327793\n",
      "\n",
      "\n",
      "**** iteration =  13  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.79014319e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997386521924017\n",
      "l2 error for x1_hat =  0.02290060668079365\n",
      "B / (A+B) =  [0.00161126]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990601728132583\n",
      "alpha1 part I =  [0.00160975]\n",
      "alpha2 part II =  [7.12494738e-07]\n",
      "alpha1 =  0.07122681070801878\n",
      "true gam2 =  29577.682383313775\n",
      "gam2 =  13861.48674801753\n",
      "corr(z1_hat, X*beta_true) =  0.999880504581025\n",
      "l2 error for z1_hat =  0.01853327385579232\n",
      "v1 =  0.9823977735871364\n",
      "true tau2 =  2160.852523346879\n",
      "tau2 = 1956.9806377709722\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99973772]]\n",
      "l2 error for x2_hat =  0.022942481451721845\n",
      "alpha2 =  0.9330883782545584\n",
      "true gam1 =  1383.5836341982906\n",
      "gam1 =  994.0050478902958\n",
      "corr(z2_hat, beta_true) =  [[0.99987041]]\n",
      "l2 error for z2_hat =  0.020460328487175473\n",
      "true tau1 =  299297.8234045122\n",
      "tau1 =  115032.00194681522\n",
      "\n",
      "\n",
      "**** iteration =  14  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.18954808e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997147007224769\n",
      "l2 error for x1_hat =  0.02394638680303319\n",
      "B / (A+B) =  [0.00167232]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9989949799730963\n",
      "alpha1 part I =  [0.00167064]\n",
      "alpha2 part II =  [1.31626101e-05]\n",
      "alpha1 =  0.06991694523481211\n",
      "true gam2 =  27210.305257571814\n",
      "gam2 =  13222.93541699967\n",
      "corr(z1_hat, X*beta_true) =  0.9998709300332358\n",
      "l2 error for z1_hat =  0.02039100350243386\n",
      "v1 =  0.9820172124608912\n",
      "true tau2 =  2166.8924338836746\n",
      "tau2 = 2106.476368193297\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99971559]]\n",
      "l2 error for x2_hat =  0.023906608775320477\n",
      "alpha2 =  0.9257581243691883\n",
      "true gam1 =  1368.9687407867295\n",
      "gam1 =  1060.4233447824968\n",
      "corr(z2_hat, beta_true) =  [[0.99988409]]\n",
      "l2 error for z2_hat =  0.01769018554241227\n",
      "true tau1 =  276876.8423723896\n",
      "tau1 =  111386.15028193785\n",
      "\n",
      "\n",
      "**** iteration =  15  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.71644093e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997310247136606\n",
      "l2 error for x1_hat =  0.02322147349392879\n",
      "B / (A+B) =  [0.00161312]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990578688466618\n",
      "alpha1 part I =  [0.0016116]\n",
      "alpha2 part II =  [4.94509208e-07]\n",
      "alpha1 =  0.07029439500237672\n",
      "true gam2 =  28857.17014274948\n",
      "gam2 =  14025.037519439222\n",
      "corr(z1_hat, X*beta_true) =  0.9998838538833235\n",
      "l2 error for z1_hat =  0.01772409137406024\n",
      "v1 =  0.9826201284157642\n",
      "true tau2 =  2164.312279189168\n",
      "tau2 = 1970.1173751484234\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99973022]]\n",
      "l2 error for x2_hat =  0.023256977929187697\n",
      "alpha2 =  0.9333784356441953\n",
      "true gam1 =  1387.1770793864484\n",
      "gam1 =  1001.0622744342875\n",
      "corr(z2_hat, beta_true) =  [[0.99987672]]\n",
      "l2 error for z2_hat =  0.019180074662975673\n",
      "true tau1 =  291622.454222041\n",
      "tau1 =  116316.95043530707\n",
      "\n",
      "\n",
      "**** iteration =  16  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.04105425e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997100969344213\n",
      "l2 error for x1_hat =  0.024120996883549524\n",
      "B / (A+B) =  [0.00166454]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990020580302112\n",
      "alpha1 part I =  [0.00166288]\n",
      "alpha2 part II =  [9.31520201e-06]\n",
      "alpha1 =  0.069031125522067\n",
      "true gam2 =  26885.475913735783\n",
      "gam2 =  13500.545034782777\n",
      "corr(z1_hat, X*beta_true) =  0.9998771248587982\n",
      "l2 error for z1_hat =  0.01912383348307726\n",
      "v1 =  0.982283548173335\n",
      "true tau2 =  2169.6761424982965\n",
      "tau2 = 2097.890830854132\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99971087]]\n",
      "l2 error for x2_hat =  0.024086952423089874\n",
      "alpha2 =  0.9273278749720211\n",
      "true gam1 =  1374.9717285373945\n",
      "gam1 =  1058.0004367313943\n",
      "corr(z2_hat, beta_true) =  [[0.99988621]]\n",
      "l2 error for z2_hat =  0.017002030602436796\n",
      "true tau1 =  272911.41710663086\n",
      "tau1 =  113373.66473719564\n",
      "\n",
      "\n",
      "**** iteration =  17  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.64236378e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997232680250676\n",
      "l2 error for x1_hat =  0.023544426305660796\n",
      "B / (A+B) =  [0.00161487]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990557133261564\n",
      "alpha1 part I =  [0.00161334]\n",
      "alpha2 part II =  [3.01159978e-07]\n",
      "alpha1 =  0.06935018677587415\n",
      "true gam2 =  28162.47293738629\n",
      "gam2 =  14197.912862401294\n",
      "corr(z1_hat, X*beta_true) =  0.9998860277053062\n",
      "l2 error for z1_hat =  0.017027802596457437\n",
      "v1 =  0.9828256989618736\n",
      "true tau2 =  2167.6843114889152\n",
      "tau2 = 1981.1381102965572\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99972257]]\n",
      "l2 error for x2_hat =  0.02357459324216799\n",
      "alpha2 =  0.933760589504116\n",
      "true gam1 =  1390.9099334104492\n",
      "gam1 =  1007.1761314930128\n",
      "corr(z2_hat, beta_true) =  [[0.99988131]]\n",
      "l2 error for z2_hat =  0.018087149156804826\n",
      "true tau1 =  284113.35657375236\n",
      "tau1 =  117653.87044218213\n",
      "\n",
      "\n",
      "**** iteration =  18  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.90467793e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997050066205388\n",
      "l2 error for x1_hat =  0.024317396804797737\n",
      "B / (A+B) =  [0.00165801]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990081098245015\n",
      "alpha1 part I =  [0.00165636]\n",
      "alpha2 part II =  [6.31579874e-06]\n",
      "alpha1 =  0.06814861861108718\n",
      "true gam2 =  26523.898422201455\n",
      "gam2 =  13771.936813419334\n",
      "corr(z1_hat, X*beta_true) =  0.9998816261770268\n",
      "l2 error for z1_hat =  0.018042157197091506\n",
      "v1 =  0.982540839132796\n",
      "true tau2 =  2172.3906292344777\n",
      "tau2 = 2090.638647155111\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99970568]]\n",
      "l2 error for x2_hat =  0.024288416272388973\n",
      "alpha2 =  0.9287739793288137\n",
      "true gam1 =  1380.766598281557\n",
      "gam1 =  1056.1452818302982\n",
      "corr(z2_hat, beta_true) =  [[0.99988757]]\n",
      "l2 error for z2_hat =  0.01641856283257748\n",
      "true tau1 =  268530.09197202534\n",
      "tau1 =  115318.06269285137\n",
      "\n",
      "\n",
      "**** iteration =  19  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.5668144e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997155072383237\n",
      "l2 error for x1_hat =  0.023864637453706018\n",
      "B / (A+B) =  [0.0016162]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990540562236927\n",
      "alpha1 part I =  [0.00161467]\n",
      "alpha2 part II =  [1.33271964e-07]\n",
      "alpha1 =  0.06841233646285313\n",
      "true gam2 =  27502.22500706681\n",
      "gam2 =  14381.790862972608\n",
      "corr(z1_hat, X*beta_true) =  0.999887427533879\n",
      "l2 error for z1_hat =  0.016437804239641737\n",
      "v1 =  0.9830305752872543\n",
      "true tau2 =  2170.8464530027836\n",
      "tau2 = 1990.6615644322133\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9997149]]\n",
      "l2 error for x2_hat =  0.02389052216186306\n",
      "alpha2 =  0.934220053929817\n",
      "true gam1 =  1394.7541675965026\n",
      "gam1 =  1012.6451721727431\n",
      "corr(z2_hat, beta_true) =  [[0.99988446]]\n",
      "l2 error for z2_hat =  0.017181064041752105\n",
      "true tau1 =  276886.12390933256\n",
      "tau1 =  119059.0919460559\n",
      "\n",
      "\n",
      "**** iteration =  20  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.77835376e-05]\n",
      "corr(x1_hat, beta_true) =  0.999699501357857\n",
      "l2 error for x1_hat =  0.02453212652062601\n",
      "B / (A+B) =  [0.0016524]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990134614878533\n",
      "alpha1 part I =  [0.00165077]\n",
      "alpha2 part II =  [4.03233241e-06]\n",
      "alpha1 =  0.0672832343582751\n",
      "true gam2 =  26134.37643734562\n",
      "gam2 =  14037.83778737896\n",
      "corr(z1_hat, X*beta_true) =  0.9998847000464869\n",
      "l2 error for z1_hat =  0.017145716172648085\n",
      "v1 =  0.9827920505181076\n",
      "true tau2 =  2174.988045879982\n",
      "tau2 = 2084.63513567051\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99970008]]\n",
      "l2 error for x2_hat =  0.02450751623647428\n",
      "alpha2 =  0.9301100319225152\n",
      "true gam1 =  1386.3379363195368\n",
      "gam1 =  1054.8257745472404\n",
      "corr(z2_hat, beta_true) =  [[0.99988819]]\n",
      "l2 error for z2_hat =  0.015949818998872187\n",
      "true tau1 =  263847.27800343843\n",
      "tau1 =  117224.91345987844\n",
      "\n",
      "\n",
      "**** iteration =  21  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.49061086e-05]\n",
      "corr(x1_hat, beta_true) =  0.999707756273086\n",
      "l2 error for x1_hat =  0.02418175060032813\n",
      "B / (A+B) =  [0.00161715]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990528740402944\n",
      "alpha1 part I =  [0.00161562]\n",
      "alpha2 part II =  [2.47431408e-08]\n",
      "alpha1 =  0.06749112344491089\n",
      "true gam2 =  26874.040319312855\n",
      "gam2 =  14574.278035055719\n",
      "corr(z1_hat, X*beta_true) =  0.9998880853924164\n",
      "l2 error for z1_hat =  0.015963892479858834\n",
      "v1 =  0.9832336244973058\n",
      "true tau2 =  2173.807977077121\n",
      "tau2 = 1998.9520988402094\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99970722]]\n",
      "l2 error for x2_hat =  0.02420409427141079\n",
      "alpha2 =  0.9347364783485486\n",
      "true gam1 =  1398.6581673688552\n",
      "gam1 =  1017.579534047516\n",
      "corr(z2_hat, beta_true) =  [[0.99988634]]\n",
      "l2 error for z2_hat =  0.016460879080905565\n",
      "true tau1 =  269946.171739588\n",
      "tau1 =  120516.78399740541\n",
      "\n",
      "\n",
      "**** iteration =  22  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.66069049e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996936872035752\n",
      "l2 error for x1_hat =  0.02476009583128561\n",
      "B / (A+B) =  [0.00164756]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990182406316115\n",
      "alpha1 part I =  [0.00164595]\n",
      "alpha2 part II =  [2.34016839e-06]\n",
      "alpha1 =  0.06643715133991732\n",
      "true gam2 =  25728.599472199156\n",
      "gam2 =  14298.843785206473\n",
      "corr(z1_hat, X*beta_true) =  0.9998865279405988\n",
      "l2 error for z1_hat =  0.01643375629622396\n",
      "v1 =  0.9830363130015755\n",
      "true tau2 =  2177.468456728361\n",
      "tau2 = 2079.6881811480434\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99969419]]\n",
      "l2 error for x2_hat =  0.024739236942227905\n",
      "alpha2 =  0.9313507641996815\n",
      "true gam1 =  1391.7017415790078\n",
      "gam1 =  1053.958118052396\n",
      "corr(z2_hat, beta_true) =  [[0.99988813]]\n",
      "l2 error for z2_hat =  0.015600921996204865\n",
      "true tau1 =  258998.19627422956\n",
      "tau1 =  119097.95680807097\n",
      "\n",
      "\n",
      "**** iteration =  23  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.41441688e-05]\n",
      "corr(x1_hat, beta_true) =  0.9997000684551038\n",
      "l2 error for x1_hat =  0.02449367936097056\n",
      "B / (A+B) =  [0.00161781]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990520950709909\n",
      "alpha1 part I =  [0.00161627]\n",
      "alpha2 part II =  [5.02075301e-09]\n",
      "alpha1 =  0.06659113759527627\n",
      "true gam2 =  26279.46118825436\n",
      "gam2 =  14773.344975312388\n",
      "corr(z1_hat, X*beta_true) =  0.999888044391091\n",
      "l2 error for z1_hat =  0.01561099053335318\n",
      "v1 =  0.9834341831764776\n",
      "true tau2 =  2176.5829998590966\n",
      "tau2 = 2006.1890976431944\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996996]]\n",
      "l2 error for x2_hat =  0.024513067374037783\n",
      "alpha2 =  0.9352943367353665\n",
      "true gam1 =  1402.5923087762446\n",
      "gam1 =  1022.0516127590934\n",
      "corr(z2_hat, beta_true) =  [[0.99988714]]\n",
      "l2 error for z2_hat =  0.015921957282442736\n",
      "true tau1 =  263329.0182677008\n",
      "tau1 =  122013.19322061077\n",
      "\n",
      "\n",
      "**** iteration =  24  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.5505933e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996876738300473\n",
      "l2 error for x1_hat =  0.024996255825881965\n",
      "B / (A+B) =  [0.00164337]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990225322090026\n",
      "alpha1 part I =  [0.00164177]\n",
      "alpha2 part II =  [1.15357371e-06]\n",
      "alpha1 =  0.06561278332772187\n",
      "true gam2 =  25317.30459162838\n",
      "gam2 =  14554.968000235576\n",
      "corr(z1_hat, X*beta_true) =  0.9998872758159553\n",
      "l2 error for z1_hat =  0.01590178445091991\n",
      "v1 =  0.9832730808500031\n",
      "true tau2 =  2179.829324126072\n",
      "tau2 = 2075.6236064856175\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99968811]]\n",
      "l2 error for x2_hat =  0.024978621128644577\n",
      "alpha2 =  0.9325067912235658\n",
      "true gam1 =  1396.86748887793\n",
      "gam1 =  1053.4630988426763\n",
      "corr(z2_hat, beta_true) =  [[0.99988742]]\n",
      "l2 error for z2_hat =  0.015372488569688808\n",
      "true tau1 =  254104.2337297513\n",
      "tau1 =  120936.67017026777\n",
      "\n",
      "\n",
      "**** iteration =  25  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.33875786e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996925020430979\n",
      "l2 error for x1_hat =  0.02479822380016662\n",
      "B / (A+B) =  [0.00161823]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990516500756664\n",
      "alpha1 part I =  [0.0016167]\n",
      "alpha2 part II =  [9.95728451e-08]\n",
      "alpha1 =  0.06571709625416959\n",
      "true gam2 =  25720.003625169353\n",
      "gam2 =  14976.811500757221\n",
      "corr(z1_hat, X*beta_true) =  0.9998873597564815\n",
      "l2 error for z1_hat =  0.01537953371792583\n",
      "v1 =  0.9836312838741109\n",
      "true tau2 =  2179.181687113843\n",
      "tau2 = 2012.5203983251365\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99969208]]\n",
      "l2 error for x2_hat =  0.024815122104676006\n",
      "alpha2 =  0.9358793420353961\n",
      "true gam1 =  1406.5261594474248\n",
      "gam1 =  1026.1183942278733\n",
      "corr(z2_hat, beta_true) =  [[0.99988699]]\n",
      "l2 error for z2_hat =  0.015555811762271107\n",
      "true tau1 =  257065.01718079497\n",
      "tau1 =  123533.31535626714\n",
      "\n",
      "\n",
      "**** iteration =  26  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.4471612e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996815608821382\n",
      "l2 error for x1_hat =  0.025236175703958977\n",
      "B / (A+B) =  [0.00163975]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990264024034428\n",
      "alpha1 part I =  [0.00163815]\n",
      "alpha2 part II =  [4.06288491e-07]\n",
      "alpha1 =  0.06481298403687939\n",
      "true gam2 =  24909.14378203124\n",
      "gam2 =  14805.869740186663\n",
      "corr(z1_hat, X*beta_true) =  0.9998870949572719\n",
      "l2 error for z1_hat =  0.015541431444076806\n",
      "v1 =  0.9835015725548308\n",
      "true tau2 =  2182.069267946334\n",
      "tau2 = 2072.295049993882\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99968193]]\n",
      "l2 error for x2_hat =  0.025221313960620023\n",
      "alpha2 =  0.9335858012303216\n",
      "true gam1 =  1401.8399480735056\n",
      "gam1 =  1053.272205497191\n",
      "corr(z2_hat, beta_true) =  [[0.99988614]]\n",
      "l2 error for z2_hat =  0.015261015666979497\n",
      "true tau1 =  249262.56419985197\n",
      "tau1 =  122738.06709443333\n",
      "\n",
      "\n",
      "**** iteration =  27  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.26403558e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996851090489224\n",
      "l2 error for x1_hat =  0.02509351877505941\n",
      "B / (A+B) =  [0.00161849]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990514783612944\n",
      "alpha1 part I =  [0.00161696]\n",
      "alpha2 part II =  [3.292429e-07]\n",
      "alpha1 =  0.0648729519612187\n",
      "true gam2 =  25196.33912328288\n",
      "gam2 =  15182.650064956004\n",
      "corr(z1_hat, X*beta_true) =  0.999886092352376\n",
      "l2 error for z1_hat =  0.015265851600897062\n",
      "v1 =  0.9838238740647499\n",
      "true tau2 =  2181.6133453163516\n",
      "tau2 = 2018.071001027627\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99968474]]\n",
      "l2 error for x2_hat =  0.02510830593254355\n",
      "alpha2 =  0.9364793431780356\n",
      "true gam1 =  1410.4327591265085\n",
      "gam1 =  1029.8272048919073\n",
      "corr(z2_hat, beta_true) =  [[0.99988605]]\n",
      "l2 error for z2_hat =  0.015350174475497422\n",
      "true tau1 =  251171.8416736301\n",
      "tau1 =  125063.17166835305\n",
      "\n",
      "\n",
      "**** iteration =  28  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.34966216e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996754321554089\n",
      "l2 error for x1_hat =  0.025476242159463078\n",
      "B / (A+B) =  [0.00163662]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990299053078397\n",
      "alpha1 part I =  [0.00163503]\n",
      "alpha2 part II =  [4.70969021e-08]\n",
      "alpha1 =  0.06404040467780175\n",
      "true gam2 =  24510.5058562665\n",
      "gam2 =  15051.070629422919\n",
      "corr(z1_hat, X*beta_true) =  0.9998861201664748\n",
      "l2 error for z1_hat =  0.015340538120981793\n",
      "v1 =  0.9837211099165368\n",
      "true tau2 =  2184.188524557798\n",
      "tau2 = 2069.58009191359\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99967575]]\n",
      "l2 error for x2_hat =  0.025463766352473195\n",
      "alpha2 =  0.9345938200280568\n",
      "true gam1 =  1406.6217376425773\n",
      "gam1 =  1053.3271387659195\n",
      "corr(z2_hat, beta_true) =  [[0.99988434]]\n",
      "l2 error for z2_hat =  0.015259462513924417\n",
      "true tau1 =  244544.60880804923\n",
      "tau1 =  124498.28201538954\n",
      "\n",
      "\n",
      "**** iteration =  29  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.19056883e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996779318965654\n",
      "l2 error for x1_hat =  0.02537814418440702\n",
      "B / (A+B) =  [0.00161864]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999051527781813\n",
      "alpha1 part I =  [0.00161711]\n",
      "alpha2 part II =  [7.10519377e-07]\n",
      "alpha1 =  0.06406189573391931\n",
      "true gam2 =  24708.24299524202\n",
      "gam2 =  15389.007679749402\n",
      "corr(z1_hat, X*beta_true) =  0.9998843039783207\n",
      "l2 error for z1_hat =  0.015262748500941377\n",
      "v1 =  0.984011006631128\n",
      "true tau2 =  2183.886807236278\n",
      "tau2 = 2022.9470932394097\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996776]]\n",
      "l2 error for x2_hat =  0.02539113225585318\n",
      "alpha2 =  0.9370841840425999\n",
      "true gam1 =  1414.288204259481\n",
      "gam1 =  1033.2177102480218\n",
      "corr(z2_hat, beta_true) =  [[0.99988442]]\n",
      "l2 error for z2_hat =  0.015289529972310834\n",
      "true tau1 =  245654.85401948987\n",
      "tau1 =  126589.99783680063\n",
      "\n",
      "\n",
      "**** iteration =  30  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.25750466e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996693564963997\n",
      "l2 error for x1_hat =  0.025713583377991546\n",
      "B / (A+B) =  [0.00163394]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990330855968805\n",
      "alpha1 part I =  [0.00163236]\n",
      "alpha2 part II =  [3.58030865e-08]\n",
      "alpha1 =  0.0632974201882544\n",
      "true gam2 =  24125.88242886292\n",
      "gam2 =  15290.002212066409\n",
      "corr(z1_hat, X*beta_true) =  0.9998844706697186\n",
      "l2 error for z1_hat =  0.015283700059900832\n",
      "v1 =  0.9839311482310991\n",
      "true tau2 =  2186.1886849926946\n",
      "tau2 = 2067.3762735553432\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99966963]]\n",
      "l2 error for x2_hat =  0.025703159815036174\n",
      "alpha2 =  0.9355356505658556\n",
      "true gam1 =  1411.2137159014612\n",
      "gam1 =  1053.5782841106227\n",
      "corr(z2_hat, beta_true) =  [[0.99988209]]\n",
      "l2 error for z2_hat =  0.015357992830985906\n",
      "true tau1 =  240000.2640193231\n",
      "tau1 =  126212.90836143275\n",
      "\n",
      "\n",
      "**** iteration =  31  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.11861104e-05]\n",
      "corr(x1_hat, beta_true) =  0.999671003881557\n",
      "l2 error for x1_hat =  0.025651079052102614\n",
      "B / (A+B) =  [0.00161872]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999051753658247\n",
      "alpha1 part I =  [0.00161719]\n",
      "alpha2 part II =  [1.25554704e-06]\n",
      "alpha1 =  0.06328639031153908\n",
      "true gam2 =  24254.824076539102\n",
      "gam2 =  15594.207739459163\n",
      "corr(z1_hat, X*beta_true) =  0.9998820556530601\n",
      "l2 error for z1_hat =  0.015360247059878153\n",
      "v1 =  0.9841918530547747\n",
      "true tau2 =  2186.010604113415\n",
      "tau2 = 2027.2390952729584\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99967071]]\n",
      "l2 error for x2_hat =  0.025662528017162355\n",
      "alpha2 =  0.9376854938050581\n",
      "true gam1 =  1418.071466410099\n",
      "gam1 =  1036.3233314429012\n",
      "corr(z2_hat, beta_true) =  [[0.99988222]]\n",
      "l2 error for z2_hat =  0.01535607748837926\n",
      "true tau1 =  240510.17237730624\n",
      "tau1 =  128102.27450023133\n",
      "\n",
      "\n",
      "**** iteration =  32  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.17020674e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996633894058459\n",
      "l2 error for x1_hat =  0.025945966396792558\n",
      "B / (A+B) =  [0.00163164]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999035980422219\n",
      "alpha1 part I =  [0.00163007]\n",
      "alpha2 part II =  [3.39692314e-07]\n",
      "alpha1 =  0.06258600352976577\n",
      "true gam2 =  23758.257987848145\n",
      "gam2 =  15522.064694564033\n",
      "corr(z1_hat, X*beta_true) =  0.9998822519028557\n",
      "l2 error for z1_hat =  0.015353233686989744\n",
      "v1 =  0.9841312782136498\n",
      "true tau2 =  2188.0724282878773\n",
      "tau2 = 2065.5977502642945\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99966362]]\n",
      "l2 error for x2_hat =  0.025937306472950485\n",
      "alpha2 =  0.9364152722776626\n",
      "true gam1 =  1415.6157953501677\n",
      "gam1 =  1053.9835119217362\n",
      "corr(z2_hat, beta_true) =  [[0.99987943]]\n",
      "l2 error for z2_hat =  0.015544886001570826\n",
      "true tau1 =  235662.30799780777\n",
      "tau1 =  127877.4136775348\n",
      "\n",
      "\n",
      "**** iteration =  33  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.04836233e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996643496871923\n",
      "l2 error for x1_hat =  0.02591165748953707\n",
      "B / (A+B) =  [0.00161877]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990521178874365\n",
      "alpha1 part I =  [0.00161724]\n",
      "alpha2 part II =  [1.97225658e-06]\n",
      "alpha1 =  0.06254818184717487\n",
      "true gam2 =  23834.70831898959\n",
      "gam2 =  15796.762277891205\n",
      "corr(z1_hat, X*beta_true) =  0.9998794064964962\n",
      "l2 error for z1_hat =  0.015546501992632142\n",
      "v1 =  0.9843657255466911\n",
      "true tau2 =  2187.99302029499\n",
      "tau2 = 2031.024171126593\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99966409]]\n",
      "l2 error for x2_hat =  0.02592178584232104\n",
      "alpha2 =  0.9382765213745877\n",
      "true gam1 =  1421.764420138017\n",
      "gam1 =  1039.1724577970926\n",
      "corr(z2_hat, beta_true) =  [[0.99987954]]\n",
      "l2 error for z2_hat =  0.015530946399740838\n",
      "true tau1 =  235727.123226627\n",
      "tau1 =  129589.82522736446\n",
      "\n",
      "\n",
      "**** iteration =  34  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.08737258e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996575743836611\n",
      "l2 error for x1_hat =  0.026171709653472326\n",
      "B / (A+B) =  [0.00162971]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990386209589535\n",
      "alpha1 part I =  [0.00162814]\n",
      "alpha2 part II =  [9.31046439e-07]\n",
      "alpha1 =  0.061907655643498455\n",
      "true gam2 =  23409.432990651174\n",
      "gam2 =  15746.674898162779\n",
      "corr(z1_hat, X*beta_true) =  0.9998795570042797\n",
      "l2 error for z1_hat =  0.015530389484253634\n",
      "v1 =  0.9843212313882183\n",
      "true tau2 =  2189.8432607623545\n",
      "tau2 = 2064.1725682535184\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99965777]]\n",
      "l2 error for x2_hat =  0.026164563361023584\n",
      "alpha2 =  0.9372361311678818\n",
      "true gam1 =  1419.8275764628188\n",
      "gam1 =  1054.507188726022\n",
      "corr(z2_hat, beta_true) =  [[0.99987644]]\n",
      "l2 error for z2_hat =  0.01580748243045491\n",
      "true tau1 =  231550.1015179176\n",
      "tau1 =  129487.47373161379\n",
      "\n",
      "\n",
      "**** iteration =  35  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.79979242e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996579861019411\n",
      "l2 error for x1_hat =  0.026159521420439095\n",
      "B / (A+B) =  [0.00161882]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990525881673937\n",
      "alpha1 part I =  [0.00161728]\n",
      "alpha2 part II =  [2.86455143e-06]\n",
      "alpha1 =  0.061848344958151724\n",
      "true gam2 =  23446.19118867655\n",
      "gam2 =  15995.378130590609\n",
      "corr(z1_hat, X*beta_true) =  0.9998764128739902\n",
      "l2 error for z1_hat =  0.01580874763763341\n",
      "v1 =  0.9845320876292244\n",
      "true tau2 =  2189.842113701056\n",
      "tau2 = 2034.3683278182848\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99965775]]\n",
      "l2 error for x2_hat =  0.02616851394951889\n",
      "alpha2 =  0.938851958507049\n",
      "true gam1 =  1425.351795549163\n",
      "gam1 =  1041.7894288468408\n",
      "corr(z2_hat, beta_true) =  [[0.99987646]]\n",
      "l2 error for z2_hat =  0.015795381451315926\n",
      "true tau1 =  231290.2725217825\n",
      "tau1 =  131043.86463915581\n",
      "\n",
      "\n",
      "**** iteration =  36  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.00867398e-05]\n",
      "corr(x1_hat, beta_true) =  0.9996519443170986\n",
      "l2 error for x1_hat =  0.026389599556948588\n",
      "B / (A+B) =  [0.00162809]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990410336235324\n",
      "alpha1 part I =  [0.00162653]\n",
      "alpha2 part II =  [1.78535981e-06]\n",
      "alpha1 =  0.061263381393592845\n",
      "true gam2 =  23080.300260744425\n",
      "gam2 =  15963.30244085846\n",
      "corr(z1_hat, X*beta_true) =  0.9998764681429767\n",
      "l2 error for z1_hat =  0.01579653145591865\n",
      "v1 =  0.9845008760549842\n",
      "true tau2 =  2191.505308173208\n",
      "tau2 = 2063.0404194406433\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996521]]\n",
      "l2 error for x2_hat =  0.026383750187298435\n",
      "alpha2 =  0.9380013406829523\n",
      "true gam1 =  1423.8488362241221\n",
      "gam1 =  1055.119333715647\n",
      "corr(z2_hat, beta_true) =  [[0.99987315]]\n",
      "l2 error for z2_hat =  0.01613302041163107\n",
      "true tau1 =  227672.76073772175\n",
      "tau1 =  131039.21967239141\n",
      "\n",
      "\n",
      "**** iteration =  37  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.13582185e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996519229353398\n",
      "l2 error for x1_hat =  0.026394570382002252\n",
      "B / (A+B) =  [0.00161888]\n",
      "gam1 / (gam1 + 1/sigma) =  0.99905313730364\n",
      "alpha1 part I =  [0.00161735]\n",
      "alpha2 part II =  [3.93256906e-06]\n",
      "alpha1 =  0.06118734396056727\n",
      "true gam2 =  23087.364966418365\n",
      "gam2 =  16188.958696467\n",
      "corr(z1_hat, X*beta_true) =  0.999873127827857\n",
      "l2 error for z1_hat =  0.016134135669972727\n",
      "v1 =  0.9846905544475976\n",
      "true tau2 =  2191.565722280829\n",
      "tau2 = 2037.328163393629\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99965171]]\n",
      "l2 error for x2_hat =  0.026402584025388122\n",
      "alpha2 =  0.9394077645046965\n",
      "true gam1 =  1428.8211061315344\n",
      "gam1 =  1044.195326911379\n",
      "corr(z2_hat, beta_true) =  [[0.99987306]]\n",
      "l2 error for z2_hat =  0.016131690227844834\n",
      "true tau1 =  227181.09953466532\n",
      "tau1 =  132457.01070624872\n",
      "\n",
      "\n",
      "**** iteration =  38  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.338357e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996465228866459\n",
      "l2 error for x1_hat =  0.02659881238484805\n",
      "B / (A+B) =  [0.00162677]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990432410342333\n",
      "alpha1 part I =  [0.00162521]\n",
      "alpha2 part II =  [2.88009922e-06]\n",
      "alpha1 =  0.06065369801446991\n",
      "true gam2 =  22771.07560134411\n",
      "gam2 =  16171.495737172949\n",
      "corr(z1_hat, X*beta_true) =  0.9998730577163055\n",
      "l2 error for z1_hat =  0.016134078399754538\n",
      "v1 =  0.9846702079221015\n",
      "true tau2 =  2193.0631417253717\n",
      "tau2 = 2062.1507760163804\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99964666]]\n",
      "l2 error for x2_hat =  0.026594072115114685\n",
      "alpha2 =  0.938713816816471\n",
      "true gam1 =  1427.6798917300487\n",
      "gam1 =  1055.7948890761966\n",
      "corr(z2_hat, beta_true) =  [[0.99986962]]\n",
      "l2 error for z2_hat =  0.016509281821353913\n",
      "true tau1 =  224031.79915905854\n",
      "tau1 =  132529.41090378462\n",
      "\n",
      "\n",
      "**** iteration =  39  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-8.49261268e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996461640323433\n",
      "l2 error for x1_hat =  0.026616912129393072\n",
      "B / (A+B) =  [0.00161899]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990537425849266\n",
      "alpha1 part I =  [0.00161745]\n",
      "alpha2 part II =  [5.1730094e-06]\n",
      "alpha1 =  0.06056510554311942\n",
      "true gam2 =  22756.22071109877\n",
      "gam2 =  16376.60087096292\n",
      "corr(z1_hat, X*beta_true) =  0.999869600734425\n",
      "l2 error for z1_hat =  0.016510380064230026\n",
      "v1 =  0.9848408859487395\n",
      "true tau2 =  2193.1714550773645\n",
      "tau2 = 2039.952324990499\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99964597]]\n",
      "l2 error for x2_hat =  0.026624080506131246\n",
      "alpha2 =  0.9399409952305176\n",
      "true gam1 =  1432.1625347527922\n",
      "gam1 =  1046.408609484957\n",
      "corr(z2_hat, beta_true) =  [[0.9998694]]\n",
      "l2 error for z2_hat =  0.016523864769450003\n",
      "true tau1 =  223379.3260504013\n",
      "tau1 =  133823.25971591577\n",
      "\n",
      "\n",
      "**** iteration =  40  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-8.62623765e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996413259502781\n",
      "l2 error for x1_hat =  0.026798842775557625\n",
      "B / (A+B) =  [0.00162571]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990452627647468\n",
      "alpha1 part I =  [0.00162416]\n",
      "alpha2 part II =  [4.19388249e-06]\n",
      "alpha1 =  0.06007866842053821\n",
      "true gam2 =  22481.485697643693\n",
      "gam2 =  16370.898348124587\n",
      "corr(z1_hat, X*beta_true) =  0.9998693894253206\n",
      "l2 error for z1_hat =  0.01652712094768315\n",
      "v1 =  0.9848293368278074\n",
      "true tau2 =  2194.5216305849845\n",
      "tau2 = 2061.4613332847744\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99964144]]\n",
      "l2 error for x2_hat =  0.026795048920310375\n",
      "alpha2 =  0.939376362211495\n",
      "true gam1 =  1431.3218406318322\n",
      "gam1 =  1056.5130778814428\n",
      "corr(z2_hat, beta_true) =  [[0.9998659]]\n",
      "l2 error for z2_hat =  0.01692502315462522\n",
      "true tau1 =  220623.27244699205\n",
      "tau1 =  133955.53853574343\n",
      "\n",
      "\n",
      "**** iteration =  41  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.87080941e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996407083109138\n",
      "l2 error for x1_hat =  0.026826816405339654\n",
      "B / (A+B) =  [0.00161914]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999054385216679\n",
      "alpha1 part I =  [0.00161761]\n",
      "alpha2 part II =  [6.57952125e-06]\n",
      "alpha1 =  0.059981097733249784\n",
      "true gam2 =  22450.727020900846\n",
      "gam2 =  16557.587327216308\n",
      "corr(z1_hat, X*beta_true) =  0.999865877135321\n",
      "l2 error for z1_hat =  0.01692618615630599\n",
      "v1 =  0.9849829746725828\n",
      "true tau2 =  2194.6666743429705\n",
      "tau2 = 2042.2827263666677\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99964054]]\n",
      "l2 error for x2_hat =  0.02683325342342431\n",
      "alpha2 =  0.9404496395401918\n",
      "true gam1 =  1435.3687754014024\n",
      "gam1 =  1048.4456075314863\n",
      "corr(z2_hat, beta_true) =  [[0.99986553]]\n",
      "l2 error for z2_hat =  0.016957889899969\n",
      "true tau1 =  219863.9382864386\n",
      "tau1 =  135137.92646783608\n",
      "\n",
      "\n",
      "**** iteration =  42  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.9483634e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996363628647031\n",
      "l2 error for x1_hat =  0.02698943977828851\n",
      "B / (A+B) =  [0.00162489]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990471159316658\n",
      "alpha1 part I =  [0.00162334]\n",
      "alpha2 part II =  [5.70597594e-06]\n",
      "alpha1 =  0.05953795089211221\n",
      "true gam2 =  22210.91782588923\n",
      "gam2 =  16561.256974127027\n",
      "corr(z1_hat, X*beta_true) =  0.9998655192373521\n",
      "l2 error for z1_hat =  0.01696172764944366\n",
      "v1 =  0.9849784709835602\n",
      "true tau2 =  2195.8858180010166\n",
      "tau2 = 2060.9367041607074\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99963645]]\n",
      "l2 error for x2_hat =  0.026986451560335245\n",
      "alpha2 =  0.9399917129989254\n",
      "true gam1 =  1434.776694151293\n",
      "gam1 =  1057.2568330749739\n",
      "corr(z2_hat, beta_true) =  [[0.99986202]]\n",
      "l2 error for z2_hat =  0.01737021230189558\n",
      "true tau1 =  217439.47900244888\n",
      "tau1 =  135315.86954420293\n",
      "\n",
      "\n",
      "**** iteration =  43  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.27083742e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996355507614798\n",
      "l2 error for x1_hat =  0.02702467350509652\n",
      "B / (A+B) =  [0.00161935]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990550498057317\n",
      "alpha1 part I =  [0.00161782]\n",
      "alpha2 part II =  [8.14313319e-06]\n",
      "alpha1 =  0.059434410198562417\n",
      "true gam2 =  22168.8883818787\n",
      "gam2 =  16731.3748626518\n",
      "corr(z1_hat, X*beta_true) =  0.9998619986989526\n",
      "l2 error for z1_hat =  0.017371484758439304\n",
      "v1 =  0.9851168301173743\n",
      "true tau2 =  2196.058473880898\n",
      "tau2 = 2044.3555654222632\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996354]]\n",
      "l2 error for x2_hat =  0.02703047631002501\n",
      "alpha2 =  0.9409324663458796\n",
      "true gam1 =  1438.4348367883126\n",
      "gam1 =  1050.320913696802\n",
      "corr(z2_hat, beta_true) =  [[0.99986151]]\n",
      "l2 error for z2_hat =  0.017421806924690822\n",
      "true tau1 =  216613.94438779817\n",
      "tau1 =  136397.55585030201\n",
      "\n",
      "\n",
      "**** iteration =  44  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.30296505e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996316377077717\n",
      "l2 error for x1_hat =  0.027170551012709033\n",
      "B / (A+B) =  [0.00162429]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990488156499392\n",
      "alpha1 part I =  [0.00162275]\n",
      "alpha2 part II =  [7.39602905e-06]\n",
      "alpha1 =  0.05903085796377768\n",
      "true gam2 =  21958.536495019333\n",
      "gam2 =  16742.42257550162\n",
      "corr(z1_hat, X*beta_true) =  0.9998614962439106\n",
      "l2 error for z1_hat =  0.017426008484452183\n",
      "v1 =  0.9851179001159533\n",
      "true tau2 =  2197.1608184386855\n",
      "tau2 = 2060.5473211532335\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99963171]]\n",
      "l2 error for x2_hat =  0.027168246753908686\n",
      "alpha2 =  0.9405625595654183\n",
      "true gam1 =  1438.0474208693408\n",
      "gam1 =  1058.0122868400858\n",
      "corr(z2_hat, beta_true) =  [[0.99985802]]\n",
      "l2 error for z2_hat =  0.017836113567268146\n",
      "true tau1 =  214470.27761704638\n",
      "tau1 =  136609.4429131082\n",
      "\n",
      "\n",
      "**** iteration =  45  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.69293415e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996306833655735\n",
      "l2 error for x1_hat =  0.027210958491375847\n",
      "B / (A+B) =  [0.00161963]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990557238925114\n",
      "alpha1 part I =  [0.0016181]\n",
      "alpha2 part II =  [9.85271124e-06]\n",
      "alpha1 =  0.05892383202130493\n",
      "true gam2 =  21908.786290828535\n",
      "gam2 =  16897.579712973216\n",
      "corr(z1_hat, X*beta_true) =  0.9998580032759012\n",
      "l2 error for z1_hat =  0.017837514349062937\n",
      "v1 =  0.9852425613517636\n",
      "true tau2 =  2197.3536574369537\n",
      "tau2 = 2046.2021756286783\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99963054]]\n",
      "l2 error for x2_hat =  0.02721620992771734\n",
      "alpha2 =  0.9413888846524594\n",
      "true gam1 =  1441.35781681304\n",
      "gam1 =  1052.0476816729831\n",
      "corr(z2_hat, beta_true) =  [[0.99985738]]\n",
      "l2 error for z2_hat =  0.017905615659015817\n",
      "true tau1 =  213608.9126652282\n",
      "tau1 =  137599.81298688878\n",
      "\n",
      "\n",
      "**** iteration =  46  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.68846644e-06]\n",
      "corr(x1_hat, beta_true) =  0.999627150377083\n",
      "l2 error for x1_hat =  0.027342275016824593\n",
      "B / (A+B) =  [0.00162389]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990503753843214\n",
      "alpha1 part I =  [0.00162235]\n",
      "alpha2 part II =  [9.24397919e-06]\n",
      "alpha1 =  0.058556418750477006\n",
      "true gam2 =  21723.372290078663\n",
      "gam2 =  16914.346167582236\n",
      "corr(z1_hat, X*beta_true) =  0.999857363422388\n",
      "l2 error for z1_hat =  0.017910018083118977\n",
      "v1 =  0.9852479786004534\n",
      "true tau2 =  2198.3517336170694\n",
      "tau2 = 2060.268510918064\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99962721]]\n",
      "l2 error for x2_hat =  0.027340549680135617\n",
      "alpha2 =  0.9410915501265962\n",
      "true gam1 =  1441.137920675207\n",
      "gam1 =  1058.7683134763906\n",
      "corr(z2_hat, beta_true) =  [[0.99985394]]\n",
      "l2 error for z2_hat =  0.018315267738415204\n",
      "true tau1 =  211704.08519493125\n",
      "tau1 =  137836.0292423345\n",
      "\n",
      "\n",
      "**** iteration =  47  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.13717552e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996260959076491\n",
      "l2 error for x1_hat =  0.027386201313686423\n",
      "B / (A+B) =  [0.00161998]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990563975283242\n",
      "alpha1 part I =  [0.00161845]\n",
      "alpha2 part II =  [1.16954247e-05]\n",
      "alpha1 =  0.058447924074412565\n",
      "true gam2 =  21668.60634516387\n",
      "gam2 =  17055.96082777467\n",
      "corr(z1_hat, X*beta_true) =  0.9998539250195865\n",
      "l2 error for z1_hat =  0.018316798508166594\n",
      "v1 =  0.9853603592166956\n",
      "true tau2 =  2198.558719842943\n",
      "tau2 = 2047.8497396717933\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99962597]]\n",
      "l2 error for x2_hat =  0.027390972012153045\n",
      "alpha2 =  0.9418188180902706\n",
      "true gam1 =  1444.1366587621617\n",
      "gam1 =  1053.63785529168\n",
      "corr(z2_hat, beta_true) =  [[0.99985318]]\n",
      "l2 error for z2_hat =  0.01840108714418431\n",
      "true tau1 =  210829.33365172092\n",
      "tau1 =  138743.35954508418\n",
      "\n",
      "\n",
      "**** iteration =  48  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.1034411e-06]\n",
      "corr(x1_hat, beta_true) =  0.999622897550886\n",
      "l2 error for x1_hat =  0.027504821478244523\n",
      "B / (A+B) =  [0.00162366]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990518072199073\n",
      "alpha1 part I =  [0.00162212]\n",
      "alpha2 part II =  [1.1230072e-05]\n",
      "alpha1 =  0.05811344033901302\n",
      "true gam2 =  21504.387921027745\n",
      "gam2 =  17077.0707922283\n",
      "corr(z1_hat, X*beta_true) =  0.9998531583103216\n",
      "l2 error for z1_hat =  0.018405570331993377\n",
      "v1 =  0.9853691094183687\n",
      "true tau2 =  2199.4635854964577\n",
      "tau2 = 2060.079713306882\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99962294]]\n",
      "l2 error for x2_hat =  0.027503584511225143\n",
      "alpha2 =  0.9415812839384544\n",
      "true gam1 =  1444.0529479690197\n",
      "gam1 =  1059.5161212224211\n",
      "corr(z2_hat, beta_true) =  [[0.99984981]]\n",
      "l2 error for z2_hat =  0.018801408030088944\n",
      "true tau1 =  209128.61395469063\n",
      "tau1 =  138996.0647686455\n",
      "\n",
      "\n",
      "**** iteration =  49  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.60349885e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996217766681217\n",
      "l2 error for x1_hat =  0.02755096264822113\n",
      "B / (A+B) =  [0.00162039]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990570628960856\n",
      "alpha1 part I =  [0.00161886]\n",
      "alpha2 part II =  [1.36572025e-05]\n",
      "alpha1 =  0.058005084106675514\n",
      "true gam2 =  21446.654270934414\n",
      "gam2 =  17206.40207439462\n",
      "corr(z1_hat, X*beta_true) =  0.9998497945501685\n",
      "l2 error for z1_hat =  0.01880305960823611\n",
      "v1 =  0.9854704791313265\n",
      "true tau2 =  2199.679832534605\n",
      "tau2 = 2049.3218888705073\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99962166]]\n",
      "l2 error for x2_hat =  0.027555312812965412\n",
      "alpha2 =  0.9422225946421409\n",
      "true gam1 =  1446.771900107046\n",
      "gam1 =  1055.1023431784547\n",
      "corr(z2_hat, beta_true) =  [[0.99984894]]\n",
      "l2 error for z2_hat =  0.018901539706039496\n",
      "true tau1 =  208256.8447008747\n",
      "tau1 =  139827.72338012408\n",
      "\n",
      "\n",
      "**** iteration =  50  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.54657913e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996188735074405\n",
      "l2 error for x1_hat =  0.027658478759595203\n",
      "B / (A+B) =  [0.00162359]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990531220705463\n",
      "alpha1 part I =  [0.00162205]\n",
      "alpha2 part II =  [1.33349537e-05]\n",
      "alpha1 =  0.057700565196300374\n",
      "true gam2 =  21300.525993836894\n",
      "gam2 =  17230.72102075118\n",
      "corr(z1_hat, X*beta_true) =  0.9998489136011879\n",
      "l2 error for z1_hat =  0.018906016514719248\n",
      "v1 =  0.9854817295095618\n",
      "true tau2 =  2200.5012642642\n",
      "tau2 = 2059.9638220640522\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996189]]\n",
      "l2 error for x2_hat =  0.027657652201349185\n",
      "alpha2 =  0.9420342991724218\n",
      "true gam1 =  1446.7980014401028\n",
      "gam1 =  1060.248889673938\n",
      "corr(z2_hat, beta_true) =  [[0.99984566]]\n",
      "l2 error for z2_hat =  0.01928934285458226\n",
      "true tau1 =  206731.40125713998\n",
      "tau1 =  140090.56952119793\n",
      "\n",
      "\n",
      "**** iteration =  51  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.09172295e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996177129962855\n",
      "l2 error for x1_hat =  0.02770581499065114\n",
      "B / (A+B) =  [0.00162086]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990577139729143\n",
      "alpha1 part I =  [0.00161933]\n",
      "alpha2 part II =  [1.57231646e-05]\n",
      "alpha1 =  0.05759360350143785\n",
      "true gam2 =  21241.363506580456\n",
      "gam2 =  17348.89423066352\n",
      "corr(z1_hat, X*beta_true) =  0.9998456391452267\n",
      "l2 error for z1_hat =  0.019291099771193535\n",
      "v1 =  0.9855732252014832\n",
      "true tau2 =  2200.7228342165813\n",
      "tau2 = 2050.6392079240186\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99961761]]\n",
      "l2 error for x2_hat =  0.02770979593785462\n",
      "alpha2 =  0.9426008515378874\n",
      "true gam1 =  1449.2654237306335\n",
      "gam1 =  1056.4511521230231\n",
      "corr(z2_hat, beta_true) =  [[0.99984468]]\n",
      "l2 error for z2_hat =  0.019401611782796053\n",
      "true tau1 =  205874.35037215514\n",
      "tau1 =  140853.16775552474\n",
      "\n",
      "\n",
      "**** iteration =  52  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-5.01666199e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996150708071272\n",
      "l2 error for x1_hat =  0.02780358794367557\n",
      "B / (A+B) =  [0.00162366]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990543298402084\n",
      "alpha1 part I =  [0.00162212]\n",
      "alpha2 part II =  [1.55398022e-05]\n",
      "alpha1 =  0.05731632268894402\n",
      "true gam2 =  21110.74243548984\n",
      "gam2 =  17375.491138668884\n",
      "corr(z1_hat, X*beta_true) =  0.9998446576705705\n",
      "l2 error for z1_hat =  0.01940602011250437\n",
      "v1 =  0.9855862968648799\n",
      "true tau2 =  2201.469489393367\n",
      "tau2 = 2059.9066282957306\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99961509]]\n",
      "l2 error for x2_hat =  0.027803104764439333\n",
      "alpha2 =  0.9424530589694491\n",
      "true gam1 =  1449.3791951821377\n",
      "gam1 =  1060.9614499285651\n",
      "corr(z2_hat, beta_true) =  [[0.9998415]]\n",
      "l2 error for z2_hat =  0.019774826563697608\n",
      "true tau1 =  204500.1778520526\n",
      "tau1 =  141121.05773970802\n",
      "\n",
      "\n",
      "**** iteration =  53  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.60156602e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996138917695425\n",
      "l2 error for x1_hat =  0.027851328363433674\n",
      "B / (A+B) =  [0.00162139]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990583462327496\n",
      "alpha1 part I =  [0.00161986]\n",
      "alpha2 part II =  [1.78780169e-05]\n",
      "alpha1 =  0.05721171538716746\n",
      "true gam2 =  21051.296572688538\n",
      "gam2 =  17483.517469270875\n",
      "corr(z1_hat, X*beta_true) =  0.9998414829453063\n",
      "l2 error for z1_hat =  0.019776670213722352\n",
      "v1 =  0.9856689360555703\n",
      "true tau2 =  2201.693226792426\n",
      "tau2 = 2051.819661139545\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99961379]]\n",
      "l2 error for x2_hat =  0.027854983847998477\n",
      "alpha2 =  0.9429544546951795\n",
      "true gam1 =  1451.6202196040397\n",
      "gam1 =  1057.6934897702133\n",
      "corr(z2_hat, beta_true) =  [[0.99984044]]\n",
      "l2 error for z2_hat =  0.019897050047973226\n",
      "true tau1 =  203666.06632507622\n",
      "tau1 =  141820.56512724183\n",
      "\n",
      "\n",
      "**** iteration =  54  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.51254378e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996114808474407\n",
      "l2 error for x1_hat =  0.027940522532806742\n",
      "B / (A+B) =  [0.00162385]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990554395491588\n",
      "alpha1 part I =  [0.00162231]\n",
      "alpha2 part II =  [1.78264714e-05]\n",
      "alpha1 =  0.05695917373820202\n",
      "true gam2 =  20934.028891999227\n",
      "gam2 =  17511.632930441312\n",
      "corr(z1_hat, X*beta_true) =  0.9998404150412765\n",
      "l2 error for z1_hat =  0.01990134664579626\n",
      "v1 =  0.985683279509905\n",
      "true tau2 =  2202.3727818834122\n",
      "tau2 = 2059.8963509694354\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99961149]]\n",
      "l2 error for x2_hat =  0.027940325180008066\n",
      "alpha2 =  0.9428399379706954\n",
      "true gam1 =  1451.8031229928374\n",
      "gam1 =  1061.6500046581068\n",
      "corr(z2_hat, beta_true) =  [[0.99983737]]\n",
      "l2 error for z2_hat =  0.02025443131101043\n",
      "true tau1 =  202423.1127998987\n",
      "tau1 =  142089.44693794282\n",
      "\n",
      "\n",
      "**** iteration =  55  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.13266161e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996102997500822\n",
      "l2 error for x1_hat =  0.0279880599334121\n",
      "B / (A+B) =  [0.00162198]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990589563867533\n",
      "alpha1 part I =  [0.00162045]\n",
      "alpha2 part II =  [2.01064005e-05]\n",
      "alpha1 =  0.056857634304508\n",
      "true gam2 =  20875.14205623862\n",
      "gam2 =  17610.42486522323\n",
      "corr(z1_hat, X*beta_true) =  0.9998373471659467\n",
      "l2 error for z1_hat =  0.02025634207009789\n",
      "v1 =  0.9857579726097058\n",
      "true tau2 =  2202.5961762307506\n",
      "tau2 = 2052.878953445875\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99961021]]\n",
      "l2 error for x2_hat =  0.027991427292008937\n",
      "alpha2 =  0.9432844316670103\n",
      "true gam1 =  1453.8401629367468\n",
      "gam1 =  1058.8378449662912\n",
      "corr(z2_hat, beta_true) =  [[0.99983623]]\n",
      "l2 error for z2_hat =  0.020384521306912012\n",
      "true tau1 =  201617.50906954074\n",
      "tau1 =  142731.2791735055\n",
      "\n",
      "\n",
      "**** iteration =  56  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.03313726e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996080943044672\n",
      "l2 error for x1_hat =  0.02806967292481629\n",
      "B / (A+B) =  [0.00162415]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990564594341016\n",
      "alpha1 part I =  [0.00162261]\n",
      "alpha2 part II =  [2.01776317e-05]\n",
      "alpha1 =  0.05662754833134828\n",
      "true gam2 =  20769.426825487866\n",
      "gam2 =  17639.4437541354\n",
      "corr(z1_hat, X*beta_true) =  0.9998362067953778\n",
      "l2 error for z1_hat =  0.020388676992285765\n",
      "v1 =  0.9857731463871788\n",
      "true tau2 =  2203.2154458713535\n",
      "tau2 = 2059.9232411780617\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996081]]\n",
      "l2 error for x2_hat =  0.028069712052425408\n",
      "alpha2 =  0.9431972106962584\n",
      "true gam1 =  1454.0767247904041\n",
      "gam1 =  1062.3118851907018\n",
      "corr(z2_hat, beta_true) =  [[0.99983327]]\n",
      "l2 error for z2_hat =  0.02072542738811107\n",
      "true tau1 =  200488.966182952\n",
      "tau1 =  142997.97031845205\n",
      "\n",
      "\n",
      "**** iteration =  57  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.68457283e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996069238526988\n",
      "l2 error for x1_hat =  0.02811654683481307\n",
      "B / (A+B) =  [0.00162261]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990595421588646\n",
      "alpha1 part I =  [0.00162109]\n",
      "alpha2 part II =  [2.23931926e-05]\n",
      "alpha1 =  0.056529588005871954\n",
      "true gam2 =  20711.708669167103\n",
      "gam2 =  17729.82728766786\n",
      "corr(z1_hat, X*beta_true) =  0.999833250310422\n",
      "l2 error for z1_hat =  0.02072738597598151\n",
      "v1 =  0.9858407077970754\n",
      "true tau2 =  2203.4365177716327\n",
      "tau2 = 2053.830837122287\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99960684]]\n",
      "l2 error for x2_hat =  0.028119657968312152\n",
      "alpha2 =  0.9435919167844227\n",
      "true gam1 =  1455.9298127567538\n",
      "gam1 =  1059.892052115863\n",
      "corr(z2_hat, beta_true) =  [[0.99983208]]\n",
      "l2 error for z2_hat =  0.02086145055024482\n",
      "true tau1 =  199715.44917160354\n",
      "tau1 =  143587.05749252142\n",
      "\n",
      "\n",
      "**** iteration =  58  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.57740373e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996049014762128\n",
      "l2 error for x1_hat =  0.02819143482485427\n",
      "B / (A+B) =  [0.00162454]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990573970292213\n",
      "alpha1 part I =  [0.00162301]\n",
      "alpha2 part II =  [2.25768941e-05]\n",
      "alpha1 =  0.05631987611020655\n",
      "true gam2 =  20616.03550572637\n",
      "gam2 =  17759.25538425047\n",
      "corr(z1_hat, X*beta_true) =  0.9998320509404213\n",
      "l2 error for z1_hat =  0.02086544657656632\n",
      "v1 =  0.9858563600397764\n",
      "true tau2 =  2204.0015579413703\n",
      "tau2 = 2059.9792489447573\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996049]]\n",
      "l2 error for x2_hat =  0.028191668185303748\n",
      "alpha2 =  0.9435270424565653\n",
      "true gam1 =  1456.207161368994\n",
      "gam1 =  1062.9453425167305\n",
      "corr(z2_hat, beta_true) =  [[0.99982923]]\n",
      "l2 error for z2_hat =  0.021185675525829124\n",
      "true tau1 =  198687.17441778758\n",
      "tau1 =  143849.09571744973\n",
      "\n",
      "\n",
      "**** iteration =  59  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.25680514e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996037513380648\n",
      "l2 error for x1_hat =  0.028237301543946276\n",
      "B / (A+B) =  [0.00162329]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990601020935582\n",
      "alpha1 part I =  [0.00162177]\n",
      "alpha2 part II =  [2.47237547e-05]\n",
      "alpha1 =  0.0562258421821852\n",
      "true gam2 =  20559.917506564685\n",
      "gam2 =  17841.979888705824\n",
      "corr(z1_hat, X*beta_true) =  0.9998292083793361\n",
      "l2 error for z1_hat =  0.0211876638378583\n",
      "v1 =  0.9859175181774765\n",
      "true tau2 =  2204.218764724866\n",
      "tau2 = 2054.687373211647\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99960368]]\n",
      "l2 error for x2_hat =  0.028240183758953943\n",
      "alpha2 =  0.943878107055258\n",
      "true gam1 =  1457.8942331418064\n",
      "gam1 =  1060.8633442724476\n",
      "corr(z2_hat, beta_true) =  [[0.99982799]]\n",
      "l2 error for z2_hat =  0.021325884226750313\n",
      "true tau1 =  197947.84134449498\n",
      "tau1 =  144389.9363129285\n",
      "\n",
      "\n",
      "**** iteration =  60  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.14434568e-06]\n",
      "corr(x1_hat, beta_true) =  0.9996018925432291\n",
      "l2 error for x1_hat =  0.0283062008326728\n",
      "B / (A+B) =  [0.00162501]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990582592332677\n",
      "alpha1 part I =  [0.00162348]\n",
      "alpha2 part II =  [2.50089119e-05]\n",
      "alpha1 =  0.056034610564516536\n",
      "true gam2 =  20473.0156183643\n",
      "gam2 =  17871.423925771163\n",
      "corr(z1_hat, X*beta_true) =  0.9998279627361557\n",
      "l2 error for z1_hat =  0.021329709530492794\n",
      "v1 =  0.985933370934694\n",
      "true tau2 =  2204.7349626071364\n",
      "tau2 = 2060.057743001026\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99960189]]\n",
      "l2 error for x2_hat =  0.028306592312381328\n",
      "alpha2 =  0.9438314830204214\n",
      "true gam1 =  1458.2017014965445\n",
      "gam1 =  1063.549369016127\n",
      "corr(z2_hat, beta_true) =  [[0.99982525]]\n",
      "l2 error for z2_hat =  0.021633532264476483\n",
      "true tau1 =  197007.88747204316\n",
      "tau1 =  144645.4530149212\n",
      "\n",
      "\n",
      "**** iteration =  61  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.84881763e-06]\n",
      "corr(x1_hat, beta_true) =  0.999600769945404\n",
      "l2 error for x1_hat =  0.028350809222640307\n",
      "B / (A+B) =  [0.00162401]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990606353926786\n",
      "alpha1 part I =  [0.00162248]\n",
      "alpha2 part II =  [2.70841315e-05]\n",
      "alpha1 =  0.05594471902408944\n",
      "true gam2 =  20418.793353618978\n",
      "gam2 =  17947.170276535573\n",
      "corr(z1_hat, X*beta_true) =  0.9998252350745018\n",
      "l2 error for z1_hat =  0.02163553383587502\n",
      "v1 =  0.985988777270824\n",
      "true tau2 =  2204.94712009466\n",
      "tau2 = 2055.459154985852\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9996007]]\n",
      "l2 error for x2_hat =  0.02835348594960948\n",
      "alpha2 =  0.9441442273510006\n",
      "true gam1 =  1459.7388377858351\n",
      "gam1 =  1061.758398366369\n",
      "corr(z2_hat, beta_true) =  [[0.99982398]]\n",
      "l2 error for z2_hat =  0.021776376227571625\n",
      "true tau1 =  196303.74148239824\n",
      "tau1 =  145142.1576716554\n",
      "\n",
      "\n",
      "**** iteration =  62  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.73300165e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995990577613177\n",
      "l2 error for x1_hat =  0.028414354534995946\n",
      "B / (A+B) =  [0.00162555]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990590523664296\n",
      "alpha1 part I =  [0.00162402]\n",
      "alpha2 part II =  [2.74594572e-05]\n",
      "alpha1 =  0.05577024754446963\n",
      "true gam2 =  20339.589823810045\n",
      "gam2 =  17976.320956037653\n",
      "corr(z1_hat, X*beta_true) =  0.9998239549872892\n",
      "l2 error for z1_hat =  0.02178002535993653\n",
      "v1 =  0.9860046132281852\n",
      "true tau2 =  2205.4192726343294\n",
      "tau2 = 2060.153275409112\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959905]]\n",
      "l2 error for x2_hat =  0.02841487331642688\n",
      "alpha2 =  0.9441124629494072\n",
      "true gam1 =  1460.0676234631342\n",
      "gam1 =  1064.123547660168\n",
      "corr(z2_hat, beta_true) =  [[0.99982136]]\n",
      "l2 error for z2_hat =  0.022067768124990957\n",
      "true tau1 =  195441.97280515239\n",
      "tau1 =  145389.7709210454\n",
      "\n",
      "\n",
      "**** iteration =  63  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.46003308e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995979679771712\n",
      "l2 error for x1_hat =  0.02845752653770506\n",
      "B / (A+B) =  [0.00162475]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990611417781564\n",
      "alpha1 part I =  [0.00162323]\n",
      "alpha2 part II =  [2.94612027e-05]\n",
      "alpha1 =  0.05568461054308683\n",
      "true gam2 =  20287.455652908968\n",
      "gam2 =  18045.708366074527\n",
      "corr(z1_hat, X*beta_true) =  0.9998213419954576\n",
      "l2 error for z1_hat =  0.022069768347121214\n",
      "v1 =  0.9860548504158152\n",
      "true tau2 =  2205.6254902845258\n",
      "tau2 = 2056.1554995133984\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995979]]\n",
      "l2 error for x2_hat =  0.028460017941305725\n",
      "alpha2 =  0.9443915034710479\n",
      "true gam1 =  1461.46925746895\n",
      "gam1 =  1062.583374955258\n",
      "corr(z2_hat, beta_true) =  [[0.99982006]]\n",
      "l2 error for z2_hat =  0.02221189353174723\n",
      "true tau1 =  194773.2178603264\n",
      "tau1 =  145846.09885781346\n",
      "\n",
      "\n",
      "**** iteration =  64  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.34244262e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995963875995665\n",
      "l2 error for x1_hat =  0.028516266537773092\n",
      "B / (A+B) =  [0.00162614]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990597822196665\n",
      "alpha1 part I =  [0.00162461]\n",
      "alpha2 part II =  [2.99154699e-05]\n",
      "alpha1 =  0.05552533887111744\n",
      "true gam2 =  20215.041270930877\n",
      "gam2 =  18074.325945340326\n",
      "corr(z1_hat, X*beta_true) =  0.9998200383068649\n",
      "l2 error for z1_hat =  0.022215365109703206\n",
      "v1 =  0.9860705017640395\n",
      "true tau2 =  2206.057873055553\n",
      "tau2 = 2060.2613840767417\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959638]]\n",
      "l2 error for x2_hat =  0.02851688637251272\n",
      "alpha2 =  0.9443717923376559\n",
      "true gam1 =  1461.8121318313606\n",
      "gam1 =  1064.667925495168\n",
      "corr(z2_hat, beta_true) =  [[0.99981756]]\n",
      "l2 error for z2_hat =  0.02248749760764977\n",
      "true tau1 =  193980.99711402293\n",
      "tau1 =  146084.823324189\n",
      "\n",
      "\n",
      "**** iteration =  65  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.08984676e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995953343467766\n",
      "l2 error for x1_hat =  0.028557881548941295\n",
      "B / (A+B) =  [0.00162552]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990616213774706\n",
      "alpha1 part I =  [0.001624]\n",
      "alpha2 part II =  [3.18427911e-05]\n",
      "alpha1 =  0.05544398754347796\n",
      "true gam2 =  20165.10956084037\n",
      "gam2 =  18137.91783117103\n",
      "corr(z1_hat, X*beta_true) =  0.9998175388275171\n",
      "l2 error for z1_hat =  0.022489483781748497\n",
      "v1 =  0.9861160909418399\n",
      "true tau2 =  2206.257500217027\n",
      "tau2 = 2056.7846123200948\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959527]]\n",
      "l2 error for x2_hat =  0.028560205044871553\n",
      "alpha2 =  0.9446211417767572\n",
      "true gam1 =  1463.0912291757895\n",
      "gam1 =  1063.34395411471\n",
      "corr(z2_hat, beta_true) =  [[0.99981625]]\n",
      "l2 error for z2_hat =  0.022631738466045142\n",
      "true tau1 =  193347.2615704135\n",
      "tau1 =  146504.2134515114\n",
      "\n",
      "\n",
      "**** iteration =  66  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.97176954e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995938728352992\n",
      "l2 error for x1_hat =  0.02861229196947986\n",
      "B / (A+B) =  [0.00162678]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990604540983824\n",
      "alpha1 part I =  [0.00162525]\n",
      "alpha2 part II =  [3.23650821e-05]\n",
      "alpha1 =  0.05529850182672245\n",
      "true gam2 =  20098.71081199762\n",
      "gam2 =  18165.819928962854\n",
      "corr(z1_hat, X*beta_true) =  0.9998162213541002\n",
      "l2 error for z1_hat =  0.022635034015832556\n",
      "v1 =  0.9861314300991856\n",
      "true tau2 =  2206.653927907928\n",
      "tau2 = 2060.3784272566613\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959386]]\n",
      "l2 error for x2_hat =  0.028612990548410152\n",
      "alpha2 =  0.9446111616038823\n",
      "true gam1 =  1463.4422891311112\n",
      "gam1 =  1065.1829083512741\n",
      "corr(z2_hat, beta_true) =  [[0.99981385]]\n",
      "l2 error for z2_hat =  0.022892119741942905\n",
      "true tau1 =  192617.1940622575\n",
      "tau1 =  146733.38485925237\n",
      "\n",
      "\n",
      "**** iteration =  67  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.73763416e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995928585986312\n",
      "l2 error for x1_hat =  0.02865227434071434\n",
      "B / (A+B) =  [0.00162631]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990620746288773\n",
      "alpha1 part I =  [0.00162479]\n",
      "alpha2 part II =  [3.42177335e-05]\n",
      "alpha1 =  0.05522140506186995\n",
      "true gam2 =  20051.037376629778\n",
      "gam2 =  18224.12903794646\n",
      "corr(z1_hat, X*beta_true) =  0.9998138335206656\n",
      "l2 error for z1_hat =  0.022894081030053685\n",
      "v1 =  0.9861728374441634\n",
      "true tau2 =  2206.8465092952215\n",
      "tau2 = 2057.3537292664396\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995928]]\n",
      "l2 error for x2_hat =  0.02865444503169932\n",
      "alpha2 =  0.9448343142226006\n",
      "true gam1 =  1464.6105051163595\n",
      "gam1 =  1064.0453685272041\n",
      "corr(z2_hat, beta_true) =  [[0.99981254]]\n",
      "l2 error for z2_hat =  0.023035484797931573\n",
      "true tau1 =  192017.6995744383\n",
      "tau1 =  147118.98299339288\n",
      "\n",
      "\n",
      "**** iteration =  68  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.62011171e-06]\n",
      "corr(x1_hat, beta_true) =  0.999591504615764\n",
      "l2 error for x1_hat =  0.028702769076088215\n",
      "B / (A+B) =  [0.00162746]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990610728617291\n",
      "alpha1 part I =  [0.00162593]\n",
      "alpha2 part II =  [3.47976204e-05]\n",
      "alpha1 =  0.055088425264217554\n",
      "true gam2 =  19989.9934614012\n",
      "gam2 =  18251.180351282037\n",
      "corr(z1_hat, X*beta_true) =  0.9998125110498112\n",
      "l2 error for z1_hat =  0.023038607893772274\n",
      "v1 =  0.9861877693654794\n",
      "true tau2 =  2207.2103889015752\n",
      "tau2 = 2060.5014450019926\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959149]]\n",
      "l2 error for x2_hat =  0.02870352748423857\n",
      "alpha2 =  0.9448321439518849\n",
      "true gam1 =  1464.9649615956896\n",
      "gam1 =  1065.669173908831\n",
      "corr(z2_hat, beta_true) =  [[0.99981025]]\n",
      "l2 error for z2_hat =  0.023281267842826605\n",
      "true tau1 =  191343.42390320075\n",
      "tau1 =  147338.1950136683\n",
      "\n",
      "\n",
      "**** iteration =  69  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.40275778e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995905309081031\n",
      "l2 error for x1_hat =  0.028741078143910075\n",
      "B / (A+B) =  [0.00162711]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990625022036256\n",
      "alpha1 part I =  [0.00162559]\n",
      "alpha2 part II =  [3.65759182e-05]\n",
      "alpha1 =  0.055015504999985955\n",
      "true gam2 =  19944.590518703713\n",
      "gam2 =  18304.673312433937\n",
      "corr(z1_hat, X*beta_true) =  0.9998102324588692\n",
      "l2 error for z1_hat =  0.02328319515722585\n",
      "v1 =  0.9862254119654363\n",
      "true tau2 =  2207.395627726323\n",
      "tau2 = 2057.8692390666265\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99959048]]\n",
      "l2 error for x2_hat =  0.028743109186335977\n",
      "alpha2 =  0.9450321477561471\n",
      "true gam1 =  1466.0327795509222\n",
      "gam1 =  1064.6924344308072\n",
      "corr(z2_hat, beta_true) =  [[0.99980894]]\n",
      "l2 error for z2_hat =  0.02342292524411776\n",
      "true tau1 =  190777.1125012629\n",
      "tau1 =  147692.87815687218\n",
      "\n",
      "\n",
      "**** iteration =  70  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.28662573e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995892744945837\n",
      "l2 error for x1_hat =  0.02878801860968627\n",
      "B / (A+B) =  [0.00162816]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990616429584263\n",
      "alpha1 part I =  [0.00162663]\n",
      "alpha2 part II =  [3.72035872e-05]\n",
      "alpha1 =  0.05489387299695586\n",
      "true gam2 =  19888.334480079455\n",
      "gam2 =  18330.7769741469\n",
      "corr(z1_hat, X*beta_true) =  0.9998089127720005\n",
      "l2 error for z1_hat =  0.02342588086834065\n",
      "v1 =  0.9862398677962568\n",
      "true tau2 =  2207.730005369776\n",
      "tau2 = 2060.62804328828\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958926]]\n",
      "l2 error for x2_hat =  0.028788820854718435\n",
      "alpha2 =  0.945036199132113\n",
      "true gam1 =  1466.3867776094305\n",
      "gam1 =  1066.1276004939668\n",
      "corr(z2_hat, beta_true) =  [[0.99980676]]\n",
      "l2 error for z2_hat =  0.02365476718790227\n",
      "true tau1 =  190153.12913502654\n",
      "tau1 =  147901.92991308603\n",
      "\n",
      "\n",
      "**** iteration =  71  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.08457292e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995883420674108\n",
      "l2 error for x1_hat =  0.028824640757265558\n",
      "B / (A+B) =  [0.00162792]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990629049426356\n",
      "alpha1 part I =  [0.0016264]\n",
      "alpha2 part II =  [3.89082953e-05]\n",
      "alpha1 =  0.05482501657477402\n",
      "true gam2 =  19845.182142305028\n",
      "gam2 =  18379.878385476157\n",
      "corr(z1_hat, X*beta_true) =  0.9998067406195326\n",
      "l2 error for z1_hat =  0.023656653047032367\n",
      "v1 =  0.986274118907813\n",
      "true tau2 =  2207.9077328362473\n",
      "tau2 = 2058.33678930973\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958829]]\n",
      "l2 error for x2_hat =  0.028826543668567465\n",
      "alpha2 =  0.9452157172067888\n",
      "true gam1 =  1467.3636312869146\n",
      "gam1 =  1065.2895808274702\n",
      "corr(z2_hat, beta_true) =  [[0.99980545]]\n",
      "l2 error for z2_hat =  0.023794028354010795\n",
      "true tau1 =  189618.75839111113\n",
      "tau1 =  148228.32824409983\n",
      "\n",
      "\n",
      "**** iteration =  72  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-9.7049482e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995871744495256\n",
      "l2 error for x1_hat =  0.028868343776871853\n",
      "B / (A+B) =  [0.00162888]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990621684596936\n",
      "alpha1 part I =  [0.00162736]\n",
      "alpha2 part II =  [3.95746272e-05]\n",
      "alpha1 =  0.05471368505421683\n",
      "true gam2 =  19793.225351768517\n",
      "gam2 =  18404.968724235598\n",
      "corr(z1_hat, X*beta_true) =  0.999805430533677\n",
      "l2 error for z1_hat =  0.023796822422976326\n",
      "v1 =  0.9862880507690243\n",
      "true tau2 =  2208.215334997599\n",
      "tau2 = 2060.7562972001256\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958716]]\n",
      "l2 error for x2_hat =  0.028869176381488955\n",
      "alpha2 =  0.9452246781617429\n",
      "true gam1 =  1467.7140973580624\n",
      "gam1 =  1066.5592092386653\n",
      "corr(z2_hat, beta_true) =  [[0.99980338]]\n",
      "l2 error for z2_hat =  0.02401259944599938\n",
      "true tau1 =  189040.28905921624\n",
      "tau1 =  148427.1808278589\n",
      "\n",
      "\n",
      "**** iteration =  73  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-7.82432663e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995862834621573\n",
      "l2 error for x1_hat =  0.028903286126569287\n",
      "B / (A+B) =  [0.00162873]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999063283805389\n",
      "alpha1 part I =  [0.00162721]\n",
      "alpha2 part II =  [4.12068648e-05]\n",
      "alpha1 =  0.05464875511485421\n",
      "true gam2 =  19752.280436171433\n",
      "gam2 =  18450.0648565264\n",
      "corr(z1_hat, X*beta_true) =  0.9998033617229886\n",
      "l2 error for z1_hat =  0.024014437815550925\n",
      "v1 =  0.9863192445208894\n",
      "true tau2 =  2208.3854850830317\n",
      "tau2 = 2058.7613783669494\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958624]]\n",
      "l2 error for x2_hat =  0.028905071042307006\n",
      "alpha2 =  0.9453860409192002\n",
      "true gam1 =  1468.6084796781645\n",
      "gam1 =  1065.8408771645431\n",
      "corr(z2_hat, beta_true) =  [[0.99980209]]\n",
      "l2 error for z2_hat =  0.024148903074796516\n",
      "true tau1 =  188536.50294901125\n",
      "tau1 =  148727.69783592076\n",
      "\n",
      "\n",
      "**** iteration =  74  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-6.70928418e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995851968867127\n",
      "l2 error for x1_hat =  0.028944030570616137\n",
      "B / (A+B) =  [0.00162962]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990626530896924\n",
      "alpha1 part I =  [0.00162809]\n",
      "alpha2 part II =  [4.19034794e-05]\n",
      "alpha1 =  0.05454677729546226\n",
      "true gam2 =  19704.19982565009\n",
      "gam2 =  18474.101352441936\n",
      "corr(z1_hat, X*beta_true) =  0.9998020671446365\n",
      "l2 error for z1_hat =  0.024151542088861784\n",
      "v1 =  0.9863326212379421\n",
      "true tau2 =  2208.668754928434\n",
      "tau2 = 2060.8846701036573\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958518]]\n",
      "l2 error for x2_hat =  0.028944882220358917\n",
      "alpha2 =  0.9453988287106921\n",
      "true gam1 =  1468.952992120151\n",
      "gam1 =  1066.9651175011106\n",
      "corr(z2_hat, beta_true) =  [[0.99980012]]\n",
      "l2 error for z2_hat =  0.024354872827841573\n",
      "true tau1 =  187999.3751179964\n",
      "tau1 =  148916.43844876683\n",
      "\n",
      "\n",
      "**** iteration =  75  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-4.95692191e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995843470420538\n",
      "l2 error for x1_hat =  0.028977315981171946\n",
      "B / (A+B) =  [0.00162955]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990636398290424\n",
      "alpha1 part I =  [0.00162802]\n",
      "alpha2 part II =  [4.34646467e-05]\n",
      "alpha1 =  0.05448561963920909\n",
      "true gam2 =  19665.402596294705\n",
      "gam2 =  18515.543525445446\n",
      "corr(z1_hat, X*beta_true) =  0.9998000983720121\n",
      "l2 error for z1_hat =  0.02435665895907861\n",
      "v1 =  0.9863610568348092\n",
      "true tau2 =  2208.8313435496307\n",
      "tau2 = 2059.1474352028395\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995843]]\n",
      "l2 error for x2_hat =  0.028978991869575543\n",
      "alpha2 =  0.9455440785145227\n",
      "true gam1 =  1469.7725521129853\n",
      "gam1 =  1066.3500596044485\n",
      "corr(z2_hat, beta_true) =  [[0.99979885]]\n",
      "l2 error for z2_hat =  0.024487769608809617\n",
      "true tau1 =  187524.75641448662\n",
      "tau1 =  149193.2694944777\n",
      "\n",
      "\n",
      "**** iteration =  76  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-3.871619e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995833346352978\n",
      "l2 error for x1_hat =  0.02901534835271026\n",
      "B / (A+B) =  [0.00163036]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990631002537531\n",
      "alpha1 part I =  [0.00162884]\n",
      "alpha2 part II =  [4.41839208e-05]\n",
      "alpha1 =  0.0543921397979547\n",
      "true gam2 =  19620.83013669405\n",
      "gam2 =  18538.50578106513\n",
      "corr(z1_hat, X*beta_true) =  0.9997988243586187\n",
      "l2 error for z1_hat =  0.02449026039505788\n",
      "v1 =  0.9863738604515039\n",
      "true tau2 =  2209.0924729454273\n",
      "tau2 = 2061.011946218432\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958332]]\n",
      "l2 error for x2_hat =  0.0290162095916883\n",
      "alpha2 =  0.9455598009048338\n",
      "true gam1 =  1470.1092316822617\n",
      "gam1 =  1067.346501704391\n",
      "corr(z2_hat, beta_true) =  [[0.99979697]]\n",
      "l2 error for z2_hat =  0.024681797069226692\n",
      "true tau1 =  187025.30820388495\n",
      "tau1 =  149372.08201551414\n",
      "\n",
      "\n",
      "**** iteration =  77  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-2.23712369e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995825252884833\n",
      "l2 error for x1_hat =  0.029047011458201964\n",
      "B / (A+B) =  [0.00163035]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990639740960403\n",
      "alpha1 part I =  [0.00162882]\n",
      "alpha2 part II =  [4.56756381e-05]\n",
      "alpha1 =  0.05433458957301011\n",
      "true gam2 =  19584.10944974877\n",
      "gam2 =  18576.61345257452\n",
      "corr(z1_hat, X*beta_true) =  0.9997969521814357\n",
      "l2 error for z1_hat =  0.02468352734211679\n",
      "v1 =  0.9863998059289217\n",
      "true tau2 =  2209.24758077227\n",
      "tau2 = 2059.498888788708\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958248]]\n",
      "l2 error for x2_hat =  0.029048586298918457\n",
      "alpha2 =  0.9456907302730911\n",
      "true gam1 =  1470.8608610785077\n",
      "gam1 =  1066.8205559306411\n",
      "corr(z2_hat, beta_true) =  [[0.99979572]]\n",
      "l2 error for z2_hat =  0.024810935428979275\n",
      "true tau1 =  186578.4168679806\n",
      "tau1 =  149627.2315087868\n",
      "\n",
      "\n",
      "**** iteration =  78  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-1.18456406e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995815809356575\n",
      "l2 error for x1_hat =  0.02908255058907267\n",
      "B / (A+B) =  [0.00163111]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990635130645819\n",
      "alpha1 part I =  [0.00162958]\n",
      "alpha2 part II =  [4.64107014e-05]\n",
      "alpha1 =  0.0542488343584953\n",
      "true gam2 =  19542.72346862601\n",
      "gam2 =  18598.497022705564\n",
      "corr(z1_hat, X*beta_true) =  0.9997957030070632\n",
      "l2 error for z1_hat =  0.024813284953312812\n",
      "v1 =  0.9864120288700338\n",
      "true tau2 =  2209.4885385084394\n",
      "tau2 = 2061.137174419076\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958156]]\n",
      "l2 error for x2_hat =  0.029083413557151667\n",
      "alpha2 =  0.9457086533423363\n",
      "true gam1 =  1471.1882784083157\n",
      "gam1 =  1067.7045680005206\n",
      "corr(z2_hat, beta_true) =  [[0.99979394]]\n",
      "l2 error for z2_hat =  0.024993662486905446\n",
      "true tau1 =  186113.41863405865\n",
      "tau1 =  149796.37245161118\n",
      "\n",
      "\n",
      "**** iteration =  79  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.41372204e-08]\n",
      "corr(x1_hat, beta_true) =  0.9995808111807954\n",
      "l2 error for x1_hat =  0.029112634668681085\n",
      "B / (A+B) =  [0.00163115]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990642877087436\n",
      "alpha1 part I =  [0.00162962]\n",
      "alpha2 part II =  [4.78347591e-05]\n",
      "alpha1 =  0.05419472088577051\n",
      "true gam2 =  19508.000686057552\n",
      "gam2 =  18633.560620743345\n",
      "corr(z1_hat, X*beta_true) =  0.9997939238980275\n",
      "l2 error for z1_hat =  0.02499533426253898\n",
      "v1 =  0.9864357244458536\n",
      "true tau2 =  2209.6362968067924\n",
      "tau2 = 2059.8192285530226\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99958077]]\n",
      "l2 error for x2_hat =  0.029114115601524816\n",
      "alpha2 =  0.9458268377275371\n",
      "true gam1 =  1471.8781891639717\n",
      "gam1 =  1067.255509102071\n",
      "corr(z2_hat, beta_true) =  [[0.99979272]]\n",
      "l2 error for z2_hat =  0.025118775530134543\n",
      "true tau1 =  185692.81960874883\n",
      "tau1 =  150031.66977799224\n",
      "\n",
      "\n",
      "**** iteration =  80  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.35901316e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995799294233969\n",
      "l2 error for x1_hat =  0.02914587566857157\n",
      "B / (A+B) =  [0.00163185]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990638943665823\n",
      "alpha1 part I =  [0.00163032]\n",
      "alpha2 part II =  [4.85794757e-05]\n",
      "alpha1 =  0.054115991378783763\n",
      "true gam2 =  19469.5186909757\n",
      "gam2 =  18654.37356781603\n",
      "corr(z1_hat, X*beta_true) =  0.999792703120497\n",
      "l2 error for z1_hat =  0.025120990761221536\n",
      "v1 =  0.9864473672145168\n",
      "true tau2 =  2209.858853482586\n",
      "tau2 = 2061.259621418644\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957991]]\n",
      "l2 error for x2_hat =  0.029146733874381523\n",
      "alpha2 =  0.9458463591663944\n",
      "true gam1 =  1472.1952867529164\n",
      "gam1 =  1068.0405293918352\n",
      "corr(z2_hat, beta_true) =  [[0.99979103]]\n",
      "l2 error for z2_hat =  0.025290822464479744\n",
      "true tau1 =  185259.4091283861\n",
      "tau1 =  150191.44876080388\n",
      "\n",
      "\n",
      "**** iteration =  81  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.78475765e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995791981626689\n",
      "l2 error for x1_hat =  0.02917443017786832\n",
      "B / (A+B) =  [0.00163193]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990645817698147\n",
      "alpha1 part I =  [0.0016304]\n",
      "alpha2 part II =  [4.99377939e-05]\n",
      "alpha1 =  0.05406514187286765\n",
      "true gam2 =  19436.71064499699\n",
      "gam2 =  18686.657088960786\n",
      "corr(z1_hat, X*beta_true) =  0.9997910135108767\n",
      "l2 error for z1_hat =  0.025292433949173587\n",
      "v1 =  0.9864690282792452\n",
      "true tau2 =  2209.999432464175\n",
      "tau2 = 2060.111557102382\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957916]]\n",
      "l2 error for x2_hat =  0.02917582362649776\n",
      "alpha2 =  0.9459531851395724\n",
      "true gam1 =  1472.829080492438\n",
      "gam1 =  1067.6577994695851\n",
      "corr(z2_hat, beta_true) =  [[0.99978984]]\n",
      "l2 error for z2_hat =  0.025411716165811737\n",
      "true tau1 =  184863.69213975695\n",
      "tau1 =  150408.56304823642\n",
      "\n",
      "\n",
      "**** iteration =  82  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.76599072e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995783741108706\n",
      "l2 error for x1_hat =  0.02920554775523565\n",
      "B / (A+B) =  [0.00163259]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990642467584139\n",
      "alpha1 part I =  [0.00163106]\n",
      "alpha2 part II =  [5.06867314e-05]\n",
      "alpha1 =  0.05399280635512376\n",
      "true gam2 =  19400.88338144952\n",
      "gam2 =  18706.417147613945\n",
      "corr(z1_hat, X*beta_true) =  0.9997898240384934\n",
      "l2 error for z1_hat =  0.025413803977787103\n",
      "v1 =  0.9864800975935001\n",
      "true tau2 =  2210.20518244088\n",
      "tau2 = 2061.378732804396\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957835]]\n",
      "l2 error for x2_hat =  0.029206395880129993\n",
      "alpha2 =  0.9459738120674569\n",
      "true gam1 =  1473.1351070220715\n",
      "gam1 =  1068.3555881454674\n",
      "corr(z2_hat, beta_true) =  [[0.99978824]]\n",
      "l2 error for z2_hat =  0.02557367882547767\n",
      "true tau1 =  184459.32090962163\n",
      "tau1 =  150559.32701665367\n",
      "\n",
      "\n",
      "**** iteration =  83  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [5.09909161e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995776801094377\n",
      "l2 error for x1_hat =  0.0292326263840075\n",
      "B / (A+B) =  [0.0016327]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990648573672914\n",
      "alpha1 part I =  [0.00163118]\n",
      "alpha2 part II =  [5.19813255e-05]\n",
      "alpha1 =  0.05394504875601271\n",
      "true gam2 =  19369.904607410877\n",
      "gam2 =  18736.160540434146\n",
      "corr(z1_hat, X*beta_true) =  0.9997882203525815\n",
      "l2 error for z1_hat =  0.02557522894759193\n",
      "v1 =  0.9864999173767397\n",
      "true tau2 =  2210.3387817047796\n",
      "tau2 = 2060.378636251892\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957765]]\n",
      "l2 error for x2_hat =  0.02923393815873858\n",
      "alpha2 =  0.9460705015976035\n",
      "true gam1 =  1473.7178373039874\n",
      "gam1 =  1068.0300656516597\n",
      "corr(z2_hat, beta_true) =  [[0.99978708]]\n",
      "l2 error for z2_hat =  0.025690221459894615\n",
      "true tau1 =  184087.11425436026\n",
      "tau1 =  150759.78081550635\n",
      "\n",
      "\n",
      "**** iteration =  84  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [6.04299406e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995769093674414\n",
      "l2 error for x1_hat =  0.029261777640892314\n",
      "B / (A+B) =  [0.00163331]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990645726138765\n",
      "alpha1 part I =  [0.00163179]\n",
      "alpha2 part II =  [5.27297176e-05]\n",
      "alpha1 =  0.0538785361391613\n",
      "true gam2 =  19336.511128658094\n",
      "gam2 =  18754.892793519495\n",
      "corr(z1_hat, X*beta_true) =  0.9997870645090395\n",
      "l2 error for z1_hat =  0.025692188564001295\n",
      "v1 =  0.9865104246659451\n",
      "true tau2 =  2210.5291624771453\n",
      "tau2 = 2061.494100627506\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957689]]\n",
      "l2 error for x2_hat =  0.02926261136964718\n",
      "alpha2 =  0.9460918321250661\n",
      "true gam1 =  1474.0122924367304\n",
      "gam1 =  1068.650922520368\n",
      "corr(z2_hat, beta_true) =  [[0.99978556]]\n",
      "l2 error for z2_hat =  0.025842669637762692\n",
      "true tau1 =  183709.5028759678\n",
      "tau1 =  150901.9013840894\n",
      "\n",
      "\n",
      "**** iteration =  85  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [7.29028355e-07]\n",
      "corr(x1_hat, beta_true) =  0.999576251296938\n",
      "l2 error for x1_hat =  0.029287436789842823\n",
      "B / (A+B) =  [0.00163346]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990651155634552\n",
      "alpha1 part I =  [0.00163193]\n",
      "alpha2 part II =  [5.39626704e-05]\n",
      "alpha1 =  0.0538337012320633\n",
      "true gam2 =  19307.27553451257\n",
      "gam2 =  18782.314143278985\n",
      "corr(z1_hat, X*beta_true) =  0.999785543191589\n",
      "l2 error for z1_hat =  0.02584415793736585\n",
      "v1 =  0.9865285766135129\n",
      "true tau2 =  2210.6560031787963\n",
      "tau2 = 2060.6229272640694\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957622]]\n",
      "l2 error for x2_hat =  0.029288672173121453\n",
      "alpha2 =  0.9461794635327007\n",
      "true gam1 =  1474.5485205999034\n",
      "gam1 =  1068.3747240870887\n",
      "corr(z2_hat, beta_true) =  [[0.99978444]]\n",
      "l2 error for z2_hat =  0.025954782395215314\n",
      "true tau1 =  183359.48270176782\n",
      "tau1 =  151087.08332171224\n",
      "\n",
      "\n",
      "**** iteration =  86  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [8.19639828e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995755298993411\n",
      "l2 error for x1_hat =  0.029314763575807902\n",
      "B / (A+B) =  [0.00163403]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990648741012149\n",
      "alpha1 part I =  [0.0016325]\n",
      "alpha2 part II =  [5.4706373e-05]\n",
      "alpha1 =  0.053772495100510874\n",
      "true gam2 =  19276.119102441626\n",
      "gam2 =  18800.049125133522\n",
      "corr(z1_hat, X*beta_true) =  0.999784422778084\n",
      "l2 error for z1_hat =  0.02595663529303066\n",
      "v1 =  0.9865385368089947\n",
      "true tau2 =  2210.8323124779063\n",
      "tau2 = 2061.60543646898\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957551]]\n",
      "l2 error for x2_hat =  0.029315579450418922\n",
      "alpha2 =  0.9462011714226068\n",
      "true gam1 =  1474.8311086608305\n",
      "gam1 =  1068.927676985397\n",
      "corr(z2_hat, beta_true) =  [[0.99978299]]\n",
      "l2 error for z2_hat =  0.0260982590657638\n",
      "true tau1 =  183006.58371066648\n",
      "tau1 =  151220.94669220608\n",
      "\n",
      "\n",
      "**** iteration =  87  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [9.36408029e-07]\n",
      "corr(x1_hat, beta_true) =  0.9995749063722132\n",
      "l2 error for x1_hat =  0.029339061166250152\n",
      "B / (A+B) =  [0.00163419]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990653573867557\n",
      "alpha1 part I =  [0.00163266]\n",
      "alpha2 part II =  [5.58798113e-05]\n",
      "alpha1 =  0.05373041806910905\n",
      "true gam2 =  19248.541204743997\n",
      "gam2 =  18825.34665400013\n",
      "corr(z1_hat, X*beta_true) =  0.9997829803160924\n",
      "l2 error for z1_hat =  0.026099685596734076\n",
      "v1 =  0.9865551767013703\n",
      "true tau2 =  2210.9526309364196\n",
      "tau2 = 2060.8466260611863\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957488]]\n",
      "l2 error for x2_hat =  0.029340224983764623\n",
      "alpha2 =  0.9462806974936497\n",
      "true gam1 =  1475.3249539218466\n",
      "gam1 =  1068.6939872826986\n",
      "corr(z2_hat, beta_true) =  [[0.99978191]]\n",
      "l2 error for z2_hat =  0.026205907771791787\n",
      "true tau1 =  182677.47993602385\n",
      "tau1 =  151392.12315645374\n",
      "\n",
      "\n",
      "**** iteration =  88  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.0232331e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995742307297308\n",
      "l2 error for x1_hat =  0.0293646920637466\n",
      "B / (A+B) =  [0.00163473]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990651532009259\n",
      "alpha1 part I =  [0.0016332]\n",
      "alpha2 part II =  [5.66152571e-05]\n",
      "alpha1 =  0.053674051288731844\n",
      "true gam2 =  19219.44587329351\n",
      "gam2 =  18842.11881001879\n",
      "corr(z1_hat, X*beta_true) =  0.9997818966699894\n",
      "l2 error for z1_hat =  0.02620765272451927\n",
      "v1 =  0.9865646072671116\n",
      "true tau2 =  2211.1160418361183\n",
      "tau2 = 2061.7125490718704\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957421]]\n",
      "l2 error for x2_hat =  0.029365487357188958\n",
      "alpha2 =  0.9463025193904058\n",
      "true gam1 =  1475.5955451029404\n",
      "gam1 =  1069.1869552417813\n",
      "corr(z2_hat, beta_true) =  [[0.99978054]]\n",
      "l2 error for z2_hat =  0.026340928948610263\n",
      "true tau1 =  182347.4467338883\n",
      "tau1 =  151518.12215948614\n",
      "\n",
      "\n",
      "**** iteration =  89  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.13260559e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995736403262299\n",
      "l2 error for x1_hat =  0.029387686612116735\n",
      "B / (A+B) =  [0.00163491]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990655838261698\n",
      "alpha1 part I =  [0.00163338]\n",
      "alpha2 part II =  [5.77313318e-05]\n",
      "alpha1 =  0.053634572820078504\n",
      "true gam2 =  19193.441699887277\n",
      "gam2 =  18865.472705952037\n",
      "corr(z1_hat, X*beta_true) =  0.9997805296099136\n",
      "l2 error for z1_hat =  0.026342294192434938\n",
      "v1 =  0.9865798751070414\n",
      "true tau2 =  2211.230084331945\n",
      "tau2 = 2061.0516940721586\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957361]]\n",
      "l2 error for x2_hat =  0.0293887832920342\n",
      "alpha2 =  0.9463747830603646\n",
      "true gam1 =  1476.0507294959987\n",
      "gam1 =  1068.9898807890356\n",
      "corr(z2_hat, beta_true) =  [[0.9997795]]\n",
      "l2 error for z2_hat =  0.02644411680087343\n",
      "true tau1 =  182038.0464755545\n",
      "tau1 =  151676.4480640908\n",
      "\n",
      "\n",
      "**** iteration =  90  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.21566755e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995730071793556\n",
      "l2 error for x1_hat =  0.029411738613767783\n",
      "B / (A+B) =  [0.00163541]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990654117221534\n",
      "alpha1 part I =  [0.00163388]\n",
      "alpha2 part II =  [5.8455483e-05]\n",
      "alpha1 =  0.05358262266661523\n",
      "true gam2 =  19166.24945994097\n",
      "gam2 =  18881.319148318493\n",
      "corr(z1_hat, X*beta_true) =  0.9997794836595737\n",
      "l2 error for z1_hat =  0.02644575981054984\n",
      "v1 =  0.986588795265912\n",
      "true tau2 =  2211.3816586008184\n",
      "tau2 = 2061.815325784762\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957299]]\n",
      "l2 error for x2_hat =  0.029412511220997185\n",
      "alpha2 =  0.9463965078491878\n",
      "true gam1 =  1476.30932742261\n",
      "gam1 =  1069.4298154840114\n",
      "corr(z2_hat, beta_true) =  [[0.9997782]]\n",
      "l2 error for z2_hat =  0.026571171833419123\n",
      "true tau1 =  181729.2072753727\n",
      "tau1 =  151794.97594325367\n",
      "\n",
      "\n",
      "**** iteration =  91  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.31816042e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995724484686447\n",
      "l2 error for x1_hat =  0.029433488516374014\n",
      "B / (A+B) =  [0.0016356]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999065795827494\n",
      "alpha1 part I =  [0.00163408]\n",
      "alpha2 part II =  [5.95163531e-05]\n",
      "alpha1 =  0.05354558970368755\n",
      "true gam2 =  19141.737197112958\n",
      "gam2 =  18902.893234874748\n",
      "corr(z1_hat, X*beta_true) =  0.999778188620831\n",
      "l2 error for z1_hat =  0.026572476623781358\n",
      "v1 =  0.9866028169600816\n",
      "true tau2 =  2211.489677161416\n",
      "tau2 = 2061.239885284117\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957242]]\n",
      "l2 error for x2_hat =  0.029434522138769317\n",
      "alpha2 =  0.9464622558040726\n",
      "true gam1 =  1476.7292161083833\n",
      "gam1 =  1069.26425894489\n",
      "corr(z2_hat, beta_true) =  [[0.9997772]]\n",
      "l2 error for z2_hat =  0.026669933059814063\n",
      "true tau1 =  181438.35644552225\n",
      "tau1 =  151941.50462638435\n",
      "\n",
      "\n",
      "**** iteration =  92  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.39750749e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995718548480398\n",
      "l2 error for x1_hat =  0.029456068444807554\n",
      "B / (A+B) =  [0.00163608]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990656513177542\n",
      "alpha1 part I =  [0.00163455]\n",
      "alpha2 part II =  [6.02266543e-05]\n",
      "alpha1 =  0.053497673466368884\n",
      "true gam2 =  19116.305583893776\n",
      "gam2 =  18917.852743761385\n",
      "corr(z1_hat, X*beta_true) =  0.9997771809363872\n",
      "l2 error for z1_hat =  0.026671479859321532\n",
      "v1 =  0.9866112470790668\n",
      "true tau2 =  2211.630377074504\n",
      "tau2 = 2061.913717181113\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957184]]\n",
      "l2 error for x2_hat =  0.02945681678870153\n",
      "alpha2 =  0.9464837157389124\n",
      "true gam1 =  1476.9759307798377\n",
      "gam1 =  1069.6572674302658\n",
      "corr(z2_hat, beta_true) =  [[0.99977597]]\n",
      "l2 error for z2_hat =  0.026789485235990104\n",
      "true tau1 =  181149.19234253955\n",
      "tau1 =  152052.9502462244\n",
      "\n",
      "\n",
      "**** iteration =  93  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.49359335e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995713264045731\n",
      "l2 error for x1_hat =  0.02947663143032015\n",
      "B / (A+B) =  [0.00163628]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990659942911515\n",
      "alpha1 part I =  [0.00163475]\n",
      "alpha2 part II =  [6.1234473e-05]\n",
      "alpha1 =  0.05346293968508408\n",
      "true gam2 =  19093.206027004857\n",
      "gam2 =  18937.79600264675\n",
      "corr(z1_hat, X*beta_true) =  0.9997759546218216\n",
      "l2 error for z1_hat =  0.026790730693161055\n",
      "v1 =  0.9866241359361942\n",
      "true tau2 =  2211.7326260781842\n",
      "tau2 = 2061.4127699848277\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995713]]\n",
      "l2 error for x2_hat =  0.029477605768527163\n",
      "alpha2 =  0.9465436102271226\n",
      "true gam1 =  1477.363568198891\n",
      "gam1 =  1069.5188194380307\n",
      "corr(z2_hat, beta_true) =  [[0.999775]]\n",
      "l2 error for z2_hat =  0.02688387958132023\n",
      "true tau1 =  180875.79590640755\n",
      "tau1 =  152188.64255498178\n",
      "\n",
      "\n",
      "**** iteration =  94  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.56929361e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995707695971454\n",
      "l2 error for x1_hat =  0.02949783714315234\n",
      "B / (A+B) =  [0.00163672]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990658734981185\n",
      "alpha1 part I =  [0.00163519]\n",
      "alpha2 part II =  [6.19288057e-05]\n",
      "alpha1 =  0.05341871070307182\n",
      "true gam2 =  19069.40610869741\n",
      "gam2 =  18951.90823040143\n",
      "corr(z1_hat, X*beta_true) =  0.9997749854618416\n",
      "l2 error for z1_hat =  0.02688533563084969\n",
      "v1 =  0.9866320970407895\n",
      "true tau2 =  2211.863324866674\n",
      "tau2 = 2062.0077243289466\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957075]]\n",
      "l2 error for x2_hat =  0.029498560093329497\n",
      "alpha2 =  0.9465646735288115\n",
      "true gam1 =  1477.5985934569405\n",
      "gam1 =  1069.870270742447\n",
      "corr(z2_hat, beta_true) =  [[0.99977384]]\n",
      "l2 error for z2_hat =  0.026996366937195808\n",
      "true tau1 =  180604.9223489136\n",
      "tau1 =  152293.3867685444\n",
      "\n",
      "\n",
      "**** iteration =  95  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.65940635e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995702700132794\n",
      "l2 error for x1_hat =  0.029517269857521535\n",
      "B / (A+B) =  [0.00163693]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990661800711802\n",
      "alpha1 part I =  [0.0016354]\n",
      "alpha2 part II =  [6.28857086e-05]\n",
      "alpha1 =  0.0533861367768095\n",
      "true gam2 =  19047.64296364289\n",
      "gam2 =  18970.3561875839\n",
      "corr(z1_hat, X*beta_true) =  0.9997738246656992\n",
      "l2 error for z1_hat =  0.026997554411243928\n",
      "v1 =  0.9866439551062234\n",
      "true tau2 =  2211.9600583235924\n",
      "tau2 = 2061.571755625846\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99957025]]\n",
      "l2 error for x2_hat =  0.0295181884128223\n",
      "alpha2 =  0.9466193026329099\n",
      "true gam1 =  1477.9567357459978\n",
      "gam1 =  1069.7551167388533\n",
      "corr(z2_hat, beta_true) =  [[0.99977291]]\n",
      "l2 error for z2_hat =  0.027086474888741587\n",
      "true tau1 =  180347.94363013603\n",
      "tau1 =  152419.11937875664\n",
      "\n",
      "\n",
      "**** iteration =  96  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.73154351e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995697475330856\n",
      "l2 error for x1_hat =  0.02953719127264862\n",
      "B / (A+B) =  [0.00163735]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990660796438259\n",
      "alpha1 part I =  [0.00163582]\n",
      "alpha2 part II =  [6.35623467e-05]\n",
      "alpha1 =  0.05334528086922855\n",
      "true gam2 =  19025.35764517119\n",
      "gam2 =  18983.661030066476\n",
      "corr(z1_hat, X*beta_true) =  0.9997728940197766\n",
      "l2 error for z1_hat =  0.027087845376947715\n",
      "v1 =  0.9866514684994024\n",
      "true tau2 =  2212.081549436597\n",
      "tau2 = 2062.0973882652315\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956973]]\n",
      "l2 error for x2_hat =  0.029537888075464\n",
      "alpha2 =  0.9466398673104242\n",
      "true gam1 =  1478.1803305668561\n",
      "gam1 =  1070.0697345193278\n",
      "corr(z2_hat, beta_true) =  [[0.99977181]]\n",
      "l2 error for z2_hat =  0.027192311152796956\n",
      "true tau1 =  180094.09470169403\n",
      "tau1 =  152517.53233353805\n",
      "\n",
      "\n",
      "**** iteration =  97  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.81608235e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995692754286636\n",
      "l2 error for x1_hat =  0.02955554896985644\n",
      "B / (A+B) =  [0.00163756]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999066353975123\n",
      "alpha1 part I =  [0.00163603]\n",
      "alpha2 part II =  [6.44704429e-05]\n",
      "alpha1 =  0.053314734569673325\n",
      "true gam2 =  19004.857715527087\n",
      "gam2 =  19000.737016303523\n",
      "corr(z1_hat, X*beta_true) =  0.9997717956336352\n",
      "l2 error for z1_hat =  0.027193442174659167\n",
      "v1 =  0.9866623877440341\n",
      "true tau2 =  2212.173018831026\n",
      "tau2 = 2061.718105169319\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956925]]\n",
      "l2 error for x2_hat =  0.029556415000695294\n",
      "alpha2 =  0.9466897538920861\n",
      "true gam1 =  1478.5114746242764\n",
      "gam1 =  1069.9745744648205\n",
      "corr(z2_hat, beta_true) =  [[0.99977092]]\n",
      "l2 error for z2_hat =  0.027278229821547168\n",
      "true tau1 =  179852.5540105466\n",
      "tau1 =  152634.10535779965\n",
      "\n",
      "\n",
      "**** iteration =  98  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.88475217e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995687849918813\n",
      "l2 error for x1_hat =  0.029574268940791293\n",
      "B / (A+B) =  [0.00163795]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990662710172183\n",
      "alpha1 part I =  [0.00163642]\n",
      "alpha2 part II =  [6.51280112e-05]\n",
      "alpha1 =  0.05327696682213522\n",
      "true gam2 =  18983.98030288087\n",
      "gam2 =  19013.274121672915\n",
      "corr(z1_hat, X*beta_true) =  0.9997709032610197\n",
      "l2 error for z1_hat =  0.027279519670066456\n",
      "v1 =  0.9866694747099888\n",
      "true tau2 =  2212.286024143998\n",
      "tau2 = 2062.182781309254\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956877]]\n",
      "l2 error for x2_hat =  0.029574939158987738\n",
      "alpha2 =  0.9467097425828348\n",
      "true gam1 =  1478.7239476134475\n",
      "gam1 =  1070.2565176130747\n",
      "corr(z2_hat, beta_true) =  [[0.99976988]]\n",
      "l2 error for z2_hat =  0.027377805440390788\n",
      "true tau1 =  179614.56903857714\n",
      "tau1 =  152726.54455893504\n",
      "\n",
      "\n",
      "**** iteration =  99  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [1.96408523e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995683390214042\n",
      "l2 error for x1_hat =  0.02959160525720355\n",
      "B / (A+B) =  [0.00163816]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990665167646045\n",
      "alpha1 part I =  [0.00163663]\n",
      "alpha2 part II =  [6.59893746e-05]\n",
      "alpha1 =  0.053248322997176877\n",
      "true gam2 =  18964.673590885413\n",
      "gam2 =  19029.090417121708\n",
      "corr(z1_hat, X*beta_true) =  0.9997698642780223\n",
      "l2 error for z1_hat =  0.02737888167990728\n",
      "v1 =  0.9866795380895758\n",
      "true tau2 =  2212.3724767395242\n",
      "tau2 = 2061.8529532364873\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956832]]\n",
      "l2 error for x2_hat =  0.02959242180388621\n",
      "alpha2 =  0.9467553520815463\n",
      "true gam1 =  1479.0303571532042\n",
      "gam1 =  1070.1784967367137\n",
      "corr(z2_hat, beta_true) =  [[0.99976902]]\n",
      "l2 error for z2_hat =  0.027459645020942204\n",
      "true tau1 =  179387.5418408771\n",
      "tau1 =  152834.68849027503\n",
      "\n",
      "\n",
      "**** iteration =  100  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.02939256e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995678785247623\n",
      "l2 error for x1_hat =  0.029609200322751557\n",
      "B / (A+B) =  [0.00163854]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990664487729669\n",
      "alpha1 part I =  [0.00163701]\n",
      "alpha2 part II =  [6.66268096e-05]\n",
      "alpha1 =  0.05321338487123131\n",
      "true gam2 =  18945.106571752054\n",
      "gam2 =  19040.898806960293\n",
      "corr(z1_hat, X*beta_true) =  0.9997690097424726\n",
      "l2 error for z1_hat =  0.02746085889127344\n",
      "v1 =  0.9866862196656989\n",
      "true tau2 =  2212.477653838822\n",
      "tau2 = 2062.2639999069543\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956786]]\n",
      "l2 error for x2_hat =  0.029609843783483525\n",
      "alpha2 =  0.9467747077407384\n",
      "true gam1 =  1479.2320537559121\n",
      "gam1 =  1070.4314295613924\n",
      "corr(z2_hat, beta_true) =  [[0.99976804]]\n",
      "l2 error for z2_hat =  0.027553328227370794\n",
      "true tau1 =  179164.35393988012\n",
      "tau1 =  152921.4974691043\n",
      "\n",
      "\n",
      "**** iteration =  101  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.10385994e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995674573826215\n",
      "l2 error for x1_hat =  0.0296255671181021\n",
      "B / (A+B) =  [0.00163875]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990666691564113\n",
      "alpha1 part I =  [0.00163722]\n",
      "alpha2 part II =  [6.7443473e-05]\n",
      "alpha1 =  0.05318652532984778\n",
      "true gam2 =  18926.926314015072\n",
      "gam2 =  19055.557679952333\n",
      "corr(z1_hat, X*beta_true) =  0.9997680272601593\n",
      "l2 error for z1_hat =  0.02755435145745534\n",
      "v1 =  0.9866955020647168\n",
      "true tau2 =  2212.55933136503\n",
      "tau2 = 2061.9773203391683\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956744]]\n",
      "l2 error for x2_hat =  0.029626337023797123\n",
      "alpha2 =  0.9468164549827174\n",
      "true gam1 =  1479.5157826640109\n",
      "gam1 =  1070.3680785941444\n",
      "corr(z2_hat, beta_true) =  [[0.99976722]]\n",
      "l2 error for z2_hat =  0.027631208966674422\n",
      "true tau1 =  178950.96872191667\n",
      "tau1 =  153021.879513131\n",
      "\n",
      "\n",
      "**** iteration =  102  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.16591621e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995670248847376\n",
      "l2 error for x1_hat =  0.029642108147288623\n",
      "B / (A+B) =  [0.0016391]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990666139677111\n",
      "alpha1 part I =  [0.00163757]\n",
      "alpha2 part II =  [6.8059986e-05]\n",
      "alpha1 =  0.05315418206325356\n",
      "true gam2 =  18908.580317617354\n",
      "gam2 =  19066.675462408984\n",
      "corr(z1_hat, X*beta_true) =  0.9997672099612108\n",
      "l2 error for z1_hat =  0.027632351268674703\n",
      "v1 =  0.9867017988689386\n",
      "true tau2 =  2212.6572800206677\n",
      "tau2 = 2062.3411587485634\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956701]]\n",
      "l2 error for x2_hat =  0.029642724897386254\n",
      "alpha2 =  0.9468351372823269\n",
      "true gam1 =  1479.7070746310017\n",
      "gam1 =  1070.595231975576\n",
      "corr(z2_hat, beta_true) =  [[0.99976629]]\n",
      "l2 error for z2_hat =  0.02771934686239804\n",
      "true tau1 =  178741.59494265888\n",
      "tau1 =  153103.3869801863\n",
      "\n",
      "\n",
      "**** iteration =  103  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.23583266e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995666273089163\n",
      "l2 error for x1_hat =  0.029657555398061867\n",
      "B / (A+B) =  [0.00163931]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990668118239417\n",
      "alpha1 part I =  [0.00163778]\n",
      "alpha2 part II =  [6.88339351e-05]\n",
      "alpha1 =  0.05312899539398141\n",
      "true gam2 =  18891.4629725127\n",
      "gam2 =  19080.27011069672\n",
      "corr(z1_hat, X*beta_true) =  0.9997662811831851\n",
      "l2 error for z1_hat =  0.027720318928587884\n",
      "v1 =  0.9867103679419449\n",
      "true tau2 =  2212.73441767651\n",
      "tau2 = 2062.092125425418\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956661]]\n",
      "l2 error for x2_hat =  0.02965828132673831\n",
      "alpha2 =  0.9468733924310969\n",
      "true gam1 =  1479.9699878994645\n",
      "gam1 =  1070.5444155285202\n",
      "corr(z2_hat, beta_true) =  [[0.99976551]]\n",
      "l2 error for z2_hat =  0.02779339647431579\n",
      "true tau1 =  178541.03089418742\n",
      "tau1 =  153196.61681818386\n",
      "\n",
      "\n",
      "**** iteration =  104  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.29475384e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995662210141154\n",
      "l2 error for x1_hat =  0.02967310814675952\n",
      "B / (A+B) =  [0.00163964]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990667675688396\n",
      "alpha1 part I =  [0.00163811]\n",
      "alpha2 part II =  [6.9428979e-05]\n",
      "alpha1 =  0.05309903366426825\n",
      "true gam2 =  18874.25587923994\n",
      "gam2 =  19090.73426794624\n",
      "corr(z1_hat, X*beta_true) =  0.9997655003840743\n",
      "l2 error for z1_hat =  0.02779447137574894\n",
      "v1 =  0.9867163000441782\n",
      "true tau2 =  2212.8256855946383\n",
      "tau2 = 2062.4143859472506\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956621]]\n",
      "l2 error for x2_hat =  0.029673698414268982\n",
      "alpha2 =  0.946891374750348\n",
      "true gam1 =  1480.1512646571712\n",
      "gam1 =  1070.7486402485827\n",
      "corr(z2_hat, beta_true) =  [[0.99976463]]\n",
      "l2 error for z2_hat =  0.027876316106931913\n",
      "true tau1 =  178344.5637200074\n",
      "tau1 =  153273.13619569884\n",
      "\n",
      "\n",
      "**** iteration =  105  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.36041112e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995658457886644\n",
      "l2 error for x1_hat =  0.029687683881105528\n",
      "B / (A+B) =  [0.00163984]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990669453989062\n",
      "alpha1 part I =  [0.00163831]\n",
      "alpha2 part II =  [7.01621489e-05]\n",
      "alpha1 =  0.053075415005894674\n",
      "true gam2 =  18858.14107847935\n",
      "gam2 =  19103.349671176074\n",
      "corr(z1_hat, X*beta_true) =  0.9997646226207061\n",
      "l2 error for z1_hat =  0.027877238901640407\n",
      "v1 =  0.9867242169657117\n",
      "true tau2 =  2212.89851130865\n",
      "tau2 = 2062.198196955506\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956583]]\n",
      "l2 error for x2_hat =  0.0296883683329595\n",
      "alpha2 =  0.9469264685138483\n",
      "true gam1 =  1480.3950571450766\n",
      "gam1 =  1070.7085121988025\n",
      "corr(z2_hat, beta_true) =  [[0.99976389]]\n",
      "l2 error for z2_hat =  0.027946667576362473\n",
      "true tau1 =  178156.04832098316\n",
      "tau1 =  153359.77122624667\n",
      "\n",
      "\n",
      "**** iteration =  106  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.41631598e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995654640328928\n",
      "l2 error for x1_hat =  0.029702309474855873\n",
      "B / (A+B) =  [0.00164015]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990669104624835\n",
      "alpha1 part I =  [0.00163862]\n",
      "alpha2 part II =  [7.07353869e-05]\n",
      "alpha1 =  0.05304764083026047\n",
      "true gam2 =  18841.997254184436\n",
      "gam2 =  19113.1959073174\n",
      "corr(z1_hat, X*beta_true) =  0.9997638774731786\n",
      "l2 error for z1_hat =  0.02794767901308203\n",
      "v1 =  0.9867298037948544\n",
      "true tau2 =  2212.983599252968\n",
      "tau2 = 2062.4838190979\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956545]]\n",
      "l2 error for x2_hat =  0.029702873636019374\n",
      "alpha2 =  0.9469437354251272\n",
      "true gam1 =  1480.5667187593274\n",
      "gam1 =  1070.8923254819804\n",
      "corr(z2_hat, beta_true) =  [[0.99976306]]\n",
      "l2 error for z2_hat =  0.028024676996591436\n",
      "true tau1 =  177971.64828900588\n",
      "tau1 =  153431.60047983204\n",
      "\n",
      "\n",
      "**** iteration =  107  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.47798497e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995651099894297\n",
      "l2 error for x1_hat =  0.029716059740208498\n",
      "B / (A+B) =  [0.00164036]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999067070473193\n",
      "alpha1 part I =  [0.00163883]\n",
      "alpha2 part II =  [7.1429658e-05]\n",
      "alpha1 =  0.05302549161011468\n",
      "true gam2 =  18826.827728402408\n",
      "gam2 =  19124.90959854405\n",
      "corr(z1_hat, X*beta_true) =  0.9997630481415082\n",
      "l2 error for z1_hat =  0.02802555243745296\n",
      "v1 =  0.9867371239281729\n",
      "true tau2 =  2213.052333158147\n",
      "tau2 = 2062.2962826867606\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956509]]\n",
      "l2 error for x2_hat =  0.029716705065013557\n",
      "alpha2 =  0.9469759636173228\n",
      "true gam1 =  1480.7929320155947\n",
      "gam1 =  1070.8612903911103\n",
      "corr(z2_hat, beta_true) =  [[0.99976235]]\n",
      "l2 error for z2_hat =  0.028091466722919872\n",
      "true tau1 =  177794.45486376397\n",
      "tau1 =  153512.1505816043\n",
      "\n",
      "\n",
      "**** iteration =  108  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.53099365e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995647512279476\n",
      "l2 error for x1_hat =  0.029729815094849725\n",
      "B / (A+B) =  [0.00164065]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990670434607867\n",
      "alpha1 part I =  [0.00163912]\n",
      "alpha2 part II =  [7.19809356e-05]\n",
      "alpha1 =  0.052999728458472714\n",
      "true gam2 =  18811.677363169885\n",
      "gam2 =  19134.172235963095\n",
      "corr(z1_hat, X*beta_true) =  0.9997623377077679\n",
      "l2 error for z1_hat =  0.02809241840937444\n",
      "v1 =  0.986742384207482\n",
      "true tau2 =  2213.1316995135858\n",
      "tau2 = 2062.5496020713595\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956474]]\n",
      "l2 error for x2_hat =  0.029730353645791473\n",
      "alpha2 =  0.9469925087861486\n",
      "true gam1 =  1480.9553834846668\n",
      "gam1 =  1071.0269165510092\n",
      "corr(z2_hat, beta_true) =  [[0.99976156]]\n",
      "l2 error for z2_hat =  0.028164856012296985\n",
      "true tau1 =  177621.34413307603\n",
      "tau1 =  153579.572282195\n",
      "\n",
      "\n",
      "**** iteration =  109  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.58892617e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995644172463948\n",
      "l2 error for x1_hat =  0.029742783951034163\n",
      "B / (A+B) =  [0.00164085]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990671876008326\n",
      "alpha1 part I =  [0.00163932]\n",
      "alpha2 part II =  [7.26381316e-05]\n",
      "alpha1 =  0.05297895611053041\n",
      "true gam2 =  18797.39884924009\n",
      "gam2 =  19145.05499938024\n",
      "corr(z1_hat, X*beta_true) =  0.9997615543307429\n",
      "l2 error for z1_hat =  0.028165686024066196\n",
      "v1 =  0.9867491577010284\n",
      "true tau2 =  2213.19655359235\n",
      "tau2 = 2062.3870583241624\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995644]]\n",
      "l2 error for x2_hat =  0.029743392359774554\n",
      "alpha2 =  0.9470221363273764\n",
      "true gam1 =  1481.1654208207199\n",
      "gam1 =  1071.0035962785835\n",
      "corr(z2_hat, beta_true) =  [[0.99976089]]\n",
      "l2 error for z2_hat =  0.028228222247820497\n",
      "true tau1 =  177454.7894197841\n",
      "tau1 =  153654.5041374909\n",
      "\n",
      "\n",
      "**** iteration =  110  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.63915903e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995640800429866\n",
      "l2 error for x1_hat =  0.02975572214084897\n",
      "B / (A+B) =  [0.00164112]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990671673085133\n",
      "alpha1 part I =  [0.00163959]\n",
      "alpha2 part II =  [7.31674513e-05]\n",
      "alpha1 =  0.052955043210024304\n",
      "true gam2 =  18783.177383882587\n",
      "gam2 =  19153.766913885862\n",
      "corr(z1_hat, X*beta_true) =  0.9997608776027667\n",
      "l2 error for z1_hat =  0.02822911768765417\n",
      "v1 =  0.9867541094059905\n",
      "true tau2 =  2213.2706184355625\n",
      "tau2 = 2062.6118824143477\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956407]]\n",
      "l2 error for x2_hat =  0.02975623567334687\n",
      "alpha2 =  0.947037960759138\n",
      "true gam1 =  1481.3190674833586\n",
      "gam1 =  1071.1530022412128\n",
      "corr(z2_hat, beta_true) =  [[0.99976015]]\n",
      "l2 error for z2_hat =  0.028297264510400766\n",
      "true tau1 =  177292.24613895756\n",
      "tau1 =  153717.78569887625\n",
      "\n",
      "\n",
      "**** iteration =  111  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.69358944e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995637650517001\n",
      "l2 error for x1_hat =  0.02976795167319151\n",
      "B / (A+B) =  [0.00164132]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990672973000032\n",
      "alpha1 part I =  [0.00163979]\n",
      "alpha2 part II =  [7.37893367e-05]\n",
      "alpha1 =  0.05293556088174665\n",
      "true gam2 =  18769.738519586732\n",
      "gam2 =  19163.88341560413\n",
      "corr(z1_hat, X*beta_true) =  0.9997601378079383\n",
      "l2 error for z1_hat =  0.028298051009929555\n",
      "v1 =  0.9867603817255606\n",
      "true tau2 =  2213.3317963106406\n",
      "tau2 = 2062.4711351769984\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956375]]\n",
      "l2 error for x2_hat =  0.02976852524827794\n",
      "alpha2 =  0.947065225188109\n",
      "true gam1 =  1481.5142074959053\n",
      "gam1 =  1071.1362070387995\n",
      "corr(z2_hat, beta_true) =  [[0.9997595]]\n",
      "l2 error for z2_hat =  0.028357346054615738\n",
      "true tau1 =  177135.68790481897\n",
      "tau1 =  153787.5267164201\n",
      "\n",
      "\n",
      "**** iteration =  112  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.7411661e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995634480691717\n",
      "l2 error for x1_hat =  0.02978012225484173\n",
      "B / (A+B) =  [0.00164158]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990672826890513\n",
      "alpha1 part I =  [0.00164005]\n",
      "alpha2 part II =  [7.42968348e-05]\n",
      "alpha1 =  0.05291335169293515\n",
      "true gam2 =  18756.386145840628\n",
      "gam2 =  19172.07600251425\n",
      "corr(z1_hat, X*beta_true) =  0.9997594937244014\n",
      "l2 error for z1_hat =  0.02835818855119409\n",
      "v1 =  0.9867650420595971\n",
      "true tau2 =  2213.400945045173\n",
      "tau2 = 2062.6708092557983\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956344]]\n",
      "l2 error for x2_hat =  0.02978061143563266\n",
      "alpha2 =  0.9470803357657323\n",
      "true gam1 =  1481.659451363628\n",
      "gam1 =  1071.2711334108837\n",
      "corr(z2_hat, beta_true) =  [[0.9997588]]\n",
      "l2 error for z2_hat =  0.028422298368604163\n",
      "true tau1 =  176983.0412553269\n",
      "tau1 =  153846.92076522214\n",
      "\n",
      "\n",
      "**** iteration =  113  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.79231279e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995631510445988\n",
      "l2 error for x1_hat =  0.02979165260260903\n",
      "B / (A+B) =  [0.00164176]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990674000550411\n",
      "alpha1 part I =  [0.00164023]\n",
      "alpha2 part II =  [7.48851141e-05]\n",
      "alpha1 =  0.05289507794795965\n",
      "true gam2 =  18743.738356496604\n",
      "gam2 =  19181.485360583592\n",
      "corr(z1_hat, X*beta_true) =  0.9997587952421748\n",
      "l2 error for z1_hat =  0.028423043252474873\n",
      "v1 =  0.9867708544634144\n",
      "true tau2 =  2213.4586418801487\n",
      "tau2 = 2062.549066941597\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956314]]\n",
      "l2 error for x2_hat =  0.029792193306908653\n",
      "alpha2 =  0.9471054503260053\n",
      "true gam1 =  1481.8408600548755\n",
      "gam1 =  1071.259836882106\n",
      "corr(z2_hat, beta_true) =  [[0.99975819]]\n",
      "l2 error for z2_hat =  0.02847923348376541\n",
      "true tau1 =  176835.87598224837\n",
      "tau1 =  153911.8626373811\n",
      "\n",
      "\n",
      "**** iteration =  114  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.83735136e-06]\n",
      "corr(x1_hat, beta_true) =  0.999562853036382\n",
      "l2 error for x1_hat =  0.0298031019013729\n",
      "B / (A+B) =  [0.00164201]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990673902298647\n",
      "alpha1 part I =  [0.00164048]\n",
      "alpha2 part II =  [7.53710401e-05]\n",
      "alpha1 =  0.05287443879583451\n",
      "true gam2 =  18731.199579696822\n",
      "gam2 =  19189.188524916874\n",
      "corr(z1_hat, X*beta_true) =  0.999758182703204\n",
      "l2 error for z1_hat =  0.028480026150508573\n",
      "v1 =  0.9867752398475832\n",
      "true tau2 =  2213.5232284871654\n",
      "tau2 = 2062.7265316319454\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956284]]\n",
      "l2 error for x2_hat =  0.02980356745451748\n",
      "alpha2 =  0.9471198585909031\n",
      "true gam1 =  1481.9780969169317\n",
      "gam1 =  1071.3818251399616\n",
      "corr(z2_hat, beta_true) =  [[0.99975753]]\n",
      "l2 error for z2_hat =  0.0285403378107525\n",
      "true tau1 =  176692.50179810572\n",
      "tau1 =  153967.6074778075\n",
      "\n",
      "\n",
      "**** iteration =  115  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.885418e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995625730023552\n",
      "l2 error for x1_hat =  0.02981397129788473\n",
      "B / (A+B) =  [0.00164219]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990674963184223\n",
      "alpha1 part I =  [0.00164066]\n",
      "alpha2 part II =  [7.59273567e-05]\n",
      "alpha1 =  0.05285729731785535\n",
      "true gam2 =  18719.296960164742\n",
      "gam2 =  19197.94482425809\n",
      "corr(z1_hat, X*beta_true) =  0.9997575233647228\n",
      "l2 error for z1_hat =  0.028541042945199248\n",
      "v1 =  0.9867806298104259\n",
      "true tau2 =  2213.577630982679\n",
      "tau2 = 2062.621355714281\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956256]]\n",
      "l2 error for x2_hat =  0.029814480982766796\n",
      "alpha2 =  0.9471430149460744\n",
      "true gam1 =  1482.1468385703488\n",
      "gam1 =  1071.3751425381856\n",
      "corr(z2_hat, beta_true) =  [[0.99975695]]\n",
      "l2 error for z2_hat =  0.02859426332846969\n",
      "true tau1 =  176554.16245372963\n",
      "tau1 =  154028.10940465436\n",
      "\n",
      "\n",
      "**** iteration =  116  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.92803446e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995622928050534\n",
      "l2 error for x1_hat =  0.02982474266195949\n",
      "B / (A+B) =  [0.00164242]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999067490507442\n",
      "alpha1 part I =  [0.00164089]\n",
      "alpha2 part II =  [7.6392055e-05]\n",
      "alpha1 =  0.05283810616126004\n",
      "true gam2 =  18707.520214726897\n",
      "gam2 =  19205.18698988167\n",
      "corr(z1_hat, X*beta_true) =  0.9997569412446896\n",
      "l2 error for z1_hat =  0.02859500909890667\n",
      "v1 =  0.9867847558839908\n",
      "true tau2 =  2213.637980929631\n",
      "tau2 = 2062.779197157739\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956228]]\n",
      "l2 error for x2_hat =  0.029825185353859897\n",
      "alpha2 =  0.9471567360836073\n",
      "true gam1 =  1482.2764557383584\n",
      "gam1 =  1071.4855588382839\n",
      "corr(z2_hat, beta_true) =  [[0.99975633]]\n",
      "l2 error for z2_hat =  0.02865174737928854\n",
      "true tau1 =  176419.4793321815\n",
      "tau1 =  154080.4295509935\n",
      "\n",
      "\n",
      "**** iteration =  117  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [2.97321119e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995620288318044\n",
      "l2 error for x1_hat =  0.029834987483556553\n",
      "B / (A+B) =  [0.0016426]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990675865126956\n",
      "alpha1 part I =  [0.00164107]\n",
      "alpha2 part II =  [7.69179911e-05]\n",
      "alpha1 =  0.05282202546292794\n",
      "true gam2 =  18696.31940925951\n",
      "gam2 =  19213.339747421207\n",
      "corr(z1_hat, X*beta_true) =  0.9997563189794346\n",
      "l2 error for z1_hat =  0.028652414592084056\n",
      "v1 =  0.9867897574761062\n",
      "true tau2 =  2213.689267391294\n",
      "tau2 = 2062.6884573268817\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956202]]\n",
      "l2 error for x2_hat =  0.029835467896110898\n",
      "alpha2 =  0.9471781067084092\n",
      "true gam1 =  1482.433502676109\n",
      "gam1 =  1071.4827282486988\n",
      "corr(z2_hat, beta_true) =  [[0.99975577]]\n",
      "l2 error for z2_hat =  0.02870279797169568\n",
      "true tau1 =  176289.4332347771\n",
      "tau1 =  154136.8211619362\n",
      "\n",
      "\n",
      "**** iteration =  118  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.01351891e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995617653585503\n",
      "l2 error for x1_hat =  0.029845121511028583\n",
      "B / (A+B) =  [0.00164282]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999067584051789\n",
      "alpha1 part I =  [0.00164129]\n",
      "alpha2 part II =  [7.73618846e-05]\n",
      "alpha1 =  0.052804170788334964\n",
      "true gam2 =  18685.25671915294\n",
      "gam2 =  19220.147880699362\n",
      "corr(z1_hat, X*beta_true) =  0.9997557661379879\n",
      "l2 error for z1_hat =  0.0287034996091832\n",
      "v1 =  0.9867936391055057\n",
      "true tau2 =  2213.7456802399206\n",
      "tau2 = 2062.828950984981\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956175]]\n",
      "l2 error for x2_hat =  0.029845542137738348\n",
      "alpha2 =  0.9471911587047814\n",
      "true gam1 =  1482.555877260486\n",
      "gam1 =  1071.582784292896\n",
      "corr(z2_hat, beta_true) =  [[0.99975519]]\n",
      "l2 error for z2_hat =  0.02875687602878555\n",
      "true tau1 =  176162.89906859305\n",
      "tau1 =  154185.92791554783\n",
      "\n",
      "\n",
      "**** iteration =  119  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.05598338e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995615165615112\n",
      "l2 error for x1_hat =  0.02985477633245497\n",
      "B / (A+B) =  [0.00164299]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990676710323491\n",
      "alpha1 part I =  [0.00164145]\n",
      "alpha2 part II =  [7.78589611e-05]\n",
      "alpha1 =  0.052789083928058984\n",
      "true gam2 =  18674.716801148024\n",
      "gam2 =  19227.7424654737\n",
      "corr(z1_hat, X*beta_true) =  0.9997551789711435\n",
      "l2 error for z1_hat =  0.028757507102811598\n",
      "v1 =  0.9867982833312438\n",
      "true tau2 =  2213.7940207051674\n",
      "tau2 = 2062.7507860865053\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956151]]\n",
      "l2 error for x2_hat =  0.029855229122014645\n",
      "alpha2 =  0.9472108989928223\n",
      "true gam1 =  1482.7021186022548\n",
      "gam1 =  1071.5831503091508\n",
      "corr(z2_hat, beta_true) =  [[0.99975466]]\n",
      "l2 error for z2_hat =  0.028805183621078895\n",
      "true tau1 =  176040.64585228247\n",
      "tau1 =  154238.5119163061\n",
      "\n",
      "\n",
      "**** iteration =  120  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.09409271e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995612687960268\n",
      "l2 error for x1_hat =  0.029864311074870965\n",
      "B / (A+B) =  [0.00164319]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990676713505039\n",
      "alpha1 part I =  [0.00164166]\n",
      "alpha2 part II =  [7.82825365e-05]\n",
      "alpha1 =  0.05277246375489332\n",
      "true gam2 =  18664.323478747807\n",
      "gam2 =  19234.142109860997\n",
      "corr(z1_hat, X*beta_true) =  0.9997546542626661\n",
      "l2 error for z1_hat =  0.028805843728145746\n",
      "v1 =  0.9868019346254333\n",
      "true tau2 =  2213.8467724510274\n",
      "tau2 = 2062.8759349970023\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956126]]\n",
      "l2 error for x2_hat =  0.029864710451388974\n",
      "alpha2 =  0.9472233019358833\n",
      "true gam1 =  1482.8176162260154\n",
      "gam1 =  1071.6739216400294\n",
      "corr(z2_hat, beta_true) =  [[0.99975411]]\n",
      "l2 error for z2_hat =  0.028856057317965957\n",
      "true tau1 =  175921.75472470067\n",
      "tau1 =  154284.60396917452\n",
      "\n",
      "\n",
      "**** iteration =  121  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.13401101e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995610343344777\n",
      "l2 error for x1_hat =  0.02987340872923958\n",
      "B / (A+B) =  [0.00164335]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990677502456002\n",
      "alpha1 part I =  [0.00164182]\n",
      "alpha2 part II =  [7.87522134e-05]\n",
      "alpha1 =  0.05275830806358581\n",
      "true gam2 =  18654.40583179731\n",
      "gam2 =  19241.220122430106\n",
      "corr(z1_hat, X*beta_true) =  0.999754100312312\n",
      "l2 error for z1_hat =  0.02885665398622125\n",
      "v1 =  0.9868062497260319\n",
      "true tau2 =  2213.8923288613605\n",
      "tau2 = 2062.808718988653\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956102]]\n",
      "l2 error for x2_hat =  0.029873835453312958\n",
      "alpha2 =  0.947241552059397\n",
      "true gam1 =  1482.9538657545759\n",
      "gam1 =  1071.676921199143\n",
      "corr(z2_hat, beta_true) =  [[0.99975361]]\n",
      "l2 error for z2_hat =  0.028901750622112993\n",
      "true tau1 =  175806.82440670984\n",
      "tau1 =  154333.65853956464\n",
      "\n",
      "\n",
      "**** iteration =  122  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.17002904e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995608013257336\n",
      "l2 error for x1_hat =  0.02988237987500586\n",
      "B / (A+B) =  [0.00164355]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990677528524785\n",
      "alpha1 part I =  [0.00164202]\n",
      "alpha2 part II =  [7.9156009e-05]\n",
      "alpha1 =  0.052742829049484914\n",
      "true gam2 =  18644.640209667297\n",
      "gam2 =  19247.235441155623\n",
      "corr(z1_hat, X*beta_true) =  0.999753602593966\n",
      "l2 error for z1_hat =  0.028902371649408745\n",
      "v1 =  0.9868096840565596\n",
      "true tau2 =  2213.9416740354623\n",
      "tau2 = 2062.92028719819\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956079]]\n",
      "l2 error for x2_hat =  0.029882758826283197\n",
      "alpha2 =  0.9472533275602923\n",
      "true gam1 =  1483.0628396281925\n",
      "gam1 =  1071.7593632522223\n",
      "corr(z2_hat, beta_true) =  [[0.99975309]]\n",
      "l2 error for z2_hat =  0.028949609681026427\n",
      "true tau1 =  175695.10380045528\n",
      "tau1 =  154376.922590566\n",
      "\n",
      "\n",
      "**** iteration =  123  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.20755656e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995605804013427\n",
      "l2 error for x1_hat =  0.02989095151681369\n",
      "B / (A+B) =  [0.0016437]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990678244961029\n",
      "alpha1 part I =  [0.00164217]\n",
      "alpha2 part II =  [7.95996861e-05]\n",
      "alpha1 =  0.05272954586857017\n",
      "true gam2 =  18635.308411005204\n",
      "gam2 =  19253.835056309286\n",
      "corr(z1_hat, X*beta_true) =  0.9997530800681389\n",
      "l2 error for z1_hat =  0.028950173622858982\n",
      "v1 =  0.9868136957810285\n",
      "true tau2 =  2213.984600443647\n",
      "tau2 = 2062.8625994663166\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956057]]\n",
      "l2 error for x2_hat =  0.029891353646512457\n",
      "alpha2 =  0.9472702141127064\n",
      "true gam1 =  1483.189842855703\n",
      "gam1 =  1071.764513338389\n",
      "corr(z2_hat, beta_true) =  [[0.99975261]]\n",
      "l2 error for z2_hat =  0.028992813833033884\n",
      "true tau1 =  175587.05495074284\n",
      "tau1 =  154422.7035566753\n",
      "\n",
      "\n",
      "**** iteration =  124  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.24158684e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995603612587457\n",
      "l2 error for x1_hat =  0.029899392557144484\n",
      "B / (A+B) =  [0.00164389]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990678289712548\n",
      "alpha1 part I =  [0.00164236]\n",
      "alpha2 part II =  [7.99842798e-05]\n",
      "alpha1 =  0.0527151225043476\n",
      "true gam2 =  18626.131602028356\n",
      "gam2 =  19259.48888078958\n",
      "corr(z1_hat, X*beta_true) =  0.9997526082066657\n",
      "l2 error for z1_hat =  0.028993398087870288\n",
      "v1 =  0.9868169258055529\n",
      "true tau2 =  2214.0307740033204\n",
      "tau2 = 2062.9621412633687\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956035]]\n",
      "l2 error for x2_hat =  0.029899751910571887\n",
      "alpha2 =  0.9472813848288989\n",
      "true gam1 =  1483.2926331483786\n",
      "gam1 =  1071.839475534336\n",
      "corr(z2_hat, beta_true) =  [[0.99975212]]\n",
      "l2 error for z2_hat =  0.029037836762013002\n",
      "true tau1 =  175482.06322991557\n",
      "tau1 =  154463.31492940048\n",
      "\n",
      "\n",
      "**** iteration =  125  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.27686905e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995601531140316\n",
      "l2 error for x1_hat =  0.0299074677271622\n",
      "B / (A+B) =  [0.00164404]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990678941045659\n",
      "alpha1 part I =  [0.0016425]\n",
      "alpha2 part II =  [8.04032977e-05]\n",
      "alpha1 =  0.05270265693584258\n",
      "true gam2 =  18617.351309116333\n",
      "gam2 =  19265.64515715006\n",
      "corr(z1_hat, X*beta_true) =  0.9997521154003243\n",
      "l2 error for z1_hat =  0.029038369600391054\n",
      "v1 =  0.9868206576531271\n",
      "true tau2 =  2214.071216806931\n",
      "tau2 = 2062.9127407292094\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99956014]]\n",
      "l2 error for x2_hat =  0.029907846652195477\n",
      "alpha2 =  0.9472970222769876\n",
      "true gam1 =  1483.4110736684809\n",
      "gam1 =  1071.846362502185\n",
      "corr(z2_hat, beta_true) =  [[0.99975167]]\n",
      "l2 error for z2_hat =  0.02907867304743405\n",
      "true tau1 =  175380.4812414264\n",
      "tau1 =  154506.0577315752\n",
      "\n",
      "\n",
      "**** iteration =  126  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.30901152e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995599470030687\n",
      "l2 error for x1_hat =  0.02991541010686236\n",
      "B / (A+B) =  [0.00164421]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990679000880726\n",
      "alpha1 part I =  [0.00164268]\n",
      "alpha2 part II =  [8.0769298e-05]\n",
      "alpha1 =  0.05268921082079025\n",
      "true gam2 =  18608.72699112721\n",
      "gam2 =  19270.959039306053\n",
      "corr(z1_hat, X*beta_true) =  0.9997516682777311\n",
      "l2 error for z1_hat =  0.029079222701916017\n",
      "v1 =  0.9868236953413375\n",
      "true tau2 =  2214.114435837961\n",
      "tau2 = 2063.0016262185004\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955994]]\n",
      "l2 error for x2_hat =  0.02991575068603389\n",
      "alpha2 =  0.9473076115204401\n",
      "true gam1 =  1483.5080071198404\n",
      "gam1 =  1071.9146006258934\n",
      "corr(z2_hat, beta_true) =  [[0.99975121]]\n",
      "l2 error for z2_hat =  0.02912102779847956\n",
      "true tau1 =  175281.80537161013\n",
      "tau1 =  154544.1809856508\n",
      "\n",
      "\n",
      "**** iteration =  127  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.34218465e-06]\n",
      "corr(x1_hat, beta_true) =  0.999559750919821\n",
      "l2 error for x1_hat =  0.029923016797925403\n",
      "B / (A+B) =  [0.00164435]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990679593702829\n",
      "alpha1 part I =  [0.00164282]\n",
      "alpha2 part II =  [8.11649389e-05]\n",
      "alpha1 =  0.05267751149000438\n",
      "true gam2 =  18600.465831931888\n",
      "gam2 =  19276.704199054693\n",
      "corr(z1_hat, X*beta_true) =  0.9997512035696658\n",
      "l2 error for z1_hat =  0.0291215310981403\n",
      "v1 =  0.9868271687786284\n",
      "true tau2 =  2214.152534031569\n",
      "tau2 = 2062.959428740416\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955974]]\n",
      "l2 error for x2_hat =  0.029923373831219884\n",
      "alpha2 =  0.9473221034893037\n",
      "true gam1 =  1483.618512319586\n",
      "gam1 =  1071.9228709272631\n",
      "corr(z2_hat, beta_true) =  [[0.99975079]]\n",
      "l2 error for z2_hat =  0.02915961345285315\n",
      "true tau1 =  175186.30082855\n",
      "tau1 =  154584.10246155574\n",
      "\n",
      "\n",
      "**** iteration =  128  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.3725355e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995595570580992\n",
      "l2 error for x1_hat =  0.02993049005295186\n",
      "B / (A+B) =  [0.00164452]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990679665546361\n",
      "alpha1 part I =  [0.00164298]\n",
      "alpha2 part II =  [8.15129759e-05]\n",
      "alpha1 =  0.052664970679243917\n",
      "true gam2 =  18592.360053591216\n",
      "gam2 =  19281.698466029535\n",
      "corr(z1_hat, X*beta_true) =  0.9997507800879398\n",
      "l2 error for z1_hat =  0.029160130551603356\n",
      "v1 =  0.9868300254397165\n",
      "true tau2 =  2214.1929992844443\n",
      "tau2 = 2063.03886622804\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955955]]\n",
      "l2 error for x2_hat =  0.029930812672526484\n",
      "alpha2 =  0.9473321349060846\n",
      "true gam1 =  1483.709902050168\n",
      "gam1 =  1071.985058008272\n",
      "corr(z2_hat, beta_true) =  [[0.99975035]]\n",
      "l2 error for z2_hat =  0.029199458042827725\n",
      "true tau1 =  175093.55430544552\n",
      "tau1 =  154619.8919910835\n",
      "\n",
      "\n",
      "**** iteration =  129  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.40372721e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995593723557754\n",
      "l2 error for x1_hat =  0.029937654775877197\n",
      "B / (A+B) =  [0.00164465]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990680205725733\n",
      "alpha1 part I =  [0.00164312]\n",
      "alpha2 part II =  [8.18864652e-05]\n",
      "alpha1 =  0.05265398951010042\n",
      "true gam2 =  18584.58752093539\n",
      "gam2 =  19287.062147762095\n",
      "corr(z1_hat, X*beta_true) =  0.9997503419376471\n",
      "l2 error for z1_hat =  0.029199933309164237\n",
      "v1 =  0.9868332600953067\n",
      "true tau2 =  2214.2288847256636\n",
      "tau2 = 2063.002924872789\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955936]]\n",
      "l2 error for x2_hat =  0.029937991157867404\n",
      "alpha2 =  0.94734557531739\n",
      "true gam1 =  1483.8130482510421\n",
      "gam1 =  1071.994410136888\n",
      "corr(z2_hat, beta_true) =  [[0.99974995]]\n",
      "l2 error for z2_hat =  0.029235906115498315\n",
      "true tau1 =  175003.7614463934\n",
      "tau1 =  154657.19199193787\n",
      "\n",
      "\n",
      "**** iteration =  130  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.43237885e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995591900094193\n",
      "l2 error for x1_hat =  0.02994468665923896\n",
      "B / (A+B) =  [0.00164481]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990680286956272\n",
      "alpha1 part I =  [0.00164327]\n",
      "alpha2 part II =  [8.22171834e-05]\n",
      "alpha1 =  0.05264228792656856\n",
      "true gam2 =  18576.968526184137\n",
      "gam2 =  19291.755957860558\n",
      "corr(z1_hat, X*beta_true) =  0.9997499410226035\n",
      "l2 error for z1_hat =  0.029236392582983054\n",
      "v1 =  0.9868359464063653\n",
      "true tau2 =  2214.266782000935\n",
      "tau2 = 2063.0739804694554\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955918]]\n",
      "l2 error for x2_hat =  0.029944992120749154\n",
      "alpha2 =  0.9473550726271686\n",
      "true gam1 =  1483.899193728356\n",
      "gam1 =  1072.0511460180376\n",
      "corr(z2_hat, beta_true) =  [[0.99974953]]\n",
      "l2 error for z2_hat =  0.029273389211471955\n",
      "true tau1 =  174916.58240876126\n",
      "tau1 =  154690.79260642984\n",
      "\n",
      "\n",
      "**** iteration =  131  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.46170882e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995590160435398\n",
      "l2 error for x1_hat =  0.02995143450830713\n",
      "B / (A+B) =  [0.00164494]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068077972135\n",
      "alpha1 part I =  [0.0016434]\n",
      "alpha2 part II =  [8.25696911e-05]\n",
      "alpha1 =  0.052631979929616345\n",
      "true gam2 =  18569.655876347348\n",
      "gam2 =  19296.765445181256\n",
      "corr(z1_hat, X*beta_true) =  0.9997495279671549\n",
      "l2 error for z1_hat =  0.029273837890038235\n",
      "v1 =  0.9868389602452982\n",
      "true tau2 =  2214.300579683849\n",
      "tau2 = 2063.043468281289\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955901]]\n",
      "l2 error for x2_hat =  0.029951751410938286\n",
      "alpha2 =  0.9473675467082675\n",
      "true gam1 =  1483.9955108148094\n",
      "gam1 =  1072.0613235105627\n",
      "corr(z2_hat, beta_true) =  [[0.99974915]]\n",
      "l2 error for z2_hat =  0.029307808482798348\n",
      "true tau1 =  174832.15768027576\n",
      "tau1 =  154725.6554621067\n",
      "\n",
      "\n",
      "**** iteration =  132  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.48874984e-06]\n",
      "corr(x1_hat, beta_true) =  0.999558844523891\n",
      "l2 error for x1_hat =  0.02995805110574525\n",
      "B / (A+B) =  [0.00164508]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990680868109862\n",
      "alpha1 part I =  [0.00164355]\n",
      "alpha2 part II =  [8.28837432e-05]\n",
      "alpha1 =  0.05262105683391335\n",
      "true gam2 =  18562.493945052014\n",
      "gam2 =  19301.176844135625\n",
      "corr(z1_hat, X*beta_true) =  0.9997491485715366\n",
      "l2 error for z1_hat =  0.029308266130265336\n",
      "v1 =  0.9868414862800955\n",
      "true tau2 =  2214.3360810859012\n",
      "tau2 = 2063.1070830776584\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955884]]\n",
      "l2 error for x2_hat =  0.02995834019421594\n",
      "alpha2 =  0.9473765334940556\n",
      "true gam1 =  1484.0766979480595\n",
      "gam1 =  1072.1131432680286\n",
      "corr(z2_hat, beta_true) =  [[0.99974876]]\n",
      "l2 error for z2_hat =  0.02934306995363899\n",
      "true tau1 =  174750.20718508807\n",
      "tau1 =  154757.20294682943\n",
      "\n",
      "\n",
      "**** iteration =  133  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.5163303e-06]\n",
      "corr(x1_hat, beta_true) =  0.999558680684444\n",
      "l2 error for x1_hat =  0.029964405823242328\n",
      "B / (A+B) =  [0.00164521]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990681318123132\n",
      "alpha1 part I =  [0.00164367]\n",
      "alpha2 part II =  [8.3216385e-05]\n",
      "alpha1 =  0.05261137990669343\n",
      "true gam2 =  18555.614100783678\n",
      "gam2 =  19305.857272437228\n",
      "corr(z1_hat, X*beta_true) =  0.9997487592224577\n",
      "l2 error for z1_hat =  0.029343493430169326\n",
      "v1 =  0.9868442957604497\n",
      "true tau2 =  2214.367909419661\n",
      "tau2 = 2063.081278024386\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955867]]\n",
      "l2 error for x2_hat =  0.029964704353714712\n",
      "alpha2 =  0.9473881186735514\n",
      "true gam1 =  1484.1666735384083\n",
      "gam1 =  1072.1239286227683\n",
      "corr(z2_hat, beta_true) =  [[0.9997484]]\n",
      "l2 error for z2_hat =  0.02937556489693571\n",
      "true tau1 =  174670.8278820107\n",
      "tau1 =  154789.79879469433\n",
      "\n",
      "\n",
      "**** iteration =  134  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.54184553e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995585193450395\n",
      "l2 error for x1_hat =  0.029970631659774465\n",
      "B / (A+B) =  [0.00164534]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990681411779874\n",
      "alpha1 part I =  [0.00164381]\n",
      "alpha2 part II =  [8.35144262e-05]\n",
      "alpha1 =  0.052601179418932296\n",
      "true gam2 =  18548.881403698808\n",
      "gam2 =  19310.003249249745\n",
      "corr(z1_hat, X*beta_true) =  0.999748400328373\n",
      "l2 error for z1_hat =  0.029375995428977352\n",
      "v1 =  0.9868466710182052\n",
      "true tau2 =  2214.4011744901227\n",
      "tau2 = 2063.1382831455844\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955851]]\n",
      "l2 error for x2_hat =  0.029970905141038288\n",
      "alpha2 =  0.9473966182134603\n",
      "true gam1 =  1484.2431748721192\n",
      "gam1 =  1072.1713099790059\n",
      "corr(z2_hat, beta_true) =  [[0.99974804]]\n",
      "l2 error for z2_hat =  0.02940873633285794\n",
      "true tau1 =  174593.78832448376\n",
      "tau1 =  154819.4204479744\n",
      "\n",
      "\n",
      "**** iteration =  135  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.56778175e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995583650549092\n",
      "l2 error for x1_hat =  0.029976615699242898\n",
      "B / (A+B) =  [0.00164546]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990681823202863\n",
      "alpha1 part I =  [0.00164393]\n",
      "alpha2 part II =  [8.38282657e-05]\n",
      "alpha1 =  0.05259209415840406\n",
      "true gam2 =  18542.40886166537\n",
      "gam2 =  19314.37779281378\n",
      "corr(z1_hat, X*beta_true) =  0.9997480333685553\n",
      "l2 error for z1_hat =  0.029409135933710962\n",
      "v1 =  0.9868492912316712\n",
      "true tau2 =  2214.4311455787815\n",
      "tau2 = 2063.116554962186\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955836]]\n",
      "l2 error for x2_hat =  0.029976896903526385\n",
      "alpha2 =  0.9474073849166866\n",
      "true gam1 =  1484.3272580794933\n",
      "gam1 =  1072.182519371514\n",
      "corr(z2_hat, beta_true) =  [[0.9997477]]\n",
      "l2 error for z2_hat =  0.029439407113596522\n",
      "true tau1 =  174519.15131250097\n",
      "tau1 =  154849.90643839518\n",
      "\n",
      "\n",
      "**** iteration =  136  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.59185228e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995582132887004\n",
      "l2 error for x1_hat =  0.029982473837613297\n",
      "B / (A+B) =  [0.00164559]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990681920531229\n",
      "alpha1 part I =  [0.00164406]\n",
      "alpha2 part II =  [8.41109493e-05]\n",
      "alpha1 =  0.05258256482660989\n",
      "true gam2 =  18536.079327985786\n",
      "gam2 =  19318.274334663995\n",
      "corr(z1_hat, X*beta_true) =  0.9997476939893444\n",
      "l2 error for z1_hat =  0.02943981213435261\n",
      "v1 =  0.9868515246654926\n",
      "true tau2 =  2214.4623223247363\n",
      "tau2 = 2063.1676847701647\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955821]]\n",
      "l2 error for x2_hat =  0.02998273245622034\n",
      "alpha2 =  0.9474154200508701\n",
      "true gam1 =  1484.3993330667386\n",
      "gam1 =  1072.2258892258887\n",
      "corr(z2_hat, beta_true) =  [[0.99974735]]\n",
      "l2 error for z2_hat =  0.029470612315393177\n",
      "true tau1 =  174446.7249748105\n",
      "tau1 =  154877.72158475057\n",
      "\n",
      "\n",
      "**** iteration =  137  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.61624306e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995580680021271\n",
      "l2 error for x1_hat =  0.029988108425547402\n",
      "B / (A+B) =  [0.0016457]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990682297081733\n",
      "alpha1 part I =  [0.00164417]\n",
      "alpha2 part II =  [8.44069994e-05]\n",
      "alpha1 =  0.05257403435311245\n",
      "true gam2 =  18529.99007061991\n",
      "gam2 =  19322.36437608084\n",
      "corr(z1_hat, X*beta_true) =  0.9997473481699967\n",
      "l2 error for z1_hat =  0.029470989308343288\n",
      "v1 =  0.9868539694636951\n",
      "true tau2 =  2214.4905422447428\n",
      "tau2 = 2063.1494834569494\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955806]]\n",
      "l2 error for x2_hat =  0.029988373291688086\n",
      "alpha2 =  0.9474254324072553\n",
      "true gam1 =  1484.4779378920455\n",
      "gam1 =  1072.237367916919\n",
      "corr(z2_hat, beta_true) =  [[0.99974703]]\n",
      "l2 error for z2_hat =  0.029499554821227708\n",
      "true tau1 =  174376.54549072942\n",
      "tau1 =  154906.24297554366\n",
      "\n",
      "\n",
      "**** iteration =  138  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.6389463e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995579252389197\n",
      "l2 error for x1_hat =  0.029993620557410252\n",
      "B / (A+B) =  [0.00164583]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990682396738189\n",
      "alpha1 part I =  [0.00164429]\n",
      "alpha2 part II =  [8.4674973e-05]\n",
      "alpha1 =  0.05256512876346431\n",
      "true gam2 =  18524.039266714437\n",
      "gam2 =  19326.026521853742\n",
      "corr(z1_hat, X*beta_true) =  0.9997470273516024\n",
      "l2 error for z1_hat =  0.029499935840243484\n",
      "v1 =  0.9868560695084754\n",
      "true tau2 =  2214.5197680712213\n",
      "tau2 = 2063.195387132677\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955792]]\n",
      "l2 error for x2_hat =  0.029993865035045197\n",
      "alpha2 =  0.9474330254341855\n",
      "true gam1 =  1484.545833227525\n",
      "gam1 =  1072.2771081016253\n",
      "corr(z2_hat, beta_true) =  [[0.99974671]]\n",
      "l2 error for z2_hat =  0.02952891026084177\n",
      "true tau1 =  174308.453206124\n",
      "tau1 =  154932.36345367762\n",
      "\n",
      "\n",
      "**** iteration =  139  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.66188437e-06]\n",
      "corr(x1_hat, beta_true) =  0.999557788439995\n",
      "l2 error for x1_hat =  0.029998925753177298\n",
      "B / (A+B) =  [0.00164593]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990682741740678\n",
      "alpha1 part I =  [0.0016444]\n",
      "alpha2 part II =  [8.49541974e-05]\n",
      "alpha1 =  0.05255711855578925\n",
      "true gam2 =  18518.3106784095\n",
      "gam2 =  19329.851805480383\n",
      "corr(z1_hat, X*beta_true) =  0.9997467014892603\n",
      "l2 error for z1_hat =  0.02952926585615271\n",
      "v1 =  0.9868583516165462\n",
      "true tau2 =  2214.546337146513\n",
      "tau2 = 2063.180232898135\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955778]]\n",
      "l2 error for x2_hat =  0.029999175214413643\n",
      "alpha2 =  0.9474423419067582\n",
      "true gam1 =  1484.6193416241283\n",
      "gam1 =  1072.288726447326\n",
      "corr(z2_hat, beta_true) =  [[0.9997464]]\n",
      "l2 error for z2_hat =  0.029556216156902605\n",
      "true tau1 =  174242.4637317286\n",
      "tau1 =  154959.05460396444\n",
      "\n",
      "\n",
      "**** iteration =  140  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.68329414e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995576541440795\n",
      "l2 error for x1_hat =  0.03000411228372751\n",
      "B / (A+B) =  [0.00164605]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990682842599958\n",
      "alpha1 part I =  [0.00164451]\n",
      "alpha2 part II =  [8.52080996e-05]\n",
      "alpha1 =  0.052548792980344\n",
      "true gam2 =  18512.715696526753\n",
      "gam2 =  19333.293697651705\n",
      "corr(z1_hat, X*beta_true) =  0.9997463983111716\n",
      "l2 error for z1_hat =  0.029556574594657353\n",
      "v1 =  0.9868603262161141\n",
      "true tau2 =  2214.573739703423\n",
      "tau2 = 2063.2214846071\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955765]]\n",
      "l2 error for x2_hat =  0.030004343318057177\n",
      "alpha2 =  0.9474495145040194\n",
      "true gam1 =  1484.6832916222122\n",
      "gam1 =  1072.325178803677\n",
      "corr(z2_hat, beta_true) =  [[0.99974609]]\n",
      "l2 error for z2_hat =  0.029583831410934285\n",
      "true tau1 =  174178.44365249382\n",
      "tau1 =  154983.5852296645\n",
      "\n",
      "\n",
      "**** iteration =  141  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.70486656e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995575253452897\n",
      "l2 error for x1_hat =  0.030009107037549304\n",
      "B / (A+B) =  [0.00164615]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068315903001\n",
      "alpha1 part I =  [0.00164462]\n",
      "alpha2 part II =  [8.54714148e-05]\n",
      "alpha1 =  0.05254127072136607\n",
      "true gam2 =  18507.32648409487\n",
      "gam2 =  19336.872468706068\n",
      "corr(z1_hat, X*beta_true) =  0.9997460912847712\n",
      "l2 error for z1_hat =  0.029584166762657346\n",
      "v1 =  0.9868624573349046\n",
      "true tau2 =  2214.5987527749785\n",
      "tau2 = 2063.2089590709634\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955752]]\n",
      "l2 error for x2_hat =  0.03000934197525549\n",
      "alpha2 =  0.9474581884502205\n",
      "true gam1 =  1484.7520562653278\n",
      "gam1 =  1072.3368287889941\n",
      "corr(z2_hat, beta_true) =  [[0.99974581]]\n",
      "l2 error for z2_hat =  0.029609588215627557\n",
      "true tau1 =  174116.39285791613\n",
      "tau1 =  155008.57050298454\n",
      "\n",
      "\n",
      "**** iteration =  142  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.72505317e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995573990132506\n",
      "l2 error for x1_hat =  0.0300139871642517\n",
      "B / (A+B) =  [0.00164626]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990683260154892\n",
      "alpha1 part I =  [0.00164472]\n",
      "alpha2 part II =  [8.57118724e-05]\n",
      "alpha1 =  0.052533484799481875\n",
      "true gam2 =  18502.065839957293\n",
      "gam2 =  19340.107403343318\n",
      "corr(z1_hat, X*beta_true) =  0.9997458048605989\n",
      "l2 error for z1_hat =  0.029609925408749918\n",
      "v1 =  0.9868643139683101\n",
      "true tau2 =  2214.6244507279257\n",
      "tau2 = 2063.246066889048\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955739]]\n",
      "l2 error for x2_hat =  0.03001420542813813\n",
      "alpha2 =  0.9474649616156268\n",
      "true gam1 =  1484.8122832715896\n",
      "gam1 =  1072.3702996467457\n",
      "corr(z2_hat, beta_true) =  [[0.99974552]]\n",
      "l2 error for z2_hat =  0.0296355663733192\n",
      "true tau1 =  174056.1993167365\n",
      "tau1 =  155031.60950689268\n",
      "\n",
      "\n",
      "**** iteration =  143  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.7453417e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995572777540623\n",
      "l2 error for x1_hat =  0.030018689373173476\n",
      "B / (A+B) =  [0.00164635]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990683550678372\n",
      "alpha1 part I =  [0.00164482]\n",
      "alpha2 part II =  [8.59601494e-05]\n",
      "alpha1 =  0.05252642023177283\n",
      "true gam2 =  18496.995957194133\n",
      "gam2 =  19343.456534066878\n",
      "corr(z1_hat, X*beta_true) =  0.9997455156086237\n",
      "l2 error for z1_hat =  0.02963588258076842\n",
      "v1 =  0.9868663048664331\n",
      "true tau2 =  2214.6479974166427\n",
      "tau2 = 2063.2358053863204\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955727]]\n",
      "l2 error for x2_hat =  0.03001891061964106\n",
      "alpha2 =  0.9474730417874191\n",
      "true gam1 =  1484.876630062876\n",
      "gam1 =  1072.381891874211\n",
      "corr(z2_hat, beta_true) =  [[0.99974525]]\n",
      "l2 error for z2_hat =  0.029659857550546353\n",
      "true tau1 =  173997.85106896653\n",
      "tau1 =  155055.00409239993\n",
      "\n",
      "\n",
      "**** iteration =  144  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.76437208e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995571589127465\n",
      "l2 error for x1_hat =  0.03002328115910611\n",
      "B / (A+B) =  [0.00164646]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990683651293447\n",
      "alpha1 part I =  [0.00164492]\n",
      "alpha2 part II =  [8.61877754e-05]\n",
      "alpha1 =  0.05251913668179661\n",
      "true gam2 =  18492.049495596708\n",
      "gam2 =  19346.497008812363\n",
      "corr(z1_hat, X*beta_true) =  0.9997452450863646\n",
      "l2 error for z1_hat =  0.02966017475673184\n",
      "v1 =  0.9868680505732845\n",
      "true tau2 =  2214.672101148228\n",
      "tau2 = 2063.269219140002\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955715]]\n",
      "l2 error for x2_hat =  0.03002348730012822\n",
      "alpha2 =  0.9474794357970053\n",
      "true gam1 =  1484.9333448875507\n",
      "gam1 =  1072.4126560062546\n",
      "corr(z2_hat, beta_true) =  [[0.99974498]]\n",
      "l2 error for z2_hat =  0.029684295597690903\n",
      "true tau1 =  173941.25352512664\n",
      "tau1 =  155076.6435331572\n",
      "\n",
      "\n",
      "**** iteration =  145  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.7834535e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995570447582447\n",
      "l2 error for x1_hat =  0.03002770772087217\n",
      "B / (A+B) =  [0.00164655]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990683918301089\n",
      "alpha1 part I =  [0.00164501]\n",
      "alpha2 part II =  [8.64218416e-05]\n",
      "alpha1 =  0.052512501472694983\n",
      "true gam2 =  18487.280071826597\n",
      "gam2 =  19349.632112968975\n",
      "corr(z1_hat, X*beta_true) =  0.9997449726040695\n",
      "l2 error for z1_hat =  0.02968459370705385\n",
      "v1 =  0.9868699111700644\n",
      "true tau2 =  2214.694266111788\n",
      "tau2 = 2063.2609039872996\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955704]]\n",
      "l2 error for x2_hat =  0.030027916061943584\n",
      "alpha2 =  0.9474869667872606\n",
      "true gam1 =  1484.9935752231856\n",
      "gam1 =  1072.4241170810478\n",
      "corr(z2_hat, beta_true) =  [[0.99974472]]\n",
      "l2 error for z2_hat =  0.029707200661998667\n",
      "true tau1 =  173886.38595786676\n",
      "tau1 =  155098.55419274673\n",
      "\n",
      "\n",
      "**** iteration =  146  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.80139127e-06]\n",
      "corr(x1_hat, beta_true) =  0.999556932962871\n",
      "l2 error for x1_hat =  0.030032028163180766\n",
      "B / (A+B) =  [0.00164664]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684017769982\n",
      "alpha1 part I =  [0.00164511]\n",
      "alpha2 part II =  [8.66372334e-05]\n",
      "alpha1 =  0.05250568583079836\n",
      "true gam2 =  18482.628879424148\n",
      "gam2 =  19352.489872938564\n",
      "corr(z1_hat, X*beta_true) =  0.9997447171661044\n",
      "l2 error for z1_hat =  0.02970749906464465\n",
      "v1 =  0.9868715525748515\n",
      "true tau2 =  2214.7168783614075\n",
      "tau2 = 2063.291022143009\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955693]]\n",
      "l2 error for x2_hat =  0.03003222280341405\n",
      "alpha2 =  0.9474930011672603\n",
      "true gam1 =  1485.0469775896765\n",
      "gam1 =  1072.4524211969488\n",
      "corr(z2_hat, beta_true) =  [[0.99974446]]\n",
      "l2 error for z2_hat =  0.029730189842178158\n",
      "true tau1 =  173833.16802026666\n",
      "tau1 =  155118.88034633253\n",
      "\n",
      "\n",
      "**** iteration =  147  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.8193377e-06]\n",
      "corr(x1_hat, beta_true) =  0.999556825502446\n",
      "l2 error for x1_hat =  0.030036195027976574\n",
      "B / (A+B) =  [0.00164673]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684263407921\n",
      "alpha1 part I =  [0.0016452]\n",
      "alpha2 part II =  [8.68578739e-05]\n",
      "alpha1 =  0.05249945344637379\n",
      "true gam2 =  18478.142151881955\n",
      "gam2 =  19355.42540980597\n",
      "corr(z1_hat, X*beta_true) =  0.9997444605028255\n",
      "l2 error for z1_hat =  0.029730470848227154\n",
      "v1 =  0.9868732920151599\n",
      "true tau2 =  2214.737741541324\n",
      "tau2 = 2063.2843767448653\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955682]]\n",
      "l2 error for x2_hat =  0.03003639120553908\n",
      "alpha2 =  0.9475000238086209\n",
      "true gam1 =  1485.103370414187\n",
      "gam1 =  1072.463691456408\n",
      "corr(z2_hat, beta_true) =  [[0.99974422]]\n",
      "l2 error for z2_hat =  0.02975178447384851\n",
      "true tau1 =  173781.57266148872\n",
      "tau1 =  155139.40609484975\n",
      "\n",
      "\n",
      "**** iteration =  148  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.83624331e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995567203348475\n",
      "l2 error for x1_hat =  0.03004026012183534\n",
      "B / (A+B) =  [0.00164682]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684361213529\n",
      "alpha1 part I =  [0.00164529]\n",
      "alpha2 part II =  [8.7061612e-05]\n",
      "alpha1 =  0.052493073829862784\n",
      "true gam2 =  18473.768476492347\n",
      "gam2 =  19358.11149132693\n",
      "corr(z1_hat, X*beta_true) =  0.9997442193656942\n",
      "l2 error for z1_hat =  0.02975206518642215\n",
      "v1 =  0.986874835350529\n",
      "true tau2 =  2214.758957989233\n",
      "tau2 = 2063.3115524653103\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955672]]\n",
      "l2 error for x2_hat =  0.030040443857847526\n",
      "alpha2 =  0.9475057173188717\n",
      "true gam1 =  1485.1536494150005\n",
      "gam1 =  1072.4897572903276\n",
      "corr(z2_hat, beta_true) =  [[0.99974398]]\n",
      "l2 error for z2_hat =  0.029773410628314248\n",
      "true tau1 =  173731.53118176747\n",
      "tau1 =  155158.499820686\n",
      "\n",
      "\n",
      "**** iteration =  149  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.85312253e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995566191809361\n",
      "l2 error for x1_hat =  0.0300441823418825\n",
      "B / (A+B) =  [0.0016469]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684587410278\n",
      "alpha1 part I =  [0.00164537]\n",
      "alpha2 part II =  [8.7269572e-05]\n",
      "alpha1 =  0.05248721941723522\n",
      "true gam2 =  18469.547726384822\n",
      "gam2 =  19360.860860215507\n",
      "corr(z1_hat, X*beta_true) =  0.9997439776222459\n",
      "l2 error for z1_hat =  0.029773675476188356\n",
      "v1 =  0.9868764620723303\n",
      "true tau2 =  2214.778594850833\n",
      "tau2 = 2063.306336156056\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955661]]\n",
      "l2 error for x2_hat =  0.030044367056231806\n",
      "alpha2 =  0.9475122690404865\n",
      "true gam1 =  1485.2064630845468\n",
      "gam1 =  1072.5007888337386\n",
      "corr(z2_hat, beta_true) =  [[0.99974375]]\n",
      "l2 error for z2_hat =  0.029793766795863014\n",
      "true tau1 =  173683.01213544756\n",
      "tau1 =  155177.73254568013\n",
      "\n",
      "\n",
      "**** iteration =  150  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.86905337e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995565202479229\n",
      "l2 error for x1_hat =  0.030048007140337445\n",
      "B / (A+B) =  [0.00164699]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684683137621\n",
      "alpha1 part I =  [0.00164545]\n",
      "alpha2 part II =  [8.74622186e-05]\n",
      "alpha1 =  0.05248124630981623\n",
      "true gam2 =  18465.434902192217\n",
      "gam2 =  19363.38563242938\n",
      "corr(z1_hat, X*beta_true) =  0.9997437500362352\n",
      "l2 error for z1_hat =  0.029794030866015883\n",
      "v1 =  0.9868779132013019\n",
      "true tau2 =  2214.798504651419\n",
      "tau2 = 2063.3308826258217\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955652]]\n",
      "l2 error for x2_hat =  0.030048180543363903\n",
      "alpha2 =  0.9475176396672719\n",
      "true gam1 =  1485.253797638863\n",
      "gam1 =  1072.5248158752893\n",
      "corr(z2_hat, beta_true) =  [[0.99974353]]\n",
      "l2 error for z2_hat =  0.02981411068330863\n",
      "true tau1 =  173635.9563650564\n",
      "tau1 =  155195.66963066655\n",
      "\n",
      "\n",
      "**** iteration =  151  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.88492905e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995564250347996\n",
      "l2 error for x1_hat =  0.03005169891737378\n",
      "B / (A+B) =  [0.00164707]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684891627916\n",
      "alpha1 part I =  [0.00164553]\n",
      "alpha2 part II =  [8.76582045e-05]\n",
      "alpha1 =  0.05247574658733058\n",
      "true gam2 =  18461.464394251605\n",
      "gam2 =  19365.961258646483\n",
      "corr(z1_hat, X*beta_true) =  0.9997435223623935\n",
      "l2 error for z1_hat =  0.02981436027034195\n",
      "v1 =  0.9868794349966917\n",
      "true tau2 =  2214.8169864145275\n",
      "tau2 = 2063.3268861539727\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955642]]\n",
      "l2 error for x2_hat =  0.030051872829455394\n",
      "alpha2 =  0.9475237548141712\n",
      "true gam1 =  1485.3032716122993\n",
      "gam1 =  1072.5355708546886\n",
      "corr(z2_hat, beta_true) =  [[0.99974331]]\n",
      "l2 error for z2_hat =  0.029833296771242655\n",
      "true tau1 =  173590.3295434967\n",
      "tau1 =  155213.69465738986\n",
      "\n",
      "\n",
      "**** iteration =  152  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.89993956e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995563319666293\n",
      "l2 error for x1_hat =  0.030055297587391897\n",
      "B / (A+B) =  [0.00164715]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990684984949275\n",
      "alpha1 part I =  [0.00164561]\n",
      "alpha2 part II =  [8.78403036e-05]\n",
      "alpha1 =  0.05247015264414714\n",
      "true gam2 =  18457.596772376917\n",
      "gam2 =  19368.334462983992\n",
      "corr(z1_hat, X*beta_true) =  0.9997433076109731\n",
      "l2 error for z1_hat =  0.029833545184686186\n",
      "v1 =  0.9868807994338105\n",
      "true tau2 =  2214.8356726846823\n",
      "tau2 = 2063.3490812647747\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955633]]\n",
      "l2 error for x2_hat =  0.030055461203657492\n",
      "alpha2 =  0.9475288197707021\n",
      "true gam1 =  1485.347830921872\n",
      "gam1 =  1072.5577387656551\n",
      "corr(z2_hat, beta_true) =  [[0.9997431]]\n",
      "l2 error for z2_hat =  0.029852434368648675\n",
      "true tau1 =  173546.08034930835\n",
      "tau1 =  155230.54613877684\n",
      "\n",
      "\n",
      "**** iteration =  153  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.91487154e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995562423492503\n",
      "l2 error for x1_hat =  0.030058772318026863\n",
      "B / (A+B) =  [0.00164722]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068517729517\n",
      "alpha1 part I =  [0.00164569]\n",
      "alpha2 part II =  [8.80249849e-05]\n",
      "alpha1 =  0.05246498579887703\n",
      "true gam2 =  18453.861697783188\n",
      "gam2 =  19370.74787609286\n",
      "corr(z1_hat, X*beta_true) =  0.9997430932030539\n",
      "l2 error for z1_hat =  0.029852669546222996\n",
      "v1 =  0.9868822235042174\n",
      "true tau2 =  2214.8530665448443\n",
      "tau2 = 2063.346122839594\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955624]]\n",
      "l2 error for x2_hat =  0.030058936051561944\n",
      "alpha2 =  0.9475345298900462\n",
      "true gam1 =  1485.394187296751\n",
      "gam1 =  1072.5681879039646\n",
      "corr(z2_hat, beta_true) =  [[0.99974289]]\n",
      "l2 error for z2_hat =  0.029870515308667592\n",
      "true tau1 =  173503.17275319927\n",
      "tau1 =  155247.4427457525\n",
      "\n",
      "\n",
      "**** iteration =  154  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.92901334e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995561547982018\n",
      "l2 error for x1_hat =  0.030062158193041186\n",
      "B / (A+B) =  [0.0016473]\n",
      "gam1 / (gam1 + 1/sigma) =  0.99906852679572\n",
      "alpha1 part I =  [0.00164576]\n",
      "alpha2 part II =  [8.81970607e-05]\n",
      "alpha1 =  0.0524597456693635\n",
      "true gam2 =  18450.224581748706\n",
      "gam2 =  19372.978663657395\n",
      "corr(z1_hat, X*beta_true) =  0.9997428906021837\n",
      "l2 error for z1_hat =  0.02987074899282298\n",
      "v1 =  0.9868835064356574\n",
      "true tau2 =  2214.87060681103\n",
      "tau2 = 2063.366213313118\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955615]]\n",
      "l2 error for x2_hat =  0.03006231254420263\n",
      "alpha2 =  0.9475393056231178\n",
      "true gam1 =  1485.4361312956598\n",
      "gam1 =  1072.5886586579547\n",
      "corr(z2_hat, beta_true) =  [[0.99974269]]\n",
      "l2 error for z2_hat =  0.029888518094342762\n",
      "true tau1 =  173461.56188682394\n",
      "tau1 =  155263.27521386408\n",
      "\n",
      "\n",
      "**** iteration =  155  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.94305787e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995560704511004\n",
      "l2 error for x1_hat =  0.030065428512051722\n",
      "B / (A+B) =  [0.00164737]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068544556674\n",
      "alpha1 part I =  [0.00164583]\n",
      "alpha2 part II =  [8.83710719e-05]\n",
      "alpha1 =  0.05245489126147844\n",
      "true gam2 =  18446.711004228506\n",
      "gam2 =  19375.24056876887\n",
      "corr(z1_hat, X*beta_true) =  0.9997426887007109\n",
      "l2 error for z1_hat =  0.0298887396697483\n",
      "v1 =  0.9868848394418044\n",
      "true tau2 =  2214.886976152246\n",
      "tau2 = 2063.3641351435713\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955607]]\n",
      "l2 error for x2_hat =  0.030065582655553032\n",
      "alpha2 =  0.9475446397209901\n",
      "true gam1 =  1485.4795762052545\n",
      "gam1 =  1072.5987799651582\n",
      "corr(z2_hat, beta_true) =  [[0.9997425]]\n",
      "l2 error for z2_hat =  0.029905555498456665\n",
      "true tau1 =  173421.21092981426\n",
      "tau1 =  155279.11710365032\n",
      "\n",
      "\n",
      "**** iteration =  156  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.95637987e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995559880901371\n",
      "l2 error for x1_hat =  0.03006861414124146\n",
      "B / (A+B) =  [0.00164744]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990685533379309\n",
      "alpha1 part I =  [0.0016459]\n",
      "alpha2 part II =  [8.85336292e-05]\n",
      "alpha1 =  0.052449981428249526\n",
      "true gam2 =  18443.2905899205\n",
      "gam2 =  19377.337535693045\n",
      "corr(z1_hat, X*beta_true) =  0.9997424975980495\n",
      "l2 error for z1_hat =  0.029905775325891396\n",
      "v1 =  0.9868860457444427\n",
      "true tau2 =  2214.9034427602614\n",
      "tau2 = 2063.382340161191\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955598]]\n",
      "l2 error for x2_hat =  0.030068759724924808\n",
      "alpha2 =  0.9475491419225829\n",
      "true gam1 =  1485.5190560011235\n",
      "gam1 =  1072.6176997434106\n",
      "corr(z2_hat, beta_true) =  [[0.99974231]]\n",
      "l2 error for z2_hat =  0.029922490718310157\n",
      "true tau1 =  173382.08034655507\n",
      "tau1 =  155293.99298556964\n",
      "\n",
      "\n",
      "**** iteration =  157  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.96958981e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995559087063716\n",
      "l2 error for x1_hat =  0.030071691962818944\n",
      "B / (A+B) =  [0.0016475]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990685697523066\n",
      "alpha1 part I =  [0.00164597]\n",
      "alpha2 part II =  [8.86975711e-05]\n",
      "alpha1 =  0.05244542030181298\n",
      "true gam2 =  18439.98539490311\n",
      "gam2 =  19379.45787846168\n",
      "corr(z1_hat, X*beta_true) =  0.9997423074855147\n",
      "l2 error for z1_hat =  0.029922699456598655\n",
      "v1 =  0.9868872938516162\n",
      "true tau2 =  2214.918847358276\n",
      "tau2 = 2063.3810054252444\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955591]]\n",
      "l2 error for x2_hat =  0.030071837071504164\n",
      "alpha2 =  0.9475541266946069\n",
      "true gam1 =  1485.559780885985\n",
      "gam1 =  1072.6274774048616\n",
      "corr(z2_hat, beta_true) =  [[0.99974213]]\n",
      "l2 error for z2_hat =  0.029938543012595704\n",
      "true tau1 =  173344.13322182136\n",
      "tau1 =  155308.84871493027\n",
      "\n",
      "\n",
      "**** iteration =  158  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.98213835e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995558312278935\n",
      "l2 error for x1_hat =  0.030074689157392115\n",
      "B / (A+B) =  [0.00164757]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990685782349599\n",
      "alpha1 part I =  [0.00164604]\n",
      "alpha2 part II =  [8.8851095e-05]\n",
      "alpha1 =  0.05244081893401329\n",
      "true gam2 =  18436.768714622038\n",
      "gam2 =  19381.429099296533\n",
      "corr(z1_hat, X*beta_true) =  0.9997421272595466\n",
      "l2 error for z1_hat =  0.02993874980425914\n",
      "v1 =  0.9868884281111018\n",
      "true tau2 =  2214.9343078496354\n",
      "tau2 = 2063.397519824378\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955583]]\n",
      "l2 error for x2_hat =  0.030074826447807873\n",
      "alpha2 =  0.9475583703173879\n",
      "true gam1 =  1485.5969391904134\n",
      "gam1 =  1072.6449782768177\n",
      "corr(z2_hat, beta_true) =  [[0.99974195]]\n",
      "l2 error for z2_hat =  0.029954473930650337\n",
      "true tau1 =  173307.33444492167\n",
      "tau1 =  155322.82654014457\n",
      "\n",
      "\n",
      "**** iteration =  159  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [3.9945634e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995557565180399\n",
      "l2 error for x1_hat =  0.030077585714443335\n",
      "B / (A+B) =  [0.00164763]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990685934175327\n",
      "alpha1 part I =  [0.0016461]\n",
      "alpha2 part II =  [8.90055361e-05]\n",
      "alpha1 =  0.05243653313374501\n",
      "true gam2 =  18433.659561244072\n",
      "gam2 =  19383.417125236425\n",
      "corr(z1_hat, X*beta_true) =  0.999741948258262\n",
      "l2 error for z1_hat =  0.029954670556469245\n",
      "v1 =  0.9868895970302003\n",
      "true tau2 =  2214.9488040660226\n",
      "tau2 = 2063.3968100154984\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955575]]\n",
      "l2 error for x2_hat =  0.030077722312049103\n",
      "alpha2 =  0.9475630303560684\n",
      "true gam1 =  1485.6351219564456\n",
      "gam1 =  1072.65440169162\n",
      "corr(z2_hat, beta_true) =  [[0.99974178]]\n",
      "l2 error for z2_hat =  0.02996959648859128\n",
      "true tau1 =  173271.64753070002\n",
      "tau1 =  155336.75991351777\n",
      "\n",
      "\n",
      "**** iteration =  160  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.00638231e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995556836327137\n",
      "l2 error for x1_hat =  0.030080405591089435\n",
      "B / (A+B) =  [0.0016477]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068601592445\n",
      "alpha1 part I =  [0.00164616]\n",
      "alpha2 part II =  [8.91504921e-05]\n",
      "alpha1 =  0.05243221995345437\n",
      "true gam2 =  18430.6344315562\n",
      "gam2 =  19385.27018444734\n",
      "corr(z1_hat, X*beta_true) =  0.9997417783173658\n",
      "l2 error for z1_hat =  0.02996979101686054\n",
      "v1 =  0.9868906635580552\n",
      "true tau2 =  2214.9633215234808\n",
      "tau2 = 2063.411807105534\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955568]]\n",
      "l2 error for x2_hat =  0.03008053503970596\n",
      "alpha2 =  0.9475670296319204\n",
      "true gam1 =  1485.6700935034132\n",
      "gam1 =  1072.6706031056951\n",
      "corr(z2_hat, beta_true) =  [[0.99974161]]\n",
      "l2 error for z2_hat =  0.029984582622660294\n",
      "true tau1 =  173237.04105789604\n",
      "tau1 =  155349.89456256054\n",
      "\n",
      "\n",
      "**** iteration =  161  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.01806919e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995556133239106\n",
      "l2 error for x1_hat =  0.030083131472614814\n",
      "B / (A+B) =  [0.00164776]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686156470081\n",
      "alpha1 part I =  [0.00164622]\n",
      "alpha2 part II =  [8.92959706e-05]\n",
      "alpha1 =  0.052428192647071874\n",
      "true gam2 =  18427.709707406488\n",
      "gam2 =  19387.134493105343\n",
      "corr(z1_hat, X*beta_true) =  0.9997416097874028\n",
      "l2 error for z1_hat =  0.02998476782205823\n",
      "v1 =  0.9868917585828488\n",
      "true tau2 =  2214.976962491089\n",
      "tau2 = 2063.4116197091253\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955561]]\n",
      "l2 error for x2_hat =  0.030083260053118153\n",
      "alpha2 =  0.9475713876132513\n",
      "true gam1 =  1485.705899578533\n",
      "gam1 =  1072.6796660555592\n",
      "corr(z2_hat, beta_true) =  [[0.99974145]]\n",
      "l2 error for z2_hat =  0.02999882789720007\n",
      "true tau1 =  173203.47935976554\n",
      "tau1 =  155362.96499220762\n",
      "\n",
      "\n",
      "**** iteration =  162  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.02919998e-06]\n",
      "corr(x1_hat, beta_true) =  0.999555544759574\n",
      "l2 error for x1_hat =  0.030085784494350253\n",
      "B / (A+B) =  [0.00164782]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686235088406\n",
      "alpha1 part I =  [0.00164628]\n",
      "alpha2 part II =  [8.94328045e-05]\n",
      "alpha1 =  0.052424148807468554\n",
      "true gam2 =  18424.864680465416\n",
      "gam2 =  19388.87651476203\n",
      "corr(z1_hat, X*beta_true) =  0.999741449568872\n",
      "l2 error for z1_hat =  0.029999010888747284\n",
      "v1 =  0.9868927614326332\n",
      "true tau2 =  2214.990595856872\n",
      "tau2 = 2063.4252537532006\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955554]]\n",
      "l2 error for x2_hat =  0.030085906530610256\n",
      "alpha2 =  0.9475751560741178\n",
      "true gam1 =  1485.7388115289154\n",
      "gam1 =  1072.6946761625486\n",
      "corr(z2_hat, beta_true) =  [[0.99974129]]\n",
      "l2 error for z2_hat =  0.030012925240601496\n",
      "true tau1 =  173170.9341086869\n",
      "tau1 =  155375.3079293501\n",
      "\n",
      "\n",
      "**** iteration =  163  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.04019261e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995554785946136\n",
      "l2 error for x1_hat =  0.0300883496809515\n",
      "B / (A+B) =  [0.00164787]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686365293585\n",
      "alpha1 part I =  [0.00164634]\n",
      "alpha2 part II =  [8.95698294e-05]\n",
      "alpha1 =  0.0524203642132659\n",
      "true gam2 =  18422.11345893551\n",
      "gam2 =  19390.625109225057\n",
      "corr(z1_hat, X*beta_true) =  0.9997412909060962\n",
      "l2 error for z1_hat =  0.030013099662796815\n",
      "v1 =  0.986893787473617\n",
      "true tau2 =  2215.0034316563438\n",
      "tau2 = 2063.425500212406\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955548]]\n",
      "l2 error for x2_hat =  0.03008847071020219\n",
      "alpha2 =  0.9475792329256777\n",
      "true gam1 =  1485.7723948270575\n",
      "gam1 =  1072.703376094269\n",
      "corr(z2_hat, beta_true) =  [[0.99974114]]\n",
      "l2 error for z2_hat =  0.030026342894180602\n",
      "true tau1 =  173139.37073646122\n",
      "tau1 =  155387.57076520854\n",
      "\n",
      "\n",
      "**** iteration =  164  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.05067453e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995554140952448\n",
      "l2 error for x1_hat =  0.03009084569552113\n",
      "B / (A+B) =  [0.00164793]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068644075948\n",
      "alpha1 part I =  [0.00164639]\n",
      "alpha2 part II =  [8.96989677e-05]\n",
      "alpha1 =  0.0524165721874353\n",
      "true gam2 =  18419.437777013827\n",
      "gam2 =  19392.262784958995\n",
      "corr(z1_hat, X*beta_true) =  0.9997411398751291\n",
      "l2 error for z1_hat =  0.030026515032671775\n",
      "v1 =  0.9868947304561921\n",
      "true tau2 =  2215.016236024653\n",
      "tau2 = 2063.4379086148856\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955541]]\n",
      "l2 error for x2_hat =  0.030090960727591026\n",
      "alpha2 =  0.947582783426113\n",
      "true gam1 =  1485.8033671595056\n",
      "gam1 =  1072.7172929226022\n",
      "corr(z2_hat, beta_true) =  [[0.99974099]]\n",
      "l2 error for z2_hat =  0.03003960412433816\n",
      "true tau1 =  173108.76352598585\n",
      "tau1 =  155399.170256111\n",
      "\n",
      "\n",
      "**** iteration =  165  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.06101421e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995553518317083\n",
      "l2 error for x1_hat =  0.030093259593138865\n",
      "B / (A+B) =  [0.00164798]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686561475804\n",
      "alpha1 part I =  [0.00164645]\n",
      "alpha2 part II =  [8.98280205e-05]\n",
      "alpha1 =  0.0524130155066659\n",
      "true gam2 =  18416.849777080253\n",
      "gam2 =  19393.903117158054\n",
      "corr(z1_hat, X*beta_true) =  0.9997409905093156\n",
      "l2 error for z1_hat =  0.03003976838344469\n",
      "v1 =  0.9868956920713731\n",
      "true tau2 =  2215.0283138524064\n",
      "tau2 = 2063.438512549438\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955535]]\n",
      "l2 error for x2_hat =  0.03009337351040733\n",
      "alpha2 =  0.9475865984787043\n",
      "true gam1 =  1485.8348709615163\n",
      "gam1 =  1072.7256303293507\n",
      "corr(z2_hat, beta_true) =  [[0.99974085]]\n",
      "l2 error for z2_hat =  0.03005224115635487\n",
      "true tau1 =  173079.07920267063\n",
      "tau1 =  155410.67708829037\n",
      "\n",
      "\n",
      "**** iteration =  166  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.07088436e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995552911564652\n",
      "l2 error for x1_hat =  0.03009560786912301\n",
      "B / (A+B) =  [0.00164803]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686633794024\n",
      "alpha1 part I =  [0.0016465]\n",
      "alpha2 part II =  [8.99498708e-05]\n",
      "alpha1 =  0.05240945898604086\n",
      "true gam2 =  18414.33333008178\n",
      "gam2 =  19395.442732466927\n",
      "corr(z1_hat, X*beta_true) =  0.9997408481579874\n",
      "l2 error for z1_hat =  0.03005240308498995\n",
      "v1 =  0.9868965787693103\n",
      "true tau2 =  2215.040340739324\n",
      "tau2 = 2063.4498177854052\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955529]]\n",
      "l2 error for x2_hat =  0.03009571628466291\n",
      "alpha2 =  0.9475899432196003\n",
      "true gam1 =  1485.8640168476663\n",
      "gam1 =  1072.7385428298155\n",
      "corr(z2_hat, beta_true) =  [[0.99974071]]\n",
      "l2 error for z2_hat =  0.030064715831036957\n",
      "true tau1 =  173050.29426787616\n",
      "tau1 =  155421.57840352308\n",
      "\n",
      "\n",
      "**** iteration =  167  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.08060992e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995552325658996\n",
      "l2 error for x1_hat =  0.030097879341055966\n",
      "B / (A+B) =  [0.00164808]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686745794144\n",
      "alpha1 part I =  [0.00164655]\n",
      "alpha2 part II =  [9.00714065e-05]\n",
      "alpha1 =  0.05240611633983584\n",
      "true gam2 =  18411.898878401753\n",
      "gam2 =  19396.981744654775\n",
      "corr(z1_hat, X*beta_true) =  0.9997407075510234\n",
      "l2 error for z1_hat =  0.030064870507741873\n",
      "v1 =  0.9868974801922279\n",
      "true tau2 =  2215.051705067438\n",
      "tau2 = 2063.450713432477\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955523]]\n",
      "l2 error for x2_hat =  0.030097986560500733\n",
      "alpha2 =  0.9475935143441493\n",
      "true gam1 =  1485.8935746070601\n",
      "gam1 =  1072.7465207184434\n",
      "corr(z2_hat, beta_true) =  [[0.99974058]]\n",
      "l2 error for z2_hat =  0.030076616702269212\n",
      "true tau1 =  173022.376868805\n",
      "tau1 =  155432.37733983534\n",
      "\n",
      "\n",
      "**** iteration =  168  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.08990337e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995551754882125\n",
      "l2 error for x1_hat =  0.030100088601838017\n",
      "B / (A+B) =  [0.00164813]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686814991205\n",
      "alpha1 part I =  [0.0016466]\n",
      "alpha2 part II =  [9.01863579e-05]\n",
      "alpha1 =  0.05240278014132994\n",
      "true gam2 =  18409.532164125394\n",
      "gam2 =  19398.429203646818\n",
      "corr(z1_hat, X*beta_true) =  0.9997405733972456\n",
      "l2 error for z1_hat =  0.030076769026172855\n",
      "v1 =  0.9868983139733956\n",
      "true tau2 =  2215.0630026595154\n",
      "tau2 = 2063.461024749635\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955517]]\n",
      "l2 error for x2_hat =  0.030100190768783588\n",
      "alpha2 =  0.9475966648972585\n",
      "true gam1 =  1485.9210007719562\n",
      "gam1 =  1072.7585096932867\n",
      "corr(z2_hat, beta_true) =  [[0.99974044]]\n",
      "l2 error for z2_hat =  0.030088351444218456\n",
      "true tau1 =  172995.30540691875\n",
      "tau1 =  155442.62294521378\n",
      "\n",
      "\n",
      "**** iteration =  169  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.09905133e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995551203553558\n",
      "l2 error for x1_hat =  0.030102225999103147\n",
      "B / (A+B) =  [0.00164818]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686918976915\n",
      "alpha1 part I =  [0.00164664]\n",
      "alpha2 part II =  [9.03008065e-05]\n",
      "alpha1 =  0.0523996385118301\n",
      "true gam2 =  18407.24215932933\n",
      "gam2 =  19399.87336640436\n",
      "corr(z1_hat, X*beta_true) =  0.9997404410414199\n",
      "l2 error for z1_hat =  0.030088497087408718\n",
      "v1 =  0.9868991591386558\n",
      "true tau2 =  2215.0736953875903\n",
      "tau2 = 2063.4621555990893\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955512]]\n",
      "l2 error for x2_hat =  0.030102326911162023\n",
      "alpha2 =  0.9476000086285432\n",
      "true gam1 =  1485.9487368525397\n",
      "gam1 =  1072.766133126355\n",
      "corr(z2_hat, beta_true) =  [[0.99974032]]\n",
      "l2 error for z2_hat =  0.03009955819783987\n",
      "true tau1 =  172969.04952730695\n",
      "tau1 =  155452.75886600162\n",
      "\n",
      "\n",
      "**** iteration =  170  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.10780122e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995550666620774\n",
      "l2 error for x1_hat =  0.030104304454840792\n",
      "B / (A+B) =  [0.00164823]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990686985097132\n",
      "alpha1 part I =  [0.00164669]\n",
      "alpha2 part II =  [9.04092299e-05]\n",
      "alpha1 =  0.0523965084928243\n",
      "true gam2 =  18405.01624627368\n",
      "gam2 =  19401.234215069944\n",
      "corr(z1_hat, X*beta_true) =  0.9997403146279\n",
      "l2 error for z1_hat =  0.030099701486311244\n",
      "v1 =  0.9868999431690213\n",
      "true tau2 =  2215.084308771725\n",
      "tau2 = 2063.47157051997\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955506]]\n",
      "l2 error for x2_hat =  0.030104400722190016\n",
      "alpha2 =  0.9476029759614565\n",
      "true gam1 =  1485.9745439199423\n",
      "gam1 =  1072.7772720563737\n",
      "corr(z2_hat, beta_true) =  [[0.99974019]]\n",
      "l2 error for z2_hat =  0.030110596868473217\n",
      "true tau1 =  172943.58927245336\n",
      "tau1 =  155462.3886006279\n",
      "\n",
      "\n",
      "**** iteration =  171  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.1164059e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995550147841152\n",
      "l2 error for x1_hat =  0.030106315644956232\n",
      "B / (A+B) =  [0.00164827]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687081706573\n",
      "alpha1 part I =  [0.00164674]\n",
      "alpha2 part II =  [9.05169978e-05]\n",
      "alpha1 =  0.05239355566820475\n",
      "true gam2 =  18402.86212532045\n",
      "gam2 =  19402.589562178036\n",
      "corr(z1_hat, X*beta_true) =  0.9997401900442665\n",
      "l2 error for z1_hat =  0.03011073399680788\n",
      "v1 =  0.9869007357355909\n",
      "true tau2 =  2215.09436937094\n",
      "tau2 = 2063.472888119811\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955501]]\n",
      "l2 error for x2_hat =  0.030106410617664312\n",
      "alpha2 =  0.9476061076100933\n",
      "true gam1 =  1486.0005742716107\n",
      "gam1 =  1072.7845477591286\n",
      "corr(z2_hat, beta_true) =  [[0.99974007]]\n",
      "l2 error for z2_hat =  0.030121149247405034\n",
      "true tau1 =  172918.8958213728\n",
      "tau1 =  155471.9033930534\n",
      "\n",
      "\n",
      "**** iteration =  172  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.12464355e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995549642747242\n",
      "l2 error for x1_hat =  0.03010827102265866\n",
      "B / (A+B) =  [0.00164832]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687144808641\n",
      "alpha1 part I =  [0.00164678]\n",
      "alpha2 part II =  [9.06192464e-05]\n",
      "alpha1 =  0.05239061864871837\n",
      "true gam2 =  18400.76861787326\n",
      "gam2 =  19403.86901024141\n",
      "corr(z1_hat, X*beta_true) =  0.9997400709374754\n",
      "l2 error for z1_hat =  0.0301212840360354\n",
      "v1 =  0.9869014729912879\n",
      "true tau2 =  2215.1043407466614\n",
      "tau2 = 2063.4814937678775\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955496]]\n",
      "l2 error for x2_hat =  0.030108361721255996\n",
      "alpha2 =  0.9476089021113339\n",
      "true gam1 =  1486.0248570936892\n",
      "gam1 =  1072.7949035402526\n",
      "corr(z2_hat, beta_true) =  [[0.99973996]]\n",
      "l2 error for z2_hat =  0.030131533110234393\n",
      "true tau1 =  172894.9506463416\n",
      "tau1 =  155480.9546356589\n",
      "\n",
      "\n",
      "**** iteration =  173  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.13273725e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995549154605928\n",
      "l2 error for x1_hat =  0.030110163416895663\n",
      "B / (A+B) =  [0.00164836]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068723462271\n",
      "alpha1 part I =  [0.00164682]\n",
      "alpha2 part II =  [9.07207175e-05]\n",
      "alpha1 =  0.05238784317187978\n",
      "true gam2 =  18398.742324374354\n",
      "gam2 =  19405.141170684245\n",
      "corr(z1_hat, X*beta_true) =  0.9997399536742992\n",
      "l2 error for z1_hat =  0.030131662213660933\n",
      "v1 =  0.986902216363752\n",
      "true tau2 =  2215.113806396027\n",
      "tau2 = 2063.48295667882\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955491]]\n",
      "l2 error for x2_hat =  0.030110252797134123\n",
      "alpha2 =  0.9476118358652004\n",
      "true gam1 =  1486.049289872035\n",
      "gam1 =  1072.8018395639556\n",
      "corr(z2_hat, beta_true) =  [[0.99973984]]\n",
      "l2 error for z2_hat =  0.03014146867061635\n",
      "true tau1 =  172871.7264657462\n",
      "tau1 =  155489.88740913782\n",
      "\n",
      "\n",
      "**** iteration =  174  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.14049219e-06]\n",
      "corr(x1_hat, beta_true) =  0.999554867946443\n",
      "l2 error for x1_hat =  0.030112002988737722\n",
      "B / (A+B) =  [0.0016484]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068729477679\n",
      "alpha1 part I =  [0.00164686]\n",
      "alpha2 part II =  [9.08171277e-05]\n",
      "alpha1 =  0.052385086863182356\n",
      "true gam2 =  18396.773330203123\n",
      "gam2 =  19406.34411214295\n",
      "corr(z1_hat, X*beta_true) =  0.999739841463446\n",
      "l2 error for z1_hat =  0.03014159546328163\n",
      "v1 =  0.986902909642437\n",
      "true tau2 =  2215.123175271898\n",
      "tau2 = 2063.4908309497287\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955487]]\n",
      "l2 error for x2_hat =  0.03011208843205302\n",
      "alpha2 =  0.9476144673692708\n",
      "true gam1 =  1486.0721378443714\n",
      "gam1 =  1072.8114731638707\n",
      "corr(z2_hat, beta_true) =  [[0.99973973]]\n",
      "l2 error for z2_hat =  0.03015123654499821\n",
      "true tau1 =  172849.2060087497\n",
      "tau1 =  155498.3952336994\n",
      "\n",
      "\n",
      "**** iteration =  175  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.14810527e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995548220161646\n",
      "l2 error for x1_hat =  0.030113783567953408\n",
      "B / (A+B) =  [0.00164844]\n",
      "gam1 / (gam1 + 1/sigma) =  0.999068737832486\n",
      "alpha1 part I =  [0.0016469]\n",
      "alpha2 part II =  [9.09126643e-05]\n",
      "alpha1 =  0.0523824779838249\n",
      "true gam2 =  18394.867284558044\n",
      "gam2 =  19407.538339518575\n",
      "corr(z1_hat, X*beta_true) =  0.9997397310947241\n",
      "l2 error for z1_hat =  0.03015135808621162\n",
      "v1 =  0.9869036069904289\n",
      "true tau2 =  2215.1320809881336\n",
      "tau2 = 2063.492403830981\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955482]]\n",
      "l2 error for x2_hat =  0.03011386768263178\n",
      "alpha2 =  0.9476172163854858\n",
      "true gam1 =  1486.0950739798427\n",
      "gam1 =  1072.818078598346\n",
      "corr(z2_hat, beta_true) =  [[0.99973963]]\n",
      "l2 error for z2_hat =  0.030160590765665886\n",
      "true tau1 =  172827.36351551182\n",
      "tau1 =  155506.78251826984\n",
      "\n",
      "\n",
      "**** iteration =  176  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.15540542e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995547773197798\n",
      "l2 error for x1_hat =  0.03011551417792595\n",
      "B / (A+B) =  [0.00164848]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687435610087\n",
      "alpha1 part I =  [0.00164694]\n",
      "alpha2 part II =  [9.10035559e-05]\n",
      "alpha1 =  0.05237989092295205\n",
      "true gam2 =  18393.01538405771\n",
      "gam2 =  19408.669371927324\n",
      "corr(z1_hat, X*beta_true) =  0.9997396253907519\n",
      "l2 error for z1_hat =  0.030160710036401736\n",
      "v1 =  0.9869042589219761\n",
      "true tau2 =  2215.140884363217\n",
      "tau2 = 2063.4996164271693\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955478]]\n",
      "l2 error for x2_hat =  0.030115594662820374\n",
      "alpha2 =  0.9476196941976446\n",
      "true gam1 =  1486.116571341207\n",
      "gam1 =  1072.8270456421353\n",
      "corr(z2_hat, beta_true) =  [[0.99973952]]\n",
      "l2 error for z2_hat =  0.030169779171451097\n",
      "true tau1 =  172806.18283036217\n",
      "tau1 =  155514.77983946548\n",
      "\n",
      "\n",
      "**** iteration =  177  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.16256644e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995547341038351\n",
      "l2 error for x1_hat =  0.03011718951697802\n",
      "B / (A+B) =  [0.00164851]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687513375098\n",
      "alpha1 part I =  [0.00164698]\n",
      "alpha2 part II =  [9.10935004e-05]\n",
      "alpha1 =  0.0523774385528054\n",
      "true gam2 =  18391.22245536791\n",
      "gam2 =  19409.79057149358\n",
      "corr(z1_hat, X*beta_true) =  0.9997395215148068\n",
      "l2 error for z1_hat =  0.030169893587295445\n",
      "v1 =  0.9869049131979483\n",
      "true tau2 =  2215.1492631233646\n",
      "tau2 = 2063.5012692365626\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955473]]\n",
      "l2 error for x2_hat =  0.0301172686741546\n",
      "alpha2 =  0.9476222706860795\n",
      "true gam1 =  1486.1381050618706\n",
      "gam1 =  1072.8333303706843\n",
      "corr(z2_hat, beta_true) =  [[0.99973942]]\n",
      "l2 error for z2_hat =  0.03017858555930336\n",
      "true tau1 =  172785.6396804989\n",
      "tau1 =  155522.65576855192\n",
      "\n",
      "\n",
      "**** iteration =  178  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.16943813e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995546920582477\n",
      "l2 error for x1_hat =  0.030118817605993026\n",
      "B / (A+B) =  [0.00164855]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687567877459\n",
      "alpha1 part I =  [0.00164702]\n",
      "alpha2 part II =  [9.11791773e-05]\n",
      "alpha1 =  0.052375010042396884\n",
      "true gam2 =  18389.480673005673\n",
      "gam2 =  19410.854014075452\n",
      "corr(z1_hat, X*beta_true) =  0.999739421949407\n",
      "l2 error for z1_hat =  0.030178697754069866\n",
      "v1 =  0.9869055262545126\n",
      "true tau2 =  2215.157535655662\n",
      "tau2 = 2063.507882581859\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955469]]\n",
      "l2 error for x2_hat =  0.03011889341347161\n",
      "alpha2 =  0.9476246036067143\n",
      "true gam1 =  1486.1583311798306\n",
      "gam1 =  1072.8416816637825\n",
      "corr(z2_hat, beta_true) =  [[0.99973933]]\n",
      "l2 error for z2_hat =  0.03018722885293837\n",
      "true tau1 =  172765.71890842987\n",
      "tau1 =  155530.17347780525\n",
      "\n",
      "\n",
      "**** iteration =  179  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.17617394e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995546513969825\n",
      "l2 error for x1_hat =  0.03012039389685883\n",
      "B / (A+B) =  [0.00164859]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687640300471\n",
      "alpha1 part I =  [0.00164705]\n",
      "alpha2 part II =  [9.12638525e-05]\n",
      "alpha1 =  0.05237270471340984\n",
      "true gam2 =  18387.79415260347\n",
      "gam2 =  19411.906767638386\n",
      "corr(z1_hat, X*beta_true) =  0.9997393241875487\n",
      "l2 error for z1_hat =  0.030187336555750798\n",
      "v1 =  0.9869061402100101\n",
      "true tau2 =  2215.165418512901\n",
      "tau2 = 2063.5095898763266\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955465]]\n",
      "l2 error for x2_hat =  0.030120468386800273\n",
      "alpha2 =  0.9476270189058849\n",
      "true gam1 =  1486.1785504921672\n",
      "gam1 =  1072.8476561549182\n",
      "corr(z2_hat, beta_true) =  [[0.99973923]]\n",
      "l2 error for z2_hat =  0.030195519044176774\n",
      "true tau1 =  172746.39768161761\n",
      "tau1 =  155537.56995670623\n",
      "\n",
      "\n",
      "**** iteration =  180  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.18264202e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995546118451096\n",
      "l2 error for x1_hat =  0.030121925526367145\n",
      "B / (A+B) =  [0.00164862]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687692110995\n",
      "alpha1 part I =  [0.00164709]\n",
      "alpha2 part II =  [9.13446033e-05]\n",
      "alpha1 =  0.05237042476641154\n",
      "true gam2 =  18386.15593007054\n",
      "gam2 =  19412.906678283918\n",
      "corr(z1_hat, X*beta_true) =  0.9997392304121976\n",
      "l2 error for z1_hat =  0.03019562458251863\n",
      "v1 =  0.9869067167154917\n",
      "true tau2 =  2215.173192675298\n",
      "tau2 = 2063.5156599245965\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955461]]\n",
      "l2 error for x2_hat =  0.030121996922314053\n",
      "alpha2 =  0.9476292152543547\n",
      "true gam1 =  1486.19758013442\n",
      "gam1 =  1072.8554381502693\n",
      "corr(z2_hat, beta_true) =  [[0.99973914]]\n",
      "l2 error for z2_hat =  0.030203649546741637\n",
      "true tau1 =  172727.66174366898\n",
      "tau1 =  155544.6370493916\n",
      "\n",
      "\n",
      "**** iteration =  181  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.18897789e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995545735881711\n",
      "l2 error for x1_hat =  0.03012340860000607\n",
      "B / (A+B) =  [0.00164865]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687759595254\n",
      "alpha1 part I =  [0.00164712]\n",
      "alpha2 part II =  [9.14243141e-05]\n",
      "alpha1 =  0.05236825759166282\n",
      "true gam2 =  18384.569506597047\n",
      "gam2 =  19413.89526712947\n",
      "corr(z1_hat, X*beta_true) =  0.999739138407457\n",
      "l2 error for z1_hat =  0.030203750925639126\n",
      "v1 =  0.9869072929160632\n",
      "true tau2 =  2215.1806088692\n",
      "tau2 = 2063.517400249021\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955457]]\n",
      "l2 error for x2_hat =  0.03012347869619097\n",
      "alpha2 =  0.947631479900478\n",
      "true gam1 =  1486.216567266035\n",
      "gam1 =  1072.8611132815654\n",
      "corr(z2_hat, beta_true) =  [[0.99973905]]\n",
      "l2 error for z2_hat =  0.030211453403969746\n",
      "true tau1 =  172709.48964694722\n",
      "tau1 =  155551.5839108042\n",
      "\n",
      "\n",
      "**** iteration =  182  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.19506581e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995545363822299\n",
      "l2 error for x1_hat =  0.03012484947425576\n",
      "B / (A+B) =  [0.00164869]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687808808495\n",
      "alpha1 part I =  [0.00164715]\n",
      "alpha2 part II =  [9.15004127e-05]\n",
      "alpha1 =  0.05236611688044624\n",
      "true gam2 =  18383.028677604165\n",
      "gam2 =  19414.83545835743\n",
      "corr(z1_hat, X*beta_true) =  0.9997390500924821\n",
      "l2 error for z1_hat =  0.0302115526805791\n",
      "v1 =  0.9869078350550134\n",
      "true tau2 =  2215.187915094405\n",
      "tau2 = 2063.5229771994295\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955453]]\n",
      "l2 error for x2_hat =  0.030124916710148827\n",
      "alpha2 =  0.9476335475383465\n",
      "true gam1 =  1486.2344708582407\n",
      "gam1 =  1072.8683684974317\n",
      "corr(z2_hat, beta_true) =  [[0.99973896]]\n",
      "l2 error for z2_hat =  0.0302191015216527\n",
      "true tau1 =  172691.86795517273\n",
      "tau1 =  155558.2276052361\n",
      "\n",
      "\n",
      "**** iteration =  183  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.20102549e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995545003880364\n",
      "l2 error for x1_hat =  0.03012624482125889\n",
      "B / (A+B) =  [0.00164872]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687871723056\n",
      "alpha1 part I =  [0.00164718]\n",
      "alpha2 part II =  [9.15754468e-05]\n",
      "alpha1 =  0.05236407951762614\n",
      "true gam2 =  18381.536413564765\n",
      "gam2 =  19415.763884386844\n",
      "corr(z1_hat, X*beta_true) =  0.9997389635084043\n",
      "l2 error for z1_hat =  0.030219196943761923\n",
      "v1 =  0.9869083758938929\n",
      "true tau2 =  2215.1948921543553\n",
      "tau2 = 2063.524732552232\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995545]]\n",
      "l2 error for x2_hat =  0.03012631078132639\n",
      "alpha2 =  0.9476356713282362\n",
      "true gam1 =  1486.2523026654599\n",
      "gam1 =  1072.8737554068261\n",
      "corr(z2_hat, beta_true) =  [[0.99973888]]\n",
      "l2 error for z2_hat =  0.030226447226848502\n",
      "true tau1 =  172674.77654487954\n",
      "tau1 =  155564.75275283743\n",
      "\n",
      "\n",
      "**** iteration =  184  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.20675535e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995544653889942\n",
      "l2 error for x1_hat =  0.03012760030823297\n",
      "B / (A+B) =  [0.00164875]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687918435802\n",
      "alpha1 part I =  [0.00164721]\n",
      "alpha2 part II =  [9.16471529e-05]\n",
      "alpha1 =  0.05236206932714426\n",
      "true gam2 =  18380.087180217495\n",
      "gam2 =  19416.647938317627\n",
      "corr(z1_hat, X*beta_true) =  0.9997388803420763\n",
      "l2 error for z1_hat =  0.030226540613034876\n",
      "v1 =  0.9869088857198851\n",
      "true tau2 =  2215.201758969305\n",
      "tau2 = 2063.529861482307\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955446]]\n",
      "l2 error for x2_hat =  0.030127663621838722\n",
      "alpha2 =  0.9476376176818022\n",
      "true gam1 =  1486.2691465356606\n",
      "gam1 =  1072.880522800671\n",
      "corr(z2_hat, beta_true) =  [[0.9997388]]\n",
      "l2 error for z2_hat =  0.03023364156428795\n",
      "true tau1 =  172658.20273157672\n",
      "tau1 =  155570.99860153277\n",
      "\n",
      "\n",
      "**** iteration =  185  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.21236118e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995544315242317\n",
      "l2 error for x1_hat =  0.030128913098360462\n",
      "B / (A+B) =  [0.00164878]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990687977118795\n",
      "alpha1 part I =  [0.00164724]\n",
      "alpha2 part II =  [9.17177817e-05]\n",
      "alpha1 =  0.05236015394440779\n",
      "true gam2 =  18378.683489886505\n",
      "gam2 =  19417.519943549712\n",
      "corr(z1_hat, X*beta_true) =  0.9997387988615791\n",
      "l2 error for z1_hat =  0.03023373137592044\n",
      "v1 =  0.98690939343055\n",
      "true tau2 =  2215.2083228132474\n",
      "tau2 = 2063.5316168489194\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955443]]\n",
      "l2 error for x2_hat =  0.030128975165008225\n",
      "alpha2 =  0.9476396097302188\n",
      "true gam1 =  1486.2858948798464\n",
      "gam1 =  1072.885632761771\n",
      "corr(z2_hat, beta_true) =  [[0.99973872]]\n",
      "l2 error for z2_hat =  0.030240555707737288\n",
      "true tau1 =  172642.12765192467\n",
      "tau1 =  155577.1281426981\n",
      "\n",
      "\n",
      "**** iteration =  186  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.21775386e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995543986012869\n",
      "l2 error for x1_hat =  0.03013018824951343\n",
      "B / (A+B) =  [0.00164881]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688021428984\n",
      "alpha1 part I =  [0.00164727]\n",
      "alpha2 part II =  [9.17853415e-05]\n",
      "alpha1 =  0.05235826612905072\n",
      "true gam2 =  18377.3204004923\n",
      "gam2 =  19418.3512259486\n",
      "corr(z1_hat, X*beta_true) =  0.9997387205492347\n",
      "l2 error for z1_hat =  0.030240643552811173\n",
      "v1 =  0.9869098728740543\n",
      "true tau2 =  2215.2147769635358\n",
      "tau2 = 2063.5363382744845\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995544]]\n",
      "l2 error for x2_hat =  0.030130247865558735\n",
      "alpha2 =  0.9476414418122974\n",
      "true gam1 =  1486.3017414902965\n",
      "gam1 =  1072.891948064953\n",
      "corr(z2_hat, beta_true) =  [[0.99973864]]\n",
      "l2 error for z2_hat =  0.03024732317466356\n",
      "true tau1 =  172626.53931527748\n",
      "tau1 =  155583.00013637915\n",
      "\n",
      "\n",
      "**** iteration =  187  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.22302685e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995543667404357\n",
      "l2 error for x1_hat =  0.0301314233501369\n",
      "B / (A+B) =  [0.00164884]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688076190515\n",
      "alpha1 part I =  [0.0016473]\n",
      "alpha2 part II =  [9.18518209e-05]\n",
      "alpha1 =  0.052356465373083944\n",
      "true gam2 =  18376.000029130428\n",
      "gam2 =  19419.17031052515\n",
      "corr(z1_hat, X*beta_true) =  0.9997386438735274\n",
      "l2 error for z1_hat =  0.030247407702435107\n",
      "v1 =  0.9869103495417574\n",
      "true tau2 =  2215.2209519897647\n",
      "tau2 = 2063.538081220364\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955437]]\n",
      "l2 error for x2_hat =  0.030131481751968215\n",
      "alpha2 =  0.9476433106042836\n",
      "true gam1 =  1486.3174735840669\n",
      "gam1 =  1072.896792383147\n",
      "corr(z2_hat, beta_true) =  [[0.99973857]]\n",
      "l2 error for z2_hat =  0.030253830839823442\n",
      "true tau1 =  172611.42005298752\n",
      "tau1 =  155588.7585049114\n",
      "\n",
      "\n",
      "**** iteration =  188  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.228102e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995543357705305\n",
      "l2 error for x1_hat =  0.030132622918935103\n",
      "B / (A+B) =  [0.00164886]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688118196341\n",
      "alpha1 part I =  [0.00164733]\n",
      "alpha2 part II =  [9.19154678e-05]\n",
      "alpha1 =  0.0523546923167241\n",
      "true gam2 =  18374.717957417226\n",
      "gam2 =  19419.951984046824\n",
      "corr(z1_hat, X*beta_true) =  0.9997385701367212\n",
      "l2 error for z1_hat =  0.030253913472397958\n",
      "v1 =  0.9869108004175362\n",
      "true tau2 =  2215.227018555969\n",
      "tau2 = 2063.5424315925443\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955433]]\n",
      "l2 error for x2_hat =  0.030132679049755678\n",
      "alpha2 =  0.9476450350353482\n",
      "true gam1 =  1486.3323817510447\n",
      "gam1 =  1072.9026884017446\n",
      "corr(z2_hat, beta_true) =  [[0.9997385]]\n",
      "l2 error for z2_hat =  0.030260196751375847\n",
      "true tau1 =  172596.7585187909\n",
      "tau1 =  155594.27917029575\n",
      "\n",
      "\n",
      "**** iteration =  189  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.23306193e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995543057954158\n",
      "l2 error for x1_hat =  0.030133784912463487\n",
      "B / (A+B) =  [0.00164889]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688169321111\n",
      "alpha1 part I =  [0.00164735]\n",
      "alpha2 part II =  [9.19780391e-05]\n",
      "alpha1 =  0.052352999282849616\n",
      "true gam2 =  18373.475961701555\n",
      "gam2 =  19420.7214228957\n",
      "corr(z1_hat, X*beta_true) =  0.9997384979842765\n",
      "l2 error for z1_hat =  0.030260276303274877\n",
      "v1 =  0.986911247989963\n",
      "true tau2 =  2215.232827732639\n",
      "tau2 = 2063.544151906535\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.9995543]]\n",
      "l2 error for x2_hat =  0.0301338398647946\n",
      "alpha2 =  0.9476467884741432\n",
      "true gam1 =  1486.3471604814622\n",
      "gam1 =  1072.9072783275087\n",
      "corr(z2_hat, beta_true) =  [[0.99973843]]\n",
      "l2 error for z2_hat =  0.03026632159591768\n",
      "true tau1 =  172582.5381723662\n",
      "tau1 =  155599.68924017428\n",
      "\n",
      "\n",
      "**** iteration =  190  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.23783808e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995542766627785\n",
      "l2 error for x1_hat =  0.030134913371971394\n",
      "B / (A+B) =  [0.00164891]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688209120275\n",
      "alpha1 part I =  [0.00164738]\n",
      "alpha2 part II =  [9.2037994e-05]\n",
      "alpha1 =  0.05235133386217319\n",
      "true gam2 =  18372.270087168432\n",
      "gam2 =  19421.456459417583\n",
      "corr(z1_hat, X*beta_true) =  0.999738428559967\n",
      "l2 error for z1_hat =  0.03026639932513331\n",
      "v1 =  0.9869116720040416\n",
      "true tau2 =  2215.2385302384064\n",
      "tau2 = 2063.5481640511566\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955428]]\n",
      "l2 error for x2_hat =  0.03013496621813591\n",
      "alpha2 =  0.9476484115024629\n",
      "true gam1 =  1486.3611855835052\n",
      "gam1 =  1072.9127852113959\n",
      "corr(z2_hat, beta_true) =  [[0.99973836]]\n",
      "l2 error for z2_hat =  0.030272309767082492\n",
      "true tau1 =  172568.74826892125\n",
      "tau1 =  155604.87973079586\n",
      "\n",
      "\n",
      "**** iteration =  191  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.24250353e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995542484621474\n",
      "l2 error for x1_hat =  0.030136006572286635\n",
      "B / (A+B) =  [0.00164894]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688256869917\n",
      "alpha1 part I =  [0.0016474]\n",
      "alpha2 part II =  [9.20968849e-05]\n",
      "alpha1 =  0.05234974206647225\n",
      "true gam2 =  18371.101816791837\n",
      "gam2 =  19422.179317611975\n",
      "corr(z1_hat, X*beta_true) =  0.9997383606655496\n",
      "l2 error for z1_hat =  0.030272384633485434\n",
      "v1 =  0.9869120923010538\n",
      "true tau2 =  2215.243995184118\n",
      "tau2 = 2063.549853436226\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955425]]\n",
      "l2 error for x2_hat =  0.030136058277899228\n",
      "alpha2 =  0.9476500569531748\n",
      "true gam1 =  1486.3750698041636\n",
      "gam1 =  1072.9171318695464\n",
      "corr(z2_hat, beta_true) =  [[0.9997383]]\n",
      "l2 error for z2_hat =  0.030278074100073576\n",
      "true tau1 =  172555.37333236297\n",
      "tau1 =  155609.96292119691\n",
      "\n",
      "\n",
      "**** iteration =  192  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.24699817e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995542210578617\n",
      "l2 error for x1_hat =  0.03013706813152319\n",
      "B / (A+B) =  [0.00164896]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688294559011\n",
      "alpha1 part I =  [0.00164743]\n",
      "alpha2 part II =  [9.21533569e-05]\n",
      "alpha1 =  0.05234817761707808\n",
      "true gam2 =  18369.967606476446\n",
      "gam2 =  19422.870509828943\n",
      "corr(z1_hat, X*beta_true) =  0.9997382953053131\n",
      "l2 error for z1_hat =  0.030278147216750987\n",
      "v1 =  0.986912491057243\n",
      "true tau2 =  2215.249355696336\n",
      "tau2 = 2063.553556943609\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955422]]\n",
      "l2 error for x2_hat =  0.030137117882434464\n",
      "alpha2 =  0.947651584474195\n",
      "true gam1 =  1486.3882639779138\n",
      "gam1 =  1072.9222773542647\n",
      "corr(z2_hat, beta_true) =  [[0.99973823]]\n",
      "l2 error for z2_hat =  0.030283706934451798\n",
      "true tau1 =  172542.4031813229\n",
      "tau1 =  155614.84310256052\n",
      "\n",
      "\n",
      "**** iteration =  193  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.25138663e-06]\n",
      "corr(x1_hat, beta_true) =  0.999554194526983\n",
      "l2 error for x1_hat =  0.030138096599516356\n",
      "B / (A+B) =  [0.00164899]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688339174194\n",
      "alpha1 part I =  [0.00164745]\n",
      "alpha2 part II =  [9.2208782e-05]\n",
      "alpha1 =  0.052346680970208864\n",
      "true gam2 =  18368.868686806058\n",
      "gam2 =  19423.549656843014\n",
      "corr(z1_hat, X*beta_true) =  0.9997382314190607\n",
      "l2 error for z1_hat =  0.030283777389089953\n",
      "v1 =  0.9869128857798719\n",
      "true tau2 =  2215.2544967598537\n",
      "tau2 = 2063.5552087469337\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955419]]\n",
      "l2 error for x2_hat =  0.030138145249377503\n",
      "alpha2 =  0.9476531288038944\n",
      "true gam1 =  1486.4013087861592\n",
      "gam1 =  1072.9263916864343\n",
      "corr(z2_hat, beta_true) =  [[0.99973817]]\n",
      "l2 error for z2_hat =  0.030289131789837803\n",
      "true tau1 =  172529.82334041508\n",
      "tau1 =  155619.61947547027\n",
      "\n",
      "\n",
      "**** iteration =  194  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.25561622e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995541687485834\n",
      "l2 error for x1_hat =  0.030139095219031083\n",
      "B / (A+B) =  [0.00164901]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688374848209\n",
      "alpha1 part I =  [0.00164747]\n",
      "alpha2 part II =  [9.22619689e-05]\n",
      "alpha1 =  0.05234521125509103\n",
      "true gam2 =  18367.801877978523\n",
      "gam2 =  19424.199629217394\n",
      "corr(z1_hat, X*beta_true) =  0.99973816988834\n",
      "l2 error for z1_hat =  0.030289200567561896\n",
      "v1 =  0.9869132607859217\n",
      "true tau2 =  2215.2595359823044\n",
      "tau2 = 2063.5586303175096\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955417]]\n",
      "l2 error for x2_hat =  0.030139142053502366\n",
      "alpha2 =  0.9476545663789718\n",
      "true gam1 =  1486.413721113332\n",
      "gam1 =  1072.9312013109516\n",
      "corr(z2_hat, beta_true) =  [[0.99973811]]\n",
      "l2 error for z2_hat =  0.03029443036323424\n",
      "true tau1 =  172517.62415844848\n",
      "tau1 =  155624.20800524537\n",
      "\n",
      "\n",
      "**** iteration =  195  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.25974414e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995541437888699\n",
      "l2 error for x1_hat =  0.030140062777258537\n",
      "B / (A+B) =  [0.00164903]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688416550527\n",
      "alpha1 part I =  [0.0016475]\n",
      "alpha2 part II =  [9.23141305e-05]\n",
      "alpha1 =  0.0523438040378236\n",
      "true gam2 =  18366.76819374263\n",
      "gam2 =  19424.83775211957\n",
      "corr(z1_hat, X*beta_true) =  0.9997381097748919\n",
      "l2 error for z1_hat =  0.030294496664111797\n",
      "v1 =  0.9869136315247079\n",
      "true tau2 =  2215.264372315394\n",
      "tau2 = 2063.560239294513\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955414]]\n",
      "l2 error for x2_hat =  0.03014010855119701\n",
      "alpha2 =  0.9476560159934425\n",
      "true gam1 =  1486.4259781030376\n",
      "gam1 =  1072.9350940288407\n",
      "corr(z2_hat, beta_true) =  [[0.99973805]]\n",
      "l2 error for z2_hat =  0.03029953556973252\n",
      "true tau1 =  172505.79209959705\n",
      "tau1 =  155628.6963559235\n",
      "\n",
      "\n",
      "**** iteration =  196  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.26372421e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995541195399583\n",
      "l2 error for x1_hat =  0.030141002183723682\n",
      "B / (A+B) =  [0.00164905]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688450302443\n",
      "alpha1 part I =  [0.00164752]\n",
      "alpha2 part II =  [9.23642196e-05]\n",
      "alpha1 =  0.052342423218346944\n",
      "true gam2 =  18365.764777727858\n",
      "gam2 =  19425.448971093272\n",
      "corr(z1_hat, X*beta_true) =  0.9997380518522743\n",
      "l2 error for z1_hat =  0.030299600265872906\n",
      "v1 =  0.9869139841980826\n",
      "true tau2 =  2215.2691096759563\n",
      "tau2 = 2063.563403045933\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955412]]\n",
      "l2 error for x2_hat =  0.030141046270531126\n",
      "alpha2 =  0.9476573688676098\n",
      "true gam1 =  1486.4376547859108\n",
      "gam1 =  1072.9395913314017\n",
      "corr(z2_hat, beta_true) =  [[0.999738]]\n",
      "l2 error for z2_hat =  0.030304519708772123\n",
      "true tau1 =  172494.3180129146\n",
      "tau1 =  155633.01075858236\n",
      "\n",
      "\n",
      "**** iteration =  197  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.26760704e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995540960586115\n",
      "l2 error for x1_hat =  0.030141912430237203\n",
      "B / (A+B) =  [0.00164907]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688489296122\n",
      "alpha1 part I =  [0.00164754]\n",
      "alpha2 part II =  [9.24133083e-05]\n",
      "alpha1 =  0.05234110005866262\n",
      "true gam2 =  18364.792457662224\n",
      "gam2 =  19426.048586771034\n",
      "corr(z1_hat, X*beta_true) =  0.999737995289949\n",
      "l2 error for z1_hat =  0.030304582099038177\n",
      "v1 =  0.9869143324407323\n",
      "true tau2 =  2215.2736593036343\n",
      "tau2 = 2063.5649651557146\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955409]]\n",
      "l2 error for x2_hat =  0.03014195549758311\n",
      "alpha2 =  0.9476587297450451\n",
      "true gam1 =  1486.4491722827731\n",
      "gam1 =  1072.9432728801225\n",
      "corr(z2_hat, beta_true) =  [[0.99973794]]\n",
      "l2 error for z2_hat =  0.030309323956307036\n",
      "true tau1 =  172483.18924343397\n",
      "tau1 =  155637.22869950434\n",
      "\n",
      "\n",
      "**** iteration =  198  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.27135221e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995540732484992\n",
      "l2 error for x1_hat =  0.0301427961302012\n",
      "B / (A+B) =  [0.00164909]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688521216599\n",
      "alpha1 part I =  [0.00164756]\n",
      "alpha2 part II =  [9.24604765e-05]\n",
      "alpha1 =  0.052339802667655706\n",
      "true gam2 =  18363.8486646284\n",
      "gam2 =  19426.623370369118\n",
      "corr(z1_hat, X*beta_true) =  0.9997379407664765\n",
      "l2 error for z1_hat =  0.030309384812978096\n",
      "v1 =  0.9869146641140396\n",
      "true tau2 =  2215.2781130353974\n",
      "tau2 = 2063.5678928950642\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955407]]\n",
      "l2 error for x2_hat =  0.03014283762861143\n",
      "alpha2 =  0.947660002864035\n",
      "true gam1 =  1486.4601568106657\n",
      "gam1 =  1072.9474795745648\n",
      "corr(z2_hat, beta_true) =  [[0.99973789]]\n",
      "l2 error for z2_hat =  0.030314012312402105\n",
      "true tau1 =  172472.39711344583\n",
      "tau1 =  155641.28543634585\n",
      "\n",
      "\n",
      "**** iteration =  199  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [4.27500453e-06]\n",
      "corr(x1_hat, beta_true) =  0.9995540511581726\n",
      "l2 error for x1_hat =  0.03014365245157708\n",
      "B / (A+B) =  [0.00164911]\n",
      "gam1 / (gam1 + 1/sigma) =  0.9990688557690026\n",
      "alpha1 part I =  [0.00164758]\n",
      "alpha2 part II =  [9.25066721e-05]\n",
      "alpha1 =  0.052338558519310026\n",
      "true gam2 =  18362.9340670472\n",
      "gam2 =  19427.18683686265\n",
      "corr(z1_hat, X*beta_true) =  0.9997378875464903\n",
      "l2 error for z1_hat =  0.030314071021178196\n",
      "v1 =  0.9869149912525108\n",
      "true tau2 =  2215.2823929210813\n",
      "tau2 = 2063.569405122121\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.99955405]]\n",
      "l2 error for x2_hat =  0.030143692971765022\n",
      "alpha2 =  0.9476612805859864\n",
      "true gam1 =  1486.4709800900707\n",
      "gam1 =  1072.9509601040547\n",
      "corr(z2_hat, beta_true) =  [[0.99973784]]\n",
      "l2 error for z2_hat =  0.03031853321518727\n",
      "true tau1 =  172461.92979289775\n",
      "tau1 =  155645.24947512013\n",
      "\n",
      "\n",
      "Saving results!!\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=200\n",
    "p=0.4\n",
    "la=0.05\n",
    "# This is where the sigma is defined. Note that the scope of this definition extends to gvamp\n",
    "sigma=1\n",
    "omega=1\n",
    "h2=0.9\n",
    "gam1 = 1e-2\n",
    "tau1 = 1e-1\n",
    "mu=np.full((n,1), 0) \n",
    "maxiter = 200\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, True, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43022e33",
   "metadata": {},
   "source": [
    "Once dimensionality increases, the EM updates for mu lead us in the wrong direction <br>\n",
    "Correlation between true signal z and the predicted signal z1_hat after denoising (den_z) drops and the l2 error increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa1f127",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'la' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m mu\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfull((n,\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m      7\u001b[0m maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 9\u001b[0m problem_instance \u001b[38;5;241m=\u001b[39m Problem(n\u001b[38;5;241m=\u001b[39mn, m\u001b[38;5;241m=\u001b[39mm, la\u001b[38;5;241m=\u001b[39m\u001b[43mla\u001b[49m, sigmas \u001b[38;5;241m=\u001b[39m [sigma], omegas\u001b[38;5;241m=\u001b[39m[omega], model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeibull\u001b[39m\u001b[38;5;124m'\u001b[39m, mu\u001b[38;5;241m=\u001b[39mmu)\n\u001b[1;32m     10\u001b[0m X,beta,y,alpha \u001b[38;5;241m=\u001b[39m sim_model(problem_instance,h2,p )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgam1 = \u001b[39m\u001b[38;5;124m\"\u001b[39m, gam1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'la' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=200\n",
    "r1 = np.zeros((m,1))\n",
    "p1 = np.zeros((n,1))\n",
    "mu=np.full((n,1), 0) \n",
    "\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, True, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d59497",
   "metadata": {},
   "source": [
    "Algorithm is stable if we fix mu to be empirical average of Log(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf889d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weibull\n",
      "gam1 =  6.832321945119836\n",
      "tau1 =  0.1\n",
      "alpha =  2.9361235628007685\n",
      "s.shape =  (800,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.]\n",
      "B / (A+B) =  [0.1923838]\n",
      "gam1 / (gam1 + 1/sigma) =  0.8723239408432285\n",
      "alpha1 part I =  [0.16782099]\n",
      "alpha2 part II =  [0.]\n",
      "alpha1 =  0.1678209941751314\n",
      "true gam2 =  2.3722202522924425\n",
      "gam2 =  33.87964009933029\n",
      "corr(z1_hat, X*beta_true) =  0.5290047533799667\n",
      "l2 error for z1_hat =  0.9605651047308081\n",
      "v1 =  0.050136652118083234\n",
      "true tau2 =  6.2399873309118306\n",
      "tau2 = 1.8945488136000233\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.51276119]]\n",
      "l2 error for x2_hat =  0.9838370895090972\n",
      "alpha2 =  0.9733751806234335\n",
      "true gam1 =  1.9737519457061403\n",
      "gam1 =  0.9267128607183136\n",
      "corr(z2_hat, beta_true) =  [[-0.13045969]]\n",
      "l2 error for z2_hat =  1.0248608479036438\n",
      "true tau1 =  5.39872920888024\n",
      "tau1 =  69.2626968677543\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.11978683]\n",
      "corr(x1_hat, beta_true) =  0.5522706447810106\n",
      "l2 error for x1_hat =  0.8836595897414987\n",
      "B / (A+B) =  [0.37878151]\n",
      "gam1 / (gam1 + 1/sigma) =  0.48098130220235213\n",
      "alpha1 part I =  [0.18218682]\n",
      "alpha2 part II =  [0.05401966]\n",
      "alpha1 =  0.2028785556494241\n",
      "true gam2 =  2.4654232284549185\n",
      "gam2 =  3.64110781284603\n",
      "corr(z1_hat, X*beta_true) =  -0.13714867527886146\n",
      "l2 error for z1_hat =  1.027580930470144\n",
      "v1 =  0.9812324341592523\n",
      "true tau2 =  4.790909542565209\n",
      "tau2 = 1.3247546437731763\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.61733598]]\n",
      "l2 error for x2_hat =  0.8721821272756174\n",
      "alpha2 =  0.8674285980233911\n",
      "true gam1 =  1.2736446596872317\n",
      "gam1 =  0.5564801167461226\n",
      "corr(z2_hat, beta_true) =  [[0.03963785]]\n",
      "l2 error for z2_hat =  1.1567588491111385\n",
      "true tau1 =  6.779500647000661\n",
      "tau1 =  8.668008682414762\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.18526651]\n",
      "corr(x1_hat, beta_true) =  0.6177078188047097\n",
      "l2 error for x1_hat =  0.8558433597941355\n",
      "B / (A+B) =  [0.42925099]\n",
      "gam1 / (gam1 + 1/sigma) =  0.357524719242456\n",
      "alpha1 part I =  [0.15346784]\n",
      "alpha2 part II =  [0.05987252]\n",
      "alpha1 =  0.15497435009769897\n",
      "true gam2 =  2.481985219265741\n",
      "gam2 =  3.0343084001620384\n",
      "corr(z1_hat, X*beta_true) =  0.18465671099737002\n",
      "l2 error for z1_hat =  1.090017388307753\n",
      "v1 =  0.7683398381229023\n",
      "true tau2 =  5.216847737480307\n",
      "tau2 = 2.6134689298761713\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.64888364]]\n",
      "l2 error for x2_hat =  0.7969644562898265\n",
      "alpha2 =  0.7600741243195168\n",
      "true gam1 =  1.437053614724984\n",
      "gam1 =  0.9578132930723025\n",
      "corr(z2_hat, beta_true) =  [[0.36684005]]\n",
      "l2 error for z2_hat =  0.976271169656515\n",
      "true tau1 =  7.973487180936386\n",
      "tau1 =  8.279349205990966\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.25758392]\n",
      "corr(x1_hat, beta_true) =  0.6750447522672739\n",
      "l2 error for x1_hat =  0.765645684892114\n",
      "B / (A+B) =  [0.50863874]\n",
      "gam1 / (gam1 + 1/sigma) =  0.4892260648456687\n",
      "alpha1 part I =  [0.24883933]\n",
      "alpha2 part II =  [0.18974779]\n",
      "alpha1 =  0.24414930794399126\n",
      "true gam2 =  2.725313445966466\n",
      "gam2 =  2.965250430262225\n",
      "corr(z1_hat, X*beta_true) =  0.3518841421696114\n",
      "l2 error for z1_hat =  0.9840012732309739\n",
      "v1 =  0.7706475603162721\n",
      "true tau2 =  5.421316797567066\n",
      "tau2 = 2.4640173240907473\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68269723]]\n",
      "l2 error for x2_hat =  0.7678895568914582\n",
      "alpha2 =  0.7653022242666208\n",
      "true gam1 =  1.5595420970825868\n",
      "gam1 =  0.9093632011090758\n",
      "corr(z2_hat, beta_true) =  [[0.36661107]]\n",
      "l2 error for z2_hat =  0.9860884023377464\n",
      "true tau1 =  8.64736452114053\n",
      "tau1 =  8.034664720897672\n",
      "\n",
      "\n",
      "**** iteration =  4  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.22495456]\n",
      "corr(x1_hat, beta_true) =  0.682092246164586\n",
      "l2 error for x1_hat =  0.7737097271752149\n",
      "B / (A+B) =  [0.45920382]\n",
      "gam1 / (gam1 + 1/sigma) =  0.4762651760444852\n",
      "alpha1 part I =  [0.21870279]\n",
      "alpha2 part II =  [0.13372057]\n",
      "alpha1 =  0.2293994734529522\n",
      "true gam2 =  2.6964818477327066\n",
      "gam2 =  3.054740061296965\n",
      "corr(z1_hat, X*beta_true) =  0.3847676186004052\n",
      "l2 error for z1_hat =  0.9762241107843824\n",
      "v1 =  0.7460848987137068\n",
      "true tau2 =  5.386378299030371\n",
      "tau2 = 2.734437742843245\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68289714]]\n",
      "l2 error for x2_hat =  0.765639622136356\n",
      "alpha2 =  0.7543928019794799\n",
      "true gam1 =  1.5523369178204747\n",
      "gam1 =  0.9945298326913083\n",
      "corr(z2_hat, beta_true) =  [[0.3977718]]\n",
      "l2 error for z2_hat =  0.9627881294265027\n",
      "true tau1 =  8.669335447150834\n",
      "tau1 =  8.39894012589001\n",
      "\n",
      "\n",
      "**** iteration =  5  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23758261]\n",
      "corr(x1_hat, beta_true) =  0.6861069592749012\n",
      "l2 error for x1_hat =  0.7594104444393812\n",
      "B / (A+B) =  [0.48269155]\n",
      "gam1 / (gam1 + 1/sigma) =  0.49862870757332556\n",
      "alpha1 part I =  [0.24068386]\n",
      "alpha2 part II =  [0.16968117]\n",
      "alpha1 =  0.24794577051323088\n",
      "true gam2 =  2.742145606975106\n",
      "gam2 =  3.0165481971242407\n",
      "corr(z1_hat, X*beta_true) =  0.4057308853620543\n",
      "l2 error for z1_hat =  0.9575003719381412\n",
      "v1 =  0.7478403415796041\n",
      "true tau2 =  5.3722078260932635\n",
      "tau2 = 2.831986662773987\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68733325]]\n",
      "l2 error for x2_hat =  0.7569796156666309\n",
      "alpha2 =  0.7472820124676786\n",
      "true gam1 =  1.5657436901108097\n",
      "gam1 =  1.0201449746583633\n",
      "corr(z2_hat, beta_true) =  [[0.42749407]]\n",
      "l2 error for z2_hat =  0.9425311695004333\n",
      "true tau1 =  8.863649377290649\n",
      "tau1 =  8.374127672129813\n",
      "\n",
      "\n",
      "**** iteration =  6  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23537862]\n",
      "corr(x1_hat, beta_true) =  0.6880745134385552\n",
      "l2 error for x1_hat =  0.7555288521345159\n",
      "B / (A+B) =  [0.48493597]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5049860220209618\n",
      "alpha1 part I =  [0.24488589]\n",
      "alpha2 part II =  [0.17577122]\n",
      "alpha1 =  0.2528065819867886\n",
      "true gam2 =  2.7554280219403187\n",
      "gam2 =  3.0151335637448606\n",
      "corr(z1_hat, X*beta_true) =  0.4312209482647095\n",
      "l2 error for z1_hat =  0.9402057052193357\n",
      "v1 =  0.7433461224745465\n",
      "true tau2 =  5.366930581732962\n",
      "tau2 = 2.8913211126878657\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68877963]]\n",
      "l2 error for x2_hat =  0.7540105757702029\n",
      "alpha2 =  0.7440861633478986\n",
      "true gam1 =  1.572198441403826\n",
      "gam1 =  1.0369960312723907\n",
      "corr(z2_hat, beta_true) =  [[0.43836589]]\n",
      "l2 error for z2_hat =  0.9351053447478287\n",
      "true tau1 =  8.925572446805091\n",
      "tau1 =  8.406704623288391\n",
      "\n",
      "\n",
      "**** iteration =  7  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23446744]\n",
      "corr(x1_hat, beta_true) =  0.6892795645512635\n",
      "l2 error for x1_hat =  0.753081119987843\n",
      "B / (A+B) =  [0.48611331]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5090810268415893\n",
      "alpha1 part I =  [0.24747106]\n",
      "alpha2 part II =  [0.17947596]\n",
      "alpha1 =  0.25613582697743875\n",
      "true gam2 =  2.763023938730588\n",
      "gam2 =  3.0116216240926765\n",
      "corr(z1_hat, X*beta_true) =  0.44235797086514117\n",
      "l2 error for z1_hat =  0.9325977260371018\n",
      "v1 =  0.7399900727275872\n",
      "true tau2 =  5.352766755514214\n",
      "tau2 = 2.953859434417764\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68965026]]\n",
      "l2 error for x2_hat =  0.7516274636042196\n",
      "alpha2 =  0.7406651675688032\n",
      "true gam1 =  1.5738754242639172\n",
      "gam1 =  1.0544824077442405\n",
      "corr(z2_hat, beta_true) =  [[0.44946597]]\n",
      "l2 error for z2_hat =  0.9272351414736103\n",
      "true tau1 =  8.972770902159654\n",
      "tau1 =  8.436278198564654\n",
      "\n",
      "\n",
      "**** iteration =  8  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23573313]\n",
      "corr(x1_hat, beta_true) =  0.6901265754154517\n",
      "l2 error for x1_hat =  0.7505419886124214\n",
      "B / (A+B) =  [0.48959711]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5132593999196277\n",
      "alpha1 part I =  [0.25129032]\n",
      "alpha2 part II =  [0.18568343]\n",
      "alpha1 =  0.2597180172145888\n",
      "true gam2 =  2.7720078985187757\n",
      "gam2 =  3.0056225439772546\n",
      "corr(z1_hat, X*beta_true) =  0.45164931911459644\n",
      "l2 error for z1_hat =  0.9258099443921104\n",
      "v1 =  0.738448634760901\n",
      "true tau2 =  5.346391137681987\n",
      "tau2 = 2.988048154609795\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69045884]]\n",
      "l2 error for x2_hat =  0.749756751117349\n",
      "alpha2 =  0.7386084232460608\n",
      "true gam1 =  1.5767798572669\n",
      "gam1 =  1.0636819066381946\n",
      "corr(z2_hat, beta_true) =  [[0.45642166]]\n",
      "l2 error for z2_hat =  0.9224168392672633\n",
      "true tau1 =  9.013146948376644\n",
      "tau1 =  8.443261881147754\n",
      "\n",
      "\n",
      "**** iteration =  9  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23543067]\n",
      "corr(x1_hat, beta_true) =  0.6906800434793662\n",
      "l2 error for x1_hat =  0.749264308635244\n",
      "B / (A+B) =  [0.49059308]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5154291963391622\n",
      "alpha1 part I =  [0.252866]\n",
      "alpha2 part II =  [0.18808538]\n",
      "alpha1 =  0.26151938724509605\n",
      "true gam2 =  2.77628114825698\n",
      "gam2 =  3.0036337820503523\n",
      "corr(z1_hat, X*beta_true) =  0.4579377548376433\n",
      "l2 error for z1_hat =  0.9214468675674712\n",
      "v1 =  0.7369637579824456\n",
      "true tau2 =  5.341289945124978\n",
      "tau2 = 3.013559149322609\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69086627]]\n",
      "l2 error for x2_hat =  0.7486985291171012\n",
      "alpha2 =  0.7372084541829893\n",
      "true gam1 =  1.5781496049061574\n",
      "gam1 =  1.0707006412833127\n",
      "corr(z2_hat, beta_true) =  [[0.46081429]]\n",
      "l2 error for z2_hat =  0.919332147259227\n",
      "true tau1 =  9.034931510170418\n",
      "tau1 =  8.45392980643336\n",
      "\n",
      "\n",
      "**** iteration =  10  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23553378]\n",
      "corr(x1_hat, beta_true) =  0.6910333903768734\n",
      "l2 error for x1_hat =  0.7483093539147952\n",
      "B / (A+B) =  [0.49166009]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5170716712676285\n",
      "alpha1 part I =  [0.25422351]\n",
      "alpha2 part II =  [0.1902413]\n",
      "alpha1 =  0.26292275767178114\n",
      "true gam2 =  2.7795788381800675\n",
      "gam2 =  3.001600481542725\n",
      "corr(z1_hat, X*beta_true) =  0.4619060419851203\n",
      "l2 error for z1_hat =  0.9186240055058381\n",
      "v1 =  0.7360422693977\n",
      "true tau2 =  5.3375952303166825\n",
      "tau2 = 3.031728229688902\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69116535]]\n",
      "l2 error for x2_hat =  0.7479143465932866\n",
      "alpha2 =  0.7361845625534909\n",
      "true gam1 =  1.5791190482533384\n",
      "gam1 =  1.0756386161253004\n",
      "corr(z2_hat, beta_true) =  [[0.46406336]]\n",
      "l2 error for z2_hat =  0.9170423122267624\n",
      "true tau1 =  9.051442506455327\n",
      "tau1 =  8.460124783285787\n",
      "\n",
      "\n",
      "**** iteration =  11  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23563737]\n",
      "corr(x1_hat, beta_true) =  0.6912796415729621\n",
      "l2 error for x1_hat =  0.7476442135653335\n",
      "B / (A+B) =  [0.49241463]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5182205648752332\n",
      "alpha1 part I =  [0.25517939]\n",
      "alpha2 part II =  [0.19176373]\n",
      "alpha1 =  0.26390696082120035\n",
      "true gam2 =  2.781882759190653\n",
      "gam2 =  3.0001864882153786\n",
      "corr(z1_hat, X*beta_true) =  0.46476219576063416\n",
      "l2 error for z1_hat =  0.9165870271774302\n",
      "v1 =  0.7354287812973855\n",
      "true tau2 =  5.335261009577988\n",
      "tau2 = 3.0435381116598\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69137107]]\n",
      "l2 error for x2_hat =  0.7473890415490987\n",
      "alpha2 =  0.7355163002677233\n",
      "true gam1 =  1.5798497543912677\n",
      "gam1 =  1.0788345846328091\n",
      "corr(z2_hat, beta_true) =  [[0.46616765]]\n",
      "l2 error for z2_hat =  0.9155634639887944\n",
      "true tau1 =  9.06249467776251\n",
      "tau1 =  8.463931402494069\n",
      "\n",
      "\n",
      "**** iteration =  12  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23563401]\n",
      "corr(x1_hat, beta_true) =  0.6914426783558488\n",
      "l2 error for x1_hat =  0.7472193908572977\n",
      "B / (A+B) =  [0.4928536]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5189612452129599\n",
      "alpha1 part I =  [0.25577192]\n",
      "alpha2 part II =  [0.19269797]\n",
      "alpha1 =  0.264539236072248\n",
      "true gam2 =  2.783342109977364\n",
      "gam2 =  2.9993301543708593\n",
      "corr(z1_hat, X*beta_true) =  0.46665518587787563\n",
      "l2 error for z1_hat =  0.9152465968495463\n",
      "v1 =  0.7349837660760541\n",
      "true tau2 =  5.333549143945523\n",
      "tau2 = 3.051875875374766\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69150201]]\n",
      "l2 error for x2_hat =  0.7470413536593324\n",
      "alpha2 =  0.7350527020715165\n",
      "true gam1 =  1.5802908022995426\n",
      "gam1 =  1.0810985630778132\n",
      "corr(z2_hat, beta_true) =  [[0.46760839]]\n",
      "l2 error for z2_hat =  0.914546190446585\n",
      "true tau1 =  9.069745252192298\n",
      "tau1 =  8.466927672486102\n",
      "\n",
      "\n",
      "**** iteration =  13  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23567069]\n",
      "corr(x1_hat, beta_true) =  0.6915524998916993\n",
      "l2 error for x1_hat =  0.7469200224475843\n",
      "B / (A+B) =  [0.4931929]\n",
      "gam1 / (gam1 + 1/sigma) =  0.51948455602167\n",
      "alpha1 part I =  [0.2562061]\n",
      "alpha2 part II =  [0.19338981]\n",
      "alpha1 =  0.26498970477765915\n",
      "true gam2 =  2.784378913168802\n",
      "gam2 =  2.998677154944568\n",
      "corr(z1_hat, X*beta_true) =  0.4679386182980915\n",
      "l2 error for z1_hat =  0.9143305679865893\n",
      "v1 =  0.7346929063624953\n",
      "true tau2 =  5.33239951233592\n",
      "tau2 = 3.0575168936201957\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69159362]]\n",
      "l2 error for x2_hat =  0.7468001282098101\n",
      "alpha2 =  0.7347357210642241\n",
      "true gam1 =  1.5806054489448762\n",
      "gam1 =  1.0826231942492206\n",
      "corr(z2_hat, beta_true) =  [[0.46859566]]\n",
      "l2 error for z2_hat =  0.9138493687516241\n",
      "true tau1 =  9.074806316000968\n",
      "tau1 =  8.468787763330853\n",
      "\n",
      "\n",
      "**** iteration =  14  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23568696]\n",
      "corr(x1_hat, beta_true) =  0.6916271723163775\n",
      "l2 error for x1_hat =  0.7467193069198454\n",
      "B / (A+B) =  [0.49341479]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5198363281647321\n",
      "alpha1 part I =  [0.25649493]\n",
      "alpha2 part II =  [0.19384891]\n",
      "alpha1 =  0.2652921312401802\n",
      "true gam2 =  2.785072548599425\n",
      "gam2 =  2.9982486702429685\n",
      "corr(z1_hat, X*beta_true) =  0.46881811419751945\n",
      "l2 error for z1_hat =  0.913704141549417\n",
      "v1 =  0.734491964478345\n",
      "true tau2 =  5.331617093683887\n",
      "tau2 = 3.061342139922212\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69165486]]\n",
      "l2 error for x2_hat =  0.7466382998449405\n",
      "alpha2 =  0.7345217062421828\n",
      "true gam1 =  1.5808175000532438\n",
      "gam1 =  1.083657480062685\n",
      "corr(z2_hat, beta_true) =  [[0.46925876]]\n",
      "l2 error for z2_hat =  0.9133811771010113\n",
      "true tau1 =  9.078191614164993\n",
      "tau1 =  8.470079493798714\n",
      "\n",
      "\n",
      "**** iteration =  15  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23569666]\n",
      "corr(x1_hat, beta_true) =  0.6916774522067224\n",
      "l2 error for x1_hat =  0.7465836886649838\n",
      "B / (A+B) =  [0.49356463]\n",
      "gam1 / (gam1 + 1/sigma) =  0.520074671788227\n",
      "alpha1 part I =  [0.25669046]\n",
      "alpha2 part II =  [0.19415971]\n",
      "alpha1 =  0.2654972742551356\n",
      "true gam2 =  2.785541102230162\n",
      "gam2 =  2.9979568532781538\n",
      "corr(z1_hat, X*beta_true) =  0.4694109077022646\n",
      "l2 error for z1_hat =  0.913281802331395\n",
      "v1 =  0.7343548270835533\n",
      "true tau2 =  5.3310772936015685\n",
      "tau2 = 3.063962608759709\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69169615]]\n",
      "l2 error for x2_hat =  0.7465283786848899\n",
      "alpha2 =  0.7343752777923812\n",
      "true gam1 =  1.5809588844680222\n",
      "gam1 =  1.0843658282401647\n",
      "corr(z2_hat, beta_true) =  [[0.4697116]]\n",
      "l2 error for z2_hat =  0.9130611236382729\n",
      "true tau1 =  9.08048962832294\n",
      "tau1 =  8.470967511053615\n",
      "\n",
      "\n",
      "**** iteration =  16  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23570561]\n",
      "corr(x1_hat, beta_true) =  0.6917115742706256\n",
      "l2 error for x1_hat =  0.746490954224965\n",
      "B / (A+B) =  [0.49366864]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5202377689888045\n",
      "alpha1 part I =  [0.25682507]\n",
      "alpha2 part II =  [0.19437405]\n",
      "alpha1 =  0.2656378722113344\n",
      "true gam2 =  2.785862026327038\n",
      "gam2 =  2.9977547640279143\n",
      "corr(z1_hat, X*beta_true) =  0.4698145864769675\n",
      "l2 error for z1_hat =  0.9129937894565968\n",
      "v1 =  0.7342622748414516\n",
      "true tau2 =  5.330712550034927\n",
      "tau2 = 3.065737834298278\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69172433]]\n",
      "l2 error for x2_hat =  0.7464535349863182\n",
      "alpha2 =  0.7342758981395816\n",
      "true gam1 =  1.5810562291695784\n",
      "gam1 =  1.084845211843905\n",
      "corr(z2_hat, beta_true) =  [[0.47001885]]\n",
      "l2 error for z2_hat =  0.9128439984304675\n",
      "true tau1 =  9.082055715528103\n",
      "tau1 =  8.471558981587366\n",
      "\n",
      "\n",
      "**** iteration =  17  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23571065]\n",
      "corr(x1_hat, beta_true) =  0.691734724354186\n",
      "l2 error for x1_hat =  0.7464282985403632\n",
      "B / (A+B) =  [0.49373834]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5203480842035427\n",
      "alpha1 part I =  [0.2569158]\n",
      "alpha2 part II =  [0.19451839]\n",
      "alpha1 =  0.26573293865798364\n",
      "true gam2 =  2.786078661913568\n",
      "gam2 =  2.997618999490372\n",
      "corr(z1_hat, X*beta_true) =  0.4700887972790275\n",
      "l2 error for z1_hat =  0.9127982745167253\n",
      "v1 =  0.7341990379824445\n",
      "true tau2 =  5.330463690295458\n",
      "tau2 = 3.0669456245572295\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69174335]]\n",
      "l2 error for x2_hat =  0.7464028750501882\n",
      "alpha2 =  0.734208392852538\n",
      "true gam1 =  1.581121824879552\n",
      "gam1 =  1.0851714298645105\n",
      "corr(z2_hat, beta_true) =  [[0.47022723]]\n",
      "l2 error for z2_hat =  0.9126967007051309\n",
      "true tau1 =  9.083114700717866\n",
      "tau1 =  8.471965093777376\n",
      "\n",
      "\n",
      "**** iteration =  18  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23571432]\n",
      "corr(x1_hat, beta_true) =  0.6917504127587755\n",
      "l2 error for x1_hat =  0.7463857068217992\n",
      "B / (A+B) =  [0.49378594]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5204231241241505\n",
      "alpha1 part I =  [0.25697762]\n",
      "alpha2 part II =  [0.1946168]\n",
      "alpha1 =  0.26579764793893096\n",
      "true gam2 =  2.786225989356763\n",
      "gam2 =  2.9975262097844184\n",
      "corr(z1_hat, X*beta_true) =  0.4702747813252925\n",
      "l2 error for z1_hat =  0.9126656039643599\n",
      "v1 =  0.7341561342654508\n",
      "true tau2 =  5.330294316692182\n",
      "tau2 = 3.067766985494668\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69175627]]\n",
      "l2 error for x2_hat =  0.7463684326659036\n",
      "alpha2 =  0.7341624711864787\n",
      "true gam1 =  1.58116634849901\n",
      "gam1 =  1.085393208502002\n",
      "corr(z2_hat, beta_true) =  [[0.47036894]]\n",
      "l2 error for z2_hat =  0.9125965080690734\n",
      "true tau1 =  9.083834821774444\n",
      "tau1 =  8.472240172962758\n",
      "\n",
      "\n",
      "**** iteration =  19  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [-0.23571686]\n",
      "corr(x1_hat, beta_true) =  0.6917610665141067\n",
      "l2 error for x1_hat =  0.7463567675417591\n",
      "B / (A+B) =  [0.49381832]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5204741264510356\n",
      "alpha1 part I =  [0.25701966]\n",
      "alpha2 part II =  [0.19468373]\n",
      "alpha1 =  0.2658416385681172\n",
      "true gam2 =  2.786326104491138\n",
      "gam2 =  2.997463090263585\n",
      "corr(z1_hat, X*beta_true) =  0.47040120705606264\n",
      "l2 error for z1_hat =  0.912575405875332\n",
      "v1 =  0.7341270007921483\n",
      "true tau2 =  5.330179355399723\n",
      "tau2 = 3.068324557418932\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.69176505]]\n",
      "l2 error for x2_hat =  0.7463450468131821\n",
      "alpha2 =  0.7341312953282959\n",
      "true gam1 =  1.5811966413878862\n",
      "gam1 =  1.0855437360877567\n",
      "corr(z2_hat, beta_true) =  [[0.47046512]]\n",
      "l2 error for z2_hat =  0.9125285125411408\n",
      "true tau1 =  9.084323756163128\n",
      "tau1 =  8.472426585923468\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=800\n",
    "m=800\n",
    "mu=np.full((n,1), 0) \n",
    "r1 = np.zeros((m,1))\n",
    "p1 = np.zeros((n,1))\n",
    "\n",
    "problem_instance = Problem(n=n, m=m, la=la, sigmas = [sigma], omegas=[omega], model='Weibull', mu=mu)\n",
    "X,beta,y,alpha = sim_model(problem_instance,h2,p )\n",
    "problem_instance.prior_instance.distribution_parameters['mu'] = np.mean(np.log(y)).reshape(-1, 1)\n",
    "\n",
    "print(\"gam1 = \", gam1)\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "#r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "#p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "problem_instance.prior_instance.distribution_parameters['alpha']=alpha\n",
    "\n",
    "est, gam1, corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, a, ps, dl_dmus, z1_hats =  infere(X, y, gam1, r1, tau1, p1, problem_instance, maxiter, beta, False, True)\n",
    "plot_metrics(corrs_x, l2_errs_x, corrs_z, l2_errs_z, mus, alphas, dl_dmus, a, ps, mu[0][0], alpha, n, m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
