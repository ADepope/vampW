{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea0bf76d-7842-4613-b4d4-231087c3f8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vampW code\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import sympy\n",
    "import scipy\n",
    "\n",
    "# definition of Euler-Mascheroni constant\n",
    "emc = float( sympy.S.EulerGamma.n(10) )\n",
    "\n",
    "class prior: # checked!\n",
    "    la = 0.5\n",
    "    sigma = 1\n",
    "    \n",
    "    def __init__(self, la, sigma):\n",
    "        self.la = la\n",
    "        self.sigma = sigma\n",
    "    \n",
    "def den_beta(r,gam1,prior): # checked!\n",
    "    A = (1-prior.la) * norm.pdf(r, loc=0, scale=np.sqrt(1.0/gam1)) # scale = standard deviation\n",
    "    B = prior.la * norm.pdf(r, loc=0, scale=np.sqrt(sigma + 1.0/gam1))\n",
    "    ratio = gam1 * r / (gam1 + 1/sigma) * B / (A + B)\n",
    "    return ratio\n",
    "\n",
    "def der_den_beta(r,gam1,prior): # checked!\n",
    "    A = (1-prior.la) * norm.pdf(r, loc=0, scale=np.sqrt(1.0/gam1))\n",
    "    B = prior.la * norm.pdf(r, loc=0, scale=np.sqrt(sigma + 1.0/gam1))\n",
    "    print(\"B / (A+B) = \", B[1] / (A[1]+B[1]))\n",
    "    Ader = A * (-r*gam1)\n",
    "    Bder = B * (-r) / (sigma + 1.0/gam1)\n",
    "    BoverAplusBder = ( Bder * A - Ader * B ) / (A+B) / (A+B)\n",
    "    print(\"gam1 / (gam1 + 1/sigma) = \", gam1 / (gam1 + 1/sigma))\n",
    "    print(\"alpha1 part I = \", gam1 / (gam1 + 1/sigma) * B[1] / (A[1] + B[1]))\n",
    "    print(\"alpha2 part II = \", BoverAplusBder[1] * r[1] * gam1 / (gam1 + 1.0/sigma) )\n",
    "    ratio = gam1 / (gam1 + 1/sigma) * B / (A + B) + BoverAplusBder * r * gam1 / (gam1 + 1.0/sigma)\n",
    "    return ratio\n",
    "\n",
    "def den_z_non_lin_eq(z, tau1, p1, y, alpha, mu): # checked!\n",
    "    res = tau1 * (z-p1) + alpha - alpha * np.power(y, alpha) * np.exp(- alpha * (mu + z) - emc)\n",
    "    return res\n",
    "    \n",
    "def den_z(p1, tau1, y, alpha, mu): # checked!\n",
    "    n,_ = p1.shape\n",
    "    out = np.zeros((n,1))\n",
    "    for i in range(0, n):\n",
    "        out[i] = scipy.optimize.fsolve(den_z_non_lin_eq, x0 = p1[i], args=(tau1, p1[i], y[i], alpha, mu) )\n",
    "    return out\n",
    "\n",
    "def der_den_z(p1, tau1, y, alpha, mu): # checked!\n",
    "    z = den_z(p1, tau1, y, alpha, mu)\n",
    "    nom = alpha * alpha * np.power(y, alpha-1) * np.exp(- alpha * (mu + z) - emc)\n",
    "    den = tau1 + alpha * alpha * np.power(y, alpha) * np.exp(- alpha * (mu + z) - emc)\n",
    "    return nom / den\n",
    "\n",
    "def gvamp(X, gam1, r1, tau1, p1, prior, y, alpha, mu, maxiter, beta_true):\n",
    "    #computing SVD decomposition of X\n",
    "    [n,m] = X.shape\n",
    "    u, s, vh = np.linalg.svd(X, full_matrices=False)\n",
    "    print(\"s.shape = \", s.shape)\n",
    "    Xbeta_true = X @ beta_true\n",
    "    \n",
    "    for it in range(maxiter):\n",
    "        print(\"**** iteration = \", it, \" **** \\n\" )\n",
    "        \n",
    "        # Denoising x\n",
    "        print(\"->DENOISING\")\n",
    "        vect_den_beta = lambda x: den_beta(x, gam1, prior)\n",
    "        x1_hat = vect_den_beta(r1)\n",
    "        #print(\"shape of x1_hat = \", x1_hat.shape )\n",
    "        #print(\"shape of beta_true = \", beta_true.shape )\n",
    "        print(\"x1_hat[2] = \", x1_hat[2])\n",
    "        if np.linalg.norm(x1_hat) != 0:\n",
    "            # reporting quality of estimation\n",
    "            print(\"corr(x1_hat, beta_true) = \", np.dot(x1_hat.transpose(), beta_true) / np.linalg.norm(x1_hat) / np.linalg.norm(beta_true))\n",
    "            print(\"l2 error for x1_hat = \", np.linalg.norm(x1_hat - beta_true) / np.linalg.norm(beta_true))\n",
    "        alpha1 = np.mean( der_den_beta(r1, gam1, prior) )\n",
    "        print(\"alpha1 = \", alpha1)\n",
    "        r2 = (x1_hat - alpha1 * r1) / (1-alpha1)\n",
    "        gam2 = gam1 * (1-alpha1) / alpha1\n",
    "        print(\"true gam2 = \", 1.0 / np.var(r2 - beta_true))\n",
    "        print(\"gam2 = \", gam2)\n",
    "        \n",
    "        # Denoising z\n",
    "        z1_hat = den_z(p1, tau1, y, alpha, mu) \n",
    "        # reporting quality of estimation\n",
    "        print(\"corr(z1_hat, X*beta_true) = \", np.dot(z1_hat.transpose(), Xbeta_true) / np.linalg.norm(z1_hat) / np.linalg.norm(Xbeta_true))\n",
    "        print(\"l2 error for z1_hat = \", np.linalg.norm(z1_hat - Xbeta_true) / np.linalg.norm(Xbeta_true))\n",
    "        beta1 = np.sum( der_den_z(p1, tau1, y, alpha, mu) ) / n\n",
    "        print(\"beta1 = \", beta1)\n",
    "        p2 = (z1_hat - beta1 * p1) / (1-beta1)\n",
    "        tau2 = tau1 * (1-beta1) / beta1\n",
    "        print(\"true tau2 = \", 1.0 / np.var(p2 - Xbeta_true))\n",
    "        print(\"tau2 =\", tau2)\n",
    "        \n",
    "        # LMMSE estimation of x\n",
    "        print(\"->LMMSE\")\n",
    "        dk = 1.0 / (tau2 * s * s + gam2)\n",
    "        x2_hat = vh.transpose() @ np.diag(dk) @ (tau2 * np.diag(s).transpose() @ u.transpose() @ p2 + gam2 * vh @ r2)\n",
    "        print(\"corr(x2_hat, beta_true) = \", np.dot(x2_hat.transpose(), beta_true) / np.linalg.norm(x2_hat) / np.linalg.norm(beta_true))\n",
    "        print(\"l2 error for x2_hat = \", np.linalg.norm(x2_hat - beta_true) / np.linalg.norm(beta_true))\n",
    "        alpha2 = np.sum( gam2 / (tau2 * s * s + gam2) ) / m;\n",
    "        print(\"alpha2 = \", alpha2)\n",
    "        r1 = (x2_hat - alpha2 * r2) / (1-alpha2)\n",
    "        gam1 = gam2 * (1-alpha2) / alpha2\n",
    "        print(\"true gam1 = \", 1.0 / np.var(r1 - beta_true))\n",
    "        print(\"gam1 = \", gam1)\n",
    "        \n",
    "        # LMMSE estimation of z\n",
    "        z2_hat = np.matmul(X, x2_hat)\n",
    "        print(\"corr(z2_hat, beta_true) = \", np.dot(z2_hat.transpose(), Xbeta_true) / np.linalg.norm(z2_hat) / np.linalg.norm(Xbeta_true))\n",
    "        print(\"l2 error for z2_hat = \", np.linalg.norm(z2_hat - Xbeta_true) / np.linalg.norm(Xbeta_true))\n",
    "        beta2 = (1-alpha2) * m / n;\n",
    "        p1 = (z2_hat - beta2 * p2) / (1-beta2)\n",
    "        tau1 = tau2 * (1-beta2) / beta2\n",
    "        print(\"true tau1 = \", 1.0 / np.var(p1 - Xbeta_true))\n",
    "        print(\"tau1 = \", tau1)\n",
    "        print(\"\\n\")\n",
    "    return x1_hat, gam1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62c2b7fe-1902-4ca6-add0-0dc39e1d3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "import sympy\n",
    "\n",
    "emc = float( sympy.S.EulerGamma.n(10) )\n",
    "\n",
    "#function for simultaing genotype matrix and Weibull distributed phenotypes\n",
    "\n",
    "def sim_geno(n,m,p): # checked!\n",
    "    X = random.binomial(2, p, size=[n,m])\n",
    "    # for debugging purposes we simulate a Gaussian matrix and scale it \n",
    "    X = random.normal(loc=0.0, scale=1.0, size=[n,m]) / np.sqrt(n)\n",
    "    return X\n",
    "\n",
    "def sim_beta(m, la, sigma): # checked!\n",
    "    beta = random.normal(loc=0.0, scale=np.sqrt(sigma), size=[m,1]) # scale = standard deviation\n",
    "    beta *= random.binomial(1, la, size=[m,1])\n",
    "    return beta\n",
    "\n",
    "def sim_pheno(X, beta, mu, h2):\n",
    "    # logY_i = mu + xi beta + c(wi - Ewi), wi = - standard Gumbel distribution\n",
    "    # beta is mx1 vector \n",
    "    # mu is nx1 vector \n",
    "    [n,m] = X.shape\n",
    "    g = np.matmul(X, beta)\n",
    "    sigmaG = np.var(g)\n",
    "    varwi = np.pi * np.pi / 6\n",
    "    c = np.sqrt((1/h2-1) * sigmaG / varwi)\n",
    "    wi = -random.gumbel(loc=0.0, scale=1.0, size=[n,1])\n",
    "    y = np.exp( mu + g + c * (wi + emc) )\n",
    "    alpha = 1.0 / c\n",
    "    return y, alpha\n",
    "\n",
    "def sim_model(n,m,p,la,sigma,h2):\n",
    "    X = sim_geno(n,m,p)\n",
    "    beta = sim_beta(m, la, sigma)\n",
    "    mu = np.zeros((n,1))\n",
    "    y, alpha = sim_pheno(X, beta, mu, h2)\n",
    "    return X,beta,y,alpha\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "945d405c-7b2c-48f0-b41a-02534edd441a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gam1 =  0.5\n",
      "Var(y) =  1.7899999212954631\n",
      "tau1 =  1.5\n",
      "alpha =  2.1023437957972333\n",
      "s.shape =  (800,)\n",
      "**** iteration =  0  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.56823322]\n",
      "corr(x1_hat, beta_true) =  [[0.41533314]]\n",
      "l2 error for x1_hat =  0.9099311935138438\n",
      "B / (A+B) =  [0.35422944]\n",
      "gam1 / (gam1 + 1/sigma) =  0.3333333333333333\n",
      "alpha1 part I =  [0.11807648]\n",
      "alpha2 part II =  [0.00117399]\n",
      "alpha1 =  0.16496318029950224\n",
      "true gam2 =  2.567974024616759\n",
      "gam2 =  2.5309793924451194\n",
      "corr(z1_hat, X*beta_true) =  [[0.78649778]]\n",
      "l2 error for z1_hat =  0.7756768612505774\n",
      "beta1 =  0.8393540649738744\n",
      "true tau2 =  0.07246159497585315\n",
      "tau2 = 0.28708850364201033\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.18561437]]\n",
      "l2 error for x2_hat =  1.0581678596568154\n",
      "alpha2 =  0.9066193758922034\n",
      "true gam1 =  0.06958002808011154\n",
      "gam1 =  0.2606876066793859\n",
      "corr(z2_hat, beta_true) =  [[0.26219595]]\n",
      "l2 error for z2_hat =  1.1017900284593798\n",
      "true tau1 =  2.4389246398366975\n",
      "tau1 =  2.787301996367945\n",
      "\n",
      "\n",
      "**** iteration =  1  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.54827588]\n",
      "corr(x1_hat, beta_true) =  [[0.14890996]]\n",
      "l2 error for x1_hat =  1.1785979785701284\n",
      "B / (A+B) =  [0.37588463]\n",
      "gam1 / (gam1 + 1/sigma) =  0.2067820809042689\n",
      "alpha1 part I =  [0.07772621]\n",
      "alpha2 part II =  [0.00138165]\n",
      "alpha1 =  0.13165535116209684\n",
      "true gam2 =  2.3509160860329894\n",
      "gam2 =  1.7193884356413083\n",
      "corr(z1_hat, X*beta_true) =  [[0.72302189]]\n",
      "l2 error for z1_hat =  0.6981246424836071\n",
      "beta1 =  0.5087193023118792\n",
      "true tau2 =  2.503802379662901\n",
      "tau2 = 2.6917548896220835\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.60687039]]\n",
      "l2 error for x2_hat =  0.8115430998540024\n",
      "alpha2 =  0.5409511333722965\n",
      "true gam1 =  1.3952219544219526\n",
      "gam1 =  1.459065826803098\n",
      "corr(z2_hat, beta_true) =  [[0.79915624]]\n",
      "l2 error for z2_hat =  0.6195044442709471\n",
      "true tau1 =  4.035382737850878\n",
      "tau1 =  3.172010572640005\n",
      "\n",
      "\n",
      "**** iteration =  2  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.53819047]\n",
      "corr(x1_hat, beta_true) =  [[0.64803711]]\n",
      "l2 error for x1_hat =  0.7616135497757177\n",
      "B / (A+B) =  [0.32810437]\n",
      "gam1 / (gam1 + 1/sigma) =  0.5933415083482954\n",
      "alpha1 part I =  [0.19467794]\n",
      "alpha2 part II =  [0.03625465]\n",
      "alpha1 =  0.3531523960287508\n",
      "true gam2 =  2.702283855054895\n",
      "gam2 =  2.6724814689550556\n",
      "corr(z1_hat, X*beta_true) =  [[0.80308866]]\n",
      "l2 error for z1_hat =  0.6074857716671617\n",
      "beta1 =  0.4913997719583614\n",
      "true tau2 =  3.3045495419476962\n",
      "tau2 = 3.2830403932948844\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.66967847]]\n",
      "l2 error for x2_hat =  0.7426607528637561\n",
      "alpha2 =  0.5824430843055962\n",
      "true gam1 =  1.842849810842332\n",
      "gam1 =  1.9159178802126962\n",
      "corr(z2_hat, beta_true) =  [[0.81351584]]\n",
      "l2 error for z2_hat =  0.5817580513876666\n",
      "true tau1 =  4.653315903735398\n",
      "tau1 =  4.5794575558413095\n",
      "\n",
      "\n",
      "**** iteration =  3  **** \n",
      "\n",
      "->DENOISING\n",
      "x1_hat[2] =  [0.67724851]\n",
      "corr(x1_hat, beta_true) =  [[0.67994979]]\n",
      "l2 error for x1_hat =  0.7334591769110803\n",
      "B / (A+B) =  [0.35854702]\n",
      "gam1 / (gam1 + 1/sigma) =  0.6570548139280737\n",
      "alpha1 part I =  [0.23558504]\n",
      "alpha2 part II =  [0.10846595]\n",
      "alpha1 =  0.4008154962494283\n",
      "true gam2 =  2.7606359008234054\n",
      "gam2 =  2.864131539384635\n",
      "corr(z1_hat, X*beta_true) =  [[0.81713826]]\n",
      "l2 error for z1_hat =  0.5766760059477309\n",
      "beta1 =  0.3743863920989859\n",
      "true tau2 =  6.367242419181784\n",
      "tau2 = 7.652444170518777\n",
      "->LMMSE\n",
      "corr(x2_hat, beta_true) =  [[0.68457808]]\n",
      "l2 error for x2_hat =  0.7290156687739919\n",
      "alpha2 =  0.45226144929980505\n",
      "true gam1 =  3.1015477094931905\n",
      "gam1 =  3.4687795318970482\n",
      "corr(z2_hat, beta_true) =  [[0.82065569]]\n",
      "l2 error for z2_hat =  0.5714891816641888\n",
      "true tau1 =  5.779216528643642\n",
      "tau1 =  6.318535525426245\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running simulation\n",
    "from numpy import random\n",
    "\n",
    "n=800\n",
    "m=800\n",
    "p=0.4\n",
    "la=0.4\n",
    "sigma=1\n",
    "h2=0.5\n",
    "    \n",
    "X,beta,y,alpha = sim_model(n,m,p,la,sigma,h2)\n",
    "gam1 = 1.0 / (la * sigma)\n",
    "gam1 = 0.5\n",
    "print(\"gam1 = \", gam1)\n",
    "pr = prior(la = la, sigma = sigma)\n",
    "mu = 0\n",
    "\n",
    "print(\"Var(y) = \", np.var(y))\n",
    "tau1 = 1.0 / np.var(X @ beta)\n",
    "tau1 = 1.5\n",
    "print(\"tau1 = \", tau1)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "# we start with an initialization that compleately complies with the assumptions\n",
    "r1 = np.zeros((m,1))\n",
    "r1 = beta + random.normal(loc=0.0, scale=np.sqrt(1.0/gam1), size=[m,1])\n",
    "p1 = np.zeros((n,1)) \n",
    "p1 = X @ beta + random.normal(loc=0.0, scale=np.sqrt(1.0/tau1), size=[n,1])\n",
    "\n",
    "maxiter = 4\n",
    "\n",
    "est, gam1 = gvamp(X, gam1, r1, tau1, p1, pr, y, alpha, mu, maxiter, beta)\n",
    "#print(est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ec580c2-ff59-42a4-8aa9-5c5445dad29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting function g(z)\n",
    "\n",
    "import numpy as np\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emc = float( sympy.S.EulerGamma.n(10) )\n",
    "\n",
    "tau1 = 1\n",
    "p = 5\n",
    "mu = 0\n",
    "alpha = 1\n",
    "y = 1\n",
    "\n",
    "def g(z):\n",
    "    return -alpha * z - np.power(y, alpha) * np.exp(-alpha*(z+mu) - emc) - (z-p)*(z-p)*tau1/2 \n",
    "\n",
    "net = np.arange(0, 11.0, 0.1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(net, g(net), 'r--')\n",
    "plt.grid(True)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('g(z)')\n",
    "plt.savefig('gz.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215251e-37d5-4619-83e1-e8eb4ea82d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
